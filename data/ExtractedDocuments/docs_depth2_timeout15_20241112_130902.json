{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/","content_type":"text/html","title":"OpenCV: OpenCV modules","language":null},"page_content":"OpenCV: OpenCV modules\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nOpenCV modules \n\nIntroduction\nOpenCV Tutorials\nOpenCV-Python Tutorials\nOpenCV.js Tutorials\nTutorials for contrib modules\nFrequently Asked Questions\nBibliography\nMain modules:\ncore. Core functionality\nimgproc. Image Processing\nimgcodecs. Image file reading and writing\nvideoio. Video I/O\nhighgui. High-level GUI\nvideo. Video Analysis\ncalib3d. Camera Calibration and 3D Reconstruction\nfeatures2d. 2D Features Framework\nobjdetect. Object Detection\ndnn. Deep Neural Network module\nml. Machine Learning\nflann. Clustering and Search in Multi-Dimensional Spaces\nphoto. Computational Photography\nstitching. Images stitching\ngapi. Graph API\n\nExtra modules:\nalphamat. Alpha Matting\naruco. Aruco markers, module functionality was moved to objdetect module\nbgsegm. Improved Background-Foreground Segmentation Methods\nbioinspired. Biologically inspired vision models and derivated tools\ncannops. Ascend-accelerated Computer Vision\nccalib. Custom Calibration Pattern for 3D reconstruction\ncudaarithm. Operations on Matrices\ncudabgsegm. Background Segmentation\ncudacodec. Video Encoding/Decoding\ncudafeatures2d. Feature Detection and Description\ncudafilters. Image Filtering\ncudaimgproc. Image Processing\ncudalegacy. Legacy support\ncudaobjdetect. Object Detection\ncudaoptflow. Optical Flow\ncudastereo. Stereo Correspondence\ncudawarping. Image Warping\ncudev. Device layer\ncvv. GUI for Interactive Visual Debugging of Computer Vision Programs\ndatasets. Framework for working with different datasets\ndnn_objdetect. DNN used for object detection\ndnn_superres. DNN used for super resolution\ndpm. Deformable Part-based Models\nface. Face Analysis\nfreetype. Drawing UTF-8 strings with freetype/harfbuzz\nfuzzy. Image processing based on fuzzy mathematics\nhdf. Hierarchical Data Format I/O routines\nhfs. Hierarchical Feature Selection for Efficient Image Segmentation\nimg_hash. The module brings implementations of different image hashing algorithms.\nintensity_transform. The module brings implementations of intensity transformation algorithms to adjust image contrast.\njulia. Julia bindings for OpenCV\nline_descriptor. Binary descriptors for lines extracted from an image\nmcc. Macbeth Chart module\noptflow. Optical Flow Algorithms\novis. OGRE 3D Visualiser\nphase_unwrapping. Phase Unwrapping API\nplot. Plot function for Mat data\nquality. Image Quality Analysis (IQA) API\nrapid. silhouette based 3D object tracking\nreg. Image Registration\nrgbd. RGB-Depth Processing\nsaliency. Saliency API\nsfm. Structure From Motion\nshape. Shape Distance and Matching\nsignal. Signal Processing\nstereo. Stereo Correspondance Algorithms\nstructured_light. Structured Light API\nsuperres. Super Resolution\nsurface_matching. Surface Matching\ntext. Scene Text Detection and Recognition\ntracking. Tracking API\nvideostab. Video Stabilization\nviz. 3D Visualizer\nwechat_qrcode. WeChat QR code detector for detecting and parsing QR code.\nxfeatures2d. Extra 2D Features Framework\nximgproc. Extended Image Processing\nxobjdetect. Extended object detection\nxphoto. Additional photo processing algorithms \n\nGenerated on Mon Nov 11 2024 23:11:47 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/de/daa/group__xphoto.html","content_type":"text/html","title":"OpenCV: Additional photo processing algorithms","language":null},"page_content":"OpenCV: Additional photo processing algorithms\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations |\nFunctions \nAdditional photo processing algorithms\n\nDetailed Description\n\nClasses\nclass  cv::xphoto::GrayworldWB\n Gray-world white balance algorithm.  More...\n \nclass  cv::xphoto::LearningBasedWB\n More sophisticated learning-based automatic white balance algorithm.  More...\n \nclass  cv::xphoto::SimpleWB\n A simple white balance algorithm that works by independently stretching each of the input image channels to the specified range. For increased robustness it ignores the top and bottom \\(p\\%\\) of pixel values.  More...\n \nclass  cv::xphoto::TonemapDurand\n This algorithm decomposes image into two layers: base layer and detail layer using bilateral filter and compresses contrast of the base layer thus preserving all the details.  More...\n \nclass  cv::xphoto::WhiteBalancer\n The base class for auto white balance algorithms.  More...\n \n\nEnumerations\nenum  cv::xphoto::Bm3dSteps { \n  cv::xphoto::BM3D_STEPALL = 0\n, \n  cv::xphoto::BM3D_STEP1 = 1\n, \n  cv::xphoto::BM3D_STEP2 = 2\n\n }\n BM3D algorithm steps.  More...\n \nenum  cv::xphoto::InpaintTypes { \n  cv::xphoto::INPAINT_SHIFTMAP = 0\n, \n  cv::xphoto::INPAINT_FSR_BEST = 1\n, \n  cv::xphoto::INPAINT_FSR_FAST = 2\n\n }\n Various inpainting algorithms.  More...\n \nenum  cv::xphoto::TransformTypes { cv::xphoto::HAAR = 0\n }\n BM3D transform types.  More...\n \n\nFunctions\nvoid cv::xphoto::applyChannelGains (InputArray src, OutputArray dst, float gainB, float gainG, float gainR)\n Implements an efficient fixed-point approximation for applying channel gains, which is the last step of multiple white balance algorithms.  \n \nvoid cv::xphoto::bm3dDenoising (InputArray src, InputOutputArray dstStep1, OutputArray dstStep2, float h=1, int templateWindowSize=4, int searchWindowSize=16, int blockMatchingStep1=2500, int blockMatchingStep2=400, int groupSize=8, int slidingStep=1, float beta=2.0f, int normType=cv::NORM_L2, int step=cv::xphoto::BM3D_STEPALL, int transformType=cv::xphoto::HAAR)\n Performs image denoising using the Block-Matching and 3D-filtering algorithm http://www.cs.tut.fi/~foi/GCF-BM3D/BM3D_TIP_2007.pdf with several computational optimizations. Noise expected to be a gaussian white noise.  \n \nvoid cv::xphoto::bm3dDenoising (InputArray src, OutputArray dst, float h=1, int templateWindowSize=4, int searchWindowSize=16, int blockMatchingStep1=2500, int blockMatchingStep2=400, int groupSize=8, int slidingStep=1, float beta=2.0f, int normType=cv::NORM_L2, int step=cv::xphoto::BM3D_STEPALL, int transformType=cv::xphoto::HAAR)\n Performs image denoising using the Block-Matching and 3D-filtering algorithm http://www.cs.tut.fi/~foi/GCF-BM3D/BM3D_TIP_2007.pdf with several computational optimizations. Noise expected to be a gaussian white noise.  \n \nPtr< GrayworldWB > cv::xphoto::createGrayworldWB ()\n Creates an instance of GrayworldWB.  \n \nPtr< LearningBasedWB > cv::xphoto::createLearningBasedWB (const String &path_to_model=String())\n Creates an instance of LearningBasedWB.  \n \nPtr< SimpleWB > cv::xphoto::createSimpleWB ()\n Creates an instance of SimpleWB.  \n \nPtr< TonemapDurand > cv::xphoto::createTonemapDurand (float gamma=1.0f, float contrast=4.0f, float saturation=1.0f, float sigma_color=2.0f, float sigma_space=2.0f)\n Creates TonemapDurand object.  \n \nvoid cv::xphoto::dctDenoising (const Mat &src, Mat &dst, const double sigma, const int psize=16)\n The function implements simple dct-based denoising.  \n \nvirtual float cv::xphoto::TonemapDurand::getContrast () const =0\n \nvirtual float cv::xphoto::TonemapDurand::getSaturation () const =0\n \nvirtual float cv::xphoto::TonemapDurand::getSigmaColor () const =0\n \nvirtual float cv::xphoto::TonemapDurand::getSigmaSpace () const =0\n \nvoid cv::xphoto::inpaint (const Mat &src, const Mat &mask, Mat &dst, const int algorithmType)\n The function implements different single-image inpainting algorithms.  \n \nvoid cv::xphoto::oilPainting (InputArray src, OutputArray dst, int size, int dynRatio)\n oilPainting See the book [46] for details.  \n \nvoid cv::xphoto::oilPainting (InputArray src, OutputArray dst, int size, int dynRatio, int code)\n oilPainting See the book [46] for details.  \n \nvirtual void cv::xphoto::TonemapDurand::setContrast (float contrast)=0\n \nvirtual void cv::xphoto::TonemapDurand::setSaturation (float saturation)=0\n \nvirtual void cv::xphoto::TonemapDurand::setSigmaColor (float sigma_color)=0\n \nvirtual void cv::xphoto::TonemapDurand::setSigmaSpace (float sigma_space)=0\n \n\nEnumeration Type Documentation\n\n◆ Bm3dSteps\n\nenum cv::xphoto::Bm3dSteps\n\n#include <opencv2/xphoto/bm3d_image_denoising.hpp>\nBM3D algorithm steps. \n\nEnumeratorBM3D_STEPALL Python: cv.xphoto.BM3D_STEPALLExecute all steps of the algorithm \n\nBM3D_STEP1 Python: cv.xphoto.BM3D_STEP1Execute only first step of the algorithm \n\nBM3D_STEP2 Python: cv.xphoto.BM3D_STEP2Execute only second step of the algorithm \n\n◆ InpaintTypes\n\nenum cv::xphoto::InpaintTypes\n\n#include <opencv2/xphoto/inpainting.hpp>\nVarious inpainting algorithms. \nSee alsoinpaint \n\nEnumeratorINPAINT_SHIFTMAP Python: cv.xphoto.INPAINT_SHIFTMAPThis algorithm searches for dominant correspondences (transformations) of image patches and tries to seamlessly fill-in the area to be inpainted using this transformations \n\nINPAINT_FSR_BEST Python: cv.xphoto.INPAINT_FSR_BESTPerforms Frequency Selective Reconstruction (FSR). One of the two quality profiles BEST and FAST can be chosen, depending on the time available for reconstruction. See [104] and [237] for details.\nThe algorithm may be utilized for the following areas of application:\nError Concealment (Inpainting). The sampling mask indicates the missing pixels of the distorted input image to be reconstructed.\nNon-Regular Sampling. For more information on how to choose a good sampling mask, please review [112] and [111].\n\n1-channel grayscale or 3-channel BGR image are accepted.\nConventional accepted ranges:\n0-255 for CV_8U\n0-65535 for CV_16U\n0-1 for CV_32F/CV_64F. \n\nINPAINT_FSR_FAST Python: cv.xphoto.INPAINT_FSR_FASTSee INPAINT_FSR_BEST. \n\n◆ TransformTypes\n\nenum cv::xphoto::TransformTypes\n\n#include <opencv2/xphoto/bm3d_image_denoising.hpp>\nBM3D transform types. \n\nEnumeratorHAAR Python: cv.xphoto.HAARUn-normalized Haar transform \n\nFunction Documentation\n\n◆ applyChannelGains()\n\nvoid cv::xphoto::applyChannelGains \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nfloat \ngainB, \n\nfloat \ngainG, \n\nfloat \ngainR \n\n)\n\nPython:cv.xphoto.applyChannelGains(src, gainB, gainG, gainR[, dst]) -> dst\n\n#include <opencv2/xphoto/white_balance.hpp>\nImplements an efficient fixed-point approximation for applying channel gains, which is the last step of multiple white balance algorithms. \nParameters\n\nsrcInput three-channel image in the BGR color space (either CV_8UC3 or CV_16UC3) \ndstOutput image of the same size and type as src. \ngainBgain for the B channel \ngainGgain for the G channel \ngainRgain for the R channel \n\n◆ bm3dDenoising() [1/2]\n\nvoid cv::xphoto::bm3dDenoising \n(\nInputArray \nsrc, \n\nInputOutputArray \ndstStep1, \n\nOutputArray \ndstStep2, \n\nfloat \nh = 1, \n\nint \ntemplateWindowSize = 4, \n\nint \nsearchWindowSize = 16, \n\nint \nblockMatchingStep1 = 2500, \n\nint \nblockMatchingStep2 = 400, \n\nint \ngroupSize = 8, \n\nint \nslidingStep = 1, \n\nfloat \nbeta = 2.0f, \n\nint \nnormType = cv::NORM_L2, \n\nint \nstep = cv::xphoto::BM3D_STEPALL, \n\nint \ntransformType = cv::xphoto::HAAR \n\n)\n\nPython:cv.xphoto.bm3dDenoising(src, dstStep1[, dstStep2[, h[, templateWindowSize[, searchWindowSize[, blockMatchingStep1[, blockMatchingStep2[, groupSize[, slidingStep[, beta[, normType[, step[, transformType]]]]]]]]]]]]) -> dstStep1, dstStep2cv.xphoto.bm3dDenoising(src[, dst[, h[, templateWindowSize[, searchWindowSize[, blockMatchingStep1[, blockMatchingStep2[, groupSize[, slidingStep[, beta[, normType[, step[, transformType]]]]]]]]]]]]) -> dst\n\n#include <opencv2/xphoto/bm3d_image_denoising.hpp>\nPerforms image denoising using the Block-Matching and 3D-filtering algorithm http://www.cs.tut.fi/~foi/GCF-BM3D/BM3D_TIP_2007.pdf with several computational optimizations. Noise expected to be a gaussian white noise. \nParameters\n\nsrcInput 8-bit or 16-bit 1-channel image. \ndstStep1Output image of the first step of BM3D with the same size and type as src. \ndstStep2Output image of the second step of BM3D with the same size and type as src. \nhParameter regulating filter strength. Big h value perfectly removes noise but also removes image details, smaller h value preserves details but also preserves some noise. \ntemplateWindowSizeSize in pixels of the template patch that is used for block-matching. Should be power of 2. \nsearchWindowSizeSize in pixels of the window that is used to perform block-matching. Affect performance linearly: greater searchWindowsSize - greater denoising time. Must be larger than templateWindowSize. \nblockMatchingStep1Block matching threshold for the first step of BM3D (hard thresholding), i.e. maximum distance for which two blocks are considered similar. Value expressed in euclidean distance. \nblockMatchingStep2Block matching threshold for the second step of BM3D (Wiener filtering), i.e. maximum distance for which two blocks are considered similar. Value expressed in euclidean distance. \ngroupSizeMaximum size of the 3D group for collaborative filtering. \nslidingStepSliding step to process every next reference block. \nbetaKaiser window parameter that affects the sidelobe attenuation of the transform of the window. Kaiser window is used in order to reduce border effects. To prevent usage of the window, set beta to zero. \nnormTypeNorm used to calculate distance between blocks. L2 is slower than L1 but yields more accurate results. \nstepStep of BM3D to be executed. Possible variants are: step 1, step 2, both steps. \ntransformTypeType of the orthogonal transform used in collaborative filtering step. Currently only Haar transform is supported.\n\nThis function expected to be applied to grayscale images. Advanced usage of this function can be manual denoising of colored image in different colorspaces.\nSee alsofastNlMeansDenoising \n\n◆ bm3dDenoising() [2/2]\n\nvoid cv::xphoto::bm3dDenoising \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nfloat \nh = 1, \n\nint \ntemplateWindowSize = 4, \n\nint \nsearchWindowSize = 16, \n\nint \nblockMatchingStep1 = 2500, \n\nint \nblockMatchingStep2 = 400, \n\nint \ngroupSize = 8, \n\nint \nslidingStep = 1, \n\nfloat \nbeta = 2.0f, \n\nint \nnormType = cv::NORM_L2, \n\nint \nstep = cv::xphoto::BM3D_STEPALL, \n\nint \ntransformType = cv::xphoto::HAAR \n\n)\n\nPython:cv.xphoto.bm3dDenoising(src, dstStep1[, dstStep2[, h[, templateWindowSize[, searchWindowSize[, blockMatchingStep1[, blockMatchingStep2[, groupSize[, slidingStep[, beta[, normType[, step[, transformType]]]]]]]]]]]]) -> dstStep1, dstStep2cv.xphoto.bm3dDenoising(src[, dst[, h[, templateWindowSize[, searchWindowSize[, blockMatchingStep1[, blockMatchingStep2[, groupSize[, slidingStep[, beta[, normType[, step[, transformType]]]]]]]]]]]]) -> dst\n\n#include <opencv2/xphoto/bm3d_image_denoising.hpp>\nPerforms image denoising using the Block-Matching and 3D-filtering algorithm http://www.cs.tut.fi/~foi/GCF-BM3D/BM3D_TIP_2007.pdf with several computational optimizations. Noise expected to be a gaussian white noise. \nParameters\n\nsrcInput 8-bit or 16-bit 1-channel image. \ndstOutput image with the same size and type as src. \nhParameter regulating filter strength. Big h value perfectly removes noise but also removes image details, smaller h value preserves details but also preserves some noise. \ntemplateWindowSizeSize in pixels of the template patch that is used for block-matching. Should be power of 2. \nsearchWindowSizeSize in pixels of the window that is used to perform block-matching. Affect performance linearly: greater searchWindowsSize - greater denoising time. Must be larger than templateWindowSize. \nblockMatchingStep1Block matching threshold for the first step of BM3D (hard thresholding), i.e. maximum distance for which two blocks are considered similar. Value expressed in euclidean distance. \nblockMatchingStep2Block matching threshold for the second step of BM3D (Wiener filtering), i.e. maximum distance for which two blocks are considered similar. Value expressed in euclidean distance. \ngroupSizeMaximum size of the 3D group for collaborative filtering. \nslidingStepSliding step to process every next reference block. \nbetaKaiser window parameter that affects the sidelobe attenuation of the transform of the window. Kaiser window is used in order to reduce border effects. To prevent usage of the window, set beta to zero. \nnormTypeNorm used to calculate distance between blocks. L2 is slower than L1 but yields more accurate results. \nstepStep of BM3D to be executed. Allowed are only BM3D_STEP1 and BM3D_STEPALL. BM3D_STEP2 is not allowed as it requires basic estimate to be present. \ntransformTypeType of the orthogonal transform used in collaborative filtering step. Currently only Haar transform is supported.\n\nThis function expected to be applied to grayscale images. Advanced usage of this function can be manual denoising of colored image in different colorspaces.\nSee alsofastNlMeansDenoising \n\n◆ createGrayworldWB()\n\nPtr< GrayworldWB > cv::xphoto::createGrayworldWB \n(\n)\n\nPython:cv.xphoto.createGrayworldWB() -> retval\n\n#include <opencv2/xphoto/white_balance.hpp>\nCreates an instance of GrayworldWB. \n\n◆ createLearningBasedWB()\n\nPtr< LearningBasedWB > cv::xphoto::createLearningBasedWB \n(\nconst String & \npath_to_model = String())\n\nPython:cv.xphoto.createLearningBasedWB([, path_to_model]) -> retval\n\n#include <opencv2/xphoto/white_balance.hpp>\nCreates an instance of LearningBasedWB. \nParameters\n\npath_to_modelPath to a .yml file with the model. If not specified, the default model is used \n\n◆ createSimpleWB()\n\nPtr< SimpleWB > cv::xphoto::createSimpleWB \n(\n)\n\nPython:cv.xphoto.createSimpleWB() -> retval\n\n#include <opencv2/xphoto/white_balance.hpp>\nCreates an instance of SimpleWB. \n\n◆ createTonemapDurand()\n\nPtr< TonemapDurand > cv::xphoto::createTonemapDurand \n(\nfloat \ngamma = 1.0f, \n\nfloat \ncontrast = 4.0f, \n\nfloat \nsaturation = 1.0f, \n\nfloat \nsigma_color = 2.0f, \n\nfloat \nsigma_space = 2.0f \n\n)\n\nPython:cv.xphoto.createTonemapDurand([, gamma[, contrast[, saturation[, sigma_color[, sigma_space]]]]]) -> retval\n\n#include <opencv2/xphoto/tonemap.hpp>\nCreates TonemapDurand object. \nYou need to set the OPENCV_ENABLE_NONFREE option in cmake to use those. Use them at your own risk.\nParameters\n\ngammagamma value for gamma correction. See createTonemap \ncontrastresulting contrast on logarithmic scale, i. e. log(max / min), where max and min are maximum and minimum luminance values of the resulting image. \nsaturationsaturation enhancement value. See createTonemapDrago \nsigma_colorbilateral filter sigma in color space \nsigma_spacebilateral filter sigma in coordinate space \n\n◆ dctDenoising()\n\nvoid cv::xphoto::dctDenoising \n(\nconst Mat & \nsrc, \n\nMat & \ndst, \n\nconst double \nsigma, \n\nconst int \npsize = 16 \n\n)\n\nPython:cv.xphoto.dctDenoising(src, dst, sigma[, psize]) -> None\n\n#include <opencv2/xphoto/dct_image_denoising.hpp>\nThe function implements simple dct-based denoising. \nhttp://www.ipol.im/pub/art/2011/ys-dct/. Parameters\n\nsrcsource image \ndstdestination image \nsigmaexpected noise standard deviation \npsizesize of block side where dct is computed\n\nSee alsofastNlMeansDenoising \n\n◆ getContrast()\n\nvirtual float cv::xphoto::TonemapDurand::getContrast \n(\n)\n const\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.getContrast() -> retval\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ getSaturation()\n\nvirtual float cv::xphoto::TonemapDurand::getSaturation \n(\n)\n const\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.getSaturation() -> retval\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ getSigmaColor()\n\nvirtual float cv::xphoto::TonemapDurand::getSigmaColor \n(\n)\n const\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.getSigmaColor() -> retval\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ getSigmaSpace()\n\nvirtual float cv::xphoto::TonemapDurand::getSigmaSpace \n(\n)\n const\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.getSigmaSpace() -> retval\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ inpaint()\n\nvoid cv::xphoto::inpaint \n(\nconst Mat & \nsrc, \n\nconst Mat & \nmask, \n\nMat & \ndst, \n\nconst int \nalgorithmType \n\n)\n\nPython:cv.xphoto.inpaint(src, mask, dst, algorithmType) -> None\n\n#include <opencv2/xphoto/inpainting.hpp>\nThe function implements different single-image inpainting algorithms. \nSee the original papers [119] (Shiftmap) or [104] and [237] (FSR) for details.\nParameters\n\nsrcsource image\nINPAINT_SHIFTMAP: it could be of any type and any number of channels from 1 to 4. In case of 3- and 4-channels images the function expect them in CIELab colorspace or similar one, where first color component shows intensity, while second and third shows colors. Nonetheless you can try any colorspaces.\nINPAINT_FSR_BEST or INPAINT_FSR_FAST: 1-channel grayscale or 3-channel BGR image. \n\nmaskmask (CV_8UC1), where non-zero pixels indicate valid image area, while zero pixels indicate area to be inpainted \ndstdestination image \nalgorithmTypesee xphoto::InpaintTypes \n\n◆ oilPainting() [1/2]\n\nvoid cv::xphoto::oilPainting \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nsize, \n\nint \ndynRatio \n\n)\n\nPython:cv.xphoto.oilPainting(src, size, dynRatio, code[, dst]) -> dstcv.xphoto.oilPainting(src, size, dynRatio[, dst]) -> dst\n\n#include <opencv2/xphoto/oilpainting.hpp>\noilPainting See the book [46] for details. \nParameters\n\nsrcInput three-channel or one channel image (either CV_8UC3 or CV_8UC1) \ndstOutput image of the same size and type as src. \nsizeneighbouring size is 2-size+1 \ndynRatioimage is divided by dynRatio before histogram processing \n\n◆ oilPainting() [2/2]\n\nvoid cv::xphoto::oilPainting \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nsize, \n\nint \ndynRatio, \n\nint \ncode \n\n)\n\nPython:cv.xphoto.oilPainting(src, size, dynRatio, code[, dst]) -> dstcv.xphoto.oilPainting(src, size, dynRatio[, dst]) -> dst\n\n#include <opencv2/xphoto/oilpainting.hpp>\noilPainting See the book [46] for details. \nParameters\n\nsrcInput three-channel or one channel image (either CV_8UC3 or CV_8UC1) \ndstOutput image of the same size and type as src. \nsizeneighbouring size is 2-size+1 \ndynRatioimage is divided by dynRatio before histogram processing \ncodecolor space conversion code(see ColorConversionCodes). Histogram will used only first plane \n\n◆ setContrast()\n\nvirtual void cv::xphoto::TonemapDurand::setContrast \n(\nfloat \ncontrast)\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.setContrast(contrast) -> None\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ setSaturation()\n\nvirtual void cv::xphoto::TonemapDurand::setSaturation \n(\nfloat \nsaturation)\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.setSaturation(saturation) -> None\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ setSigmaColor()\n\nvirtual void cv::xphoto::TonemapDurand::setSigmaColor \n(\nfloat \nsigma_color)\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.setSigmaColor(sigma_color) -> None\n\n#include <opencv2/xphoto/tonemap.hpp>\n\n◆ setSigmaSpace()\n\nvirtual void cv::xphoto::TonemapDurand::setSigmaSpace \n(\nfloat \nsigma_space)\n\npure virtual \n\nPython:cv.xphoto.TonemapDurand.setSigmaSpace(sigma_space) -> None\n\n#include <opencv2/xphoto/tonemap.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d5/d50/group__videostab.html","content_type":"text/html","title":"OpenCV: Video Stabilization","language":null},"page_content":"OpenCV: Video Stabilization\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nFunctions \nVideo Stabilization\n\nModules\n Global Motion Estimation\n \n Fast Marching Method\n \n\nDetailed Description\nThe video stabilization module contains a set of functions and classes that can be used to solve the problem of video stabilization. There are a few methods implemented, most of them are described in the papers [188] and [113] . However, there are some extensions and deviations from the original paper methods.\n\nReferences\n\n\"Full-Frame Video Stabilization with Motion Inpainting\" Yasuyuki Matsushita, Eyal Ofek, Weina Ge, Xiaoou Tang, Senior Member, and Heung-Yeung Shum\n\"Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths\" Matthias Grundmann, Vivek Kwatra, Irfan Essa \n\nClasses\nclass  cv::videostab::ColorAverageInpainter\n \nclass  cv::videostab::ColorInpainter\n \nclass  cv::videostab::ConsistentMosaicInpainter\n \nclass  cv::videostab::DeblurerBase\n \nclass  cv::videostab::IDenseOptFlowEstimator\n \nclass  cv::videostab::IFrameSource\n \nclass  cv::videostab::ILog\n \nclass  cv::videostab::InpainterBase\n \nclass  cv::videostab::InpaintingPipeline\n \nclass  cv::videostab::IOutlierRejector\n \nclass  cv::videostab::ISparseOptFlowEstimator\n \nclass  cv::videostab::LogToStdout\n \nclass  cv::videostab::MaskFrameSource\n \nclass  cv::videostab::MoreAccurateMotionWobbleSuppressor\n \nclass  cv::videostab::MoreAccurateMotionWobbleSuppressorBase\n \nclass  cv::videostab::MotionInpainter\n \nclass  cv::videostab::NullDeblurer\n \nclass  cv::videostab::NullFrameSource\n \nclass  cv::videostab::NullInpainter\n \nclass  cv::videostab::NullLog\n \nclass  cv::videostab::NullOutlierRejector\n \nclass  cv::videostab::NullWobbleSuppressor\n \nclass  cv::videostab::OnePassStabilizer\n \nclass  cv::videostab::PyrLkOptFlowEstimatorBase\n \nclass  cv::videostab::SparsePyrLkOptFlowEstimator\n \nclass  cv::videostab::StabilizerBase\n \nclass  cv::videostab::TranslationBasedLocalOutlierRejector\n \nclass  cv::videostab::TwoPassStabilizer\n \nclass  cv::videostab::VideoFileSource\n \nclass  cv::videostab::WeightingDeblurer\n \nclass  cv::videostab::WobbleSuppressorBase\n \n\nFunctions\n cv::videostab::ColorInpainter::ColorInpainter (int method=INPAINT_TELEA, double radius=2.)\n \ntemplate<typename T > \nconst T & cv::videostab::at (int idx, const std::vector< T > &items)\n \ntemplate<typename T > \nT & cv::videostab::at (int idx, std::vector< T > &items)\n \nfloat cv::videostab::calcBlurriness (const Mat &frame)\n \nvoid cv::videostab::calcFlowMask (const Mat &flowX, const Mat &flowY, const Mat &errors, float maxError, const Mat &mask0, const Mat &mask1, Mat &flowMask)\n \nvoid cv::videostab::completeFrameAccordingToFlow (const Mat &flowMask, const Mat &flowX, const Mat &flowY, const Mat &frame1, const Mat &mask1, float distThresh, Mat &frame0, Mat &mask0)\n \n\nFunction Documentation\n\n◆ ColorInpainter()\n\ncv::videostab::ColorInpainter::ColorInpainter \n(\nint \nmethod = INPAINT_TELEA, \n\ndouble \nradius = 2. \n\n)\n\ninline \n\n#include <opencv2/videostab/inpainting.hpp>\n\n◆ at() [1/2]\n\ntemplate<typename T > \n\nconst T & cv::videostab::at \n(\nint \nidx, \n\nconst std::vector< T > & \nitems \n\n)\n\ninline \n\n#include <opencv2/videostab/ring_buffer.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ at() [2/2]\n\ntemplate<typename T > \n\nT & cv::videostab::at \n(\nint \nidx, \n\nstd::vector< T > & \nitems \n\n)\n\ninline \n\n#include <opencv2/videostab/ring_buffer.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ calcBlurriness()\n\nfloat cv::videostab::calcBlurriness \n(\nconst Mat & \nframe)\n\n#include <opencv2/videostab/deblurring.hpp>\n\n◆ calcFlowMask()\n\nvoid cv::videostab::calcFlowMask \n(\nconst Mat & \nflowX, \n\nconst Mat & \nflowY, \n\nconst Mat & \nerrors, \n\nfloat \nmaxError, \n\nconst Mat & \nmask0, \n\nconst Mat & \nmask1, \n\nMat & \nflowMask \n\n)\n\n#include <opencv2/videostab/inpainting.hpp>\n\n◆ completeFrameAccordingToFlow()\n\nvoid cv::videostab::completeFrameAccordingToFlow \n(\nconst Mat & \nflowMask, \n\nconst Mat & \nflowX, \n\nconst Mat & \nflowY, \n\nconst Mat & \nframe1, \n\nconst Mat & \nmask1, \n\nfloat \ndistThresh, \n\nMat & \nframe0, \n\nMat & \nmask0 \n\n)\n\n#include <opencv2/videostab/inpainting.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dc/de5/group__flann.html","content_type":"text/html","title":"OpenCV: Clustering and Search in Multi-Dimensional Spaces","language":null},"page_content":"OpenCV: Clustering and Search in Multi-Dimensional Spaces\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nClustering and Search in Multi-Dimensional Spaces\n\nDetailed Description\nThis section documents OpenCV's interface to the FLANN library. FLANN (Fast Library for Approximate Nearest Neighbors) is a library that contains a collection of algorithms optimized for fast nearest neighbor search in large datasets and for high dimensional features. More information about FLANN can be found in [201] . \n\nClasses\nstruct  cv::flann::CvType< T >\n \nstruct  cv::flann::CvType< char >\n \nstruct  cv::flann::CvType< double >\n \nstruct  cv::flann::CvType< float >\n \nstruct  cv::flann::CvType< short >\n \nstruct  cv::flann::CvType< unsigned char >\n \nstruct  cv::flann::CvType< unsigned short >\n \nclass  cv::flann::GenericIndex< Distance >\n The FLANN nearest neighbor index class. This class is templated with the type of elements for which the index is built.  More...\n \n\nFunctions\ntemplate<typename Distance > \nint cv::flann::hierarchicalClustering (const Mat &features, Mat &centers, const ::cvflann::KMeansIndexParams &params, Distance d=Distance())\n Clusters features using hierarchical k-means algorithm.  \n \n\nFunction Documentation\n\n◆ hierarchicalClustering()\n\ntemplate<typename Distance > \n\nint cv::flann::hierarchicalClustering \n(\nconst Mat & \nfeatures, \n\nMat & \ncenters, \n\nconst ::cvflann::KMeansIndexParams & \nparams, \n\nDistance \nd = Distance() \n\n)\n\n#include <opencv2/flann.hpp>\nClusters features using hierarchical k-means algorithm. \nParameters\n\nfeaturesThe points to be clustered. The matrix must have elements of type Distance::ElementType. \ncentersThe centers of the clusters obtained. The matrix must have type Distance::CentersType. The number of rows in this matrix represents the number of clusters desired, however, because of the way the cut in the hierarchical tree is chosen, the number of clusters computed will be the highest number of the form (branching-1)*k+1 that's lower than the number of clusters desired, where branching is the tree's branching factor (see description of the KMeansIndexParams). \nparamsParameters used in the construction of the hierarchical k-means tree. \ndDistance to be used for clustering.\n\nThe method clusters the given feature vectors by constructing a hierarchical k-means tree and choosing a cut in the tree that minimizes the cluster's variance. It returns the number of clusters found. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/dc4/group__rapid.html","content_type":"text/html","title":"OpenCV: silhouette based 3D object tracking","language":null},"page_content":"OpenCV: silhouette based 3D object tracking\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nsilhouette based 3D object tracking\n\nDetailed Description\nimplements \"RAPID-a video rate object tracker\" [116] with the dynamic control point extraction of [73] \n\nClasses\nclass  cv::rapid::GOSTracker\n \nclass  cv::rapid::OLSTracker\n \nclass  cv::rapid::Rapid\n wrapper around silhouette based 3D object tracking function for uniform access  More...\n \nclass  cv::rapid::Tracker\n Abstract base class for stateful silhouette trackers.  More...\n \n\nFunctions\nvoid cv::rapid::convertCorrespondencies (InputArray cols, InputArray srcLocations, OutputArray pts2d, InputOutputArray pts3d=noArray(), InputArray mask=noArray())\n \nvoid cv::rapid::drawCorrespondencies (InputOutputArray bundle, InputArray cols, InputArray colors=noArray())\n \nvoid cv::rapid::drawSearchLines (InputOutputArray img, InputArray locations, const Scalar &color)\n \nvoid cv::rapid::drawWireframe (InputOutputArray img, InputArray pts2d, InputArray tris, const Scalar &color, int type=LINE_8, bool cullBackface=false)\n \nvoid cv::rapid::extractControlPoints (int num, int len, InputArray pts3d, InputArray rvec, InputArray tvec, InputArray K, const Size &imsize, InputArray tris, OutputArray ctl2d, OutputArray ctl3d)\n \nvoid cv::rapid::extractLineBundle (int len, InputArray ctl2d, InputArray img, OutputArray bundle, OutputArray srcLocations)\n \nvoid cv::rapid::findCorrespondencies (InputArray bundle, OutputArray cols, OutputArray response=noArray())\n \nfloat cv::rapid::rapid (InputArray img, int num, int len, InputArray pts3d, InputArray tris, InputArray K, InputOutputArray rvec, InputOutputArray tvec, double *rmsd=0)\n \n\nFunction Documentation\n\n◆ convertCorrespondencies()\n\nvoid cv::rapid::convertCorrespondencies \n(\nInputArray \ncols, \n\nInputArray \nsrcLocations, \n\nOutputArray \npts2d, \n\nInputOutputArray \npts3d = noArray(), \n\nInputArray \nmask = noArray() \n\n)\n\nPython:cv.rapid.convertCorrespondencies(cols, srcLocations[, pts2d[, pts3d[, mask]]]) -> pts2d, pts3d\n\n#include <opencv2/rapid.hpp>\nCollect corresponding 2d and 3d points based on correspondencies and mask Parameters\n\ncolscorrespondence-position per line in line-bundle-space \nsrcLocationsthe source image location \npts2d2d points \npts3d3d points \nmaskmask containing non-zero values for the elements to be retained \n\n◆ drawCorrespondencies()\n\nvoid cv::rapid::drawCorrespondencies \n(\nInputOutputArray \nbundle, \n\nInputArray \ncols, \n\nInputArray \ncolors = noArray() \n\n)\n\nPython:cv.rapid.drawCorrespondencies(bundle, cols[, colors]) -> bundle\n\n#include <opencv2/rapid.hpp>\nDebug draw markers of matched correspondences onto a lineBundle Parameters\n\nbundlethe lineBundle \ncolscolumn coordinates in the line bundle \ncolorscolors for the markers. Defaults to white. \n\n◆ drawSearchLines()\n\nvoid cv::rapid::drawSearchLines \n(\nInputOutputArray \nimg, \n\nInputArray \nlocations, \n\nconst Scalar & \ncolor \n\n)\n\nPython:cv.rapid.drawSearchLines(img, locations, color) -> img\n\n#include <opencv2/rapid.hpp>\nDebug draw search lines onto an image Parameters\n\nimgthe output image \nlocationsthe source locations of a line bundle \ncolorthe line color \n\n◆ drawWireframe()\n\nvoid cv::rapid::drawWireframe \n(\nInputOutputArray \nimg, \n\nInputArray \npts2d, \n\nInputArray \ntris, \n\nconst Scalar & \ncolor, \n\nint \ntype = LINE_8, \n\nbool \ncullBackface = false \n\n)\n\nPython:cv.rapid.drawWireframe(img, pts2d, tris, color[, type[, cullBackface]]) -> img\n\n#include <opencv2/rapid.hpp>\nDraw a wireframe of a triangle mesh Parameters\n\nimgthe output image \npts2dthe 2d points obtained by projectPoints \ntristriangle face connectivity \ncolorline color \ntypeline type. See LineTypes. \ncullBackfaceenable back-face culling based on CCW order \n\n◆ extractControlPoints()\n\nvoid cv::rapid::extractControlPoints \n(\nint \nnum, \n\nint \nlen, \n\nInputArray \npts3d, \n\nInputArray \nrvec, \n\nInputArray \ntvec, \n\nInputArray \nK, \n\nconst Size & \nimsize, \n\nInputArray \ntris, \n\nOutputArray \nctl2d, \n\nOutputArray \nctl3d \n\n)\n\nPython:cv.rapid.extractControlPoints(num, len, pts3d, rvec, tvec, K, imsize, tris[, ctl2d[, ctl3d]]) -> ctl2d, ctl3d\n\n#include <opencv2/rapid.hpp>\nExtract control points from the projected silhouette of a mesh\nsee [73] Sec 2.1, Step b Parameters\n\nnumnumber of control points \nlensearch radius (used to restrict the ROI) \npts3dthe 3D points of the mesh \nrvecrotation between mesh and camera \ntvectranslation between mesh and camera \nKcamera intrinsic \nimsizesize of the video frame \ntristriangle face connectivity \nctl2dthe 2D locations of the control points \nctl3dmatching 3D points of the mesh \n\n◆ extractLineBundle()\n\nvoid cv::rapid::extractLineBundle \n(\nint \nlen, \n\nInputArray \nctl2d, \n\nInputArray \nimg, \n\nOutputArray \nbundle, \n\nOutputArray \nsrcLocations \n\n)\n\nPython:cv.rapid.extractLineBundle(len, ctl2d, img[, bundle[, srcLocations]]) -> bundle, srcLocations\n\n#include <opencv2/rapid.hpp>\nExtract the line bundle from an image Parameters\n\nlenthe search radius. The bundle will have 2*len + 1 columns. \nctl2dthe search lines will be centered at this points and orthogonal to the contour defined by them. The bundle will have as many rows. \nimgthe image to read the pixel intensities values from \nbundleline bundle image with size ctl2d.rows() x (2 * len + 1) and the same type as img \nsrcLocationsthe source pixel locations of bundle in img as CV_16SC2 \n\n◆ findCorrespondencies()\n\nvoid cv::rapid::findCorrespondencies \n(\nInputArray \nbundle, \n\nOutputArray \ncols, \n\nOutputArray \nresponse = noArray() \n\n)\n\nPython:cv.rapid.findCorrespondencies(bundle[, cols[, response]]) -> cols, response\n\n#include <opencv2/rapid.hpp>\nFind corresponding image locations by searching for a maximal sobel edge along the search line (a single row in the bundle) Parameters\n\nbundlethe line bundle \ncolscorrespondence-position per line in line-bundle-space \nresponsethe sobel response for the selected point \n\n◆ rapid()\n\nfloat cv::rapid::rapid \n(\nInputArray \nimg, \n\nint \nnum, \n\nint \nlen, \n\nInputArray \npts3d, \n\nInputArray \ntris, \n\nInputArray \nK, \n\nInputOutputArray \nrvec, \n\nInputOutputArray \ntvec, \n\ndouble * \nrmsd = 0 \n\n)\n\nPython:cv.rapid.rapid(img, num, len, pts3d, tris, K, rvec, tvec) -> retval, rvec, tvec, rmsd\n\n#include <opencv2/rapid.hpp>\nHigh level function to execute a single rapid [116] iteration\n\nextractControlPoints\nextractLineBundle\nfindCorrespondencies\nconvertCorrespondencies\nsolvePnPRefineLM\n\nParameters\n\nimgthe video frame \nnumnumber of search lines \nlensearch line radius \npts3dthe 3D points of the mesh \ntristriangle face connectivity \nKcamera matrix \nrvecrotation between mesh and camera. Input values are used as an initial solution. \ntvectranslation between mesh and camera. Input values are used as an initial solution. \nrmsdthe 2d reprojection difference \n\nReturnsratio of search lines that could be extracted and matched \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d6/d1d/group__cudafeatures2d.html","content_type":"text/html","title":"OpenCV: Feature Detection and Description","language":null},"page_content":"OpenCV: Feature Detection and Description\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nFeature Detection and DescriptionCUDA-accelerated Computer Vision\n\nDetailed Description\n\nClasses\nclass  cv::cuda::DescriptorMatcher\n Abstract base class for matching keypoint descriptors.  More...\n \nclass  cv::cuda::FastFeatureDetector\n Wrapping class for feature detection using the FAST method.  More...\n \nclass  cv::cuda::Feature2DAsync\n Abstract base class for CUDA asynchronous 2D image feature detectors and descriptor extractors.  More...\n \nclass  cv::cuda::ORB\n Class implementing the ORB (oriented BRIEF) keypoint detector and descriptor extractor.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/db/d61/group__reg.html","content_type":"text/html","title":"OpenCV: Image Registration","language":null},"page_content":"OpenCV: Image Registration\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nImage Registration\n\nDetailed Description\nThe Registration module implements parametric image registration. The implemented method is direct alignment, that is, it uses directly the pixel values for calculating the registration between a pair of images, as opposed to feature-based registration. The implementation follows essentially the corresponding part of [259] .\nFeature based methods have some advantages over pixel based methods when we are trying to register pictures that have been shoot under different lighting conditions or exposition times, or when the images overlap only partially. On the other hand, the main advantage of pixel-based methods when compared to feature based methods is their better precision for some pictures (those shoot under similar lighting conditions and that have a significative overlap), due to the fact that we are using all the information available in the image, which allows us to achieve subpixel accuracy. This is particularly important for certain applications like multi-frame denoising or super-resolution.\nIn fact, pixel and feature registration methods can complement each other: an application could first obtain a coarse registration using features and then refine the registration using a pixel based method on the overlapping area of the images. The code developed allows this use case.\nThe module implements classes derived from the abstract classes cv::reg::Map or cv::reg::Mapper. The former models a coordinate transformation between two reference frames, while the later encapsulates a way of invoking a method that calculates a Map between two images. Although the objective has been to implement pixel based methods, the module can be extended to support other methods that can calculate transformations between images (feature methods, optical flow, etc.).\nEach class derived from Map implements a motion model, as follows:\n\nMapShift: Models a simple translation\nMapAffine: Models an affine transformation\nMapProjec: Models a projective transformation\n\nMapProject can also be used to model affine motion or translations, but some operations on it are more costly, and that is the reason for defining the other two classes.\nThe classes derived from Mapper are\n\nMapperGradShift: Gradient based alignment for calculating translations. It produces a MapShift (two parameters that correspond to the shift vector).\nMapperGradEuclid: Gradient based alignment for euclidean motions, that is, rotations and translations. It calculates three parameters (angle and shift vector), although the result is stored in a MapAffine object for convenience.\nMapperGradSimilar: Gradient based alignment for calculating similarities, which adds scaling to the euclidean motion. It calculates four parameters (two for the anti-symmetric matrix and two for the shift vector), although the result is stored in a MapAffine object for better convenience.\nMapperGradAffine: Gradient based alignment for an affine motion model. The number of parameters is six and the result is stored in a MapAffine object.\nMapperGradProj: Gradient based alignment for calculating projective transformations. The number of parameters is eight and the result is stored in a MapProject object.\nMapperPyramid: It implements hyerarchical motion estimation using a Gaussian pyramid. Its constructor accepts as argument any other object that implements the Mapper interface, and it is that mapper the one called by MapperPyramid for each scale of the pyramid.\n\nIf the motion between the images is not very small, the normal way of using these classes is to create a MapperGrad* object and use it as input to create a MapperPyramid, which in turn is called to perform the calculation. However, if the motion between the images is small enough, we can use directly the MapperGrad* classes. Another possibility is to use first a feature based method to perform a coarse registration and then do a refinement through MapperPyramid or directly a MapperGrad* object. The \"calculate\" method of the mappers accepts an initial estimation of the motion as input.\nWhen deciding which MapperGrad to use we must take into account that mappers with more parameters can handle more complex motions, but involve more calculations and are therefore slower. Also, if we are confident on the motion model that is followed by the sequence, increasing the number of parameters beyond what we need will decrease the accuracy: it is better to use the least number of degrees of freedom that we can.\nIn the module tests there are examples that show how to register a pair of images using any of the implemented mappers. \n\nClasses\nclass  cv::reg::Map\n Base class for modelling a Map between two images.  More...\n \nclass  cv::reg::MapAffine\n \nclass  cv::reg::Mapper\n Base class for modelling an algorithm for calculating a map.  More...\n \nclass  cv::reg::MapperGradAffine\n \nclass  cv::reg::MapperGradEuclid\n \nclass  cv::reg::MapperGradProj\n \nclass  cv::reg::MapperGradShift\n \nclass  cv::reg::MapperGradSimilar\n \nclass  cv::reg::MapperPyramid\n \nclass  cv::reg::MapProjec\n \nclass  cv::reg::MapShift\n \nclass  cv::reg::MapTypeCaster\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/d93/group__img__hash.html","content_type":"text/html","title":"OpenCV: The module brings implementations of different image hashing algorithms.","language":null},"page_content":"OpenCV: The module brings implementations of different image hashing algorithms.\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations |\nFunctions \nThe module brings implementations of different image hashing algorithms.\n\nDetailed Description\nProvide algorithms to extract the hash of images and fast way to figure out most similar images in huge data set.\nNamespace for all functions is cv::img_hash.\n\nSupported Algorithms\n\nAverage hash (also called Different hash)\nPHash (also called Perceptual hash)\nMarr Hildreth Hash\nRadial Variance Hash\nBlock Mean Hash (modes 0 and 1)\nColor Moment Hash (this is the one and only hash algorithm resist to rotation attack(-90~90 degree))\n\nYou can study more about image hashing from following paper and websites:\n\n\"Implementation and benchmarking of perceptual image hash functions\" [315]\n\"Looks Like It\" [150]\n\nCode Example\n#include \"opencv2/core.hpp\"\n#include \"opencv2/core/ocl.hpp\"\n#include \"opencv2/highgui.hpp\"\n#include \"opencv2/img_hash.hpp\"\n \n#include <iostream>\n \nusing namespace cv;\nusing namespace cv::img_hash;\nusing namespace std;\n \ntemplate <typename T>\ninline void test_one(const std::string &title, const Mat &a, const Mat &b)\n{\n    cout << \"=== \" << title << \" ===\" << endl;\n TickMeter tick;\n Mat hashA, hashB;\n Ptr<ImgHashBase> func;\n    func = T::create();\n \n    tick.reset(); tick.start();\n    func->compute(a, hashA);\n    tick.stop();\n    cout << \"compute1: \" << tick.getTimeMilli() << \" ms\" << endl;\n \n    tick.reset(); tick.start();\n    func->compute(b, hashB);\n    tick.stop();\n    cout << \"compute2: \" << tick.getTimeMilli() << \" ms\" << endl;\n \n    cout << \"compare: \" << func->compare(hashA, hashB) << endl << endl;;\n}\n \nint main(int argc, char **argv)\n{\n if (argc != 3)\n    {\n        cerr << \"must input the path of input image and target image. ex : hash_samples lena.jpg lena2.jpg\" << endl;\n return -1;\n    }\n ocl::setUseOpenCL(false);\n \n Mat input = imread(argv[1]);\n Mat target = imread(argv[2]);\n \n    test_one<AverageHash>(\"AverageHash\", input, target);\n    test_one<PHash>(\"PHash\", input, target);\n    test_one<MarrHildrethHash>(\"MarrHildrethHash\", input, target);\n    test_one<RadialVarianceHash>(\"RadialVarianceHash\", input, target);\n    test_one<BlockMeanHash>(\"BlockMeanHash\", input, target);\n \n return 0;\n}\ncv::Matn-dimensional dense array classDefinition mat.hpp:828\ncv::TickMetera Class to measure passing time.Definition utility.hpp:326\ncv::TickMeter::startvoid start()starts counting ticks.Definition utility.hpp:335\ncv::TickMeter::stopvoid stop()stops counting ticks.Definition utility.hpp:341\ncv::TickMeter::resetvoid reset()resets internal values.Definition utility.hpp:430\ncv::TickMeter::getTimeMillidouble getTimeMilli() constreturns passed time in milliseconds.Definition utility.hpp:365\ncore.hpp\ncv::Ptrstd::shared_ptr< _Tp > PtrDefinition cvstd_wrapper.hpp:23\ncv::ocl::setUseOpenCLvoid setUseOpenCL(bool flag)\ncv::imreadCV_EXPORTS_W Mat imread(const String &filename, int flags=IMREAD_COLOR_BGR)Loads an image from a file.\nhighgui.hpp\nmainint main(int argc, char *argv[])Definition highgui_qt.cpp:3\nimg_hash.hpp\ncv::img_hashDefinition average_hash.hpp:11\ncvDefinition core.hpp:107\nstdSTL namespace.\nocl.hpp\n\nPerformance under different attacks\n\nPerformance chart\n\nSpeed comparison with PHash library (100 images from ukbench)\n  \nAs you can see, hash computation speed of img_hash module outperform PHash library a lot.\nPS : I do not list out the comparison of Average hash, PHash and Color Moment hash, because I cannot find them in PHash.\n\nMotivation\nCollects useful image hash algorithms into opencv, so we do not need to rewrite them by ourselves again and again or rely on another 3rd party library(ex : PHash library). BOVW or correlation matching are good and robust, but they are very slow compare with image hash, if you need to deal with large scale CBIR(content based image retrieval) problem, image hash is a more reasonable solution.\n\nMore info\nYou can learn more about img_hash modules from following links, these links show you how to find similar image from ukbench dataset, provide thorough benchmark of different attacks(contrast, blur,\nnoise(gaussion,pepper and salt), jpeg compression, watermark, resize).\nIntroduction to image hash module of opencv Speed up image hashing of opencv(img_hash) and introduce color moment hash\n\nContributors\nTham Ngap Wei, thamn.nosp@m.gapw.nosp@m.ei@gm.nosp@m.ail..nosp@m.com \n\nClasses\nclass  cv::img_hash::AverageHash\n Computes average hash value of the input image.  More...\n \nclass  cv::img_hash::BlockMeanHash\n Image hash based on block mean.  More...\n \nclass  cv::img_hash::ColorMomentHash\n Image hash based on color moments.  More...\n \nclass  cv::img_hash::ImgHashBase\n The base class for image hash algorithms.  More...\n \nclass  cv::img_hash::MarrHildrethHash\n Marr-Hildreth Operator Based Hash, slowest but more discriminative.  More...\n \nclass  cv::img_hash::PHash\n pHash  More...\n \nclass  cv::img_hash::RadialVarianceHash\n Image hash based on Radon transform.  More...\n \n\nEnumerations\nenum  cv::img_hash::BlockMeanHashMode { \n  cv::img_hash::BLOCK_MEAN_HASH_MODE_0 = 0\n, \n  cv::img_hash::BLOCK_MEAN_HASH_MODE_1 = 1\n\n }\n \n\nFunctions\nvoid cv::img_hash::averageHash (cv::InputArray inputArr, cv::OutputArray outputArr)\n Calculates img_hash::AverageHash in one call.  \n \nvoid cv::img_hash::blockMeanHash (cv::InputArray inputArr, cv::OutputArray outputArr, int mode=BLOCK_MEAN_HASH_MODE_0)\n Computes block mean hash of the input image.  \n \nvoid cv::img_hash::colorMomentHash (cv::InputArray inputArr, cv::OutputArray outputArr)\n Computes color moment hash of the input, the algorithm is come from the paper \"Perceptual  Hashing  for  Color  Images\nUsing  Invariant Moments\".  \n \nvoid cv::img_hash::marrHildrethHash (cv::InputArray inputArr, cv::OutputArray outputArr, float alpha=2.0f, float scale=1.0f)\n Computes average hash value of the input image.  \n \nvoid cv::img_hash::pHash (cv::InputArray inputArr, cv::OutputArray outputArr)\n Computes pHash value of the input image.  \n \nvoid cv::img_hash::radialVarianceHash (cv::InputArray inputArr, cv::OutputArray outputArr, double sigma=1, int numOfAngleLine=180)\n Computes radial variance hash of the input image.  \n \n\nEnumeration Type Documentation\n\n◆ BlockMeanHashMode\n\nenum cv::img_hash::BlockMeanHashMode\n\n#include <opencv2/img_hash/block_mean_hash.hpp>\n\nEnumeratorBLOCK_MEAN_HASH_MODE_0 Python: cv.img_hash.BLOCK_MEAN_HASH_MODE_0use fewer block and generate 16*16/8 uchar hash value \n\nBLOCK_MEAN_HASH_MODE_1 Python: cv.img_hash.BLOCK_MEAN_HASH_MODE_1use block blocks(step sizes/2), generate 31*31/8 + 1 uchar hash value \n\nFunction Documentation\n\n◆ averageHash()\n\nvoid cv::img_hash::averageHash \n(\ncv::InputArray \ninputArr, \n\ncv::OutputArray \noutputArr \n\n)\n\nPython:cv.img_hash.averageHash(inputArr[, outputArr]) -> outputArr\n\n#include <opencv2/img_hash/average_hash.hpp>\nCalculates img_hash::AverageHash in one call. \nParameters\n\ninputArrinput image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1. \noutputArrHash value of input, it will contain 16 hex decimal number, return type is CV_8U \n\n◆ blockMeanHash()\n\nvoid cv::img_hash::blockMeanHash \n(\ncv::InputArray \ninputArr, \n\ncv::OutputArray \noutputArr, \n\nint \nmode = BLOCK_MEAN_HASH_MODE_0 \n\n)\n\nPython:cv.img_hash.blockMeanHash(inputArr[, outputArr[, mode]]) -> outputArr\n\n#include <opencv2/img_hash/block_mean_hash.hpp>\nComputes block mean hash of the input image. \nParameters\n\ninputArrinput image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1. \noutputArrHash value of input, it will contain 16 hex decimal number, return type is CV_8U \nmodethe mode \n\n◆ colorMomentHash()\n\nvoid cv::img_hash::colorMomentHash \n(\ncv::InputArray \ninputArr, \n\ncv::OutputArray \noutputArr \n\n)\n\nPython:cv.img_hash.colorMomentHash(inputArr[, outputArr]) -> outputArr\n\n#include <opencv2/img_hash/color_moment_hash.hpp>\nComputes color moment hash of the input, the algorithm is come from the paper \"Perceptual  Hashing  for  Color  Images\nUsing  Invariant Moments\". \nParameters\n\ninputArrinput image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1. \noutputArr42 hash values with type CV_64F(double) \n\n◆ marrHildrethHash()\n\nvoid cv::img_hash::marrHildrethHash \n(\ncv::InputArray \ninputArr, \n\ncv::OutputArray \noutputArr, \n\nfloat \nalpha = 2.0f, \n\nfloat \nscale = 1.0f \n\n)\n\nPython:cv.img_hash.marrHildrethHash(inputArr[, outputArr[, alpha[, scale]]]) -> outputArr\n\n#include <opencv2/img_hash/marr_hildreth_hash.hpp>\nComputes average hash value of the input image. \nParameters\n\ninputArrinput image want to compute hash value, type should be CV_8UC4, CV_8UC3, CV_8UC1. \noutputArrHash value of input, it will contain 16 hex decimal number, return type is CV_8U \nalphaint scale factor for marr wavelet (default=2). \nscaleint level of scale factor (default = 1) \n\n◆ pHash()\n\nvoid cv::img_hash::pHash \n(\ncv::InputArray \ninputArr, \n\ncv::OutputArray \noutputArr \n\n)\n\nPython:cv.img_hash.pHash(inputArr[, outputArr]) -> outputArr\n\n#include <opencv2/img_hash/phash.hpp>\nComputes pHash value of the input image. \nParameters\n\ninputArrinput image want to compute hash value, type should be CV_8UC4, CV_8UC3, CV_8UC1. \noutputArrHash value of input, it will contain 8 uchar value \n\n◆ radialVarianceHash()\n\nvoid cv::img_hash::radialVarianceHash \n(\ncv::InputArray \ninputArr, \n\ncv::OutputArray \noutputArr, \n\ndouble \nsigma = 1, \n\nint \nnumOfAngleLine = 180 \n\n)\n\nPython:cv.img_hash.radialVarianceHash(inputArr[, outputArr[, sigma[, numOfAngleLine]]]) -> outputArr\n\n#include <opencv2/img_hash/radial_variance_hash.hpp>\nComputes radial variance hash of the input image. \nParameters\n\ninputArrinput image want to compute hash value, type should be CV_8UC4, CV_8UC3, CV_8UC1. \noutputArrHash value of input \nsigmaGaussian kernel standard deviation \nnumOfAngleLineThe number of angles to consider \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/d46/group__stitching.html","content_type":"text/html","title":"OpenCV: Images stitching","language":null},"page_content":"OpenCV: Images stitching\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nFunctions \nImages stitching\n\nModules\n Features Finding and Images Matching\n \n Rotation Estimation\n \n Autocalibration\n \n Images Warping\n \n Seam Estimation\n \n Exposure Compensation\n \n Image Blenders\n \n\nDetailed Description\nThis figure illustrates the stitching module pipeline implemented in the Stitcher class. Using that class it's possible to configure/remove some steps, i.e. adjust the stitching pipeline according to the particular needs. All building blocks from the pipeline are available in the detail namespace, one can combine and use them separately.\nThe implemented stitching pipeline is very similar to the one proposed in [41] .\n\nstitching pipeline\n\nCamera models\nThere are currently 2 camera models implemented in stitching pipeline.\n\nHomography model expecting perspective transformations between images implemented in cv::detail::BestOf2NearestMatcher cv::detail::HomographyBasedEstimator cv::detail::BundleAdjusterReproj cv::detail::BundleAdjusterRay\nAffine model expecting affine transformation with 6 DOF or 4 DOF implemented in cv::detail::AffineBestOf2NearestMatcher cv::detail::AffineBasedEstimator cv::detail::BundleAdjusterAffine cv::detail::BundleAdjusterAffinePartial cv::AffineWarper\n\nHomography model is useful for creating photo panoramas captured by camera, while affine-based model can be used to stitch scans and object captured by specialized devices. Use cv::Stitcher::create to get preconfigured pipeline for one of those models.\nNoteCertain detailed settings of cv::Stitcher might not make sense. Especially you should not mix classes implementing affine model and classes implementing Homography model, as they work with different transformations. \n\nClasses\nstruct  cv::detail::CameraParams\n Describes camera parameters.  More...\n \nclass  cv::detail::DisjointSets\n \nclass  cv::detail::Graph\n \nstruct  cv::detail::GraphEdge\n \nclass  cv::Stitcher\n High level image stitcher.  More...\n \nclass  cv::detail::Timelapser\n \nclass  cv::detail::TimelapserCrop\n \n\nFunctions\n cv::detail::GraphEdge::GraphEdge (int from, int to, float weight)\n \nPtr< Stitcher > cv::createStitcher (bool try_use_gpu=false)\n \nPtr< Stitcher > cv::createStitcherScans (bool try_use_gpu=false)\n \nbool cv::detail::overlapRoi (Point tl1, Point tl2, Size sz1, Size sz2, Rect &roi)\n \nRect cv::detail::resultRoi (const std::vector< Point > &corners, const std::vector< Size > &sizes)\n \nRect cv::detail::resultRoi (const std::vector< Point > &corners, const std::vector< UMat > &images)\n \nRect cv::detail::resultRoiIntersection (const std::vector< Point > &corners, const std::vector< Size > &sizes)\n \nPoint cv::detail::resultTl (const std::vector< Point > &corners)\n \nvoid cv::detail::selectRandomSubset (int count, int size, std::vector< int > &subset)\n \nint & cv::detail::stitchingLogLevel ()\n \n\nFunction Documentation\n\n◆ GraphEdge()\n\ncv::detail::GraphEdge::GraphEdge \n(\nint \nfrom, \n\nint \nto, \n\nfloat \nweight \n\n)\n\ninline \n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ createStitcher()\n\nPtr< Stitcher > cv::createStitcher \n(\nbool \ntry_use_gpu = false)\n\n#include <opencv2/stitching.hpp>\nDeprecated:use Stitcher::create \n\n◆ createStitcherScans()\n\nPtr< Stitcher > cv::createStitcherScans \n(\nbool \ntry_use_gpu = false)\n\n#include <opencv2/stitching.hpp>\nDeprecated:use Stitcher::create \n\n◆ overlapRoi()\n\nbool cv::detail::overlapRoi \n(\nPoint \ntl1, \n\nPoint \ntl2, \n\nSize \nsz1, \n\nSize \nsz2, \n\nRect & \nroi \n\n)\n\nPython:cv.detail.overlapRoi(tl1, tl2, sz1, sz2, roi) -> retval\n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ resultRoi() [1/2]\n\nRect cv::detail::resultRoi \n(\nconst std::vector< Point > & \ncorners, \n\nconst std::vector< Size > & \nsizes \n\n)\n\nPython:cv.detail.resultRoi(corners, images) -> retvalcv.detail.resultRoi(corners, sizes) -> retval\n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ resultRoi() [2/2]\n\nRect cv::detail::resultRoi \n(\nconst std::vector< Point > & \ncorners, \n\nconst std::vector< UMat > & \nimages \n\n)\n\nPython:cv.detail.resultRoi(corners, images) -> retvalcv.detail.resultRoi(corners, sizes) -> retval\n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ resultRoiIntersection()\n\nRect cv::detail::resultRoiIntersection \n(\nconst std::vector< Point > & \ncorners, \n\nconst std::vector< Size > & \nsizes \n\n)\n\nPython:cv.detail.resultRoiIntersection(corners, sizes) -> retval\n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ resultTl()\n\nPoint cv::detail::resultTl \n(\nconst std::vector< Point > & \ncorners)\n\nPython:cv.detail.resultTl(corners) -> retval\n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ selectRandomSubset()\n\nvoid cv::detail::selectRandomSubset \n(\nint \ncount, \n\nint \nsize, \n\nstd::vector< int > & \nsubset \n\n)\n\nPython:cv.detail.selectRandomSubset(count, size, subset) -> None\n\n#include <opencv2/stitching/detail/util.hpp>\n\n◆ stitchingLogLevel()\n\nint & cv::detail::stitchingLogLevel \n(\n)\n\nPython:cv.detail.stitchingLogLevel() -> retval\n\n#include <opencv2/stitching/detail/util.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d3/d2d/faq.html","content_type":"text/html","title":"OpenCV: Frequently Asked Questions","language":null},"page_content":"OpenCV: Frequently Asked Questions\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nFrequently Asked Questions\n\nCompatibility page. FAQ migrated to the project wiki. \n\nGenerated on Mon Nov 11 2024 23:11:40 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/d63/group__wechat__qrcode.html","content_type":"text/html","title":"OpenCV: WeChat QR code detector for detecting and parsing QR code.","language":null},"page_content":"OpenCV: WeChat QR code detector for detecting and parsing QR code.\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nWeChat QR code detector for detecting and parsing QR code.\n\nDetailed Description\n\nClasses\nclass  cv::wechat_qrcode::WeChatQRCode\n WeChat QRCode includes two CNN-based models: A object detection model and a super resolution model. Object detection model is applied to detect QRCode with the bounding box. super resolution model is applied to zoom in QRCode when it is small.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dc/d66/group__cudafilters.html","content_type":"text/html","title":"OpenCV: Image Filtering","language":null},"page_content":"OpenCV: Image Filtering\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nImage FilteringCUDA-accelerated Computer Vision\n\nDetailed Description\nFunctions and classes described in this section are used to perform various linear or non-linear filtering operations on 2D images.\nNote\nAn example containing all basic morphology operators like erode and dilate can be found at opencv_source_code/samples/gpu/morphology.cpp \n\nClasses\nclass  cv::cuda::Filter\n Common interface for all CUDA filters :  More...\n \n\nFunctions\nPtr< Filter > cv::cuda::createBoxFilter (int srcType, int dstType, Size ksize, Point anchor=Point(-1, -1), int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates a normalized 2D box filter.  \n \nPtr< Filter > cv::cuda::createBoxMaxFilter (int srcType, Size ksize, Point anchor=Point(-1, -1), int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates the maximum filter.  \n \nPtr< Filter > cv::cuda::createBoxMinFilter (int srcType, Size ksize, Point anchor=Point(-1, -1), int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates the minimum filter.  \n \nPtr< Filter > cv::cuda::createColumnSumFilter (int srcType, int dstType, int ksize, int anchor=-1, int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates a vertical 1D box filter.  \n \nPtr< Filter > cv::cuda::createDerivFilter (int srcType, int dstType, int dx, int dy, int ksize, bool normalize=false, double scale=1, int rowBorderMode=BORDER_DEFAULT, int columnBorderMode=-1)\n Creates a generalized Deriv operator.  \n \nPtr< Filter > cv::cuda::createGaussianFilter (int srcType, int dstType, Size ksize, double sigma1, double sigma2=0, int rowBorderMode=BORDER_DEFAULT, int columnBorderMode=-1)\n Creates a Gaussian filter.  \n \nPtr< Filter > cv::cuda::createLaplacianFilter (int srcType, int dstType, int ksize=1, double scale=1, int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates a Laplacian operator.  \n \nPtr< Filter > cv::cuda::createLinearFilter (int srcType, int dstType, InputArray kernel, Point anchor=Point(-1, -1), int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates a non-separable linear 2D filter.  \n \nPtr< Filter > cv::cuda::createMorphologyFilter (int op, int srcType, InputArray kernel, Point anchor=Point(-1, -1), int iterations=1)\n Creates a 2D morphological filter.  \n \nPtr< Filter > cv::cuda::createRowSumFilter (int srcType, int dstType, int ksize, int anchor=-1, int borderMode=BORDER_DEFAULT, Scalar borderVal=Scalar::all(0))\n Creates a horizontal 1D box filter.  \n \nPtr< Filter > cv::cuda::createScharrFilter (int srcType, int dstType, int dx, int dy, double scale=1, int rowBorderMode=BORDER_DEFAULT, int columnBorderMode=-1)\n Creates a vertical or horizontal Scharr operator.  \n \nPtr< Filter > cv::cuda::createSeparableLinearFilter (int srcType, int dstType, InputArray rowKernel, InputArray columnKernel, Point anchor=Point(-1,-1), int rowBorderMode=BORDER_DEFAULT, int columnBorderMode=-1)\n Creates a separable linear filter. In-place processing is supported.  \n \nPtr< Filter > cv::cuda::createSobelFilter (int srcType, int dstType, int dx, int dy, int ksize=3, double scale=1, int rowBorderMode=BORDER_DEFAULT, int columnBorderMode=-1)\n Creates a Sobel operator.  \n \n\nFunction Documentation\n\n◆ createBoxFilter()\n\nPtr< Filter > cv::cuda::createBoxFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nSize \nksize, \n\nPoint \nanchor = Point(-1, -1), \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a normalized 2D box filter. \nParameters\n\nsrcTypeInput image type. Only CV_8UC1, CV_8UC4 and CV_32FC1 are supported for now. \ndstTypeOutput image type. Only the same type as src is supported for now. \nksizeKernel size. \nanchorAnchor point. The default value Point(-1, -1) means that the anchor is at the kernel center. \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value.\n\nSee alsoboxFilter \n\n◆ createBoxMaxFilter()\n\nPtr< Filter > cv::cuda::createBoxMaxFilter \n(\nint \nsrcType, \n\nSize \nksize, \n\nPoint \nanchor = Point(-1, -1), \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates the maximum filter. \nParameters\n\nsrcTypeInput/output image type. Only CV_8UC1 and CV_8UC4 are supported. \nksizeKernel size. \nanchorAnchor point. The default value (-1) means that the anchor is at the kernel center. \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value. \n\n◆ createBoxMinFilter()\n\nPtr< Filter > cv::cuda::createBoxMinFilter \n(\nint \nsrcType, \n\nSize \nksize, \n\nPoint \nanchor = Point(-1, -1), \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates the minimum filter. \nParameters\n\nsrcTypeInput/output image type. Only CV_8UC1 and CV_8UC4 are supported. \nksizeKernel size. \nanchorAnchor point. The default value (-1) means that the anchor is at the kernel center. \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value. \n\n◆ createColumnSumFilter()\n\nPtr< Filter > cv::cuda::createColumnSumFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nint \nksize, \n\nint \nanchor = -1, \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a vertical 1D box filter. \nParameters\n\nsrcTypeInput image type. Only CV_8UC1 type is supported for now. \ndstTypeOutput image type. Only CV_32FC1 type is supported for now. \nksizeKernel size. \nanchorAnchor point. The default value (-1) means that the anchor is at the kernel center. \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value. \n\n◆ createDerivFilter()\n\nPtr< Filter > cv::cuda::createDerivFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nint \ndx, \n\nint \ndy, \n\nint \nksize, \n\nbool \nnormalize = false, \n\ndouble \nscale = 1, \n\nint \nrowBorderMode = BORDER_DEFAULT, \n\nint \ncolumnBorderMode = -1 \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a generalized Deriv operator. \nParameters\n\nsrcTypeSource image type. \ndstTypeDestination array type. \ndxDerivative order in respect of x. \ndyDerivative order in respect of y. \nksizeAperture size. See getDerivKernels for details. \nnormalizeFlag indicating whether to normalize (scale down) the filter coefficients or not. See getDerivKernels for details. \nscaleOptional scale factor for the computed derivative values. By default, no scaling is applied. For details, see getDerivKernels . \nrowBorderModePixel extrapolation method in the vertical direction. For details, see borderInterpolate. \ncolumnBorderModePixel extrapolation method in the horizontal direction. \n\n◆ createGaussianFilter()\n\nPtr< Filter > cv::cuda::createGaussianFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nSize \nksize, \n\ndouble \nsigma1, \n\ndouble \nsigma2 = 0, \n\nint \nrowBorderMode = BORDER_DEFAULT, \n\nint \ncolumnBorderMode = -1 \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a Gaussian filter. \nParameters\n\nsrcTypeSource image type. \ndstTypeDestination array type. \nksizeAperture size. See getGaussianKernel for details. \nsigma1Gaussian sigma in the horizontal direction. See getGaussianKernel for details. \nsigma2Gaussian sigma in the vertical direction. If 0, then \\(\\texttt{sigma2}\\leftarrow\\texttt{sigma1}\\) . \nrowBorderModePixel extrapolation method in the vertical direction. For details, see borderInterpolate. \ncolumnBorderModePixel extrapolation method in the horizontal direction.\n\nSee alsoGaussianBlur \n\n◆ createLaplacianFilter()\n\nPtr< Filter > cv::cuda::createLaplacianFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nint \nksize = 1, \n\ndouble \nscale = 1, \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a Laplacian operator. \nParameters\n\nsrcTypeInput image type. Supports CV_8U , CV_16U and CV_32F one and four channel image. \ndstTypeOutput image type. Only the same type as src is supported for now. \nksizeAperture size used to compute the second-derivative filters (see getDerivKernels). It must be positive and odd. Only ksize = 1 and ksize = 3 are supported. \nscaleOptional scale factor for the computed Laplacian values. By default, no scaling is applied (see getDerivKernels ). \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value.\n\nSee alsoLaplacian \n\n◆ createLinearFilter()\n\nPtr< Filter > cv::cuda::createLinearFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nInputArray \nkernel, \n\nPoint \nanchor = Point(-1, -1), \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a non-separable linear 2D filter. \nParameters\n\nsrcTypeInput image type. Supports CV_8U , CV_16U and CV_32F one and four channel image. \ndstTypeOutput image type. Only the same type as src is supported for now. \nkernel2D array of filter coefficients. \nanchorAnchor point. The default value Point(-1, -1) means that the anchor is at the kernel center. \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value.\n\nSee alsofilter2D \n\n◆ createMorphologyFilter()\n\nPtr< Filter > cv::cuda::createMorphologyFilter \n(\nint \nop, \n\nint \nsrcType, \n\nInputArray \nkernel, \n\nPoint \nanchor = Point(-1, -1), \n\nint \niterations = 1 \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a 2D morphological filter. \nParameters\n\nopType of morphological operation. The following types are possible:\nMORPH_ERODE erode\nMORPH_DILATE dilate\nMORPH_OPEN opening\nMORPH_CLOSE closing\nMORPH_GRADIENT morphological gradient\nMORPH_TOPHAT \"top hat\"\nMORPH_BLACKHAT \"black hat\" \n\nsrcTypeInput/output image type. Only CV_8UC1, CV_8UC4, CV_32FC1 and CV_32FC4 are supported. \nkernel2D 8-bit structuring element for the morphological operation. \nanchorAnchor position within the structuring element. Negative values mean that the anchor is at the center. \niterationsNumber of times erosion and dilation to be applied.\n\nSee alsomorphologyEx \n\n◆ createRowSumFilter()\n\nPtr< Filter > cv::cuda::createRowSumFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nint \nksize, \n\nint \nanchor = -1, \n\nint \nborderMode = BORDER_DEFAULT, \n\nScalar \nborderVal = Scalar::all(0) \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a horizontal 1D box filter. \nParameters\n\nsrcTypeInput image type. Only CV_8UC1 type is supported for now. \ndstTypeOutput image type. Only CV_32FC1 type is supported for now. \nksizeKernel size. \nanchorAnchor point. The default value (-1) means that the anchor is at the kernel center. \nborderModePixel extrapolation method. For details, see borderInterpolate . \nborderValDefault border value. \n\n◆ createScharrFilter()\n\nPtr< Filter > cv::cuda::createScharrFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nint \ndx, \n\nint \ndy, \n\ndouble \nscale = 1, \n\nint \nrowBorderMode = BORDER_DEFAULT, \n\nint \ncolumnBorderMode = -1 \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a vertical or horizontal Scharr operator. \nParameters\n\nsrcTypeSource image type. \ndstTypeDestination array type. \ndxOrder of the derivative x. \ndyOrder of the derivative y. \nscaleOptional scale factor for the computed derivative values. By default, no scaling is applied. See getDerivKernels for details. \nrowBorderModePixel extrapolation method in the vertical direction. For details, see borderInterpolate. \ncolumnBorderModePixel extrapolation method in the horizontal direction.\n\nSee alsoScharr \n\n◆ createSeparableLinearFilter()\n\nPtr< Filter > cv::cuda::createSeparableLinearFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nInputArray \nrowKernel, \n\nInputArray \ncolumnKernel, \n\nPoint \nanchor = Point(-1,-1), \n\nint \nrowBorderMode = BORDER_DEFAULT, \n\nint \ncolumnBorderMode = -1 \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a separable linear filter. In-place processing is supported. \nParameters\n\nsrcTypeSource array type. \ndstTypeDestination array type. \nrowKernelHorizontal filter coefficients. Support kernels with size <= 32 . noArray() is supported to ignore the row filtering. \ncolumnKernelVertical filter coefficients. Support kernels with size <= 32 . noArray() is supported to ignore the column filtering. \nanchorAnchor position within the kernel. Negative values mean that anchor is positioned at the aperture center. \nrowBorderModePixel extrapolation method in the vertical direction For details, see borderInterpolate. \ncolumnBorderModePixel extrapolation method in the horizontal direction.\n\nSee alsosepFilter2D \n\n◆ createSobelFilter()\n\nPtr< Filter > cv::cuda::createSobelFilter \n(\nint \nsrcType, \n\nint \ndstType, \n\nint \ndx, \n\nint \ndy, \n\nint \nksize = 3, \n\ndouble \nscale = 1, \n\nint \nrowBorderMode = BORDER_DEFAULT, \n\nint \ncolumnBorderMode = -1 \n\n)\n\n#include <opencv2/cudafilters.hpp>\nCreates a Sobel operator. \nParameters\n\nsrcTypeSource image type. \ndstTypeDestination array type. \ndxDerivative order in respect of x. \ndyDerivative order in respect of y. \nksizeSize of the extended Sobel kernel. Possible values are 1, 3, 5 or 7. \nscaleOptional scale factor for the computed derivative values. By default, no scaling is applied. For details, see getDerivKernels . \nrowBorderModePixel extrapolation method in the vertical direction. For details, see borderInterpolate. \ncolumnBorderModePixel extrapolation method in the horizontal direction.\n\nSee alsoSobel \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/db/d77/group__hdf.html","content_type":"text/html","title":"OpenCV: Hierarchical Data Format I/O routines","language":null},"page_content":"OpenCV: Hierarchical Data Format I/O routines\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nHierarchical Data Format I/O routines\n\nModules\n Hierarchical Data Format version 5\n \n\nDetailed Description\nThis module provides storage routines for Hierarchical Data Format objects. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d0/de1/group__core.html","content_type":"text/html","title":"OpenCV: Core functionality","language":null},"page_content":"OpenCV: Core functionality\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nCore functionality\n\nModules\n Basic structures\n \n Operations on arrays\n \n Asynchronous API\n \n XML/YAML/JSON Persistence\n \n Clustering\n \n Utility and system functions and macros\n \n OpenGL interoperability\n \n Optimization Algorithms\n \n DirectX interoperability\n \n Eigen support\n \n OpenCL support\n \n Intel VA-API/OpenCL (CL-VA) interoperability\n \n Hardware Acceleration Layer\n \n Parallel Processing\n \n Quaternion\n \n\nDetailed Description\nThe Core module is the backbone of OpenCV, offering fundamental data structures, matrix operations, and utility functions that other modules depend on. It’s essential for handling image data, performing mathematical computations, and managing memory efficiently within the OpenCV ecosystem. \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d2/d3a/group__rgbd.html","content_type":"text/html","title":"OpenCV: RGB-Depth Processing","language":null},"page_content":"OpenCV: RGB-Depth Processing\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nRGB-Depth Processing\n\nDetailed Description\nICP point-to-plane odometry algorithm \n\nClasses\nclass  cv::linemod::ColorGradient\n Modality that computes quantized gradient orientations from a color image.  More...\n \nclass  cv::rgbd::DepthCleaner\n \nclass  cv::linemod::DepthNormal\n Modality that computes quantized surface normals from a dense depth map.  More...\n \nclass  cv::linemod::Detector\n Object detector using the LINE template matching algorithm with any set of modalities.  More...\n \nclass  cv::rgbd::FastICPOdometry\n \nstruct  cv::linemod::Feature\n Discriminant feature described by its location and label.  More...\n \nclass  cv::rgbd::ICPOdometry\n \nstruct  cv::linemod::Match\n Represents a successful template match.  More...\n \nclass  cv::linemod::Modality\n Interface for modalities that plug into the LINE template matching representation.  More...\n \nclass  cv::rgbd::Odometry\n \nstruct  cv::rgbd::OdometryFrame\n \nclass  cv::linemod::QuantizedPyramid\n Represents a modality operating over an image pyramid.  More...\n \nstruct  cv::rgbd::RgbdFrame\n \nclass  cv::rgbd::RgbdICPOdometry\n \nclass  cv::rgbd::RgbdNormals\n \nclass  cv::rgbd::RgbdOdometry\n \nclass  cv::rgbd::RgbdPlane\n \nstruct  cv::linemod::Template\n \n\nFunctions\n cv::linemod::QuantizedPyramid::Candidate::Candidate (int x, int y, int label, float score)\n \n cv::linemod::Feature::Feature (int x, int y, int label)\n \n cv::linemod::Match::Match (int x, int y, float similarity, const String &class_id, int template_id)\n \nvoid cv::linemod::colormap (const Mat &quantized, Mat &dst)\n Debug function to colormap a quantized image for viewing.  \n \nvoid cv::rgbd::depthTo3d (InputArray depth, InputArray K, OutputArray points3d, InputArray mask=noArray())\n \nvoid cv::rgbd::depthTo3dSparse (InputArray depth, InputArray in_K, InputArray in_points, OutputArray points3d)\n \nvoid cv::linemod::drawFeatures (InputOutputArray img, const std::vector< Template > &templates, const Point2i &tl, int size=10)\n Debug function to draw linemod features.  \n \nPtr< linemod::Detector > cv::linemod::getDefaultLINE ()\n Factory function for detector using LINE algorithm with color gradients.  \n \nPtr< linemod::Detector > cv::linemod::getDefaultLINEMOD ()\n Factory function for detector using LINE-MOD algorithm with color gradients and depth normals.  \n \nbool cv::rgbd::isValidDepth (const double &depth)\n \nbool cv::rgbd::isValidDepth (const float &depth)\n \nbool cv::rgbd::isValidDepth (const int &depth)\n \nbool cv::rgbd::isValidDepth (const short int &depth)\n \nbool cv::rgbd::isValidDepth (const unsigned int &depth)\n \nbool cv::rgbd::isValidDepth (const unsigned short int &depth)\n \nvoid cv::rgbd::registerDepth (InputArray unregisteredCameraMatrix, InputArray registeredCameraMatrix, InputArray registeredDistCoeffs, InputArray Rt, InputArray unregisteredDepth, const Size &outputImagePlaneSize, OutputArray registeredDepth, bool depthDilation=false)\n \nvoid cv::rgbd::rescaleDepth (InputArray in, int depth, OutputArray out, double depth_factor=1000.0)\n \nvoid cv::rgbd::warpFrame (const Mat &image, const Mat &depth, const Mat &mask, const Mat &Rt, const Mat &cameraMatrix, const Mat &distCoeff, OutputArray warpedImage, OutputArray warpedDepth=noArray(), OutputArray warpedMask=noArray())\n \n\nFunction Documentation\n\n◆ Candidate()\n\ncv::linemod::QuantizedPyramid::Candidate::Candidate \n(\nint \nx, \n\nint \ny, \n\nint \nlabel, \n\nfloat \nscore \n\n)\n\ninline \n\n#include <opencv2/rgbd/linemod.hpp>\n\n◆ Feature()\n\ncv::linemod::Feature::Feature \n(\nint \nx, \n\nint \ny, \n\nint \nlabel \n\n)\n\ninline \n\n#include <opencv2/rgbd/linemod.hpp>\n\n◆ Match()\n\ncv::linemod::Match::Match \n(\nint \nx, \n\nint \ny, \n\nfloat \nsimilarity, \n\nconst String & \nclass_id, \n\nint \ntemplate_id \n\n)\n\ninline \n\n#include <opencv2/rgbd/linemod.hpp>\n\n◆ colormap()\n\nvoid cv::linemod::colormap \n(\nconst Mat & \nquantized, \n\nMat & \ndst \n\n)\n\nPython:cv.linemod.colormap(quantized[, dst]) -> dst\n\n#include <opencv2/rgbd/linemod.hpp>\nDebug function to colormap a quantized image for viewing. \n\n◆ depthTo3d()\n\nvoid cv::rgbd::depthTo3d \n(\nInputArray \ndepth, \n\nInputArray \nK, \n\nOutputArray \npoints3d, \n\nInputArray \nmask = noArray() \n\n)\n\nPython:cv.rgbd.depthTo3d(depth, K[, points3d[, mask]]) -> points3d\n\n#include <opencv2/rgbd/depth.hpp>\nConverts a depth image to an organized set of 3d points. The coordinate system is x pointing left, y down and z away from the camera Parameters\n\ndepththe depth image (if given as short int CV_U, it is assumed to be the depth in millimeters (as done with the Microsoft Kinect), otherwise, if given as CV_32F or CV_64F, it is assumed in meters) \nKThe calibration matrix \npoints3dthe resulting 3d points. They are of depth the same as depth if it is CV_32F or CV_64F, and the depth of K if depth is of depth CV_U \nmaskthe mask of the points to consider (can be empty) \n\n◆ depthTo3dSparse()\n\nvoid cv::rgbd::depthTo3dSparse \n(\nInputArray \ndepth, \n\nInputArray \nin_K, \n\nInputArray \nin_points, \n\nOutputArray \npoints3d \n\n)\n\nPython:cv.rgbd.depthTo3dSparse(depth, in_K, in_points[, points3d]) -> points3d\n\n#include <opencv2/rgbd/depth.hpp>\nParameters\n\ndepththe depth image \nin_K\nin_pointsthe list of xy coordinates \npoints3dthe resulting 3d points \n\n◆ drawFeatures()\n\nvoid cv::linemod::drawFeatures \n(\nInputOutputArray \nimg, \n\nconst std::vector< Template > & \ntemplates, \n\nconst Point2i & \ntl, \n\nint \nsize = 10 \n\n)\n\nPython:cv.linemod.drawFeatures(img, templates, tl[, size]) -> img\n\n#include <opencv2/rgbd/linemod.hpp>\nDebug function to draw linemod features. \nParameters\n\nimg\ntemplatessee Detector::addTemplate \ntltemplate bbox top-left offset see Detector::addTemplate \nsizemarker size see cv::drawMarker \n\n◆ getDefaultLINE()\n\nPtr< linemod::Detector > cv::linemod::getDefaultLINE \n(\n)\n\nPython:cv.linemod.getDefaultLINE() -> retval\n\n#include <opencv2/rgbd/linemod.hpp>\nFactory function for detector using LINE algorithm with color gradients. \nDefault parameter settings suitable for VGA images. \n\n◆ getDefaultLINEMOD()\n\nPtr< linemod::Detector > cv::linemod::getDefaultLINEMOD \n(\n)\n\nPython:cv.linemod.getDefaultLINEMOD() -> retval\n\n#include <opencv2/rgbd/linemod.hpp>\nFactory function for detector using LINE-MOD algorithm with color gradients and depth normals. \nDefault parameter settings suitable for VGA images. \n\n◆ isValidDepth() [1/6]\n\nbool cv::rgbd::isValidDepth \n(\nconst double & \ndepth)\n\ninline \n\n#include <opencv2/rgbd/depth.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ isValidDepth() [2/6]\n\nbool cv::rgbd::isValidDepth \n(\nconst float & \ndepth)\n\ninline \n\n#include <opencv2/rgbd/depth.hpp>\nChecks if the value is a valid depth. For CV_16U or CV_16S, the convention is to be invalid if it is a limit. For a float/double, we just check if it is a NaN Parameters\n\ndepththe depth to check for validity \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ isValidDepth() [3/6]\n\nbool cv::rgbd::isValidDepth \n(\nconst int & \ndepth)\n\ninline \n\n#include <opencv2/rgbd/depth.hpp>\n\n◆ isValidDepth() [4/6]\n\nbool cv::rgbd::isValidDepth \n(\nconst short int & \ndepth)\n\ninline \n\n#include <opencv2/rgbd/depth.hpp>\n\n◆ isValidDepth() [5/6]\n\nbool cv::rgbd::isValidDepth \n(\nconst unsigned int & \ndepth)\n\ninline \n\n#include <opencv2/rgbd/depth.hpp>\n\n◆ isValidDepth() [6/6]\n\nbool cv::rgbd::isValidDepth \n(\nconst unsigned short int & \ndepth)\n\ninline \n\n#include <opencv2/rgbd/depth.hpp>\n\n◆ registerDepth()\n\nvoid cv::rgbd::registerDepth \n(\nInputArray \nunregisteredCameraMatrix, \n\nInputArray \nregisteredCameraMatrix, \n\nInputArray \nregisteredDistCoeffs, \n\nInputArray \nRt, \n\nInputArray \nunregisteredDepth, \n\nconst Size & \noutputImagePlaneSize, \n\nOutputArray \nregisteredDepth, \n\nbool \ndepthDilation = false \n\n)\n\nPython:cv.rgbd.registerDepth(unregisteredCameraMatrix, registeredCameraMatrix, registeredDistCoeffs, Rt, unregisteredDepth, outputImagePlaneSize[, registeredDepth[, depthDilation]]) -> registeredDepth\n\n#include <opencv2/rgbd/depth.hpp>\nRegisters depth data to an external camera Registration is performed by creating a depth cloud, transforming the cloud by the rigid body transformation between the cameras, and then projecting the transformed points into the RGB camera.\nuv_rgb = K_rgb * [R | t] * z * inv(K_ir) * uv_ir\nCurrently does not check for negative depth values.\nParameters\n\nunregisteredCameraMatrixthe camera matrix of the depth camera \nregisteredCameraMatrixthe camera matrix of the external camera \nregisteredDistCoeffsthe distortion coefficients of the external camera \nRtthe rigid body transform between the cameras. Transforms points from depth camera frame to external camera frame. \nunregisteredDepththe input depth data \noutputImagePlaneSizethe image plane dimensions of the external camera (width, height) \nregisteredDepththe result of transforming the depth into the external camera \ndepthDilationwhether or not the depth is dilated to avoid holes and occlusion errors (optional) \n\n◆ rescaleDepth()\n\nvoid cv::rgbd::rescaleDepth \n(\nInputArray \nin, \n\nint \ndepth, \n\nOutputArray \nout, \n\ndouble \ndepth_factor = 1000.0 \n\n)\n\nPython:cv.rgbd.rescaleDepth(in_, depth[, out[, depth_factor]]) -> out\n\n#include <opencv2/rgbd/depth.hpp>\nIf the input image is of type CV_16UC1 (like the Kinect one), the image is converted to floats, divided by depth_factor to get a depth in meters, and the values 0 are converted to std::numeric_limits<float>::quiet_NaN() Otherwise, the image is simply converted to floats Parameters\n\ninthe depth image (if given as short int CV_U, it is assumed to be the depth in millimeters (as done with the Microsoft Kinect), it is assumed in meters) \ndepththe desired output depth (floats or double) \noutThe rescaled float depth image \ndepth_factor(optional) factor by which depth is converted to distance (by default = 1000.0 for Kinect sensor) \n\n◆ warpFrame()\n\nvoid cv::rgbd::warpFrame \n(\nconst Mat & \nimage, \n\nconst Mat & \ndepth, \n\nconst Mat & \nmask, \n\nconst Mat & \nRt, \n\nconst Mat & \ncameraMatrix, \n\nconst Mat & \ndistCoeff, \n\nOutputArray \nwarpedImage, \n\nOutputArray \nwarpedDepth = noArray(), \n\nOutputArray \nwarpedMask = noArray() \n\n)\n\nPython:cv.rgbd.warpFrame(image, depth, mask, Rt, cameraMatrix, distCoeff[, warpedImage[, warpedDepth[, warpedMask]]]) -> warpedImage, warpedDepth, warpedMask\n\n#include <opencv2/rgbd/depth.hpp>\nWarp the image: compute 3d points from the depth, transform them using given transformation, then project color point cloud to an image plane. This function can be used to visualize results of the Odometry algorithm. Parameters\n\nimageThe image (of CV_8UC1 or CV_8UC3 type) \ndepthThe depth (of type used in depthTo3d fuction) \nmaskThe mask of used pixels (of CV_8UC1), it can be empty \nRtThe transformation that will be applied to the 3d points computed from the depth \ncameraMatrixCamera matrix \ndistCoeffDistortion coefficients \nwarpedImageThe warped image. \nwarpedDepthThe warped depth. \nwarpedMaskThe warped mask. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dc/d29/group__hfs.html","content_type":"text/html","title":"OpenCV: Hierarchical Feature Selection for Efficient Image Segmentation","language":null},"page_content":"OpenCV: Hierarchical Feature Selection for Efficient Image Segmentation\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nHierarchical Feature Selection for Efficient Image Segmentation\n\nDetailed Description\nThe opencv hfs module contains an efficient algorithm to segment an image. This module is implemented based on the paper Hierarchical Feature Selection for Efficient Image Segmentation, ECCV 2016. The original project was developed by Yun Liu(https://github.com/yun-liu/hfs).\n\nIntroduction to Hierarchical Feature Selection\nThis algorithm is executed in 3 stages:\nIn the first stage, the algorithm uses SLIC (simple linear iterative clustering) algorithm to obtain the superpixel of the input image.\nIn the second stage, the algorithm view each superpixel as a node in the graph. It will calculate a feature vector for each edge of the graph. It then calculates a weight for each edge based on the feature vector and trained SVM parameters. After obtaining weight for each edge, it will exploit EGB (Efficient Graph-based Image Segmentation) algorithm to merge some nodes in the graph thus obtaining a coarser segmentation After these operations, a post process will be executed to merge regions that are smaller then a specific number of pixels into their nearby region.\nIn the third stage, the algorithm exploits the similar mechanism to further merge the small regions obtained in the second stage into even coarser segmentation.\nAfter these three stages, we can obtain the final segmentation of the image. For further details about the algorithm, please refer to the original paper: Hierarchical Feature Selection for Efficient Image Segmentation, ECCV 2016 \n\nClasses\nclass  cv::hfs::HfsSegment\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/d40/group__alphamat.html","content_type":"text/html","title":"OpenCV: Alpha Matting","language":null},"page_content":"OpenCV: Alpha Matting\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nFunctions \nAlpha Matting\n\nDetailed Description\nInformation Flow algorithm implementaton for alphamatting\nAlpha matting is used to extract a foreground object with soft boundaries from a background image.\nThis module is dedicated to computing alpha matte of objects in images from a given input image and a greyscale trimap image that contains information about the foreground, background and unknown pixels. The unknown pixels are assumed to be a combination of foreground and background pixels. The algorithm uses a combination of multiple carefully defined pixels affinities to estimate the opacity of the foreground pixels in the unkown region.\nThe implementation is based on [7].\nThis module was developed by Muskaan Kularia and Sunita Nayak as a project for Google Summer of Code 2019 (GSoC 19). \n\nFunctions\nvoid cv::alphamat::infoFlow (InputArray image, InputArray tmap, OutputArray result)\n Compute alpha matte of an object in an image.  \n \n\nFunction Documentation\n\n◆ infoFlow()\n\nvoid cv::alphamat::infoFlow \n(\nInputArray \nimage, \n\nInputArray \ntmap, \n\nOutputArray \nresult \n\n)\n\n#include <opencv2/alphamat.hpp>\nCompute alpha matte of an object in an image. \nParameters\n\nimageInput RGB image \ntmapInput greyscale trimap image \nresultOutput alpha matte image\n\nThe function infoFlow performs alpha matting on a RGB image using a greyscale trimap image, and outputs a greyscale alpha matte image. The output alpha matte can be used to softly extract the foreground object from a background image. Examples can be found in the samples directory. \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/db/d7c/group__face.html","content_type":"text/html","title":"OpenCV: Face Analysis","language":null},"page_content":"OpenCV: Face Analysis\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nTypedefs |\nFunctions \nFace Analysis\n\nDetailed Description\n\nFace module changelog\nFace Recognition with OpenCV \n\nClasses\nclass  cv::face::BasicFaceRecognizer\n \nstruct  cv::face::CParams\n \nclass  cv::face::EigenFaceRecognizer\n \nclass  cv::face::Facemark\n Abstract base class for all facemark models.  More...\n \nclass  cv::face::FacemarkAAM\n \nclass  cv::face::FacemarkLBF\n \nclass  cv::face::FacemarkTrain\n Abstract base class for trainable facemark models.  More...\n \nclass  cv::face::FaceRecognizer\n Abstract base class for all face recognition models.  More...\n \nclass  cv::face::FisherFaceRecognizer\n \nclass  cv::face::LBPHFaceRecognizer\n \nclass  cv::face::MACE\n Minimum Average Correlation Energy Filter useful for authentication with (cancellable) biometrical features. (does not need many positives to train (10-50), and no negatives at all, also robust to noise/salting)  More...\n \nclass  cv::face::PredictCollector\n Abstract base class for all strategies of prediction result handling.  More...\n \nclass  cv::face::StandardCollector\n Default predict collector.  More...\n \n\nTypedefs\ntypedef bool(* cv::face::FN_FaceDetector) (InputArray, OutputArray, void *userData)\n \n\nFunctions\nPtr< Facemark > cv::face::createFacemarkAAM ()\n construct an AAM facemark detector  \n \nPtr< Facemark > cv::face::createFacemarkKazemi ()\n construct a Kazemi facemark detector  \n \nPtr< Facemark > cv::face::createFacemarkLBF ()\n construct an LBF facemark detector  \n \nvoid cv::face::drawFacemarks (InputOutputArray image, InputArray points, Scalar color=Scalar(255, 0, 0))\n Utility to draw the detected facial landmark points.  \n \nbool cv::face::getFaces (InputArray image, OutputArray faces, CParams *params)\n Default face detector This function is mainly utilized by the implementation of a Facemark Algorithm. End users are advised to use function Facemark::getFaces which can be manually defined and circumvented to the algorithm by Facemark::setFaceDetector.  \n \nbool cv::face::getFacesHAAR (InputArray image, OutputArray faces, const String &face_cascade_name)\n \nbool cv::face::loadDatasetList (String imageList, String annotationList, std::vector< String > &images, std::vector< String > &annotations)\n A utility to load list of paths to training image and annotation file.  \n \nbool cv::face::loadFacePoints (String filename, OutputArray points, float offset=0.0f)\n A utility to load facial landmark information from a given file.  \n \nbool cv::face::loadTrainingData (std::vector< String > filename, std::vector< std::vector< Point2f > > &trainlandmarks, std::vector< String > &trainimages)\n This function extracts the data for training from .txt files which contains the corresponding image name and landmarks. The first file in each file should give the path of the image whose landmarks are being described in the file. Then in the subsequent lines there should be coordinates of the landmarks in the image i.e each line should be of the form x,y where x represents the x coordinate of the landmark and y represents the y coordinate of the landmark.  \n \nbool cv::face::loadTrainingData (String filename, std::vector< String > &images, OutputArray facePoints, char delim=' ', float offset=0.0f)\n A utility to load facial landmark dataset from a single file.  \n \nbool cv::face::loadTrainingData (String imageList, String groundTruth, std::vector< String > &images, OutputArray facePoints, float offset=0.0f)\n A utility to load facial landmark information from the dataset.  \n \n\nTypedef Documentation\n\n◆ FN_FaceDetector\n\ntypedef bool(* cv::face::FN_FaceDetector) (InputArray, OutputArray, void *userData)\n\n#include <opencv2/face/facemark_train.hpp>\n\nFunction Documentation\n\n◆ createFacemarkAAM()\n\nPtr< Facemark > cv::face::createFacemarkAAM \n(\n)\n\nPython:cv.face.createFacemarkAAM() -> retval\n\n#include <opencv2/face/facemark.hpp>\nconstruct an AAM facemark detector \n\n◆ createFacemarkKazemi()\n\nPtr< Facemark > cv::face::createFacemarkKazemi \n(\n)\n\nPython:cv.face.createFacemarkKazemi() -> retval\n\n#include <opencv2/face/facemark.hpp>\nconstruct a Kazemi facemark detector \n\n◆ createFacemarkLBF()\n\nPtr< Facemark > cv::face::createFacemarkLBF \n(\n)\n\nPython:cv.face.createFacemarkLBF() -> retval\n\n#include <opencv2/face/facemark.hpp>\nconstruct an LBF facemark detector \n\n◆ drawFacemarks()\n\nvoid cv::face::drawFacemarks \n(\nInputOutputArray \nimage, \n\nInputArray \npoints, \n\nScalar \ncolor = Scalar(255, 0, 0) \n\n)\n\nPython:cv.face.drawFacemarks(image, points[, color]) -> image\n\n#include <opencv2/face/facemark_train.hpp>\nUtility to draw the detected facial landmark points. \nParameters\n\nimageThe input image to be processed. \npointsContains the data of points which will be drawn. \ncolorThe color of points in BGR format represented by cv::Scalar.\n\nExample of usage std::vector<Rect> faces;\nstd::vector<std::vector<Point2f> > landmarks;\nfacemark->getFaces(img, faces);\nfacemark->fit(img, faces, landmarks);\nfor(int j=0;j<rects.size();j++){\n face::drawFacemarks(frame, landmarks[j], Scalar(0,0,255));\n}\ncv::ScalarScalar_< double > ScalarDefinition types.hpp:709\ncv::face::drawFacemarksvoid drawFacemarks(InputOutputArray image, InputArray points, Scalar color=Scalar(255, 0, 0))Utility to draw the detected facial landmark points.\n\n◆ getFaces()\n\nbool cv::face::getFaces \n(\nInputArray \nimage, \n\nOutputArray \nfaces, \n\nCParams * \nparams \n\n)\n\n#include <opencv2/face/facemark_train.hpp>\nDefault face detector This function is mainly utilized by the implementation of a Facemark Algorithm. End users are advised to use function Facemark::getFaces which can be manually defined and circumvented to the algorithm by Facemark::setFaceDetector. \nParameters\n\nimageThe input image to be processed. \nfacesOutput of the function which represent region of interest of the detected faces. Each face is stored in cv::Rect container. \nparamsdetector parameters\n\nExample of usage std::vector<cv::Rect> faces;\nCParams params(\"haarcascade_frontalface_alt.xml\");\ncv::face::getFaces(frame, faces, &params);\nfor(int j=0;j<faces.size();j++){\n cv::rectangle(frame, faces[j], cv::Scalar(255,0,255));\n}\ncv::imshow(\"detection\", frame);\ncv::Scalar_< double >\ncv::face::getFacesbool getFaces(InputArray image, OutputArray faces, CParams *params)Default face detector This function is mainly utilized by the implementation of a Facemark Algorithm....\ncv::imshowvoid imshow(const String &winname, InputArray mat)Displays an image in the specified window.\ncv::rectanglevoid rectangle(InputOutputArray img, Point pt1, Point pt2, const Scalar &color, int thickness=1, int lineType=LINE_8, int shift=0)Draws a simple, thick, or filled up-right rectangle.\ncv::face::CParamsDefinition facemark_train.hpp:29\n\n◆ getFacesHAAR()\n\nbool cv::face::getFacesHAAR \n(\nInputArray \nimage, \n\nOutputArray \nfaces, \n\nconst String & \nface_cascade_name \n\n)\n\nPython:cv.face.getFacesHAAR(image, face_cascade_name[, faces]) -> retval, faces\n\n#include <opencv2/face/facemark_train.hpp>\n\n◆ loadDatasetList()\n\nbool cv::face::loadDatasetList \n(\nString \nimageList, \n\nString \nannotationList, \n\nstd::vector< String > & \nimages, \n\nstd::vector< String > & \nannotations \n\n)\n\nPython:cv.face.loadDatasetList(imageList, annotationList, images, annotations) -> retval\n\n#include <opencv2/face/facemark_train.hpp>\nA utility to load list of paths to training image and annotation file. \nParameters\n\nimageListThe specified file contains paths to the training images. \nannotationListThe specified file contains paths to the training annotations. \nimagesThe loaded paths of training images. \nannotationsThe loaded paths of annotation files.\n\nExample of usage: String imageFiles = \"images_path.txt\";\nString ptsFiles = \"annotations_path.txt\";\nstd::vector<String> images_train;\nstd::vector<String> landmarks_train;\nloadDatasetList(imageFiles,ptsFiles,images_train,landmarks_train);\ncv::Stringstd::string StringDefinition cvstd.hpp:151\ncv::face::loadDatasetListbool loadDatasetList(String imageList, String annotationList, std::vector< String > &images, std::vector< String > &annotations)A utility to load list of paths to training image and annotation file.\n\n◆ loadFacePoints()\n\nbool cv::face::loadFacePoints \n(\nString \nfilename, \n\nOutputArray \npoints, \n\nfloat \noffset = 0.0f \n\n)\n\nPython:cv.face.loadFacePoints(filename[, points[, offset]]) -> retval, points\n\n#include <opencv2/face/facemark_train.hpp>\nA utility to load facial landmark information from a given file. \nParameters\n\nfilenameThe filename of file contains the facial landmarks data. \npointsThe loaded facial landmark points. \noffsetAn offset value to adjust the loaded points.\n\nExample of usage std::vector<Point2f> points;\nface::loadFacePoints(\"filename.txt\", points, 0.0f);\ncv::face::loadFacePointsbool loadFacePoints(String filename, OutputArray points, float offset=0.0f)A utility to load facial landmark information from a given file.\nThe annotation file should follow the default format which is version: 1\nn_points:  68\n{\n212.716603 499.771793\n230.232816 566.290071\n...\n}\n where n_points is the number of points considered and each point is represented as its position in x and y. \n\n◆ loadTrainingData() [1/3]\n\nbool cv::face::loadTrainingData \n(\nstd::vector< String > \nfilename, \n\nstd::vector< std::vector< Point2f > > & \ntrainlandmarks, \n\nstd::vector< String > & \ntrainimages \n\n)\n\nPython:cv.face.loadTrainingData(filename, images[, facePoints[, delim[, offset]]]) -> retval, facePointscv.face.loadTrainingData(imageList, groundTruth, images[, facePoints[, offset]]) -> retval, facePointscv.face.loadTrainingData(filename, trainlandmarks, trainimages) -> retval\n\n#include <opencv2/face/facemark_train.hpp>\nThis function extracts the data for training from .txt files which contains the corresponding image name and landmarks. The first file in each file should give the path of the image whose landmarks are being described in the file. Then in the subsequent lines there should be coordinates of the landmarks in the image i.e each line should be of the form x,y where x represents the x coordinate of the landmark and y represents the y coordinate of the landmark. \nFor reference you can see the files as provided in the HELEN dataset\nParameters\n\nfilenameA vector of type cv::String containing name of the .txt files. \ntrainlandmarksA vector of type cv::Point2f that would store shape or landmarks of all images. \ntrainimagesA vector of type cv::String which stores the name of images whose landmarks are tracked \n\nReturnsA boolean value. It returns true when it reads the data successfully and false otherwise \n\n◆ loadTrainingData() [2/3]\n\nbool cv::face::loadTrainingData \n(\nString \nfilename, \n\nstd::vector< String > & \nimages, \n\nOutputArray \nfacePoints, \n\nchar \ndelim = ' ', \n\nfloat \noffset = 0.0f \n\n)\n\nPython:cv.face.loadTrainingData(filename, images[, facePoints[, delim[, offset]]]) -> retval, facePointscv.face.loadTrainingData(imageList, groundTruth, images[, facePoints[, offset]]) -> retval, facePointscv.face.loadTrainingData(filename, trainlandmarks, trainimages) -> retval\n\n#include <opencv2/face/facemark_train.hpp>\nA utility to load facial landmark dataset from a single file. \nParameters\n\nfilenameThe filename of a file that contains the dataset information. Each line contains the filename of an image followed by pairs of x and y values of facial landmarks points separated by a space. Example /home/user/ibug/image_003_1.jpg 336.820955 240.864510 334.238298 260.922709 335.266918 ...\n/home/user/ibug/image_005_1.jpg 376.158428 230.845712 376.736984 254.924635 383.265403 ...\n \nimagesA vector where each element represent the filename of image in the dataset. Images are not loaded by default to save the memory. \nfacePointsThe loaded landmark points for all training data. \ndelimDelimiter between each element, the default value is a whitespace. \noffsetAn offset value to adjust the loaded points.\n\nExample of usage cv::String imageFiles = \"../data/images_train.txt\";\ncv::String ptsFiles = \"../data/points_train.txt\";\nstd::vector<String> images;\nstd::vector<std::vector<Point2f> > facePoints;\nloadTrainingData(imageFiles, ptsFiles, images, facePoints, 0.0f);\ncv::face::loadTrainingDatabool loadTrainingData(String filename, std::vector< String > &images, OutputArray facePoints, char delim=' ', float offset=0.0f)A utility to load facial landmark dataset from a single file.\n\n◆ loadTrainingData() [3/3]\n\nbool cv::face::loadTrainingData \n(\nString \nimageList, \n\nString \ngroundTruth, \n\nstd::vector< String > & \nimages, \n\nOutputArray \nfacePoints, \n\nfloat \noffset = 0.0f \n\n)\n\nPython:cv.face.loadTrainingData(filename, images[, facePoints[, delim[, offset]]]) -> retval, facePointscv.face.loadTrainingData(imageList, groundTruth, images[, facePoints[, offset]]) -> retval, facePointscv.face.loadTrainingData(filename, trainlandmarks, trainimages) -> retval\n\n#include <opencv2/face/facemark_train.hpp>\nA utility to load facial landmark information from the dataset. \nParameters\n\nimageListA file contains the list of image filenames in the training dataset. \ngroundTruthA file contains the list of filenames where the landmarks points information are stored. The content in each file should follow the standard format (see face::loadFacePoints). \nimagesA vector where each element represent the filename of image in the dataset. Images are not loaded by default to save the memory. \nfacePointsThe loaded landmark points for all training data. \noffsetAn offset value to adjust the loaded points.\n\nExample of usage cv::String imageFiles = \"../data/images_train.txt\";\ncv::String ptsFiles = \"../data/points_train.txt\";\nstd::vector<String> images;\nstd::vector<std::vector<Point2f> > facePoints;\nloadTrainingData(imageFiles, ptsFiles, images, facePoints, 0.0f);\nexample of content in the images_train.txt /home/user/ibug/image_003_1.jpg\n/home/user/ibug/image_004_1.jpg\n/home/user/ibug/image_005_1.jpg\n/home/user/ibug/image_006.jpg\nexample of content in the points_train.txt /home/user/ibug/image_003_1.pts\n/home/user/ibug/image_004_1.pts\n/home/user/ibug/image_005_1.pts\n/home/user/ibug/image_006.pts\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d5/dc3/group__cudalegacy.html","content_type":"text/html","title":"OpenCV: Legacy support","language":null},"page_content":"OpenCV: Legacy support\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nNamespaces |\nClasses |\nMacros |\nTypedefs |\nEnumerations |\nFunctions |\nVariables \nLegacy supportCUDA-accelerated Computer Vision\n\nModules\n NPPST Core\n \n NPPST Image Processing\n \n NPPST Signal Processing\n \n\nDetailed Description\n\nNamespaces\nnamespace  NcvCTprep\n \n\nClasses\nclass  cv::cuda::BackgroundSubtractorFGD\n The class discriminates between foreground and background pixels by building and maintaining a model of the background.  More...\n \nclass  cv::cuda::BackgroundSubtractorGMG\n Background/Foreground Segmentation Algorithm.  More...\n \nclass  cv::cuda::FastOpticalFlowBM\n \nstruct  cv::cuda::FGDParams\n \nstruct  HaarClassifierCascadeDescriptor\n \nstruct  HaarClassifierNode128\n \nstruct  HaarClassifierNodeDescriptor32\n \nstruct  HaarFeature64\n \nstruct  HaarFeatureDescriptor32\n \nstruct  HaarStage64\n \nclass  cv::cuda::ImagePyramid\n \nclass  INCVMemAllocator\n \nstruct  NCVBroxOpticalFlowDescriptor\n Model and solver parameters.  More...\n \nclass  NCVMatrix< T >\n \nclass  NCVMatrixAlloc< T >\n \nclass  NCVMatrixReuse< T >\n \nclass  NCVMemNativeAllocator\n \nstruct  NCVMemPtr\n \nstruct  NCVMemSegment\n \nclass  NCVMemStackAllocator\n \nstruct  NcvPoint2D32s\n \nstruct  NcvPoint2D32u\n \nstruct  NcvRect32s\n \nstruct  NcvRect32u\n \nstruct  NcvRect8u\n \nstruct  NcvSize32s\n \nstruct  NcvSize32u\n \nclass  NCVVector< T >\n \nclass  NCVVectorAlloc< T >\n \nclass  NCVVectorReuse< T >\n \n\nMacros\n#define CLAMP(x,  a,  b)   ( (x) > (b) ? (b) : ( (x) < (a) ? (a) : (x) ) )\n \n#define CLAMP_0_255(x)   CLAMP(x,0,255)\n \n#define CLAMP_BOTTOM(x,  a)   (((x) < (a)) ? (a) : (x))\n \n#define CLAMP_TOP(x,  a)   (((x) > (a)) ? (a) : (x))\n \n#define HAAR_STDDEV_BORDER   1\n \n#define NCV_CT_ASSERT(X)\n \n#define NCV_CT_PREP_PASTE(a,  b)   NCV_CT_PREP_PASTE_AUX(a, b)\n Concatenation macro.  \n \n#define NCV_CT_PREP_PASTE_AUX(a,  b)   a##b\n Concatenation indirection macro.  \n \n#define NCV_RESET_SKIP_COND(x)       __ncv_skip_cond = x\n \n#define NCV_SET_SKIP_COND(x)       bool __ncv_skip_cond = x\n \n#define NCV_SKIP_COND_BEGIN       if (!__ncv_skip_cond) {\n \n#define NCV_SKIP_COND_END       }\n \n#define ncvAssertCUDALastErrorReturn(errCode)\n \n#define ncvAssertCUDAReturn(cudacall,  errCode)\n \n#define ncvAssertPrintCheck(pred,  msg)\n \n#define ncvAssertPrintReturn(pred,  msg,  err)\n \n#define ncvAssertReturn(pred,  err)\n \n#define ncvAssertReturnNcvStat(ncvOp)\n \n#define ncvSafeMatAlloc(name,  type,  alloc,  width,  height,  err)\n \n#define OBJDET_MASK_ELEMENT_INVALID_32U   0xFFFFFFFF\n \n#define RECT_SIMILARITY_PROPORTION   0.2f\n \n#define SQR(x)   ((x)*(x))\n \n#define SUB_BEGIN(type,  name)   struct { __inline type name\n \n#define SUB_CALL(name)   name.name\n \n#define SUB_END(name)   } name;\n \n\nTypedefs\ntypedef short Ncv16s\n \ntypedef unsigned short Ncv16u\n \ntypedef float Ncv32f\n \ntypedef Ncv32f Ncv32f_a\n \ntypedef int Ncv32s\n \ntypedef unsigned int Ncv32u\n \ntypedef Ncv32u Ncv32u_a\n \ntypedef double Ncv64f\n \ntypedef long long Ncv64s\n \ntypedef uint64 Ncv64u\n \ntypedef signed char Ncv8s\n \ntypedef unsigned char Ncv8u\n \ntypedef bool NcvBool\n \ntypedef void NCVDebugOutputHandler(const cv::String &msg)\n \ntypedef Ncv32u NCVStatus\n \ntypedef struct _NcvTimer * NcvTimer\n \n\nEnumerations\nenum  { \n  NCV_SUCCESS\n, \n  NCV_UNKNOWN_ERROR\n, \n  NCV_CUDA_ERROR\n, \n  NCV_NPP_ERROR\n, \n  NCV_FILE_ERROR\n, \n  NCV_NULL_PTR\n, \n  NCV_INCONSISTENT_INPUT\n, \n  NCV_TEXTURE_BIND_ERROR\n, \n  NCV_DIMENSIONS_INVALID\n, \n  NCV_INVALID_ROI\n, \n  NCV_INVALID_STEP\n, \n  NCV_INVALID_SCALE\n, \n  NCV_ALLOCATOR_NOT_INITIALIZED\n, \n  NCV_ALLOCATOR_BAD_ALLOC\n, \n  NCV_ALLOCATOR_BAD_DEALLOC\n, \n  NCV_ALLOCATOR_INSUFFICIENT_CAPACITY\n, \n  NCV_ALLOCATOR_DEALLOC_ORDER\n, \n  NCV_ALLOCATOR_BAD_REUSE\n, \n  NCV_MEM_COPY_ERROR\n, \n  NCV_MEM_RESIDENCE_ERROR\n, \n  NCV_MEM_INSUFFICIENT_CAPACITY\n, \n  NCV_HAAR_INVALID_PIXEL_STEP\n, \n  NCV_HAAR_TOO_MANY_FEATURES_IN_CLASSIFIER\n, \n  NCV_HAAR_TOO_MANY_FEATURES_IN_CASCADE\n, \n  NCV_HAAR_TOO_LARGE_FEATURES\n, \n  NCV_HAAR_XML_LOADING_EXCEPTION\n, \n  NCV_NOIMPL_HAAR_TILTED_FEATURES\n, \n  NCV_NOT_IMPLEMENTED\n, \n  NCV_WARNING_HAAR_DETECTIONS_VECTOR_OVERFLOW\n, \n  NPPST_SUCCESS = NCV_SUCCESS\n, \n  NPPST_ERROR\n, \n  NPPST_CUDA_KERNEL_EXECUTION_ERROR\n, \n  NPPST_NULL_POINTER_ERROR\n, \n  NPPST_TEXTURE_BIND_ERROR\n, \n  NPPST_MEMCPY_ERROR\n, \n  NPPST_MEM_ALLOC_ERR\n, \n  NPPST_MEMFREE_ERR\n, \n  NPPST_INVALID_ROI\n, \n  NPPST_INVALID_STEP\n, \n  NPPST_INVALID_SCALE\n, \n  NPPST_MEM_INSUFFICIENT_BUFFER\n, \n  NPPST_MEM_RESIDENCE_ERROR\n, \n  NPPST_MEM_INTERNAL_ERROR\n, \n  NCV_LAST_STATUS\n\n }\n \nenum  { \n  NCVPipeObjDet_Default = 0x000\n, \n  NCVPipeObjDet_UseFairImageScaling = 0x001\n, \n  NCVPipeObjDet_FindLargestObject = 0x002\n, \n  NCVPipeObjDet_VisualizeInPlace = 0x004\n\n }\n \nenum  NCVMemoryType { \n  NCVMemoryTypeNone\n, \n  NCVMemoryTypeHostPageable\n, \n  NCVMemoryTypeHostPinned\n, \n  NCVMemoryTypeDevice\n\n }\n \n\nFunctions\nvirtual INCVMemAllocator::~INCVMemAllocator ()=0\n \nNcv32u alignUp (Ncv32u what, Ncv32u alignment)\n \nvoid cv::cuda::calcOpticalFlowBM (const GpuMat &prev, const GpuMat &curr, Size block_size, Size shift_size, Size max_range, bool use_previous, GpuMat &velx, GpuMat &vely, GpuMat &buf, Stream &stream=Stream::Null())\n Calculates optical flow for 2 images using block matching algorithm *‍/.  \n \nvoid cv::cuda::connectivityMask (const GpuMat &image, GpuMat &mask, const cv::Scalar &lo, const cv::Scalar &hi, Stream &stream=Stream::Null())\n compute mask for Generalized Flood fill componetns labeling.  \n \nPtr< cuda::BackgroundSubtractorFGD > cv::cuda::createBackgroundSubtractorFGD (const FGDParams &params=FGDParams())\n Creates FGD Background Subtractor.  \n \nPtr< cuda::BackgroundSubtractorGMG > cv::cuda::createBackgroundSubtractorGMG (int initializationFrames=120, double decisionThreshold=0.8)\n Creates GMG Background Subtractor.  \n \nPtr< ImagePyramid > cv::cuda::createImagePyramid (InputArray img, int nLayers=-1, Stream &stream=Stream::Null())\n \nvoid cv::cuda::createOpticalFlowNeedleMap (const GpuMat &u, const GpuMat &v, GpuMat &vertex, GpuMat &colors)\n \nvoid cv::cuda::graphcut (GpuMat &terminals, GpuMat &leftTransp, GpuMat &rightTransp, GpuMat &top, GpuMat &bottom, GpuMat &labels, GpuMat &buf, Stream &stream=Stream::Null())\n performs labeling via graph cuts of a 2D regular 4-connected graph.  \n \nvoid cv::cuda::graphcut (GpuMat &terminals, GpuMat &leftTransp, GpuMat &rightTransp, GpuMat &top, GpuMat &topLeft, GpuMat &topRight, GpuMat &bottom, GpuMat &bottomLeft, GpuMat &bottomRight, GpuMat &labels, GpuMat &buf, Stream &stream=Stream::Null())\n performs labeling via graph cuts of a 2D regular 8-connected graph.  \n \nvoid cv::cuda::interpolateFrames (const GpuMat &frame0, const GpuMat &frame1, const GpuMat &fu, const GpuMat &fv, const GpuMat &bu, const GpuMat &bv, float pos, GpuMat &newFrame, GpuMat &buf, Stream &stream=Stream::Null())\n Interpolates frames (images) using provided optical flow (displacement field).  \n \nvoid cv::cuda::labelComponents (const GpuMat &mask, GpuMat &components, int flags=0, Stream &stream=Stream::Null())\n performs connected componnents labeling.  \n \nNCVStatus memSegCopyHelper (void *dst, NCVMemoryType dstType, const void *src, NCVMemoryType srcType, size_t sz, cudaStream_t cuStream)\n \nNCVStatus memSegCopyHelper2D (void *dst, Ncv32u dstPitch, NCVMemoryType dstType, const void *src, Ncv32u srcPitch, NCVMemoryType srcType, Ncv32u widthbytes, Ncv32u height, cudaStream_t cuStream)\n \n NCV_CT_ASSERT (sizeof(HaarClassifierNode128)==16)\n \n NCV_CT_ASSERT (sizeof(HaarClassifierNodeDescriptor32)==4)\n \n NCV_CT_ASSERT (sizeof(HaarFeature64)==8)\n \n NCV_CT_ASSERT (sizeof(HaarFeatureDescriptor32)==4)\n \n NCV_CT_ASSERT (sizeof(HaarStage64)==8)\n \nNCVStatus ncvApplyHaarClassifierCascade_device (NCVMatrix< Ncv32u > &d_integralImage, NCVMatrix< Ncv32f > &d_weights, NCVMatrixAlloc< Ncv32u > &d_pixelMask, Ncv32u &numDetections, HaarClassifierCascadeDescriptor &haar, NCVVector< HaarStage64 > &h_HaarStages, NCVVector< HaarStage64 > &d_HaarStages, NCVVector< HaarClassifierNode128 > &d_HaarNodes, NCVVector< HaarFeature64 > &d_HaarFeatures, NcvBool bMaskElements, NcvSize32u anchorsRoi, Ncv32u pixelStep, Ncv32f scaleArea, INCVMemAllocator &gpuAllocator, INCVMemAllocator &cpuAllocator, cudaDeviceProp &devProp, cudaStream_t cuStream)\n \nNCVStatus ncvApplyHaarClassifierCascade_host (NCVMatrix< Ncv32u > &h_integralImage, NCVMatrix< Ncv32f > &h_weights, NCVMatrixAlloc< Ncv32u > &h_pixelMask, Ncv32u &numDetections, HaarClassifierCascadeDescriptor &haar, NCVVector< HaarStage64 > &h_HaarStages, NCVVector< HaarClassifierNode128 > &h_HaarNodes, NCVVector< HaarFeature64 > &h_HaarFeatures, NcvBool bMaskElements, NcvSize32u anchorsRoi, Ncv32u pixelStep, Ncv32f scaleArea)\n \nNCVStatus NCVBroxOpticalFlow (const NCVBroxOpticalFlowDescriptor desc, INCVMemAllocator &gpu_mem_allocator, const NCVMatrix< Ncv32f > &frame0, const NCVMatrix< Ncv32f > &frame1, NCVMatrix< Ncv32f > &u, NCVMatrix< Ncv32f > &v, cudaStream_t stream)\n Compute optical flow.  \n \nvoid ncvDebugOutput (const cv::String &msg)\n \nNCVStatus ncvDetectObjectsMultiScale_device (NCVMatrix< Ncv8u > &d_srcImg, NcvSize32u srcRoi, NCVVector< NcvRect32u > &d_dstRects, Ncv32u &dstNumRects, HaarClassifierCascadeDescriptor &haar, NCVVector< HaarStage64 > &h_HaarStages, NCVVector< HaarStage64 > &d_HaarStages, NCVVector< HaarClassifierNode128 > &d_HaarNodes, NCVVector< HaarFeature64 > &d_HaarFeatures, NcvSize32u minObjSize, Ncv32u minNeighbors, Ncv32f scaleStep, Ncv32u pixelStep, Ncv32u flags, INCVMemAllocator &gpuAllocator, INCVMemAllocator &cpuAllocator, cudaDeviceProp &devProp, cudaStream_t cuStream)\n \nNCVStatus ncvDrawRects_32u_device (Ncv32u *d_dst, Ncv32u dstStride, Ncv32u dstWidth, Ncv32u dstHeight, NcvRect32u *d_rects, Ncv32u numRects, Ncv32u color, cudaStream_t cuStream)\n \nNCVStatus ncvDrawRects_32u_host (Ncv32u *h_dst, Ncv32u dstStride, Ncv32u dstWidth, Ncv32u dstHeight, NcvRect32u *h_rects, Ncv32u numRects, Ncv32u color)\n \nNCVStatus ncvDrawRects_8u_device (Ncv8u *d_dst, Ncv32u dstStride, Ncv32u dstWidth, Ncv32u dstHeight, NcvRect32u *d_rects, Ncv32u numRects, Ncv8u color, cudaStream_t cuStream)\n \nNCVStatus ncvDrawRects_8u_host (Ncv8u *h_dst, Ncv32u dstStride, Ncv32u dstWidth, Ncv32u dstHeight, NcvRect32u *h_rects, Ncv32u numRects, Ncv8u color)\n \ndouble ncvEndQueryTimerMs (NcvTimer t)\n \ndouble ncvEndQueryTimerUs (NcvTimer t)\n \nNCVStatus ncvGroupRectangles_host (NCVVector< NcvRect32u > &hypotheses, Ncv32u &numHypotheses, Ncv32u minNeighbors, Ncv32f intersectEps, NCVVector< Ncv32u > *hypothesesWeights)\n \nNCVStatus ncvGrowDetectionsVector_device (NCVVector< Ncv32u > &pixelMask, Ncv32u numPixelMaskDetections, NCVVector< NcvRect32u > &hypotheses, Ncv32u &totalDetections, Ncv32u totalMaxDetections, Ncv32u rectWidth, Ncv32u rectHeight, Ncv32f curScale, cudaStream_t cuStream)\n \nNCVStatus ncvGrowDetectionsVector_host (NCVVector< Ncv32u > &pixelMask, Ncv32u numPixelMaskDetections, NCVVector< NcvRect32u > &hypotheses, Ncv32u &totalDetections, Ncv32u totalMaxDetections, Ncv32u rectWidth, Ncv32u rectHeight, Ncv32f curScale)\n \nNCVStatus ncvHaarGetClassifierSize (const cv::String &filename, Ncv32u &numStages, Ncv32u &numNodes, Ncv32u &numFeatures)\n \nNCVStatus ncvHaarLoadFromFile_host (const cv::String &filename, HaarClassifierCascadeDescriptor &haar, NCVVector< HaarStage64 > &h_HaarStages, NCVVector< HaarClassifierNode128 > &h_HaarNodes, NCVVector< HaarFeature64 > &h_HaarFeatures)\n \nNCVStatus ncvHaarStoreNVBIN_host (const cv::String &filename, HaarClassifierCascadeDescriptor haar, NCVVector< HaarStage64 > &h_HaarStages, NCVVector< HaarClassifierNode128 > &h_HaarNodes, NCVVector< HaarFeature64 > &h_HaarFeatures)\n \nvoid ncvSetDebugOutputHandler (NCVDebugOutputHandler *func)\n \nNcvTimer ncvStartTimer (void)\n \nvoid cv::cuda::projectPoints (const GpuMat &src, const Mat &rvec, const Mat &tvec, const Mat &camera_mat, const Mat &dist_coef, GpuMat &dst, Stream &stream=Stream::Null())\n \nvoid cv::cuda::solvePnPRansac (const Mat &object, const Mat &image, const Mat &camera_mat, const Mat &dist_coef, Mat &rvec, Mat &tvec, bool use_extrinsic_guess=false, int num_iters=100, float max_dist=8.0, int min_inlier_count=100, std::vector< int > *inliers=NULL)\n Finds the object pose from 3D-2D point correspondences.  \n \nvoid cv::cuda::transformPoints (const GpuMat &src, const Mat &rvec, const Mat &tvec, GpuMat &dst, Stream &stream=Stream::Null())\n \n\nVariables\nconst Ncv32u K_LOG2_WARP_SIZE = 5\n \nconst Ncv32u K_WARP_SIZE = 32\n \n\nMacro Definition Documentation\n\n◆ CLAMP\n\n#define CLAMP\n(\n \nx, \n\n \na, \n\n \nb \n\n)\n   ( (x) > (b) ? (b) : ( (x) < (a) ? (a) : (x) ) )\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ CLAMP_0_255\n\n#define CLAMP_0_255\n(\n \nx)\n   CLAMP(x,0,255)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ CLAMP_BOTTOM\n\n#define CLAMP_BOTTOM\n(\n \nx, \n\n \na \n\n)\n   (((x) < (a)) ? (a) : (x))\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ CLAMP_TOP\n\n#define CLAMP_TOP\n(\n \nx, \n\n \na \n\n)\n   (((x) > (a)) ? (a) : (x))\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ HAAR_STDDEV_BORDER\n\n#define HAAR_STDDEV_BORDER   1\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ NCV_CT_ASSERT\n\n#define NCV_CT_ASSERT\n(\n \nX)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: typedef NcvCTprep::assertTest<sizeof(NcvCTprep::CT_ASSERT_FAILURE< (bool)(X) >)> \\\n NCV_CT_PREP_PASTE(__ct_assert_typedef_, __LINE__)\nNCV_CT_PREP_PASTE#define NCV_CT_PREP_PASTE(a, b)Concatenation macro.Definition NCV.hpp:83\nNcvCTprep::CT_ASSERT_FAILUREDefinition NCV.hpp:72\nNcvCTprep::assertTestDefinition NCV.hpp:78\nPerforms compile-time assertion of a condition on the file scope \n\n◆ NCV_CT_PREP_PASTE\n\n#define NCV_CT_PREP_PASTE\n(\n \na, \n\n \nb \n\n)\n   NCV_CT_PREP_PASTE_AUX(a, b)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nConcatenation macro. \n\n◆ NCV_CT_PREP_PASTE_AUX\n\n#define NCV_CT_PREP_PASTE_AUX\n(\n \na, \n\n \nb \n\n)\n   a##b\n\n#include <opencv2/cudalegacy/NCV.hpp>\nConcatenation indirection macro. \n\n◆ NCV_RESET_SKIP_COND\n\n#define NCV_RESET_SKIP_COND\n(\n \nx)\n       __ncv_skip_cond = x\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NCV_SET_SKIP_COND\n\n#define NCV_SET_SKIP_COND\n(\n \nx)\n       bool __ncv_skip_cond = x\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NCV_SKIP_COND_BEGIN\n\n#define NCV_SKIP_COND_BEGIN       if (!__ncv_skip_cond) {\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NCV_SKIP_COND_END\n\n#define NCV_SKIP_COND_END       }\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvAssertCUDALastErrorReturn\n\n#define ncvAssertCUDALastErrorReturn\n(\n \nerrCode)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: do \\\n    { \\\n        cudaError_t res = cudaGetLastError(); \\\n cv::String msg = cv::format(\"cudaError_t=%d\", (int)res); \\\n        ncvAssertPrintReturn(cudaSuccess==res, msg.c_str(), errCode); \\\n    } while (0)\ncv::Stringstd::string StringDefinition cvstd.hpp:151\ncv::formatString format(const char *fmt,...)Returns a text string formatted using the printf-like expression.\n\n◆ ncvAssertCUDAReturn\n\n#define ncvAssertCUDAReturn\n(\n \ncudacall, \n\n \nerrCode \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: do \\\n    { \\\n        cudaError_t res = cudacall; \\\n cv::String msg = cv::format(\"cudaError_t=%d\", (int)res); \\\n        ncvAssertPrintReturn(cudaSuccess==res, msg.c_str(), errCode); \\\n    } while (0)\n\n◆ ncvAssertPrintCheck\n\n#define ncvAssertPrintCheck\n(\n \npred, \n\n \nmsg \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: do \\\n    { \\\n        if (!(pred)) \\\n        { \\\n cv::String str = cv::format(\"NCV Assertion Failed: %s, file=%s, line=%d\", msg, __FILE__, __LINE__); \\\n            ncvDebugOutput(str); \\\n        } \\\n    } while (0)\n\n◆ ncvAssertPrintReturn\n\n#define ncvAssertPrintReturn\n(\n \npred, \n\n \nmsg, \n\n \nerr \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: do \\\n    { \\\n        ncvAssertPrintCheck(pred, msg); \\\n        if (!(pred)) return err; \\\n    } while (0)\n\n◆ ncvAssertReturn\n\n#define ncvAssertReturn\n(\n \npred, \n\n \nerr \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: do \\\n    { \\\n cv::String msg = cv::format(\"retcode=%d\", (int)err); \\\n        ncvAssertPrintReturn(pred, msg.c_str(), err); \\\n    } while (0)\n\n◆ ncvAssertReturnNcvStat\n\n#define ncvAssertReturnNcvStat\n(\n \nncvOp)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: do \\\n    { \\\n NCVStatus _ncvStat = ncvOp; \\\n cv::String msg = cv::format(\"NcvStat=%d\", (int)_ncvStat); \\\n        ncvAssertPrintReturn(NCV_SUCCESS==_ncvStat, msg.c_str(), _ncvStat); \\\n    } while (0)\nNCVStatusNcv32u NCVStatusDefinition NCV.hpp:376\nNCV_SUCCESS@ NCV_SUCCESSDefinition NCV.hpp:316\n\n◆ ncvSafeMatAlloc\n\n#define ncvSafeMatAlloc\n(\n \nname, \n\n \ntype, \n\n \nalloc, \n\n \nwidth, \n\n \nheight, \n\n \nerr \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nValue: NCVMatrixAlloc<type> name(alloc, width, height); \\\n    ncvAssertReturn(name.isMemAllocated(), err);\nNCVMatrixAllocDefinition NCV.hpp:845\n\n◆ OBJDET_MASK_ELEMENT_INVALID_32U\n\n#define OBJDET_MASK_ELEMENT_INVALID_32U   0xFFFFFFFF\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ RECT_SIMILARITY_PROPORTION\n\n#define RECT_SIMILARITY_PROPORTION   0.2f\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ SQR\n\n#define SQR\n(\n \nx)\n   ((x)*(x))\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ SUB_BEGIN\n\n#define SUB_BEGIN\n(\n \ntype, \n\n \nname \n\n)\n   struct { __inline type name\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ SUB_CALL\n\n#define SUB_CALL\n(\n \nname)\n   name.name\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ SUB_END\n\n#define SUB_END\n(\n \nname)\n   } name;\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\nTypedef Documentation\n\n◆ Ncv16s\n\ntypedef short Ncv16s\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv16u\n\ntypedef unsigned short Ncv16u\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv32f\n\ntypedef float Ncv32f\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv32f_a\n\ntypedef Ncv32f Ncv32f_a\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ Ncv32s\n\ntypedef int Ncv32s\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv32u\n\ntypedef unsigned int Ncv32u\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv32u_a\n\ntypedef Ncv32u Ncv32u_a\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ Ncv64f\n\ntypedef double Ncv64f\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv64s\n\ntypedef long long Ncv64s\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv64u\n\ntypedef uint64 Ncv64u\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv8s\n\ntypedef signed char Ncv8s\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ Ncv8u\n\ntypedef unsigned char Ncv8u\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NcvBool\n\ntypedef bool NcvBool\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NCVDebugOutputHandler\n\ntypedef void NCVDebugOutputHandler(const cv::String &msg)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NCVStatus\n\ntypedef Ncv32u NCVStatus\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NcvTimer\n\ntypedef struct _NcvTimer* NcvTimer\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/cudalegacy/NCV.hpp>\nReturn-codes for status notification, errors and warnings \n\nEnumeratorNCV_SUCCESS \nNCV_UNKNOWN_ERROR \nNCV_CUDA_ERROR \nNCV_NPP_ERROR \nNCV_FILE_ERROR \nNCV_NULL_PTR \nNCV_INCONSISTENT_INPUT \nNCV_TEXTURE_BIND_ERROR \nNCV_DIMENSIONS_INVALID \nNCV_INVALID_ROI \nNCV_INVALID_STEP \nNCV_INVALID_SCALE \nNCV_ALLOCATOR_NOT_INITIALIZED \nNCV_ALLOCATOR_BAD_ALLOC \nNCV_ALLOCATOR_BAD_DEALLOC \nNCV_ALLOCATOR_INSUFFICIENT_CAPACITY \nNCV_ALLOCATOR_DEALLOC_ORDER \nNCV_ALLOCATOR_BAD_REUSE \nNCV_MEM_COPY_ERROR \nNCV_MEM_RESIDENCE_ERROR \nNCV_MEM_INSUFFICIENT_CAPACITY \nNCV_HAAR_INVALID_PIXEL_STEP \nNCV_HAAR_TOO_MANY_FEATURES_IN_CLASSIFIER \nNCV_HAAR_TOO_MANY_FEATURES_IN_CASCADE \nNCV_HAAR_TOO_LARGE_FEATURES \nNCV_HAAR_XML_LOADING_EXCEPTION \nNCV_NOIMPL_HAAR_TILTED_FEATURES \nNCV_NOT_IMPLEMENTED \nNCV_WARNING_HAAR_DETECTIONS_VECTOR_OVERFLOW \nNPPST_SUCCESS Successful operation (same as NPP_NO_ERROR) \n\nNPPST_ERROR Unknown error. \n\nNPPST_CUDA_KERNEL_EXECUTION_ERROR CUDA kernel execution error. \n\nNPPST_NULL_POINTER_ERROR NULL pointer argument error. \n\nNPPST_TEXTURE_BIND_ERROR CUDA texture binding error or non-zero offset returned. \n\nNPPST_MEMCPY_ERROR CUDA memory copy error. \n\nNPPST_MEM_ALLOC_ERR CUDA memory allocation error. \n\nNPPST_MEMFREE_ERR CUDA memory deallocation error. \n\nNPPST_INVALID_ROI Invalid region of interest argument. \n\nNPPST_INVALID_STEP Invalid image lines step argument (check sign, alignment, relation to image width) \n\nNPPST_INVALID_SCALE Invalid scale parameter passed. \n\nNPPST_MEM_INSUFFICIENT_BUFFER Insufficient user-allocated buffer. \n\nNPPST_MEM_RESIDENCE_ERROR Memory residence error detected (check if pointers should be device or pinned) \n\nNPPST_MEM_INTERNAL_ERROR Internal memory management error. \n\nNCV_LAST_STATUS Marker to continue error numeration in other files. \n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\nEnumeratorNCVPipeObjDet_Default \nNCVPipeObjDet_UseFairImageScaling \nNCVPipeObjDet_FindLargestObject \nNCVPipeObjDet_VisualizeInPlace \n\n◆ NCVMemoryType\n\nenum NCVMemoryType\n\n#include <opencv2/cudalegacy/NCV.hpp>\nNCVMemoryType \n\nEnumeratorNCVMemoryTypeNone \nNCVMemoryTypeHostPageable \nNCVMemoryTypeHostPinned \nNCVMemoryTypeDevice \n\nFunction Documentation\n\n◆ ~INCVMemAllocator()\n\nINCVMemAllocator::~INCVMemAllocator \n(\n)\n\ninlinepure virtual \n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ alignUp()\n\nNcv32u alignUp \n(\nNcv32u \nwhat, \n\nNcv32u \nalignment \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nCalculates the aligned top bound value \n\n◆ calcOpticalFlowBM()\n\nvoid cv::cuda::calcOpticalFlowBM \n(\nconst GpuMat & \nprev, \n\nconst GpuMat & \ncurr, \n\nSize \nblock_size, \n\nSize \nshift_size, \n\nSize \nmax_range, \n\nbool \nuse_previous, \n\nGpuMat & \nvelx, \n\nGpuMat & \nvely, \n\nGpuMat & \nbuf, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nCalculates optical flow for 2 images using block matching algorithm *‍/. \n\n◆ connectivityMask()\n\nvoid cv::cuda::connectivityMask \n(\nconst GpuMat & \nimage, \n\nGpuMat & \nmask, \n\nconst cv::Scalar & \nlo, \n\nconst cv::Scalar & \nhi, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\ncompute mask for Generalized Flood fill componetns labeling. \n\n◆ createBackgroundSubtractorFGD()\n\nPtr< cuda::BackgroundSubtractorFGD > cv::cuda::createBackgroundSubtractorFGD \n(\nconst FGDParams & \nparams = FGDParams())\n\n#include <opencv2/cudalegacy.hpp>\nCreates FGD Background Subtractor. \nParameters\n\nparamsAlgorithm's parameters. See [162] for explanation. \n\n◆ createBackgroundSubtractorGMG()\n\nPtr< cuda::BackgroundSubtractorGMG > cv::cuda::createBackgroundSubtractorGMG \n(\nint \ninitializationFrames = 120, \n\ndouble \ndecisionThreshold = 0.8 \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nCreates GMG Background Subtractor. \nParameters\n\ninitializationFramesNumber of frames of video to use to initialize histograms. \ndecisionThresholdValue above which pixel is determined to be FG. \n\n◆ createImagePyramid()\n\nPtr< ImagePyramid > cv::cuda::createImagePyramid \n(\nInputArray \nimg, \n\nint \nnLayers = -1, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\n\n◆ createOpticalFlowNeedleMap()\n\nvoid cv::cuda::createOpticalFlowNeedleMap \n(\nconst GpuMat & \nu, \n\nconst GpuMat & \nv, \n\nGpuMat & \nvertex, \n\nGpuMat & \ncolors \n\n)\n\n#include <opencv2/cudalegacy.hpp>\n\n◆ graphcut() [1/2]\n\nvoid cv::cuda::graphcut \n(\nGpuMat & \nterminals, \n\nGpuMat & \nleftTransp, \n\nGpuMat & \nrightTransp, \n\nGpuMat & \ntop, \n\nGpuMat & \nbottom, \n\nGpuMat & \nlabels, \n\nGpuMat & \nbuf, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nperforms labeling via graph cuts of a 2D regular 4-connected graph. \n\n◆ graphcut() [2/2]\n\nvoid cv::cuda::graphcut \n(\nGpuMat & \nterminals, \n\nGpuMat & \nleftTransp, \n\nGpuMat & \nrightTransp, \n\nGpuMat & \ntop, \n\nGpuMat & \ntopLeft, \n\nGpuMat & \ntopRight, \n\nGpuMat & \nbottom, \n\nGpuMat & \nbottomLeft, \n\nGpuMat & \nbottomRight, \n\nGpuMat & \nlabels, \n\nGpuMat & \nbuf, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nperforms labeling via graph cuts of a 2D regular 8-connected graph. \n\n◆ interpolateFrames()\n\nvoid cv::cuda::interpolateFrames \n(\nconst GpuMat & \nframe0, \n\nconst GpuMat & \nframe1, \n\nconst GpuMat & \nfu, \n\nconst GpuMat & \nfv, \n\nconst GpuMat & \nbu, \n\nconst GpuMat & \nbv, \n\nfloat \npos, \n\nGpuMat & \nnewFrame, \n\nGpuMat & \nbuf, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nInterpolates frames (images) using provided optical flow (displacement field). \nParameters\n\nframe0First frame (32-bit floating point images, single channel). \nframe1Second frame. Must have the same type and size as frame0 . \nfuForward horizontal displacement. \nfvForward vertical displacement. \nbuBackward horizontal displacement. \nbvBackward vertical displacement. \nposNew frame position. \nnewFrameOutput image. \nbufTemporary buffer, will have width x 6*height size, CV_32FC1 type and contain 6 GpuMat: occlusion masks for first frame, occlusion masks for second, interpolated forward horizontal flow, interpolated forward vertical flow, interpolated backward horizontal flow, interpolated backward vertical flow. \nstreamStream for the asynchronous version. \n\n◆ labelComponents()\n\nvoid cv::cuda::labelComponents \n(\nconst GpuMat & \nmask, \n\nGpuMat & \ncomponents, \n\nint \nflags = 0, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nperforms connected componnents labeling. \n\n◆ memSegCopyHelper()\n\nNCVStatus memSegCopyHelper \n(\nvoid * \ndst, \n\nNCVMemoryType \ndstType, \n\nconst void * \nsrc, \n\nNCVMemoryType \nsrcType, \n\nsize_t \nsz, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nCopy dispatchers \n\n◆ memSegCopyHelper2D()\n\nNCVStatus memSegCopyHelper2D \n(\nvoid * \ndst, \n\nNcv32u \ndstPitch, \n\nNCVMemoryType \ndstType, \n\nconst void * \nsrc, \n\nNcv32u \nsrcPitch, \n\nNCVMemoryType \nsrcType, \n\nNcv32u \nwidthbytes, \n\nNcv32u \nheight, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ NCV_CT_ASSERT() [1/5]\n\nNCV_CT_ASSERT \n(\nsizeof(HaarClassifierNode128) \n = =16)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ NCV_CT_ASSERT() [2/5]\n\nNCV_CT_ASSERT \n(\nsizeof(HaarClassifierNodeDescriptor32) \n = =4)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ NCV_CT_ASSERT() [3/5]\n\nNCV_CT_ASSERT \n(\nsizeof(HaarFeature64) \n = =8)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ NCV_CT_ASSERT() [4/5]\n\nNCV_CT_ASSERT \n(\nsizeof(HaarFeatureDescriptor32) \n = =4)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ NCV_CT_ASSERT() [5/5]\n\nNCV_CT_ASSERT \n(\nsizeof(HaarStage64) \n = =8)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvApplyHaarClassifierCascade_device()\n\nNCVStatus ncvApplyHaarClassifierCascade_device \n(\nNCVMatrix< Ncv32u > & \nd_integralImage, \n\nNCVMatrix< Ncv32f > & \nd_weights, \n\nNCVMatrixAlloc< Ncv32u > & \nd_pixelMask, \n\nNcv32u & \nnumDetections, \n\nHaarClassifierCascadeDescriptor & \nhaar, \n\nNCVVector< HaarStage64 > & \nh_HaarStages, \n\nNCVVector< HaarStage64 > & \nd_HaarStages, \n\nNCVVector< HaarClassifierNode128 > & \nd_HaarNodes, \n\nNCVVector< HaarFeature64 > & \nd_HaarFeatures, \n\nNcvBool \nbMaskElements, \n\nNcvSize32u \nanchorsRoi, \n\nNcv32u \npixelStep, \n\nNcv32f \nscaleArea, \n\nINCVMemAllocator & \ngpuAllocator, \n\nINCVMemAllocator & \ncpuAllocator, \n\ncudaDeviceProp & \ndevProp, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvApplyHaarClassifierCascade_host()\n\nNCVStatus ncvApplyHaarClassifierCascade_host \n(\nNCVMatrix< Ncv32u > & \nh_integralImage, \n\nNCVMatrix< Ncv32f > & \nh_weights, \n\nNCVMatrixAlloc< Ncv32u > & \nh_pixelMask, \n\nNcv32u & \nnumDetections, \n\nHaarClassifierCascadeDescriptor & \nhaar, \n\nNCVVector< HaarStage64 > & \nh_HaarStages, \n\nNCVVector< HaarClassifierNode128 > & \nh_HaarNodes, \n\nNCVVector< HaarFeature64 > & \nh_HaarFeatures, \n\nNcvBool \nbMaskElements, \n\nNcvSize32u \nanchorsRoi, \n\nNcv32u \npixelStep, \n\nNcv32f \nscaleArea \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ NCVBroxOpticalFlow()\n\nNCVStatus NCVBroxOpticalFlow \n(\nconst NCVBroxOpticalFlowDescriptor \ndesc, \n\nINCVMemAllocator & \ngpu_mem_allocator, \n\nconst NCVMatrix< Ncv32f > & \nframe0, \n\nconst NCVMatrix< Ncv32f > & \nframe1, \n\nNCVMatrix< Ncv32f > & \nu, \n\nNCVMatrix< Ncv32f > & \nv, \n\ncudaStream_t \nstream \n\n)\n\n#include <opencv2/cudalegacy/NCVBroxOpticalFlow.hpp>\nCompute optical flow. \nBased on method by Brox et al [2004] Parameters\n\n[in]descmodel and solver parameters \n[in]gpu_mem_allocatorGPU memory allocator \n[in]frame0source frame \n[in]frame1frame to track \n[out]uflow horizontal component (along x axis) \n[out]vflow vertical component (along y axis) \nstream\n\nReturnscomputation status \n\n◆ ncvDebugOutput()\n\nvoid ncvDebugOutput \n(\nconst cv::String & \nmsg)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvDetectObjectsMultiScale_device()\n\nNCVStatus ncvDetectObjectsMultiScale_device \n(\nNCVMatrix< Ncv8u > & \nd_srcImg, \n\nNcvSize32u \nsrcRoi, \n\nNCVVector< NcvRect32u > & \nd_dstRects, \n\nNcv32u & \ndstNumRects, \n\nHaarClassifierCascadeDescriptor & \nhaar, \n\nNCVVector< HaarStage64 > & \nh_HaarStages, \n\nNCVVector< HaarStage64 > & \nd_HaarStages, \n\nNCVVector< HaarClassifierNode128 > & \nd_HaarNodes, \n\nNCVVector< HaarFeature64 > & \nd_HaarFeatures, \n\nNcvSize32u \nminObjSize, \n\nNcv32u \nminNeighbors, \n\nNcv32f \nscaleStep, \n\nNcv32u \npixelStep, \n\nNcv32u \nflags, \n\nINCVMemAllocator & \ngpuAllocator, \n\nINCVMemAllocator & \ncpuAllocator, \n\ncudaDeviceProp & \ndevProp, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvDrawRects_32u_device()\n\nNCVStatus ncvDrawRects_32u_device \n(\nNcv32u * \nd_dst, \n\nNcv32u \ndstStride, \n\nNcv32u \ndstWidth, \n\nNcv32u \ndstHeight, \n\nNcvRect32u * \nd_rects, \n\nNcv32u \nnumRects, \n\nNcv32u \ncolor, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvDrawRects_32u_host()\n\nNCVStatus ncvDrawRects_32u_host \n(\nNcv32u * \nh_dst, \n\nNcv32u \ndstStride, \n\nNcv32u \ndstWidth, \n\nNcv32u \ndstHeight, \n\nNcvRect32u * \nh_rects, \n\nNcv32u \nnumRects, \n\nNcv32u \ncolor \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvDrawRects_8u_device()\n\nNCVStatus ncvDrawRects_8u_device \n(\nNcv8u * \nd_dst, \n\nNcv32u \ndstStride, \n\nNcv32u \ndstWidth, \n\nNcv32u \ndstHeight, \n\nNcvRect32u * \nd_rects, \n\nNcv32u \nnumRects, \n\nNcv8u \ncolor, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvDrawRects_8u_host()\n\nNCVStatus ncvDrawRects_8u_host \n(\nNcv8u * \nh_dst, \n\nNcv32u \ndstStride, \n\nNcv32u \ndstWidth, \n\nNcv32u \ndstHeight, \n\nNcvRect32u * \nh_rects, \n\nNcv32u \nnumRects, \n\nNcv8u \ncolor \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvEndQueryTimerMs()\n\ndouble ncvEndQueryTimerMs \n(\nNcvTimer \nt)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvEndQueryTimerUs()\n\ndouble ncvEndQueryTimerUs \n(\nNcvTimer \nt)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvGroupRectangles_host()\n\nNCVStatus ncvGroupRectangles_host \n(\nNCVVector< NcvRect32u > & \nhypotheses, \n\nNcv32u & \nnumHypotheses, \n\nNcv32u \nminNeighbors, \n\nNcv32f \nintersectEps, \n\nNCVVector< Ncv32u > * \nhypothesesWeights \n\n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\nOperations with rectangles \n\n◆ ncvGrowDetectionsVector_device()\n\nNCVStatus ncvGrowDetectionsVector_device \n(\nNCVVector< Ncv32u > & \npixelMask, \n\nNcv32u \nnumPixelMaskDetections, \n\nNCVVector< NcvRect32u > & \nhypotheses, \n\nNcv32u & \ntotalDetections, \n\nNcv32u \ntotalMaxDetections, \n\nNcv32u \nrectWidth, \n\nNcv32u \nrectHeight, \n\nNcv32f \ncurScale, \n\ncudaStream_t \ncuStream \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvGrowDetectionsVector_host()\n\nNCVStatus ncvGrowDetectionsVector_host \n(\nNCVVector< Ncv32u > & \npixelMask, \n\nNcv32u \nnumPixelMaskDetections, \n\nNCVVector< NcvRect32u > & \nhypotheses, \n\nNcv32u & \ntotalDetections, \n\nNcv32u \ntotalMaxDetections, \n\nNcv32u \nrectWidth, \n\nNcv32u \nrectHeight, \n\nNcv32f \ncurScale \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvHaarGetClassifierSize()\n\nNCVStatus ncvHaarGetClassifierSize \n(\nconst cv::String & \nfilename, \n\nNcv32u & \nnumStages, \n\nNcv32u & \nnumNodes, \n\nNcv32u & \nnumFeatures \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvHaarLoadFromFile_host()\n\nNCVStatus ncvHaarLoadFromFile_host \n(\nconst cv::String & \nfilename, \n\nHaarClassifierCascadeDescriptor & \nhaar, \n\nNCVVector< HaarStage64 > & \nh_HaarStages, \n\nNCVVector< HaarClassifierNode128 > & \nh_HaarNodes, \n\nNCVVector< HaarFeature64 > & \nh_HaarFeatures \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvHaarStoreNVBIN_host()\n\nNCVStatus ncvHaarStoreNVBIN_host \n(\nconst cv::String & \nfilename, \n\nHaarClassifierCascadeDescriptor \nhaar, \n\nNCVVector< HaarStage64 > & \nh_HaarStages, \n\nNCVVector< HaarClassifierNode128 > & \nh_HaarNodes, \n\nNCVVector< HaarFeature64 > & \nh_HaarFeatures \n\n)\n\n#include <opencv2/cudalegacy/NCVHaarObjectDetection.hpp>\n\n◆ ncvSetDebugOutputHandler()\n\nvoid ncvSetDebugOutputHandler \n(\nNCVDebugOutputHandler * \nfunc)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ ncvStartTimer()\n\nNcvTimer ncvStartTimer \n(\nvoid \n)\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ projectPoints()\n\nvoid cv::cuda::projectPoints \n(\nconst GpuMat & \nsrc, \n\nconst Mat & \nrvec, \n\nconst Mat & \ntvec, \n\nconst Mat & \ncamera_mat, \n\nconst Mat & \ndist_coef, \n\nGpuMat & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\n\n◆ solvePnPRansac()\n\nvoid cv::cuda::solvePnPRansac \n(\nconst Mat & \nobject, \n\nconst Mat & \nimage, \n\nconst Mat & \ncamera_mat, \n\nconst Mat & \ndist_coef, \n\nMat & \nrvec, \n\nMat & \ntvec, \n\nbool \nuse_extrinsic_guess = false, \n\nint \nnum_iters = 100, \n\nfloat \nmax_dist = 8.0, \n\nint \nmin_inlier_count = 100, \n\nstd::vector< int > * \ninliers = NULL \n\n)\n\n#include <opencv2/cudalegacy.hpp>\nFinds the object pose from 3D-2D point correspondences. \nParameters\n\nobjectSingle-row matrix of object points. \nimageSingle-row matrix of image points. \ncamera_mat3x3 matrix of intrinsic camera parameters. \ndist_coefDistortion coefficients. See undistortPoints for details. \nrvecOutput 3D rotation vector. \ntvecOutput 3D translation vector. \nuse_extrinsic_guessFlag to indicate that the function must use rvec and tvec as an initial transformation guess. It is not supported for now. \nnum_itersMaximum number of RANSAC iterations. \nmax_distEuclidean distance threshold to detect whether point is inlier or not. \nmin_inlier_countFlag to indicate that the function must stop if greater or equal number of inliers is achieved. It is not supported for now. \ninliersOutput vector of inlier indices. \n\n◆ transformPoints()\n\nvoid cv::cuda::transformPoints \n(\nconst GpuMat & \nsrc, \n\nconst Mat & \nrvec, \n\nconst Mat & \ntvec, \n\nGpuMat & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudalegacy.hpp>\n\nVariable Documentation\n\n◆ K_LOG2_WARP_SIZE\n\nconst Ncv32u K_LOG2_WARP_SIZE = 5\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\n◆ K_WARP_SIZE\n\nconst Ncv32u K_WARP_SIZE = 32\n\n#include <opencv2/cudalegacy/NCV.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/df/d2d/group__ximgproc.html","content_type":"text/html","title":"OpenCV: Extended Image Processing","language":null},"page_content":"OpenCV: Extended Image Processing\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nEnumerations |\nFunctions \nExtended Image Processing\n\nModules\n Structured forests for fast edge detection\n \n EdgeBoxes\n \n Filters\n \n Superpixels\n \n Image segmentation\n \n Fast line detector\n \n EdgeDrawing\n \n Fourier descriptors\n \n Binary morphology on run-length encoded image\n \n\nDetailed Description\n\nEnumerations\nenum  cv::ximgproc::LocalBinarizationMethods { \n  cv::ximgproc::BINARIZATION_NIBLACK = 0\n, \n  cv::ximgproc::BINARIZATION_SAUVOLA = 1\n, \n  cv::ximgproc::BINARIZATION_WOLF = 2\n, \n  cv::ximgproc::BINARIZATION_NICK = 3\n\n }\n Specifies the binarization method to use in cv::ximgproc::niBlackThreshold.  More...\n \nenum  cv::ximgproc::ThinningTypes { \n  cv::ximgproc::THINNING_ZHANGSUEN = 0\n, \n  cv::ximgproc::THINNING_GUOHALL = 1\n\n }\n \n\nFunctions\nvoid cv::ximgproc::anisotropicDiffusion (InputArray src, OutputArray dst, float alpha, float K, int niters)\n Performs anisotropic diffusion on an image.  \n \nvoid cv::ximgproc::edgePreservingFilter (InputArray src, OutputArray dst, int d, double threshold)\n Smoothes an image using the Edge-Preserving filter.  \n \nvoid cv::ximgproc::findEllipses (InputArray image, OutputArray ellipses, float scoreThreshold=0.7f, float reliabilityThreshold=0.5f, float centerDistanceThreshold=0.05f)\n Finds ellipses fastly in an image using projective invariant pruning.  \n \nvoid cv::ximgproc::niBlackThreshold (InputArray _src, OutputArray _dst, double maxValue, int type, int blockSize, double k, int binarizationMethod=BINARIZATION_NIBLACK, double r=128)\n Performs thresholding on input images using Niblack's technique or some of the popular variations it inspired.  \n \nMatx23d cv::ximgproc::PeiLinNormalization (InputArray I)\n Calculates an affine transformation that normalize given image using Pei&Lin Normalization.  \n \nvoid cv::ximgproc::PeiLinNormalization (InputArray I, OutputArray T)\n \nvoid cv::ximgproc::thinning (InputArray src, OutputArray dst, int thinningType=THINNING_ZHANGSUEN)\n Applies a binary blob thinning operation, to achieve a skeletization of the input image.  \n \n\nEnumeration Type Documentation\n\n◆ LocalBinarizationMethods\n\nenum cv::ximgproc::LocalBinarizationMethods\n\n#include <opencv2/ximgproc.hpp>\nSpecifies the binarization method to use in cv::ximgproc::niBlackThreshold. \n\nEnumeratorBINARIZATION_NIBLACK Python: cv.ximgproc.BINARIZATION_NIBLACKClassic Niblack binarization. See [207] . \n\nBINARIZATION_SAUVOLA Python: cv.ximgproc.BINARIZATION_SAUVOLASauvola's technique. See [235] . \n\nBINARIZATION_WOLF Python: cv.ximgproc.BINARIZATION_WOLFWolf's technique. See [300] . \n\nBINARIZATION_NICK Python: cv.ximgproc.BINARIZATION_NICKNICK technique. See [146] . \n\n◆ ThinningTypes\n\nenum cv::ximgproc::ThinningTypes\n\n#include <opencv2/ximgproc.hpp>\n\nEnumeratorTHINNING_ZHANGSUEN Python: cv.ximgproc.THINNING_ZHANGSUEN\nTHINNING_GUOHALL Python: cv.ximgproc.THINNING_GUOHALL\n\nFunction Documentation\n\n◆ anisotropicDiffusion()\n\nvoid cv::ximgproc::anisotropicDiffusion \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nfloat \nalpha, \n\nfloat \nK, \n\nint \nniters \n\n)\n\nPython:cv.ximgproc.anisotropicDiffusion(src, alpha, K, niters[, dst]) -> dst\n\n#include <opencv2/ximgproc.hpp>\nPerforms anisotropic diffusion on an image. \nThe function applies Perona-Malik anisotropic diffusion to an image. This is the solution to the partial differential equation:\n\n\\[{\\frac  {\\partial I}{\\partial t}}={\\mathrm  {div}}\\left(c(x,y,t)\\nabla I\\right)=\\nabla c\\cdot \\nabla I+c(x,y,t)\\Delta I\\]\n\nSuggested functions for c(x,y,t) are:\n\n\\[c\\left(\\|\\nabla I\\|\\right)=e^{{-\\left(\\|\\nabla I\\|/K\\right)^{2}}}\\]\n\nor\n\n\\[ c\\left(\\|\\nabla I\\|\\right)={\\frac {1}{1+\\left({\\frac  {\\|\\nabla I\\|}{K}}\\right)^{2}}} \\]\n\nParameters\n\nsrcSource image with 3 channels. \ndstDestination image of the same size and the same number of channels as src . \nalphaThe amount of time to step forward by on each iteration (normally, it's between 0 and 1). \nKsensitivity to the edges \nnitersThe number of iterations \n\n◆ edgePreservingFilter()\n\nvoid cv::ximgproc::edgePreservingFilter \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nd, \n\ndouble \nthreshold \n\n)\n\nPython:cv.ximgproc.edgePreservingFilter(src, d, threshold[, dst]) -> dst\n\n#include <opencv2/ximgproc/edgepreserving_filter.hpp>\nSmoothes an image using the Edge-Preserving filter. \nThe function smoothes Gaussian noise as well as salt & pepper noise. For more details about this implementation, please see [ReiWoe18] Reich, S. and Wörgötter, F. and Dellen, B. (2018). A Real-Time Edge-Preserving Denoising Filter. Proceedings of the 13th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGRAPP): Visapp, 85-94, 4. DOI: 10.5220/0006509000850094.\nParameters\n\nsrcSource 8-bit 3-channel image. \ndstDestination image of the same size and type as src. \ndDiameter of each pixel neighborhood that is used during filtering. Must be greater or equal 3. \nthresholdThreshold, which distinguishes between noise, outliers, and data. \n\n◆ findEllipses()\n\nvoid cv::ximgproc::findEllipses \n(\nInputArray \nimage, \n\nOutputArray \nellipses, \n\nfloat \nscoreThreshold = 0.7f, \n\nfloat \nreliabilityThreshold = 0.5f, \n\nfloat \ncenterDistanceThreshold = 0.05f \n\n)\n\nPython:cv.ximgproc.findEllipses(image[, ellipses[, scoreThreshold[, reliabilityThreshold[, centerDistanceThreshold]]]]) -> ellipses\n\n#include <opencv2/ximgproc/find_ellipses.hpp>\nFinds ellipses fastly in an image using projective invariant pruning. \nThe function detects ellipses in images using projective invariant pruning. For more details about this implementation, please see [137] Jia, Qi et al, (2017). A Fast Ellipse Detector using Projective Invariant Pruning. IEEE Transactions on Image Processing.\nParameters\n\nimageinput image, could be gray or color. \nellipsesoutput vector of found ellipses. each vector is encoded as five float $x, y, a, b, radius, score$. \nscoreThresholdfloat, the threshold of ellipse score. \nreliabilityThresholdfloat, the threshold of reliability. \ncenterDistanceThresholdfloat, the threshold of center distance. \n\n◆ niBlackThreshold()\n\nvoid cv::ximgproc::niBlackThreshold \n(\nInputArray \n_src, \n\nOutputArray \n_dst, \n\ndouble \nmaxValue, \n\nint \ntype, \n\nint \nblockSize, \n\ndouble \nk, \n\nint \nbinarizationMethod = BINARIZATION_NIBLACK, \n\ndouble \nr = 128 \n\n)\n\nPython:cv.ximgproc.niBlackThreshold(_src, maxValue, type, blockSize, k[, _dst[, binarizationMethod[, r]]]) -> _dst\n\n#include <opencv2/ximgproc.hpp>\nPerforms thresholding on input images using Niblack's technique or some of the popular variations it inspired. \nThe function transforms a grayscale image to a binary image according to the formulae:\nTHRESH_BINARY \n\\[dst(x,y) =  \\fork{\\texttt{maxValue}}{if \\(src(x,y) > T(x,y)\\)}{0}{otherwise}\\]\n\nTHRESH_BINARY_INV \n\\[dst(x,y) =  \\fork{0}{if \\(src(x,y) > T(x,y)\\)}{\\texttt{maxValue}}{otherwise}\\]\n\n where \\(T(x,y)\\) is a threshold calculated individually for each pixel.\n\nThe threshold value \\(T(x, y)\\) is determined based on the binarization method chosen. For classic Niblack, it is the mean minus \\( k \\) times standard deviation of \\(\\texttt{blockSize} \\times\\texttt{blockSize}\\) neighborhood of \\((x, y)\\).\nThe function can't process the image in-place.\nParameters\n\n_srcSource 8-bit single-channel image. \n_dstDestination image of the same size and the same type as src. \nmaxValueNon-zero value assigned to the pixels for which the condition is satisfied, used with the THRESH_BINARY and THRESH_BINARY_INV thresholding types. \ntypeThresholding type, see cv::ThresholdTypes. \nblockSizeSize of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on. \nkThe user-adjustable parameter used by Niblack and inspired techniques. For Niblack, this is normally a value between 0 and 1 that is multiplied with the standard deviation and subtracted from the mean. \nbinarizationMethodBinarization method to use. By default, Niblack's technique is used. Other techniques can be specified, see cv::ximgproc::LocalBinarizationMethods. \nrThe user-adjustable parameter used by Sauvola's technique. This is the dynamic range of standard deviation. \n\nSee alsothreshold, adaptiveThreshold \n\n◆ PeiLinNormalization() [1/2]\n\nMatx23d cv::ximgproc::PeiLinNormalization \n(\nInputArray \nI)\n\nPython:cv.ximgproc.PeiLinNormalization(I[, T]) -> T\n\n#include <opencv2/ximgproc/peilin.hpp>\nCalculates an affine transformation that normalize given image using Pei&Lin Normalization. \nAssume given image \\(I=T(\\bar{I})\\) where \\(\\bar{I}\\) is a normalized image and \\(T\\) is an affine transformation distorting this image by translation, rotation, scaling and skew. The function returns an affine transformation matrix corresponding to the transformation \\(T^{-1}\\) described in [PeiLin95]. For more details about this implementation, please see [PeiLin95] Soo-Chang Pei and Chao-Nan Lin. Image normalization for pattern recognition. Image and Vision Computing, Vol. 13, N.10, pp. 711-723, 1995.\nParameters\n\nIGiven transformed image. \n\nReturnsTransformation matrix corresponding to inversed image transformation \n\n◆ PeiLinNormalization() [2/2]\n\nvoid cv::ximgproc::PeiLinNormalization \n(\nInputArray \nI, \n\nOutputArray \nT \n\n)\n\nPython:cv.ximgproc.PeiLinNormalization(I[, T]) -> T\n\n#include <opencv2/ximgproc/peilin.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ thinning()\n\nvoid cv::ximgproc::thinning \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nthinningType = THINNING_ZHANGSUEN \n\n)\n\nPython:cv.ximgproc.thinning(src[, dst[, thinningType]]) -> dst\n\n#include <opencv2/ximgproc.hpp>\nApplies a binary blob thinning operation, to achieve a skeletization of the input image. \nThe function transforms a binary blob image into a skeletized form using the technique of Zhang-Suen.\nParameters\n\nsrcSource 8-bit single-channel image, containing binary blobs, with blobs having 255 pixel values. \ndstDestination image of the same size and the same type as src. The function can work in-place. \nthinningTypeValue that defines which thinning algorithm should be used. See cv::ximgproc::ThinningTypes \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/d85/group__shape.html","content_type":"text/html","title":"OpenCV: Shape Distance and Matching","language":null},"page_content":"OpenCV: Shape Distance and Matching\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nShape Distance and Matching\n\nDetailed Description\n\nClasses\nclass  cv::AffineTransformer\n Wrapper class for the OpenCV Affine Transformation algorithm. :  More...\n \nclass  cv::ChiHistogramCostExtractor\n An Chi based cost extraction. :  More...\n \nclass  cv::EMDHistogramCostExtractor\n An EMD based cost extraction. :  More...\n \nclass  cv::EMDL1HistogramCostExtractor\n An EMD-L1 based cost extraction. :  More...\n \nclass  cv::HausdorffDistanceExtractor\n A simple Hausdorff distance measure between shapes defined by contours.  More...\n \nclass  cv::HistogramCostExtractor\n Abstract base class for histogram cost algorithms.  More...\n \nclass  cv::NormHistogramCostExtractor\n A norm based cost extraction. :  More...\n \nclass  cv::ShapeContextDistanceExtractor\n Implementation of the Shape Context descriptor and matching algorithm.  More...\n \nclass  cv::ShapeDistanceExtractor\n Abstract base class for shape distance algorithms.  More...\n \nclass  cv::ShapeTransformer\n Abstract base class for shape transformation algorithms.  More...\n \nclass  cv::ThinPlateSplineShapeTransformer\n Definition of the transformation.  More...\n \n\nFunctions\nPtr< AffineTransformer > cv::createAffineTransformer (bool fullAffine)\n \nPtr< HistogramCostExtractor > cv::createChiHistogramCostExtractor (int nDummies=25, float defaultCost=0.2f)\n \nPtr< HistogramCostExtractor > cv::createEMDHistogramCostExtractor (int flag=DIST_L2, int nDummies=25, float defaultCost=0.2f)\n \nPtr< HistogramCostExtractor > cv::createEMDL1HistogramCostExtractor (int nDummies=25, float defaultCost=0.2f)\n \nPtr< HausdorffDistanceExtractor > cv::createHausdorffDistanceExtractor (int distanceFlag=cv::NORM_L2, float rankProp=0.6f)\n \nPtr< HistogramCostExtractor > cv::createNormHistogramCostExtractor (int flag=DIST_L2, int nDummies=25, float defaultCost=0.2f)\n \nPtr< ShapeContextDistanceExtractor > cv::createShapeContextDistanceExtractor (int nAngularBins=12, int nRadialBins=4, float innerRadius=0.2f, float outerRadius=2, int iterations=3, const Ptr< HistogramCostExtractor > &comparer=createChiHistogramCostExtractor(), const Ptr< ShapeTransformer > &transformer=createThinPlateSplineShapeTransformer())\n \nPtr< ThinPlateSplineShapeTransformer > cv::createThinPlateSplineShapeTransformer (double regularizationParameter=0)\n \nfloat cv::EMDL1 (InputArray signature1, InputArray signature2)\n Computes the \"minimal work\" distance between two weighted point configurations base on the papers \"EMD-L1: An efficient and Robust Algorithm for comparing histogram-based descriptors\", by Haibin Ling and Kazunori Okuda; and \"The Earth Mover's Distance is the Mallows Distance: Some Insights from\nStatistics\", by Elizaveta Levina and Peter Bickel.  \n \n\nFunction Documentation\n\n◆ createAffineTransformer()\n\nPtr< AffineTransformer > cv::createAffineTransformer \n(\nbool \nfullAffine)\n\nPython:cv.createAffineTransformer(fullAffine) -> retval\n\n#include <opencv2/shape/shape_transformer.hpp>\nComplete constructor \n\n◆ createChiHistogramCostExtractor()\n\nPtr< HistogramCostExtractor > cv::createChiHistogramCostExtractor \n(\nint \nnDummies = 25, \n\nfloat \ndefaultCost = 0.2f \n\n)\n\nPython:cv.createChiHistogramCostExtractor([, nDummies[, defaultCost]]) -> retval\n\n#include <opencv2/shape/hist_cost.hpp>\n\n◆ createEMDHistogramCostExtractor()\n\nPtr< HistogramCostExtractor > cv::createEMDHistogramCostExtractor \n(\nint \nflag = DIST_L2, \n\nint \nnDummies = 25, \n\nfloat \ndefaultCost = 0.2f \n\n)\n\nPython:cv.createEMDHistogramCostExtractor([, flag[, nDummies[, defaultCost]]]) -> retval\n\n#include <opencv2/shape/hist_cost.hpp>\n\n◆ createEMDL1HistogramCostExtractor()\n\nPtr< HistogramCostExtractor > cv::createEMDL1HistogramCostExtractor \n(\nint \nnDummies = 25, \n\nfloat \ndefaultCost = 0.2f \n\n)\n\nPython:cv.createEMDL1HistogramCostExtractor([, nDummies[, defaultCost]]) -> retval\n\n#include <opencv2/shape/hist_cost.hpp>\n\n◆ createHausdorffDistanceExtractor()\n\nPtr< HausdorffDistanceExtractor > cv::createHausdorffDistanceExtractor \n(\nint \ndistanceFlag = cv::NORM_L2, \n\nfloat \nrankProp = 0.6f \n\n)\n\nPython:cv.createHausdorffDistanceExtractor([, distanceFlag[, rankProp]]) -> retval\n\n#include <opencv2/shape/shape_distance.hpp>\n\n◆ createNormHistogramCostExtractor()\n\nPtr< HistogramCostExtractor > cv::createNormHistogramCostExtractor \n(\nint \nflag = DIST_L2, \n\nint \nnDummies = 25, \n\nfloat \ndefaultCost = 0.2f \n\n)\n\nPython:cv.createNormHistogramCostExtractor([, flag[, nDummies[, defaultCost]]]) -> retval\n\n#include <opencv2/shape/hist_cost.hpp>\n\n◆ createShapeContextDistanceExtractor()\n\nPtr< ShapeContextDistanceExtractor > cv::createShapeContextDistanceExtractor \n(\nint \nnAngularBins = 12, \n\nint \nnRadialBins = 4, \n\nfloat \ninnerRadius = 0.2f, \n\nfloat \nouterRadius = 2, \n\nint \niterations = 3, \n\nconst Ptr< HistogramCostExtractor > & \ncomparer = createChiHistogramCostExtractor(), \n\nconst Ptr< ShapeTransformer > & \ntransformer = createThinPlateSplineShapeTransformer() \n\n)\n\nPython:cv.createShapeContextDistanceExtractor([, nAngularBins[, nRadialBins[, innerRadius[, outerRadius[, iterations[, comparer[, transformer]]]]]]]) -> retval\n\n#include <opencv2/shape/shape_distance.hpp>\nExamplesmodules/shape/samples/shape_example.cpp.\n\n◆ createThinPlateSplineShapeTransformer()\n\nPtr< ThinPlateSplineShapeTransformer > cv::createThinPlateSplineShapeTransformer \n(\ndouble \nregularizationParameter = 0)\n\nPython:cv.createThinPlateSplineShapeTransformer([, regularizationParameter]) -> retval\n\n#include <opencv2/shape/shape_transformer.hpp>\nComplete constructor \n\n◆ EMDL1()\n\nfloat cv::EMDL1 \n(\nInputArray \nsignature1, \n\nInputArray \nsignature2 \n\n)\n\n#include <opencv2/shape/emdL1.hpp>\nComputes the \"minimal work\" distance between two weighted point configurations base on the papers \"EMD-L1: An efficient and Robust Algorithm for comparing histogram-based descriptors\", by Haibin Ling and Kazunori Okuda; and \"The Earth Mover's Distance is the Mallows Distance: Some Insights from\nStatistics\", by Elizaveta Levina and Peter Bickel. \nParameters\n\nsignature1First signature, a single column floating-point matrix. Each row is the value of the histogram in each bin. \nsignature2Second signature of the same format and size as signature1. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/d47/group__cudastereo.html","content_type":"text/html","title":"OpenCV: Stereo Correspondence","language":null},"page_content":"OpenCV: Stereo Correspondence\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nStereo CorrespondenceCUDA-accelerated Computer Vision\n\nDetailed Description\n\nClasses\nclass  cv::cuda::DisparityBilateralFilter\n Class refining a disparity map using joint bilateral filtering. :  More...\n \nclass  cv::cuda::StereoBeliefPropagation\n Class computing stereo correspondence using the belief propagation algorithm. :  More...\n \nclass  cv::cuda::StereoBM\n Class computing stereo correspondence (disparity map) using the block matching algorithm. :  More...\n \nclass  cv::cuda::StereoConstantSpaceBP\n Class computing stereo correspondence using the constant space belief propagation algorithm. :  More...\n \nclass  cv::cuda::StereoSGM\n The class implements the modified H. Hirschmuller algorithm [126]. Limitation and difference are as follows:  More...\n \n\nFunctions\nPtr< cuda::DisparityBilateralFilter > cv::cuda::createDisparityBilateralFilter (int ndisp=64, int radius=3, int iters=1)\n Creates DisparityBilateralFilter object.  \n \nPtr< cuda::StereoBeliefPropagation > cv::cuda::createStereoBeliefPropagation (int ndisp=64, int iters=5, int levels=5, int msg_type=CV_32F)\n Creates StereoBeliefPropagation object.  \n \nPtr< cuda::StereoBM > cv::cuda::createStereoBM (int numDisparities=64, int blockSize=19)\n Creates StereoBM object.  \n \nPtr< cuda::StereoConstantSpaceBP > cv::cuda::createStereoConstantSpaceBP (int ndisp=128, int iters=8, int levels=4, int nr_plane=4, int msg_type=CV_32F)\n Creates StereoConstantSpaceBP object.  \n \nPtr< cuda::StereoSGM > cv::cuda::createStereoSGM (int minDisparity=0, int numDisparities=128, int P1=10, int P2=120, int uniquenessRatio=5, int mode=cv::cuda::StereoSGM::MODE_HH4)\n Creates StereoSGM object.  \n \nvoid cv::cuda::drawColorDisp (InputArray src_disp, OutputArray dst_disp, int ndisp, Stream &stream=Stream::Null())\n Colors a disparity image.  \n \nvoid cv::cuda::reprojectImageTo3D (GpuMat disp, GpuMat &xyzw, Mat Q, int dst_cn=4, Stream &stream=Stream::Null())\n \nvoid cv::cuda::reprojectImageTo3D (InputArray disp, OutputArray xyzw, InputArray Q, int dst_cn=4, Stream &stream=Stream::Null())\n Reprojects a disparity image to 3D space.  \n \n\nFunction Documentation\n\n◆ createDisparityBilateralFilter()\n\nPtr< cuda::DisparityBilateralFilter > cv::cuda::createDisparityBilateralFilter \n(\nint \nndisp = 64, \n\nint \nradius = 3, \n\nint \niters = 1 \n\n)\n\n#include <opencv2/cudastereo.hpp>\nCreates DisparityBilateralFilter object. \nParameters\n\nndispNumber of disparities. \nradiusFilter radius. \nitersNumber of iterations. \n\n◆ createStereoBeliefPropagation()\n\nPtr< cuda::StereoBeliefPropagation > cv::cuda::createStereoBeliefPropagation \n(\nint \nndisp = 64, \n\nint \niters = 5, \n\nint \nlevels = 5, \n\nint \nmsg_type = CV_32F \n\n)\n\n#include <opencv2/cudastereo.hpp>\nCreates StereoBeliefPropagation object. \nParameters\n\nndispNumber of disparities. \nitersNumber of BP iterations on each level. \nlevelsNumber of levels. \nmsg_typeType for messages. CV_16SC1 and CV_32FC1 types are supported. \n\n◆ createStereoBM()\n\nPtr< cuda::StereoBM > cv::cuda::createStereoBM \n(\nint \nnumDisparities = 64, \n\nint \nblockSize = 19 \n\n)\n\n#include <opencv2/cudastereo.hpp>\nCreates StereoBM object. \nParameters\n\nnumDisparitiesthe disparity search range. For each pixel algorithm will find the best disparity from 0 (default minimum disparity) to numDisparities. The search range can then be shifted by changing the minimum disparity. \nblockSizethe linear size of the blocks compared by the algorithm. The size should be odd (as the block is centered at the current pixel). Larger block size implies smoother, though less accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher chance for algorithm to find a wrong correspondence. \n\n◆ createStereoConstantSpaceBP()\n\nPtr< cuda::StereoConstantSpaceBP > cv::cuda::createStereoConstantSpaceBP \n(\nint \nndisp = 128, \n\nint \niters = 8, \n\nint \nlevels = 4, \n\nint \nnr_plane = 4, \n\nint \nmsg_type = CV_32F \n\n)\n\n#include <opencv2/cudastereo.hpp>\nCreates StereoConstantSpaceBP object. \nParameters\n\nndispNumber of disparities. \nitersNumber of BP iterations on each level. \nlevelsNumber of levels. \nnr_planeNumber of disparity levels on the first level. \nmsg_typeType for messages. CV_16SC1 and CV_32FC1 types are supported. \n\n◆ createStereoSGM()\n\nPtr< cuda::StereoSGM > cv::cuda::createStereoSGM \n(\nint \nminDisparity = 0, \n\nint \nnumDisparities = 128, \n\nint \nP1 = 10, \n\nint \nP2 = 120, \n\nint \nuniquenessRatio = 5, \n\nint \nmode = cv::cuda::StereoSGM::MODE_HH4 \n\n)\n\n#include <opencv2/cudastereo.hpp>\nCreates StereoSGM object. \nParameters\n\nminDisparityMinimum possible disparity value. Normally, it is zero but sometimes rectification algorithms can shift images, so this parameter needs to be adjusted accordingly. \nnumDisparitiesMaximum disparity minus minimum disparity. The value must be 64, 128 or 256. \nP1The first parameter controlling the disparity smoothness.This parameter is used for the case of slanted surfaces (not fronto parallel). \nP2The second parameter controlling the disparity smoothness.This parameter is used for \"solving\" the depth discontinuities problem. \nuniquenessRatioMargin in percentage by which the best (minimum) computed cost function value should \"win\" the second best value to consider the found match correct. Normally, a value within the 5-15 range is good enough. \nmodeSet it to StereoSGM::MODE_HH to run the full-scale two-pass dynamic programming algorithm. It will consume O(W*H*numDisparities) bytes. By default, it is set to StereoSGM::MODE_HH4. \n\n◆ drawColorDisp()\n\nvoid cv::cuda::drawColorDisp \n(\nInputArray \nsrc_disp, \n\nOutputArray \ndst_disp, \n\nint \nndisp, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudastereo.hpp>\nColors a disparity image. \nParameters\n\nsrc_dispInput single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no fractional bits. \ndst_dispOutput disparity image. It has the same size as src_disp. The type is CV_8UC4 in BGRA format (alpha = 255). \nndispNumber of disparities. \nstreamStream for the asynchronous version.\n\nThis function draws a colored disparity map by converting disparity values from [0..ndisp) interval first to HSV color space (where different disparity values correspond to different hues) and then converting the pixels to RGB for visualization. \n\n◆ reprojectImageTo3D() [1/2]\n\nvoid cv::cuda::reprojectImageTo3D \n(\nGpuMat \ndisp, \n\nGpuMat & \nxyzw, \n\nMat \nQ, \n\nint \ndst_cn = 4, \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudastereo.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ reprojectImageTo3D() [2/2]\n\nvoid cv::cuda::reprojectImageTo3D \n(\nInputArray \ndisp, \n\nOutputArray \nxyzw, \n\nInputArray \nQ, \n\nint \ndst_cn = 4, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudastereo.hpp>\nReprojects a disparity image to 3D space. \nParameters\n\ndispInput single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no fractional bits. \nxyzwOutput 3- or 4-channel floating-point image of the same size as disp . Each element of xyzw(x,y) contains 3D coordinates (x,y,z) or (x,y,z,1) of the point (x,y) , computed from the disparity map. \nQ\\(4 \\times 4\\) perspective transformation matrix that can be obtained via stereoRectify . \ndst_cnThe number of channels for output image. Can be 3 or 4. \nstreamStream for the asynchronous version.\n\nSee alsoreprojectImageTo3D \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d6/d0f/group__dnn.html","content_type":"text/html","title":"OpenCV: Deep Neural Network module","language":null},"page_content":"OpenCV: Deep Neural Network module\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nTypedefs |\nEnumerations |\nFunctions \nDeep Neural Network module\n\nModules\n Partial List of Implemented Layers\n \n Utilities for New Layers Registration\n \n\nDetailed Description\nThis module contains:\nAPI for new layers creation, layers are building bricks of neural networks;\nset of built-in most-useful Layers;\nAPI to construct and modify comprehensive neural networks from layers;\nfunctionality for loading serialized networks models from different frameworks.\n\nFunctionality of this module is designed only for forward pass computations (i.e. network testing). A network training is in principle not supported. \n\nClasses\nclass  cv::dnn::BackendNode\n Derivatives of this class encapsulates functions of certain backends.  More...\n \nclass  cv::dnn::BackendWrapper\n Derivatives of this class wraps cv::Mat for different backends and targets.  More...\n \nclass  cv::dnn::ClassificationModel\n This class represents high-level API for classification models.  More...\n \nclass  cv::dnn::DetectionModel\n This class represents high-level API for object detection networks.  More...\n \nclass  cv::dnn::Dict\n This class implements name-value dictionary, values are instances of DictValue.  More...\n \nstruct  cv::dnn::DictValue\n This struct stores the scalar value (or array) of one of the following type: double, cv::String or int64.  More...\n \nstruct  cv::dnn::Image2BlobParams\n Processing params of image to blob.  More...\n \nclass  cv::dnn::KeypointsModel\n This class represents high-level API for keypoints models.  More...\n \nclass  cv::dnn::Layer\n This interface class allows to build new Layers - are building blocks of networks.  More...\n \nclass  cv::dnn::LayerParams\n This class provides all data needed to initialize layer.  More...\n \nclass  cv::dnn::Model\n This class is presented high-level API for neural networks.  More...\n \nclass  cv::dnn::Net\n This class allows to create and manipulate comprehensive artificial neural networks.  More...\n \nclass  cv::dnn::SegmentationModel\n This class represents high-level API for segmentation models.  More...\n \nclass  cv::dnn::TextDetectionModel\n Base class for text detection networks.  More...\n \nclass  cv::dnn::TextDetectionModel_DB\n This class represents high-level API for text detection DL networks compatible with DB model.  More...\n \nclass  cv::dnn::TextDetectionModel_EAST\n This class represents high-level API for text detection DL networks compatible with EAST model.  More...\n \nclass  cv::dnn::TextRecognitionModel\n This class represents high-level API for text recognition networks.  More...\n \n\nTypedefs\ntypedef std::map< std::string, std::vector< LayerFactory::Constructor > > cv::dnn::LayerFactory_Impl\n \ntypedef std::vector< int > cv::dnn::MatShape\n \n\nEnumerations\nenum  cv::dnn::Backend { \n  cv::dnn::DNN_BACKEND_DEFAULT = 0\n, \n  cv::dnn::DNN_BACKEND_HALIDE\n, \n  cv::dnn::DNN_BACKEND_INFERENCE_ENGINE\n, \n  cv::dnn::DNN_BACKEND_OPENCV\n, \n  cv::dnn::DNN_BACKEND_VKCOM\n, \n  cv::dnn::DNN_BACKEND_CUDA\n, \n  cv::dnn::DNN_BACKEND_WEBNN\n, \n  cv::dnn::DNN_BACKEND_TIMVX\n, \n  cv::dnn::DNN_BACKEND_CANN\n\n }\n Enum of computation backends supported by layers.  More...\n \nenum  cv::dnn::DataLayout { \n  cv::dnn::DNN_LAYOUT_UNKNOWN = 0\n, \n  cv::dnn::DNN_LAYOUT_ND = 1\n, \n  cv::dnn::DNN_LAYOUT_NCHW = 2\n, \n  cv::dnn::DNN_LAYOUT_NCDHW = 3\n, \n  cv::dnn::DNN_LAYOUT_NHWC = 4\n, \n  cv::dnn::DNN_LAYOUT_NDHWC = 5\n, \n  cv::dnn::DNN_LAYOUT_PLANAR = 6\n\n }\n Enum of data layout for model inference.  More...\n \nenum  cv::dnn::ImagePaddingMode { \n  cv::dnn::DNN_PMODE_NULL = 0\n, \n  cv::dnn::DNN_PMODE_CROP_CENTER = 1\n, \n  cv::dnn::DNN_PMODE_LETTERBOX = 2\n\n }\n Enum of image processing mode. To facilitate the specialization pre-processing requirements of the dnn model. For example, the letter box often used in the Yolo series of models.  More...\n \nenum class  cv::dnn::SoftNMSMethod { \n  cv::dnn::SoftNMSMethod::SOFTNMS_LINEAR = 1\n, \n  cv::dnn::SoftNMSMethod::SOFTNMS_GAUSSIAN = 2\n\n }\n Enum of Soft NMS methods.  More...\n \nenum  cv::dnn::Target { \n  cv::dnn::DNN_TARGET_CPU = 0\n, \n  cv::dnn::DNN_TARGET_OPENCL\n, \n  cv::dnn::DNN_TARGET_OPENCL_FP16\n, \n  cv::dnn::DNN_TARGET_MYRIAD\n, \n  cv::dnn::DNN_TARGET_VULKAN\n, \n  cv::dnn::DNN_TARGET_FPGA\n, \n  cv::dnn::DNN_TARGET_CUDA\n, \n  cv::dnn::DNN_TARGET_CUDA_FP16\n, \n  cv::dnn::DNN_TARGET_HDDL\n, \n  cv::dnn::DNN_TARGET_NPU\n, \n  cv::dnn::DNN_TARGET_CPU_FP16\n\n }\n Enum of target devices for computations.  More...\n \n\nFunctions\nMat cv::dnn::blobFromImage (InputArray image, double scalefactor=1.0, const Size &size=Size(), const Scalar &mean=Scalar(), bool swapRB=false, bool crop=false, int ddepth=CV_32F)\n Creates 4-dimensional blob from image. Optionally resizes and crops image from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels.  \n \nvoid cv::dnn::blobFromImage (InputArray image, OutputArray blob, double scalefactor=1.0, const Size &size=Size(), const Scalar &mean=Scalar(), bool swapRB=false, bool crop=false, int ddepth=CV_32F)\n Creates 4-dimensional blob from image.  \n \nMat cv::dnn::blobFromImages (InputArrayOfArrays images, double scalefactor=1.0, Size size=Size(), const Scalar &mean=Scalar(), bool swapRB=false, bool crop=false, int ddepth=CV_32F)\n Creates 4-dimensional blob from series of images. Optionally resizes and crops images from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels.  \n \nvoid cv::dnn::blobFromImages (InputArrayOfArrays images, OutputArray blob, double scalefactor=1.0, Size size=Size(), const Scalar &mean=Scalar(), bool swapRB=false, bool crop=false, int ddepth=CV_32F)\n Creates 4-dimensional blob from series of images.  \n \nMat cv::dnn::blobFromImagesWithParams (InputArrayOfArrays images, const Image2BlobParams &param=Image2BlobParams())\n Creates 4-dimensional blob from series of images with given params.  \n \nvoid cv::dnn::blobFromImagesWithParams (InputArrayOfArrays images, OutputArray blob, const Image2BlobParams &param=Image2BlobParams())\n \nMat cv::dnn::blobFromImageWithParams (InputArray image, const Image2BlobParams &param=Image2BlobParams())\n Creates 4-dimensional blob from image with given params.  \n \nvoid cv::dnn::blobFromImageWithParams (InputArray image, OutputArray blob, const Image2BlobParams &param=Image2BlobParams())\n \nvoid cv::dnn::enableModelDiagnostics (bool isDiagnosticsMode)\n Enables detailed logging of the DNN model loading with CV DNN API.  \n \nstd::vector< std::pair< Backend, Target > > cv::dnn::getAvailableBackends ()\n \nstd::vector< Target > cv::dnn::getAvailableTargets (dnn::Backend be)\n \nLayerFactory_Impl & cv::dnn::getLayerFactoryImpl ()\n \nMutex & cv::dnn::getLayerFactoryMutex ()\n Get the mutex guarding LayerFactory_Impl, see getLayerFactoryImpl() function.  \n \nvoid cv::dnn::imagesFromBlob (const cv::Mat &blob_, OutputArrayOfArrays images_)\n Parse a 4D blob and output the images it contains as 2D arrays through a simpler data structure (std::vector<cv::Mat>).  \n \nvoid cv::dnn::NMSBoxes (const std::vector< Rect > &bboxes, const std::vector< float > &scores, const float score_threshold, const float nms_threshold, std::vector< int > &indices, const float eta=1.f, const int top_k=0)\n Performs non maximum suppression given boxes and corresponding scores.  \n \nvoid cv::dnn::NMSBoxes (const std::vector< Rect2d > &bboxes, const std::vector< float > &scores, const float score_threshold, const float nms_threshold, std::vector< int > &indices, const float eta=1.f, const int top_k=0)\n \nvoid cv::dnn::NMSBoxes (const std::vector< RotatedRect > &bboxes, const std::vector< float > &scores, const float score_threshold, const float nms_threshold, std::vector< int > &indices, const float eta=1.f, const int top_k=0)\n \nvoid cv::dnn::NMSBoxesBatched (const std::vector< Rect > &bboxes, const std::vector< float > &scores, const std::vector< int > &class_ids, const float score_threshold, const float nms_threshold, std::vector< int > &indices, const float eta=1.f, const int top_k=0)\n Performs batched non maximum suppression on given boxes and corresponding scores across different classes.  \n \nvoid cv::dnn::NMSBoxesBatched (const std::vector< Rect2d > &bboxes, const std::vector< float > &scores, const std::vector< int > &class_ids, const float score_threshold, const float nms_threshold, std::vector< int > &indices, const float eta=1.f, const int top_k=0)\n \nNet cv::dnn::readNet (const String &framework, const std::vector< uchar > &bufferModel, const std::vector< uchar > &bufferConfig=std::vector< uchar >())\n Read deep learning network represented in one of the supported formats.  \n \nNet cv::dnn::readNet (CV_WRAP_FILE_PATH const String &model, CV_WRAP_FILE_PATH const String &config=\"\", const String &framework=\"\")\n Read deep learning network represented in one of the supported formats.  \n \nNet cv::dnn::readNetFromCaffe (const char *bufferProto, size_t lenProto, const char *bufferModel=NULL, size_t lenModel=0)\n Reads a network model stored in Caffe model in memory.  \n \nNet cv::dnn::readNetFromCaffe (const std::vector< uchar > &bufferProto, const std::vector< uchar > &bufferModel=std::vector< uchar >())\n Reads a network model stored in Caffe model in memory.  \n \nNet cv::dnn::readNetFromCaffe (CV_WRAP_FILE_PATH const String &prototxt, CV_WRAP_FILE_PATH const String &caffeModel=String())\n Reads a network model stored in Caffe framework's format.  \n \nNet cv::dnn::readNetFromDarknet (const char *bufferCfg, size_t lenCfg, const char *bufferModel=NULL, size_t lenModel=0)\n Reads a network model stored in Darknet model files.  \n \nNet cv::dnn::readNetFromDarknet (const std::vector< uchar > &bufferCfg, const std::vector< uchar > &bufferModel=std::vector< uchar >())\n Reads a network model stored in Darknet model files.  \n \nNet cv::dnn::readNetFromDarknet (CV_WRAP_FILE_PATH const String &cfgFile, CV_WRAP_FILE_PATH const String &darknetModel=String())\n Reads a network model stored in Darknet model files.  \n \nNet cv::dnn::readNetFromModelOptimizer (const std::vector< uchar > &bufferModelConfig, const std::vector< uchar > &bufferWeights)\n Load a network from Intel's Model Optimizer intermediate representation.  \n \nNet cv::dnn::readNetFromModelOptimizer (const uchar *bufferModelConfigPtr, size_t bufferModelConfigSize, const uchar *bufferWeightsPtr, size_t bufferWeightsSize)\n Load a network from Intel's Model Optimizer intermediate representation.  \n \nNet cv::dnn::readNetFromModelOptimizer (CV_WRAP_FILE_PATH const String &xml, CV_WRAP_FILE_PATH const String &bin=\"\")\n Load a network from Intel's Model Optimizer intermediate representation.  \n \nNet cv::dnn::readNetFromONNX (const char *buffer, size_t sizeBuffer)\n Reads a network model from ONNX in-memory buffer.  \n \nNet cv::dnn::readNetFromONNX (const std::vector< uchar > &buffer)\n Reads a network model from ONNX in-memory buffer.  \n \nNet cv::dnn::readNetFromONNX (CV_WRAP_FILE_PATH const String &onnxFile)\n Reads a network model ONNX.  \n \nNet cv::dnn::readNetFromTensorflow (const char *bufferModel, size_t lenModel, const char *bufferConfig=NULL, size_t lenConfig=0)\n Reads a network model stored in TensorFlow framework's format.  \n \nNet cv::dnn::readNetFromTensorflow (const std::vector< uchar > &bufferModel, const std::vector< uchar > &bufferConfig=std::vector< uchar >())\n Reads a network model stored in TensorFlow framework's format.  \n \nNet cv::dnn::readNetFromTensorflow (CV_WRAP_FILE_PATH const String &model, CV_WRAP_FILE_PATH const String &config=String())\n Reads a network model stored in TensorFlow framework's format.  \n \nNet cv::dnn::readNetFromTFLite (const char *bufferModel, size_t lenModel)\n Reads a network model stored in TFLite framework's format.  \n \nNet cv::dnn::readNetFromTFLite (const std::vector< uchar > &bufferModel)\n Reads a network model stored in TFLite framework's format.  \n \nNet cv::dnn::readNetFromTFLite (CV_WRAP_FILE_PATH const String &model)\n Reads a network model stored in TFLite framework's format.  \n \nNet cv::dnn::readNetFromTorch (CV_WRAP_FILE_PATH const String &model, bool isBinary=true, bool evaluate=true)\n Reads a network model stored in Torch7 framework's format.  \n \nMat cv::dnn::readTensorFromONNX (CV_WRAP_FILE_PATH const String &path)\n Creates blob from .pb file.  \n \nMat cv::dnn::readTorchBlob (const String &filename, bool isBinary=true)\n Loads blob which was serialized as torch.Tensor object of Torch7 framework.  \n \nvoid cv::dnn::shrinkCaffeModel (CV_WRAP_FILE_PATH const String &src, CV_WRAP_FILE_PATH const String &dst, const std::vector< String > &layersTypes=std::vector< String >())\n Convert all weights of Caffe network to half precision floating point.  \n \nvoid cv::dnn::softNMSBoxes (const std::vector< Rect > &bboxes, const std::vector< float > &scores, std::vector< float > &updated_scores, const float score_threshold, const float nms_threshold, std::vector< int > &indices, size_t top_k=0, const float sigma=0.5, SoftNMSMethod method=SoftNMSMethod::SOFTNMS_GAUSSIAN)\n Performs soft non maximum suppression given boxes and corresponding scores. Reference: https://arxiv.org/abs/1704.04503.  \n \nvoid cv::dnn::writeTextGraph (CV_WRAP_FILE_PATH const String &model, CV_WRAP_FILE_PATH const String &output)\n Create a text representation for a binary network stored in protocol buffer format.  \n \n\nTypedef Documentation\n\n◆ LayerFactory_Impl\n\ntypedef std::map<std::string, std::vector<LayerFactory::Constructor> > cv::dnn::LayerFactory_Impl\n\n#include <opencv2/dnn/layer_reg.private.hpp>\n\n◆ MatShape\n\ntypedef std::vector<int> cv::dnn::MatShape\n\n#include <opencv2/dnn/dnn.hpp>\n\nEnumeration Type Documentation\n\n◆ Backend\n\nenum cv::dnn::Backend\n\n#include <opencv2/dnn/dnn.hpp>\nEnum of computation backends supported by layers. \nSee alsoNet::setPreferableBackend \n\nEnumeratorDNN_BACKEND_DEFAULT Python: cv.dnn.DNN_BACKEND_DEFAULTDNN_BACKEND_DEFAULT equals to OPENCV_DNN_BACKEND_DEFAULT, which can be defined using CMake or a configuration parameter. \n\nDNN_BACKEND_HALIDE Python: cv.dnn.DNN_BACKEND_HALIDE\nDNN_BACKEND_INFERENCE_ENGINE Python: cv.dnn.DNN_BACKEND_INFERENCE_ENGINEIntel OpenVINO computational backend NoteTutorial how to build OpenCV with OpenVINO: OpenCV usage with OpenVINO \n\nDNN_BACKEND_OPENCV Python: cv.dnn.DNN_BACKEND_OPENCV\nDNN_BACKEND_VKCOM Python: cv.dnn.DNN_BACKEND_VKCOM\nDNN_BACKEND_CUDA Python: cv.dnn.DNN_BACKEND_CUDA\nDNN_BACKEND_WEBNN Python: cv.dnn.DNN_BACKEND_WEBNN\nDNN_BACKEND_TIMVX Python: cv.dnn.DNN_BACKEND_TIMVX\nDNN_BACKEND_CANN Python: cv.dnn.DNN_BACKEND_CANN\n\n◆ DataLayout\n\nenum cv::dnn::DataLayout\n\n#include <opencv2/dnn/dnn.hpp>\nEnum of data layout for model inference. \nSee alsoImage2BlobParams \n\nEnumeratorDNN_LAYOUT_UNKNOWN Python: cv.dnn.DNN_LAYOUT_UNKNOWN\nDNN_LAYOUT_ND Python: cv.dnn.DNN_LAYOUT_NDOpenCV data layout for 2D data. \n\nDNN_LAYOUT_NCHW Python: cv.dnn.DNN_LAYOUT_NCHWOpenCV data layout for 4D data. \n\nDNN_LAYOUT_NCDHW Python: cv.dnn.DNN_LAYOUT_NCDHWOpenCV data layout for 5D data. \n\nDNN_LAYOUT_NHWC Python: cv.dnn.DNN_LAYOUT_NHWCTensorflow-like data layout for 4D data. \n\nDNN_LAYOUT_NDHWC Python: cv.dnn.DNN_LAYOUT_NDHWCTensorflow-like data layout for 5D data. \n\nDNN_LAYOUT_PLANAR Python: cv.dnn.DNN_LAYOUT_PLANARTensorflow-like data layout, it should only be used at tf or tflite model parsing. \n\n◆ ImagePaddingMode\n\nenum cv::dnn::ImagePaddingMode\n\n#include <opencv2/dnn/dnn.hpp>\nEnum of image processing mode. To facilitate the specialization pre-processing requirements of the dnn model. For example, the letter box often used in the Yolo series of models. \nSee alsoImage2BlobParams \n\nEnumeratorDNN_PMODE_NULL Python: cv.dnn.DNN_PMODE_NULL\nDNN_PMODE_CROP_CENTER Python: cv.dnn.DNN_PMODE_CROP_CENTER\nDNN_PMODE_LETTERBOX Python: cv.dnn.DNN_PMODE_LETTERBOX\n\n◆ SoftNMSMethod\n\nenum class cv::dnn::SoftNMSMethod\n\nstrong \n\n#include <opencv2/dnn/dnn.hpp>\nEnum of Soft NMS methods. \nSee alsosoftNMSBoxes \n\nEnumeratorSOFTNMS_LINEAR \nSOFTNMS_GAUSSIAN \n\n◆ Target\n\nenum cv::dnn::Target\n\n#include <opencv2/dnn/dnn.hpp>\nEnum of target devices for computations. \nSee alsoNet::setPreferableTarget \n\nEnumeratorDNN_TARGET_CPU Python: cv.dnn.DNN_TARGET_CPU\nDNN_TARGET_OPENCL Python: cv.dnn.DNN_TARGET_OPENCL\nDNN_TARGET_OPENCL_FP16 Python: cv.dnn.DNN_TARGET_OPENCL_FP16\nDNN_TARGET_MYRIAD Python: cv.dnn.DNN_TARGET_MYRIAD\nDNN_TARGET_VULKAN Python: cv.dnn.DNN_TARGET_VULKAN\nDNN_TARGET_FPGA Python: cv.dnn.DNN_TARGET_FPGAFPGA device with CPU fallbacks using Inference Engine's Heterogeneous plugin. \n\nDNN_TARGET_CUDA Python: cv.dnn.DNN_TARGET_CUDA\nDNN_TARGET_CUDA_FP16 Python: cv.dnn.DNN_TARGET_CUDA_FP16\nDNN_TARGET_HDDL Python: cv.dnn.DNN_TARGET_HDDL\nDNN_TARGET_NPU Python: cv.dnn.DNN_TARGET_NPU\nDNN_TARGET_CPU_FP16 Python: cv.dnn.DNN_TARGET_CPU_FP16\n\nFunction Documentation\n\n◆ blobFromImage() [1/2]\n\nMat cv::dnn::blobFromImage \n(\nInputArray \nimage, \n\ndouble \nscalefactor = 1.0, \n\nconst Size & \nsize = Size(), \n\nconst Scalar & \nmean = Scalar(), \n\nbool \nswapRB = false, \n\nbool \ncrop = false, \n\nint \nddepth = CV_32F \n\n)\n\nPython:cv.dnn.blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nCreates 4-dimensional blob from image. Optionally resizes and crops image from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels. \nParameters\n\nimageinput image (with 1-, 3- or 4-channels). \nscalefactormultiplier for images values. \nsizespatial size for output image \nmeanscalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true. \nswapRBflag which indicates that swap first and last channels in 3-channel image is necessary. \ncropflag which indicates whether image will be cropped after resize or not \nddepthDepth of output blob. Choose CV_32F or CV_8U.\n\nif crop is true, input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed. If crop is false, direct resize without cropping and preserving aspect ratio is performed. Returns4-dimensional Mat with NCHW dimensions order.\nNoteThe order and usage of scalefactor and mean are (input - mean) * scalefactor. \n\n◆ blobFromImage() [2/2]\n\nvoid cv::dnn::blobFromImage \n(\nInputArray \nimage, \n\nOutputArray \nblob, \n\ndouble \nscalefactor = 1.0, \n\nconst Size & \nsize = Size(), \n\nconst Scalar & \nmean = Scalar(), \n\nbool \nswapRB = false, \n\nbool \ncrop = false, \n\nint \nddepth = CV_32F \n\n)\n\nPython:cv.dnn.blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nCreates 4-dimensional blob from image. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ blobFromImages() [1/2]\n\nMat cv::dnn::blobFromImages \n(\nInputArrayOfArrays \nimages, \n\ndouble \nscalefactor = 1.0, \n\nSize \nsize = Size(), \n\nconst Scalar & \nmean = Scalar(), \n\nbool \nswapRB = false, \n\nbool \ncrop = false, \n\nint \nddepth = CV_32F \n\n)\n\nPython:cv.dnn.blobFromImages(images[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nCreates 4-dimensional blob from series of images. Optionally resizes and crops images from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels. \nParameters\n\nimagesinput images (all with 1-, 3- or 4-channels). \nsizespatial size for output image \nmeanscalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true. \nscalefactormultiplier for images values. \nswapRBflag which indicates that swap first and last channels in 3-channel image is necessary. \ncropflag which indicates whether image will be cropped after resize or not \nddepthDepth of output blob. Choose CV_32F or CV_8U.\n\nif crop is true, input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed. If crop is false, direct resize without cropping and preserving aspect ratio is performed. Returns4-dimensional Mat with NCHW dimensions order.\nNoteThe order and usage of scalefactor and mean are (input - mean) * scalefactor. \n\n◆ blobFromImages() [2/2]\n\nvoid cv::dnn::blobFromImages \n(\nInputArrayOfArrays \nimages, \n\nOutputArray \nblob, \n\ndouble \nscalefactor = 1.0, \n\nSize \nsize = Size(), \n\nconst Scalar & \nmean = Scalar(), \n\nbool \nswapRB = false, \n\nbool \ncrop = false, \n\nint \nddepth = CV_32F \n\n)\n\nPython:cv.dnn.blobFromImages(images[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nCreates 4-dimensional blob from series of images. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ blobFromImagesWithParams() [1/2]\n\nMat cv::dnn::blobFromImagesWithParams \n(\nInputArrayOfArrays \nimages, \n\nconst Image2BlobParams & \nparam = Image2BlobParams() \n\n)\n\nPython:cv.dnn.blobFromImagesWithParams(images[, param]) -> retvalcv.dnn.blobFromImagesWithParams(images[, blob[, param]]) -> blob\n\n#include <opencv2/dnn/dnn.hpp>\nCreates 4-dimensional blob from series of images with given params. \nThis function is an extension of blobFromImages to meet more image preprocess needs. Given input image and preprocessing parameters, and function outputs the blob.\nParameters\n\nimagesinput image (all with 1-, 3- or 4-channels). \nparamstruct of Image2BlobParams, contains all parameters needed by processing of image to blob. \n\nReturns4-dimensional Mat. \n\n◆ blobFromImagesWithParams() [2/2]\n\nvoid cv::dnn::blobFromImagesWithParams \n(\nInputArrayOfArrays \nimages, \n\nOutputArray \nblob, \n\nconst Image2BlobParams & \nparam = Image2BlobParams() \n\n)\n\nPython:cv.dnn.blobFromImagesWithParams(images[, param]) -> retvalcv.dnn.blobFromImagesWithParams(images[, blob[, param]]) -> blob\n\n#include <opencv2/dnn/dnn.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ blobFromImageWithParams() [1/2]\n\nMat cv::dnn::blobFromImageWithParams \n(\nInputArray \nimage, \n\nconst Image2BlobParams & \nparam = Image2BlobParams() \n\n)\n\nPython:cv.dnn.blobFromImageWithParams(image[, param]) -> retvalcv.dnn.blobFromImageWithParams(image[, blob[, param]]) -> blob\n\n#include <opencv2/dnn/dnn.hpp>\nCreates 4-dimensional blob from image with given params. \nThis function is an extension of blobFromImage to meet more image preprocess needs. Given input image and preprocessing parameters, and function outputs the blob.\nParameters\n\nimageinput image (all with 1-, 3- or 4-channels). \nparamstruct of Image2BlobParams, contains all parameters needed by processing of image to blob. \n\nReturns4-dimensional Mat. \n\n◆ blobFromImageWithParams() [2/2]\n\nvoid cv::dnn::blobFromImageWithParams \n(\nInputArray \nimage, \n\nOutputArray \nblob, \n\nconst Image2BlobParams & \nparam = Image2BlobParams() \n\n)\n\nPython:cv.dnn.blobFromImageWithParams(image[, param]) -> retvalcv.dnn.blobFromImageWithParams(image[, blob[, param]]) -> blob\n\n#include <opencv2/dnn/dnn.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ enableModelDiagnostics()\n\nvoid cv::dnn::enableModelDiagnostics \n(\nbool \nisDiagnosticsMode)\n\n#include <opencv2/dnn/dnn.hpp>\nEnables detailed logging of the DNN model loading with CV DNN API. \nParameters\n\n[in]isDiagnosticsModeIndicates whether diagnostic mode should be set.\n\nDiagnostic mode provides detailed logging of the model loading stage to explore potential problems (ex.: not implemented layer type).\nNoteIn diagnostic mode series of assertions will be skipped, it can lead to the expected application crash. \n\n◆ getAvailableBackends()\n\nstd::vector< std::pair< Backend, Target > > cv::dnn::getAvailableBackends \n(\n)\n\n#include <opencv2/dnn/dnn.hpp>\n\n◆ getAvailableTargets()\n\nstd::vector< Target > cv::dnn::getAvailableTargets \n(\ndnn::Backend \nbe)\n\nPython:cv.dnn.getAvailableTargets(be) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\n\n◆ getLayerFactoryImpl()\n\nLayerFactory_Impl & cv::dnn::getLayerFactoryImpl \n(\n)\n\n#include <opencv2/dnn/layer_reg.private.hpp>\nRegister layer types of DNN model.\nNoteIn order to thread-safely access the factory, see getLayerFactoryMutex() function. \n\n◆ getLayerFactoryMutex()\n\nMutex & cv::dnn::getLayerFactoryMutex \n(\n)\n\n#include <opencv2/dnn/layer_reg.private.hpp>\nGet the mutex guarding LayerFactory_Impl, see getLayerFactoryImpl() function. \n\n◆ imagesFromBlob()\n\nvoid cv::dnn::imagesFromBlob \n(\nconst cv::Mat & \nblob_, \n\nOutputArrayOfArrays \nimages_ \n\n)\n\nPython:cv.dnn.imagesFromBlob(blob_[, images_]) -> images_\n\n#include <opencv2/dnn/dnn.hpp>\nParse a 4D blob and output the images it contains as 2D arrays through a simpler data structure (std::vector<cv::Mat>). \nParameters\n\n[in]blob_4 dimensional array (images, channels, height, width) in floating point precision (CV_32F) from which you would like to extract the images. \n[out]images_array of 2D Mat containing the images extracted from the blob in floating point precision (CV_32F). They are non normalized neither mean added. The number of returned images equals the first dimension of the blob (batch size). Every image has a number of channels equals to the second dimension of the blob (depth). \n\n◆ NMSBoxes() [1/3]\n\nvoid cv::dnn::NMSBoxes \n(\nconst std::vector< Rect > & \nbboxes, \n\nconst std::vector< float > & \nscores, \n\nconst float \nscore_threshold, \n\nconst float \nnms_threshold, \n\nstd::vector< int > & \nindices, \n\nconst float \neta = 1.f, \n\nconst int \ntop_k = 0 \n\n)\n\nPython:cv.dnn.NMSBoxes(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indicescv.dnn.NMSBoxesRotated(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indices\n\n#include <opencv2/dnn/dnn.hpp>\nPerforms non maximum suppression given boxes and corresponding scores. \nParameters\n\nbboxesa set of bounding boxes to apply NMS. \nscoresa set of corresponding confidences. \nscore_thresholda threshold used to filter boxes by score. \nnms_thresholda threshold used in non maximum suppression. \nindicesthe kept indices of bboxes after NMS. \netaa coefficient in adaptive threshold formula: \\(nms\\_threshold_{i+1}=eta\\cdot nms\\_threshold_i\\). \ntop_kif >0, keep at most top_k picked indices. \n\n◆ NMSBoxes() [2/3]\n\nvoid cv::dnn::NMSBoxes \n(\nconst std::vector< Rect2d > & \nbboxes, \n\nconst std::vector< float > & \nscores, \n\nconst float \nscore_threshold, \n\nconst float \nnms_threshold, \n\nstd::vector< int > & \nindices, \n\nconst float \neta = 1.f, \n\nconst int \ntop_k = 0 \n\n)\n\nPython:cv.dnn.NMSBoxes(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indicescv.dnn.NMSBoxesRotated(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indices\n\n#include <opencv2/dnn/dnn.hpp>\n\n◆ NMSBoxes() [3/3]\n\nvoid cv::dnn::NMSBoxes \n(\nconst std::vector< RotatedRect > & \nbboxes, \n\nconst std::vector< float > & \nscores, \n\nconst float \nscore_threshold, \n\nconst float \nnms_threshold, \n\nstd::vector< int > & \nindices, \n\nconst float \neta = 1.f, \n\nconst int \ntop_k = 0 \n\n)\n\nPython:cv.dnn.NMSBoxes(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indicescv.dnn.NMSBoxesRotated(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indices\n\n#include <opencv2/dnn/dnn.hpp>\n\n◆ NMSBoxesBatched() [1/2]\n\nvoid cv::dnn::NMSBoxesBatched \n(\nconst std::vector< Rect > & \nbboxes, \n\nconst std::vector< float > & \nscores, \n\nconst std::vector< int > & \nclass_ids, \n\nconst float \nscore_threshold, \n\nconst float \nnms_threshold, \n\nstd::vector< int > & \nindices, \n\nconst float \neta = 1.f, \n\nconst int \ntop_k = 0 \n\n)\n\nPython:cv.dnn.NMSBoxesBatched(bboxes, scores, class_ids, score_threshold, nms_threshold[, eta[, top_k]]) -> indices\n\n#include <opencv2/dnn/dnn.hpp>\nPerforms batched non maximum suppression on given boxes and corresponding scores across different classes. \nParameters\n\nbboxesa set of bounding boxes to apply NMS. \nscoresa set of corresponding confidences. \nclass_idsa set of corresponding class ids. Ids are integer and usually start from 0. \nscore_thresholda threshold used to filter boxes by score. \nnms_thresholda threshold used in non maximum suppression. \nindicesthe kept indices of bboxes after NMS. \netaa coefficient in adaptive threshold formula: \\(nms\\_threshold_{i+1}=eta\\cdot nms\\_threshold_i\\). \ntop_kif >0, keep at most top_k picked indices. \n\n◆ NMSBoxesBatched() [2/2]\n\nvoid cv::dnn::NMSBoxesBatched \n(\nconst std::vector< Rect2d > & \nbboxes, \n\nconst std::vector< float > & \nscores, \n\nconst std::vector< int > & \nclass_ids, \n\nconst float \nscore_threshold, \n\nconst float \nnms_threshold, \n\nstd::vector< int > & \nindices, \n\nconst float \neta = 1.f, \n\nconst int \ntop_k = 0 \n\n)\n\nPython:cv.dnn.NMSBoxesBatched(bboxes, scores, class_ids, score_threshold, nms_threshold[, eta[, top_k]]) -> indices\n\n#include <opencv2/dnn/dnn.hpp>\n\n◆ readNet() [1/2]\n\nNet cv::dnn::readNet \n(\nconst String & \nframework, \n\nconst std::vector< uchar > & \nbufferModel, \n\nconst std::vector< uchar > & \nbufferConfig = std::vector< uchar >() \n\n)\n\nPython:cv.dnn.readNet(model[, config[, framework]]) -> retvalcv.dnn.readNet(framework, bufferModel[, bufferConfig]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nRead deep learning network represented in one of the supported formats. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\n[in]frameworkName of origin framework. \n[in]bufferModelA buffer with a content of binary file with weights \n[in]bufferConfigA buffer with a content of text file contains network configuration. \n\nReturnsNet object. \n\n◆ readNet() [2/2]\n\nNet cv::dnn::readNet \n(\nCV_WRAP_FILE_PATH const String & \nmodel, \n\nCV_WRAP_FILE_PATH const String & \nconfig = \"\", \n\nconst String & \nframework = \"\" \n\n)\n\nPython:cv.dnn.readNet(model[, config[, framework]]) -> retvalcv.dnn.readNet(framework, bufferModel[, bufferConfig]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nRead deep learning network represented in one of the supported formats. \nParameters\n\n[in]modelBinary file contains trained weights. The following file extensions are expected for models from different frameworks:\n*.caffemodel (Caffe, http://caffe.berkeleyvision.org/)\n*.pb (TensorFlow, https://www.tensorflow.org/)\n*.t7 | *.net (Torch, http://torch.ch/)\n*.weights (Darknet, https://pjreddie.com/darknet/)\n*.bin | *.onnx (OpenVINO, https://software.intel.com/openvino-toolkit)\n*.onnx (ONNX, https://onnx.ai/) \n\n[in]configText file contains network configuration. It could be a file with the following extensions:\n*.prototxt (Caffe, http://caffe.berkeleyvision.org/)\n*.pbtxt (TensorFlow, https://www.tensorflow.org/)\n*.cfg (Darknet, https://pjreddie.com/darknet/)\n*.xml (OpenVINO, https://software.intel.com/openvino-toolkit) \n\n[in]frameworkExplicit framework name tag to determine a format. \n\nReturnsNet object.\nThis function automatically detects an origin framework of trained model and calls an appropriate function such readNetFromCaffe, readNetFromTensorflow, readNetFromTorch or readNetFromDarknet. An order of model and config arguments does not matter. \n\n◆ readNetFromCaffe() [1/3]\n\nNet cv::dnn::readNetFromCaffe \n(\nconst char * \nbufferProto, \n\nsize_t \nlenProto, \n\nconst char * \nbufferModel = NULL, \n\nsize_t \nlenModel = 0 \n\n)\n\nPython:cv.dnn.readNetFromCaffe(prototxt[, caffeModel]) -> retvalcv.dnn.readNetFromCaffe(bufferProto[, bufferModel]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Caffe model in memory. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nbufferProtobuffer containing the content of the .prototxt file \nlenProtolength of bufferProto \nbufferModelbuffer containing the content of the .caffemodel file \nlenModellength of bufferModel \n\nReturnsNet object. \n\n◆ readNetFromCaffe() [2/3]\n\nNet cv::dnn::readNetFromCaffe \n(\nconst std::vector< uchar > & \nbufferProto, \n\nconst std::vector< uchar > & \nbufferModel = std::vector< uchar >() \n\n)\n\nPython:cv.dnn.readNetFromCaffe(prototxt[, caffeModel]) -> retvalcv.dnn.readNetFromCaffe(bufferProto[, bufferModel]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Caffe model in memory. \nParameters\n\nbufferProtobuffer containing the content of the .prototxt file \nbufferModelbuffer containing the content of the .caffemodel file \n\nReturnsNet object. \n\n◆ readNetFromCaffe() [3/3]\n\nNet cv::dnn::readNetFromCaffe \n(\nCV_WRAP_FILE_PATH const String & \nprototxt, \n\nCV_WRAP_FILE_PATH const String & \ncaffeModel = String() \n\n)\n\nPython:cv.dnn.readNetFromCaffe(prototxt[, caffeModel]) -> retvalcv.dnn.readNetFromCaffe(bufferProto[, bufferModel]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Caffe framework's format. \nParameters\n\nprototxtpath to the .prototxt file with text description of the network architecture. \ncaffeModelpath to the .caffemodel file with learned network. \n\nReturnsNet object. \n\n◆ readNetFromDarknet() [1/3]\n\nNet cv::dnn::readNetFromDarknet \n(\nconst char * \nbufferCfg, \n\nsize_t \nlenCfg, \n\nconst char * \nbufferModel = NULL, \n\nsize_t \nlenModel = 0 \n\n)\n\nPython:cv.dnn.readNetFromDarknet(cfgFile[, darknetModel]) -> retvalcv.dnn.readNetFromDarknet(bufferCfg[, bufferModel]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Darknet model files. \nParameters\n\nbufferCfgA buffer contains a content of .cfg file with text description of the network architecture. \nlenCfgNumber of bytes to read from bufferCfg \nbufferModelA buffer contains a content of .weights file with learned network. \nlenModelNumber of bytes to read from bufferModel \n\nReturnsNet object. \n\n◆ readNetFromDarknet() [2/3]\n\nNet cv::dnn::readNetFromDarknet \n(\nconst std::vector< uchar > & \nbufferCfg, \n\nconst std::vector< uchar > & \nbufferModel = std::vector< uchar >() \n\n)\n\nPython:cv.dnn.readNetFromDarknet(cfgFile[, darknetModel]) -> retvalcv.dnn.readNetFromDarknet(bufferCfg[, bufferModel]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Darknet model files. \nParameters\n\nbufferCfgA buffer contains a content of .cfg file with text description of the network architecture. \nbufferModelA buffer contains a content of .weights file with learned network. \n\nReturnsNet object. \n\n◆ readNetFromDarknet() [3/3]\n\nNet cv::dnn::readNetFromDarknet \n(\nCV_WRAP_FILE_PATH const String & \ncfgFile, \n\nCV_WRAP_FILE_PATH const String & \ndarknetModel = String() \n\n)\n\nPython:cv.dnn.readNetFromDarknet(cfgFile[, darknetModel]) -> retvalcv.dnn.readNetFromDarknet(bufferCfg[, bufferModel]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Darknet model files. \nParameters\n\ncfgFilepath to the .cfg file with text description of the network architecture. \ndarknetModelpath to the .weights file with learned network. \n\nReturnsNetwork object that ready to do forward, throw an exception in failure cases. \n\n◆ readNetFromModelOptimizer() [1/3]\n\nNet cv::dnn::readNetFromModelOptimizer \n(\nconst std::vector< uchar > & \nbufferModelConfig, \n\nconst std::vector< uchar > & \nbufferWeights \n\n)\n\nPython:cv.dnn.readNetFromModelOptimizer(xml[, bin]) -> retvalcv.dnn.readNetFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nLoad a network from Intel's Model Optimizer intermediate representation. \nParameters\n\n[in]bufferModelConfigBuffer contains XML configuration with network's topology. \n[in]bufferWeightsBuffer contains binary data with trained weights. \n\nReturnsNet object. Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine backend. \n\n◆ readNetFromModelOptimizer() [2/3]\n\nNet cv::dnn::readNetFromModelOptimizer \n(\nconst uchar * \nbufferModelConfigPtr, \n\nsize_t \nbufferModelConfigSize, \n\nconst uchar * \nbufferWeightsPtr, \n\nsize_t \nbufferWeightsSize \n\n)\n\nPython:cv.dnn.readNetFromModelOptimizer(xml[, bin]) -> retvalcv.dnn.readNetFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nLoad a network from Intel's Model Optimizer intermediate representation. \nParameters\n\n[in]bufferModelConfigPtrPointer to buffer which contains XML configuration with network's topology. \n[in]bufferModelConfigSizeBinary size of XML configuration data. \n[in]bufferWeightsPtrPointer to buffer which contains binary data with trained weights. \n[in]bufferWeightsSizeBinary size of trained weights data. \n\nReturnsNet object. Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine backend. \n\n◆ readNetFromModelOptimizer() [3/3]\n\nNet cv::dnn::readNetFromModelOptimizer \n(\nCV_WRAP_FILE_PATH const String & \nxml, \n\nCV_WRAP_FILE_PATH const String & \nbin = \"\" \n\n)\n\nPython:cv.dnn.readNetFromModelOptimizer(xml[, bin]) -> retvalcv.dnn.readNetFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nLoad a network from Intel's Model Optimizer intermediate representation. \nParameters\n\n[in]xmlXML configuration file with network's topology. \n[in]binBinary file with trained weights. \n\nReturnsNet object. Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine backend. \n\n◆ readNetFromONNX() [1/3]\n\nNet cv::dnn::readNetFromONNX \n(\nconst char * \nbuffer, \n\nsize_t \nsizeBuffer \n\n)\n\nPython:cv.dnn.readNetFromONNX(onnxFile) -> retvalcv.dnn.readNetFromONNX(buffer) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model from ONNX in-memory buffer. \nParameters\n\nbuffermemory address of the first byte of the buffer. \nsizeBuffersize of the buffer. \n\nReturnsNetwork object that ready to do forward, throw an exception in failure cases. \n\n◆ readNetFromONNX() [2/3]\n\nNet cv::dnn::readNetFromONNX \n(\nconst std::vector< uchar > & \nbuffer)\n\nPython:cv.dnn.readNetFromONNX(onnxFile) -> retvalcv.dnn.readNetFromONNX(buffer) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model from ONNX in-memory buffer. \nParameters\n\nbufferin-memory buffer that stores the ONNX model bytes. \n\nReturnsNetwork object that ready to do forward, throw an exception in failure cases. \n\n◆ readNetFromONNX() [3/3]\n\nNet cv::dnn::readNetFromONNX \n(\nCV_WRAP_FILE_PATH const String & \nonnxFile)\n\nPython:cv.dnn.readNetFromONNX(onnxFile) -> retvalcv.dnn.readNetFromONNX(buffer) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model ONNX. \nParameters\n\nonnxFilepath to the .onnx file with text description of the network architecture. \n\nReturnsNetwork object that ready to do forward, throw an exception in failure cases. \n\n◆ readNetFromTensorflow() [1/3]\n\nNet cv::dnn::readNetFromTensorflow \n(\nconst char * \nbufferModel, \n\nsize_t \nlenModel, \n\nconst char * \nbufferConfig = NULL, \n\nsize_t \nlenConfig = 0 \n\n)\n\nPython:cv.dnn.readNetFromTensorflow(model[, config]) -> retvalcv.dnn.readNetFromTensorflow(bufferModel[, bufferConfig]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in TensorFlow framework's format. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nbufferModelbuffer containing the content of the pb file \nlenModellength of bufferModel \nbufferConfigbuffer containing the content of the pbtxt file \nlenConfiglength of bufferConfig \n\n◆ readNetFromTensorflow() [2/3]\n\nNet cv::dnn::readNetFromTensorflow \n(\nconst std::vector< uchar > & \nbufferModel, \n\nconst std::vector< uchar > & \nbufferConfig = std::vector< uchar >() \n\n)\n\nPython:cv.dnn.readNetFromTensorflow(model[, config]) -> retvalcv.dnn.readNetFromTensorflow(bufferModel[, bufferConfig]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in TensorFlow framework's format. \nParameters\n\nbufferModelbuffer containing the content of the pb file \nbufferConfigbuffer containing the content of the pbtxt file \n\nReturnsNet object. \n\n◆ readNetFromTensorflow() [3/3]\n\nNet cv::dnn::readNetFromTensorflow \n(\nCV_WRAP_FILE_PATH const String & \nmodel, \n\nCV_WRAP_FILE_PATH const String & \nconfig = String() \n\n)\n\nPython:cv.dnn.readNetFromTensorflow(model[, config]) -> retvalcv.dnn.readNetFromTensorflow(bufferModel[, bufferConfig]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in TensorFlow framework's format. \nParameters\n\nmodelpath to the .pb file with binary protobuf description of the network architecture \nconfigpath to the .pbtxt file that contains text graph definition in protobuf format. Resulting Net object is built by text graph using weights from a binary one that let us make it more flexible. \n\nReturnsNet object. \n\n◆ readNetFromTFLite() [1/3]\n\nNet cv::dnn::readNetFromTFLite \n(\nconst char * \nbufferModel, \n\nsize_t \nlenModel \n\n)\n\nPython:cv.dnn.readNetFromTFLite(model) -> retvalcv.dnn.readNetFromTFLite(bufferModel) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in TFLite framework's format. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nbufferModelbuffer containing the content of the tflite file \nlenModellength of bufferModel \n\n◆ readNetFromTFLite() [2/3]\n\nNet cv::dnn::readNetFromTFLite \n(\nconst std::vector< uchar > & \nbufferModel)\n\nPython:cv.dnn.readNetFromTFLite(model) -> retvalcv.dnn.readNetFromTFLite(bufferModel) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in TFLite framework's format. \nParameters\n\nbufferModelbuffer containing the content of the tflite file \n\nReturnsNet object. \n\n◆ readNetFromTFLite() [3/3]\n\nNet cv::dnn::readNetFromTFLite \n(\nCV_WRAP_FILE_PATH const String & \nmodel)\n\nPython:cv.dnn.readNetFromTFLite(model) -> retvalcv.dnn.readNetFromTFLite(bufferModel) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in TFLite framework's format. \nParameters\n\nmodelpath to the .tflite file with binary flatbuffers description of the network architecture \n\nReturnsNet object. \n\n◆ readNetFromTorch()\n\nNet cv::dnn::readNetFromTorch \n(\nCV_WRAP_FILE_PATH const String & \nmodel, \n\nbool \nisBinary = true, \n\nbool \nevaluate = true \n\n)\n\nPython:cv.dnn.readNetFromTorch(model[, isBinary[, evaluate]]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nReads a network model stored in Torch7 framework's format. \nParameters\n\nmodelpath to the file, dumped from Torch by using torch.save() function. \nisBinaryspecifies whether the network was serialized in ascii mode or binary. \nevaluatespecifies testing phase of network. If true, it's similar to evaluate() method in Torch. \n\nReturnsNet object.\nNoteAscii mode of Torch serializer is more preferable, because binary mode extensively use long type of C language, which has various bit-length on different systems.\nThe loading file must contain serialized nn.Module object with importing network. Try to eliminate a custom objects from serialazing data to avoid importing errors.\nList of supported layers (i.e. object instances derived from Torch nn.Module class):\nnn.Sequential\nnn.Parallel\nnn.Concat\nnn.Linear\nnn.SpatialConvolution\nnn.SpatialMaxPooling, nn.SpatialAveragePooling\nnn.ReLU, nn.TanH, nn.Sigmoid\nnn.Reshape\nnn.SoftMax, nn.LogSoftMax\n\nAlso some equivalents of these classes from cunn, cudnn, and fbcunn may be successfully imported. \n\n◆ readTensorFromONNX()\n\nMat cv::dnn::readTensorFromONNX \n(\nCV_WRAP_FILE_PATH const String & \npath)\n\nPython:cv.dnn.readTensorFromONNX(path) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nCreates blob from .pb file. \nParameters\n\npathto the .pb file with input tensor. \n\nReturnsMat. \n\n◆ readTorchBlob()\n\nMat cv::dnn::readTorchBlob \n(\nconst String & \nfilename, \n\nbool \nisBinary = true \n\n)\n\nPython:cv.dnn.readTorchBlob(filename[, isBinary]) -> retval\n\n#include <opencv2/dnn/dnn.hpp>\nLoads blob which was serialized as torch.Tensor object of Torch7 framework. \nWarningThis function has the same limitations as readNetFromTorch(). \n\n◆ shrinkCaffeModel()\n\nvoid cv::dnn::shrinkCaffeModel \n(\nCV_WRAP_FILE_PATH const String & \nsrc, \n\nCV_WRAP_FILE_PATH const String & \ndst, \n\nconst std::vector< String > & \nlayersTypes = std::vector< String >() \n\n)\n\nPython:cv.dnn.shrinkCaffeModel(src, dst[, layersTypes]) -> None\n\n#include <opencv2/dnn/dnn.hpp>\nConvert all weights of Caffe network to half precision floating point. \nParameters\n\nsrcPath to origin model from Caffe framework contains single precision floating point weights (usually has .caffemodel extension). \ndstPath to destination model with updated weights. \nlayersTypesSet of layers types which parameters will be converted. By default, converts only Convolutional and Fully-Connected layers' weights.\n\nNoteShrinked model has no origin float32 weights so it can't be used in origin Caffe framework anymore. However the structure of data is taken from NVidia's Caffe fork: https://github.com/NVIDIA/caffe. So the resulting model may be used there. \n\n◆ softNMSBoxes()\n\nvoid cv::dnn::softNMSBoxes \n(\nconst std::vector< Rect > & \nbboxes, \n\nconst std::vector< float > & \nscores, \n\nstd::vector< float > & \nupdated_scores, \n\nconst float \nscore_threshold, \n\nconst float \nnms_threshold, \n\nstd::vector< int > & \nindices, \n\nsize_t \ntop_k = 0, \n\nconst float \nsigma = 0.5, \n\nSoftNMSMethod \nmethod = SoftNMSMethod::SOFTNMS_GAUSSIAN \n\n)\n\nPython:cv.dnn.softNMSBoxes(bboxes, scores, score_threshold, nms_threshold[, top_k[, sigma[, method]]]) -> updated_scores, indices\n\n#include <opencv2/dnn/dnn.hpp>\nPerforms soft non maximum suppression given boxes and corresponding scores. Reference: https://arxiv.org/abs/1704.04503. \nParameters\n\nbboxesa set of bounding boxes to apply Soft NMS. \nscoresa set of corresponding confidences. \nupdated_scoresa set of corresponding updated confidences. \nscore_thresholda threshold used to filter boxes by score. \nnms_thresholda threshold used in non maximum suppression. \nindicesthe kept indices of bboxes after NMS. \ntop_kkeep at most top_k picked indices. \nsigmaparameter of Gaussian weighting. \nmethodGaussian or linear. \n\nSee alsoSoftNMSMethod \n\n◆ writeTextGraph()\n\nvoid cv::dnn::writeTextGraph \n(\nCV_WRAP_FILE_PATH const String & \nmodel, \n\nCV_WRAP_FILE_PATH const String & \noutput \n\n)\n\nPython:cv.dnn.writeTextGraph(model, output) -> None\n\n#include <opencv2/dnn/dnn.hpp>\nCreate a text representation for a binary network stored in protocol buffer format. \nParameters\n\n[in]modelA path to binary network. \n[in]outputA path to output text file to be created.\n\nNoteTo reduce output file size, trained weights are not included. \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d6/d17/group__cudabgsegm.html","content_type":"text/html","title":"OpenCV: Background Segmentation","language":null},"page_content":"OpenCV: Background Segmentation\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nBackground SegmentationCUDA-accelerated Computer Vision\n\nDetailed Description\n\nClasses\nclass  cv::cuda::BackgroundSubtractorMOG\n Gaussian Mixture-based Background/Foreground Segmentation Algorithm.  More...\n \nclass  cv::cuda::BackgroundSubtractorMOG2\n Gaussian Mixture-based Background/Foreground Segmentation Algorithm.  More...\n \n\nFunctions\nPtr< cuda::BackgroundSubtractorMOG > cv::cuda::createBackgroundSubtractorMOG (int history=200, int nmixtures=5, double backgroundRatio=0.7, double noiseSigma=0)\n Creates mixture-of-gaussian background subtractor.  \n \nPtr< cuda::BackgroundSubtractorMOG2 > cv::cuda::createBackgroundSubtractorMOG2 (int history=500, double varThreshold=16, bool detectShadows=true)\n Creates MOG2 Background Subtractor.  \n \n\nFunction Documentation\n\n◆ createBackgroundSubtractorMOG()\n\nPtr< cuda::BackgroundSubtractorMOG > cv::cuda::createBackgroundSubtractorMOG \n(\nint \nhistory = 200, \n\nint \nnmixtures = 5, \n\ndouble \nbackgroundRatio = 0.7, \n\ndouble \nnoiseSigma = 0 \n\n)\n\n#include <opencv2/cudabgsegm.hpp>\nCreates mixture-of-gaussian background subtractor. \nParameters\n\nhistoryLength of the history. \nnmixturesNumber of Gaussian mixtures. \nbackgroundRatioBackground ratio. \nnoiseSigmaNoise strength (standard deviation of the brightness or each color channel). 0 means some automatic value. \n\n◆ createBackgroundSubtractorMOG2()\n\nPtr< cuda::BackgroundSubtractorMOG2 > cv::cuda::createBackgroundSubtractorMOG2 \n(\nint \nhistory = 500, \n\ndouble \nvarThreshold = 16, \n\nbool \ndetectShadows = true \n\n)\n\n#include <opencv2/cudabgsegm.hpp>\nCreates MOG2 Background Subtractor. \nParameters\n\nhistoryLength of the history. \nvarThresholdThreshold on the squared Mahalanobis distance between the pixel and the model to decide whether a pixel is well described by the background model. This parameter does not affect the background update. \ndetectShadowsIf true, the algorithm will detect shadows and mark them. It decreases the speed a bit, so if you do not need this feature, set the parameter to false. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d2/d84/group__optflow.html","content_type":"text/html","title":"OpenCV: Optical Flow Algorithms","language":null},"page_content":"OpenCV: Optical Flow Algorithms\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nTypedefs |\nEnumerations |\nFunctions \nOptical Flow Algorithms\n\nDetailed Description\nDense optical flow algorithms compute motion for each point:\n\ncv::optflow::calcOpticalFlowSF\ncv::optflow::createOptFlow_DeepFlow\n\nMotion templates is alternative technique for detecting motion and computing its direction. See samples/motempl.py.\n\ncv::motempl::updateMotionHistory\ncv::motempl::calcMotionGradient\ncv::motempl::calcGlobalOrientation\ncv::motempl::segmentMotion\n\nFunctions reading and writing .flo files in \"Middlebury\" format, see: http://vision.middlebury.edu/flow/code/flow-code/README.txt\n\ncv::optflow::readOpticalFlow\ncv::optflow::writeOpticalFlow \n\nClasses\nclass  cv::optflow::DenseRLOFOpticalFlow\n Fast dense optical flow computation based on robust local optical flow (RLOF) algorithms and sparse-to-dense interpolation scheme.  More...\n \nclass  cv::optflow::DualTVL1OpticalFlow\n \"Dual TV L1\" Optical Flow Algorithm.  More...\n \nclass  cv::optflow::GPCDetails\n \nclass  cv::optflow::GPCForest< T >\n \nstruct  cv::optflow::GPCMatchingParams\n Class encapsulating matching parameters.  More...\n \nstruct  cv::optflow::GPCPatchDescriptor\n \nstruct  cv::optflow::GPCPatchSample\n \nstruct  cv::optflow::GPCTrainingParams\n Class encapsulating training parameters.  More...\n \nclass  cv::optflow::GPCTrainingSamples\n Class encapsulating training samples.  More...\n \nclass  cv::optflow::GPCTree\n Class for individual tree.  More...\n \nclass  cv::optflow::OpticalFlowPCAFlow\n PCAFlow algorithm.  More...\n \nclass  cv::optflow::PCAPrior\n This class can be used for imposing a learned prior on the resulting optical flow. Solution will be regularized according to this prior. You need to generate appropriate prior file with \"learn_prior.py\" script beforehand.  More...\n \nclass  cv::optflow::RLOFOpticalFlowParameter\n This is used store and set up the parameters of the robust local optical flow (RLOF) algoritm.  More...\n \nclass  cv::optflow::SparseRLOFOpticalFlow\n Class used for calculation sparse optical flow and feature tracking with robust local optical flow (RLOF) algorithms.  More...\n \n\nTypedefs\ntypedef std::vector< GPCPatchSample > cv::optflow::GPCSamplesVector\n \n\nEnumerations\nenum  cv::optflow::GPCDescType { \n  cv::optflow::GPC_DESCRIPTOR_DCT = 0\n, \n  cv::optflow::GPC_DESCRIPTOR_WHT\n\n }\n Descriptor types for the Global Patch Collider.  More...\n \nenum  cv::optflow::InterpolationType { \n  cv::optflow::INTERP_GEO = 0\n, \n  cv::optflow::INTERP_EPIC = 1\n, \n  cv::optflow::INTERP_RIC = 2\n\n }\n \nenum  cv::optflow::SolverType { \n  cv::optflow::ST_STANDART = 0\n, \n  cv::optflow::ST_BILINEAR = 1\n\n }\n \nenum  cv::optflow::SupportRegionType { \n  cv::optflow::SR_FIXED = 0\n, \n  cv::optflow::SR_CROSS = 1\n\n }\n \n\nFunctions\ndouble cv::motempl::calcGlobalOrientation (InputArray orientation, InputArray mask, InputArray mhi, double timestamp, double duration)\n Calculates a global motion orientation in a selected region.  \n \nvoid cv::motempl::calcMotionGradient (InputArray mhi, OutputArray mask, OutputArray orientation, double delta1, double delta2, int apertureSize=3)\n Calculates a gradient orientation of a motion history image.  \n \nvoid cv::optflow::calcOpticalFlowDenseRLOF (InputArray I0, InputArray I1, InputOutputArray flow, Ptr< RLOFOpticalFlowParameter > rlofParam=Ptr< RLOFOpticalFlowParameter >(), float forwardBackwardThreshold=0, Size gridStep=Size(6, 6), InterpolationType interp_type=InterpolationType::INTERP_EPIC, int epicK=128, float epicSigma=0.05f, float epicLambda=100.f, int ricSPSize=15, int ricSLICType=100, bool use_post_proc=true, float fgsLambda=500.0f, float fgsSigma=1.5f, bool use_variational_refinement=false)\n Fast dense optical flow computation based on robust local optical flow (RLOF) algorithms and sparse-to-dense interpolation scheme.  \n \nvoid cv::optflow::calcOpticalFlowSF (InputArray from, InputArray to, OutputArray flow, int layers, int averaging_block_size, int max_flow)\n \nvoid cv::optflow::calcOpticalFlowSF (InputArray from, InputArray to, OutputArray flow, int layers, int averaging_block_size, int max_flow, double sigma_dist, double sigma_color, int postprocess_window, double sigma_dist_fix, double sigma_color_fix, double occ_thr, int upscale_averaging_radius, double upscale_sigma_dist, double upscale_sigma_color, double speed_up_thr)\n Calculate an optical flow using \"SimpleFlow\" algorithm.  \n \nvoid cv::optflow::calcOpticalFlowSparseRLOF (InputArray prevImg, InputArray nextImg, InputArray prevPts, InputOutputArray nextPts, OutputArray status, OutputArray err, Ptr< RLOFOpticalFlowParameter > rlofParam=Ptr< RLOFOpticalFlowParameter >(), float forwardBackwardThreshold=0)\n Calculates fast optical flow for a sparse feature set using the robust local optical flow (RLOF) similar to optflow::calcOpticalFlowPyrLK().  \n \nvoid cv::optflow::calcOpticalFlowSparseToDense (InputArray from, InputArray to, OutputArray flow, int grid_step=8, int k=128, float sigma=0.05f, bool use_post_proc=true, float fgs_lambda=500.0f, float fgs_sigma=1.5f)\n Fast dense optical flow based on PyrLK sparse matches interpolation.  \n \nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_DeepFlow ()\n DeepFlow optical flow algorithm implementation.  \n \nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_DenseRLOF ()\n Additional interface to the Dense RLOF algorithm - optflow::calcOpticalFlowDenseRLOF() \n \nPtr< DualTVL1OpticalFlow > cv::optflow::createOptFlow_DualTVL1 ()\n Creates instance of cv::DenseOpticalFlow.  \n \nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_Farneback ()\n Additional interface to the Farneback's algorithm - calcOpticalFlowFarneback() \n \nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_PCAFlow ()\n Creates an instance of PCAFlow.  \n \nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_SimpleFlow ()\n Additional interface to the SimpleFlow algorithm - calcOpticalFlowSF() \n \nPtr< SparseOpticalFlow > cv::optflow::createOptFlow_SparseRLOF ()\n Additional interface to the Sparse RLOF algorithm - optflow::calcOpticalFlowSparseRLOF() \n \nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_SparseToDense ()\n Additional interface to the SparseToDenseFlow algorithm - calcOpticalFlowSparseToDense() \n \nvoid cv::optflow::GPCForest< T >::findCorrespondences (InputArray imgFrom, InputArray imgTo, std::vector< std::pair< Point2i, Point2i > > &corr, const GPCMatchingParams params=GPCMatchingParams()) const\n Find correspondences between two images.  \n \nvoid cv::motempl::segmentMotion (InputArray mhi, OutputArray segmask, std::vector< Rect > &boundingRects, double timestamp, double segThresh)\n Splits a motion history image into a few parts corresponding to separate independent motions (for example, left hand, right hand).  \n \nvoid cv::motempl::updateMotionHistory (InputArray silhouette, InputOutputArray mhi, double timestamp, double duration)\n Updates the motion history image by a moving silhouette.  \n \n\nTypedef Documentation\n\n◆ GPCSamplesVector\n\ntypedef std::vector< GPCPatchSample > cv::optflow::GPCSamplesVector\n\n#include <opencv2/optflow/sparse_matching_gpc.hpp>\n\nEnumeration Type Documentation\n\n◆ GPCDescType\n\nenum cv::optflow::GPCDescType\n\n#include <opencv2/optflow/sparse_matching_gpc.hpp>\nDescriptor types for the Global Patch Collider. \n\nEnumeratorGPC_DESCRIPTOR_DCT Python: cv.optflow.GPC_DESCRIPTOR_DCTBetter quality but slow. \n\nGPC_DESCRIPTOR_WHT Python: cv.optflow.GPC_DESCRIPTOR_WHTWorse quality but much faster. \n\n◆ InterpolationType\n\nenum cv::optflow::InterpolationType\n\n#include <opencv2/optflow/rlofflow.hpp>\n\nEnumeratorINTERP_GEO Python: cv.optflow.INTERP_GEOFast geodesic interpolation, see [103] \n\nINTERP_EPIC Python: cv.optflow.INTERP_EPICEdge-preserving interpolation using ximgproc::EdgeAwareInterpolator, see [225],Geistert2016. \n\nINTERP_RIC Python: cv.optflow.INTERP_RICSLIC based robust interpolation using ximgproc::RICInterpolator, see [130]. \n\n◆ SolverType\n\nenum cv::optflow::SolverType\n\n#include <opencv2/optflow/rlofflow.hpp>\n\nEnumeratorST_STANDART Python: cv.optflow.ST_STANDARTApply standard iterative refinement \n\nST_BILINEAR Python: cv.optflow.ST_BILINEARApply optimized iterative refinement based bilinear equation solutions as described in [239] \n\n◆ SupportRegionType\n\nenum cv::optflow::SupportRegionType\n\n#include <opencv2/optflow/rlofflow.hpp>\n\nEnumeratorSR_FIXED Python: cv.optflow.SR_FIXEDApply a constant support region \n\nSR_CROSS Python: cv.optflow.SR_CROSSApply a adaptive support region obtained by cross-based segmentation as described in [240] \n\nFunction Documentation\n\n◆ calcGlobalOrientation()\n\ndouble cv::motempl::calcGlobalOrientation \n(\nInputArray \norientation, \n\nInputArray \nmask, \n\nInputArray \nmhi, \n\ndouble \ntimestamp, \n\ndouble \nduration \n\n)\n\nPython:cv.motempl.calcGlobalOrientation(orientation, mask, mhi, timestamp, duration) -> retval\n\n#include <opencv2/optflow/motempl.hpp>\nCalculates a global motion orientation in a selected region. \nParameters\n\norientationMotion gradient orientation image calculated by the function calcMotionGradient \nmaskMask image. It may be a conjunction of a valid gradient mask, also calculated by calcMotionGradient , and the mask of a region whose direction needs to be calculated. \nmhiMotion history image calculated by updateMotionHistory . \ntimestampTimestamp passed to updateMotionHistory . \ndurationMaximum duration of a motion track in milliseconds, passed to updateMotionHistory\n\nThe function calculates an average motion direction in the selected region and returns the angle between 0 degrees and 360 degrees. The average direction is computed from the weighted orientation histogram, where a recent motion has a larger weight and the motion occurred in the past has a smaller weight, as recorded in mhi . \n\n◆ calcMotionGradient()\n\nvoid cv::motempl::calcMotionGradient \n(\nInputArray \nmhi, \n\nOutputArray \nmask, \n\nOutputArray \norientation, \n\ndouble \ndelta1, \n\ndouble \ndelta2, \n\nint \napertureSize = 3 \n\n)\n\nPython:cv.motempl.calcMotionGradient(mhi, delta1, delta2[, mask[, orientation[, apertureSize]]]) -> mask, orientation\n\n#include <opencv2/optflow/motempl.hpp>\nCalculates a gradient orientation of a motion history image. \nParameters\n\nmhiMotion history single-channel floating-point image. \nmaskOutput mask image that has the type CV_8UC1 and the same size as mhi . Its non-zero elements mark pixels where the motion gradient data is correct. \norientationOutput motion gradient orientation image that has the same type and the same size as mhi . Each pixel of the image is a motion orientation, from 0 to 360 degrees. \ndelta1Minimal (or maximal) allowed difference between mhi values within a pixel neighborhood. \ndelta2Maximal (or minimal) allowed difference between mhi values within a pixel neighborhood. That is, the function finds the minimum ( \\(m(x,y)\\) ) and maximum ( \\(M(x,y)\\) ) mhi values over \\(3 \\times 3\\) neighborhood of each pixel and marks the motion orientation at \\((x, y)\\) as valid only if \n\\[\\min ( \\texttt{delta1}  ,  \\texttt{delta2}  )  \\le  M(x,y)-m(x,y)  \\le   \\max ( \\texttt{delta1}  , \\texttt{delta2} ).\\]\n\napertureSizeAperture size of the Sobel operator.\n\nThe function calculates a gradient orientation at each pixel \\((x, y)\\) as:\n\n\\[\\texttt{orientation} (x,y)= \\arctan{\\frac{d\\texttt{mhi}/dy}{d\\texttt{mhi}/dx}}\\]\n\nIn fact, fastAtan2 and phase are used so that the computed angle is measured in degrees and covers the full range 0..360. Also, the mask is filled to indicate pixels where the computed angle is valid.\nNote\n(Python) An example on how to perform a motion template technique can be found at opencv_source_code/samples/python2/motempl.py \n\n◆ calcOpticalFlowDenseRLOF()\n\nvoid cv::optflow::calcOpticalFlowDenseRLOF \n(\nInputArray \nI0, \n\nInputArray \nI1, \n\nInputOutputArray \nflow, \n\nPtr< RLOFOpticalFlowParameter > \nrlofParam = Ptr< RLOFOpticalFlowParameter >(), \n\nfloat \nforwardBackwardThreshold = 0, \n\nSize \ngridStep = Size(6, 6), \n\nInterpolationType \ninterp_type = InterpolationType::INTERP_EPIC, \n\nint \nepicK = 128, \n\nfloat \nepicSigma = 0.05f, \n\nfloat \nepicLambda = 100.f, \n\nint \nricSPSize = 15, \n\nint \nricSLICType = 100, \n\nbool \nuse_post_proc = true, \n\nfloat \nfgsLambda = 500.0f, \n\nfloat \nfgsSigma = 1.5f, \n\nbool \nuse_variational_refinement = false \n\n)\n\nPython:cv.optflow.calcOpticalFlowDenseRLOF(I0, I1, flow[, rlofParam[, forwardBackwardThreshold[, gridStep[, interp_type[, epicK[, epicSigma[, epicLambda[, ricSPSize[, ricSLICType[, use_post_proc[, fgsLambda[, fgsSigma[, use_variational_refinement]]]]]]]]]]]]]) -> flow\n\n#include <opencv2/optflow/rlofflow.hpp>\nFast dense optical flow computation based on robust local optical flow (RLOF) algorithms and sparse-to-dense interpolation scheme. \nThe RLOF is a fast local optical flow approach described in [238] [239] [240] and [241] similar to the pyramidal iterative Lucas-Kanade method as proposed by [36]. More details and experiments can be found in the following thesis [242]. The implementation is derived from optflow::calcOpticalFlowPyrLK().\nThe sparse-to-dense interpolation scheme allows for fast computation of dense optical flow using RLOF (see [103]). For this scheme the following steps are applied:\nmotion vector seeded at a regular sampled grid are computed. The sparsity of this grid can be configured with setGridStep\n(optinally) errornous motion vectors are filter based on the forward backward confidence. The threshold can be configured with setForwardBackward. The filter is only applied if the threshold >0 but than the runtime is doubled due to the estimation of the backward flow.\nVector field interpolation is applied to the motion vector set to obtain a dense vector field.\n\nParameters\n\nI0first 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image. \nI1second 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image. \nflowcomputed flow image that has the same size as I0 and type CV_32FC2. \nrlofParamsee optflow::RLOFOpticalFlowParameter \nforwardBackwardThresholdThreshold for the forward backward confidence check. For each grid point \\( \\mathbf{x} \\) a motion vector \\( d_{I0,I1}(\\mathbf{x}) \\) is computed. If the forward backward error \n\\[ EP_{FB} = || d_{I0,I1} + d_{I1,I0} || \\]\n\n is larger than threshold given by this function then the motion vector will not be used by the following vector field interpolation. \\( d_{I1,I0} \\) denotes the backward flow. Note, the forward backward test will only be applied if the threshold > 0. This may results into a doubled runtime for the motion estimation. \ngridStepSize of the grid to spawn the motion vectors. For each grid point a motion vector is computed. Some motion vectors will be removed due to the forwatd backward threshold (if set >0). The rest will be the base of the vector field interpolation. \ninterp_typeinterpolation method used to compute the dense optical flow. Two interpolation algorithms are supported:\nINTERP_GEO applies the fast geodesic interpolation, see [103].\nINTERP_EPIC_RESIDUAL applies the edge-preserving interpolation, see [225],Geistert2016. \n\nepicKsee ximgproc::EdgeAwareInterpolator sets the respective parameter. \nepicSigmasee ximgproc::EdgeAwareInterpolator sets the respective parameter. \nepicLambdasee ximgproc::EdgeAwareInterpolator sets the respective parameter. \nricSPSizesee ximgproc::RICInterpolator sets the respective parameter. \nricSLICTypesee ximgproc::RICInterpolator sets the respective parameter. \nuse_post_procenables ximgproc::fastGlobalSmootherFilter() parameter. \nfgsLambdasets the respective ximgproc::fastGlobalSmootherFilter() parameter. \nfgsSigmasets the respective ximgproc::fastGlobalSmootherFilter() parameter. \nuse_variational_refinementenables VariationalRefinement\n\nParameters have been described in [238], [239], [240], [241]. For the RLOF configuration see optflow::RLOFOpticalFlowParameter for further details. NoteIf the grid size is set to (1,1) and the forward backward threshold <= 0 that the dense optical flow field is purely computed with the RLOF.\n\nSIMD parallelization is only available when compiling with SSE4.1. \n\nNote that in output, if no correspondences are found between I0 and I1, the flow is set to 0.\nSee alsooptflow::DenseRLOFOpticalFlow, optflow::RLOFOpticalFlowParameter \n\n◆ calcOpticalFlowSF() [1/2]\n\nvoid cv::optflow::calcOpticalFlowSF \n(\nInputArray \nfrom, \n\nInputArray \nto, \n\nOutputArray \nflow, \n\nint \nlayers, \n\nint \naveraging_block_size, \n\nint \nmax_flow \n\n)\n\nPython:cv.optflow.calcOpticalFlowSF(from_, to, layers, averaging_block_size, max_flow[, flow]) -> flowcv.optflow.calcOpticalFlowSF(from_, to, layers, averaging_block_size, max_flow, sigma_dist, sigma_color, postprocess_window, sigma_dist_fix, sigma_color_fix, occ_thr, upscale_averaging_radius, upscale_sigma_dist, upscale_sigma_color, speed_up_thr[, flow]) -> flow\n\n#include <opencv2/optflow.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ calcOpticalFlowSF() [2/2]\n\nvoid cv::optflow::calcOpticalFlowSF \n(\nInputArray \nfrom, \n\nInputArray \nto, \n\nOutputArray \nflow, \n\nint \nlayers, \n\nint \naveraging_block_size, \n\nint \nmax_flow, \n\ndouble \nsigma_dist, \n\ndouble \nsigma_color, \n\nint \npostprocess_window, \n\ndouble \nsigma_dist_fix, \n\ndouble \nsigma_color_fix, \n\ndouble \nocc_thr, \n\nint \nupscale_averaging_radius, \n\ndouble \nupscale_sigma_dist, \n\ndouble \nupscale_sigma_color, \n\ndouble \nspeed_up_thr \n\n)\n\nPython:cv.optflow.calcOpticalFlowSF(from_, to, layers, averaging_block_size, max_flow[, flow]) -> flowcv.optflow.calcOpticalFlowSF(from_, to, layers, averaging_block_size, max_flow, sigma_dist, sigma_color, postprocess_window, sigma_dist_fix, sigma_color_fix, occ_thr, upscale_averaging_radius, upscale_sigma_dist, upscale_sigma_color, speed_up_thr[, flow]) -> flow\n\n#include <opencv2/optflow.hpp>\nCalculate an optical flow using \"SimpleFlow\" algorithm. \nParameters\n\nfromFirst 8-bit 3-channel image. \ntoSecond 8-bit 3-channel image of the same size as prev \nflowcomputed flow image that has the same size as prev and type CV_32FC2 \nlayersNumber of layers \naveraging_block_sizeSize of block through which we sum up when calculate cost function for pixel \nmax_flowmaximal flow that we search at each level \nsigma_distvector smooth spatial sigma parameter \nsigma_colorvector smooth color sigma parameter \npostprocess_windowwindow size for postprocess cross bilateral filter \nsigma_dist_fixspatial sigma for postprocess cross bilateralf filter \nsigma_color_fixcolor sigma for postprocess cross bilateral filter \nocc_thrthreshold for detecting occlusions \nupscale_averaging_radiuswindow size for bilateral upscale operation \nupscale_sigma_distspatial sigma for bilateral upscale operation \nupscale_sigma_colorcolor sigma for bilateral upscale operation \nspeed_up_thrthreshold to detect point with irregular flow - where flow should be recalculated after upscale\n\nSee [264] . And site of project - http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/.\nNote\nAn example using the simpleFlow algorithm can be found at samples/simpleflow_demo.cpp \n\n◆ calcOpticalFlowSparseRLOF()\n\nvoid cv::optflow::calcOpticalFlowSparseRLOF \n(\nInputArray \nprevImg, \n\nInputArray \nnextImg, \n\nInputArray \nprevPts, \n\nInputOutputArray \nnextPts, \n\nOutputArray \nstatus, \n\nOutputArray \nerr, \n\nPtr< RLOFOpticalFlowParameter > \nrlofParam = Ptr< RLOFOpticalFlowParameter >(), \n\nfloat \nforwardBackwardThreshold = 0 \n\n)\n\nPython:cv.optflow.calcOpticalFlowSparseRLOF(prevImg, nextImg, prevPts, nextPts[, status[, err[, rlofParam[, forwardBackwardThreshold]]]]) -> nextPts, status, err\n\n#include <opencv2/optflow/rlofflow.hpp>\nCalculates fast optical flow for a sparse feature set using the robust local optical flow (RLOF) similar to optflow::calcOpticalFlowPyrLK(). \nThe RLOF is a fast local optical flow approach described in [238] [239] [240] and [241] similar to the pyramidal iterative Lucas-Kanade method as proposed by [36]. More details and experiments can be found in the following thesis [242]. The implementation is derived from optflow::calcOpticalFlowPyrLK().\nParameters\n\nprevImgfirst 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image. \nnextImgsecond 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image. \nprevPtsvector of 2D points for which the flow needs to be found; point coordinates must be single-precision floating-point numbers. \nnextPtsoutput vector of 2D points (with single-precision floating-point coordinates) containing the calculated new positions of input features in the second image; when optflow::RLOFOpticalFlowParameter::useInitialFlow variable is true the vector must have the same size as in the input and contain the initialization point correspondences. \nstatusoutput status vector (of unsigned chars); each element of the vector is set to 1 if the flow for the corresponding features has passed the forward backward check. \nerroutput vector of errors; each element of the vector is set to the forward backward error for the corresponding feature. \nrlofParamsee optflow::RLOFOpticalFlowParameter \nforwardBackwardThresholdThreshold for the forward backward confidence check. If forewardBackwardThreshold <=0 the forward\n\nNoteSIMD parallelization is only available when compiling with SSE4.1.\nParameters have been described in [238], [239], [240] and [241]. For the RLOF configuration see optflow::RLOFOpticalFlowParameter for further details. \n\n◆ calcOpticalFlowSparseToDense()\n\nvoid cv::optflow::calcOpticalFlowSparseToDense \n(\nInputArray \nfrom, \n\nInputArray \nto, \n\nOutputArray \nflow, \n\nint \ngrid_step = 8, \n\nint \nk = 128, \n\nfloat \nsigma = 0.05f, \n\nbool \nuse_post_proc = true, \n\nfloat \nfgs_lambda = 500.0f, \n\nfloat \nfgs_sigma = 1.5f \n\n)\n\nPython:cv.optflow.calcOpticalFlowSparseToDense(from_, to[, flow[, grid_step[, k[, sigma[, use_post_proc[, fgs_lambda[, fgs_sigma]]]]]]]) -> flow\n\n#include <opencv2/optflow.hpp>\nFast dense optical flow based on PyrLK sparse matches interpolation. \nParameters\n\nfromfirst 8-bit 3-channel or 1-channel image. \ntosecond 8-bit 3-channel or 1-channel image of the same size as from \nflowcomputed flow image that has the same size as from and CV_32FC2 type \ngrid_stepstride used in sparse match computation. Lower values usually result in higher quality but slow down the algorithm. \nknumber of nearest-neighbor matches considered, when fitting a locally affine model. Lower values can make the algorithm noticeably faster at the cost of some quality degradation. \nsigmaparameter defining how fast the weights decrease in the locally-weighted affine fitting. Higher values can help preserve fine details, lower values can help to get rid of the noise in the output flow. \nuse_post_procdefines whether the ximgproc::fastGlobalSmootherFilter() is used for post-processing after interpolation \nfgs_lambdasee the respective parameter of the ximgproc::fastGlobalSmootherFilter() \nfgs_sigmasee the respective parameter of the ximgproc::fastGlobalSmootherFilter() \n\n◆ createOptFlow_DeepFlow()\n\nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_DeepFlow \n(\n)\n\nPython:cv.optflow.createOptFlow_DeepFlow() -> retval\n\n#include <opencv2/optflow.hpp>\nDeepFlow optical flow algorithm implementation. \nThe class implements the DeepFlow optical flow algorithm described in [296] . See also http://lear.inrialpes.fr/src/deepmatching/ . Parameters - class fields - that may be modified after creating a class instance:\nmember float alpha Smoothness assumption weight\nmember float delta Color constancy assumption weight\nmember float gamma Gradient constancy weight\nmember float sigma Gaussian smoothing parameter\nmember int minSize Minimal dimension of an image in the pyramid (next, smaller images in the pyramid are generated until one of the dimensions reaches this size)\nmember float downscaleFactor Scaling factor in the image pyramid (must be < 1)\nmember int fixedPointIterations How many iterations on each level of the pyramid\nmember int sorIterations Iterations of Succesive Over-Relaxation (solver)\nmember float omega Relaxation factor in SOR \n\n◆ createOptFlow_DenseRLOF()\n\nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_DenseRLOF \n(\n)\n\nPython:cv.optflow.createOptFlow_DenseRLOF() -> retval\n\n#include <opencv2/optflow/rlofflow.hpp>\nAdditional interface to the Dense RLOF algorithm - optflow::calcOpticalFlowDenseRLOF() \n\n◆ createOptFlow_DualTVL1()\n\nPtr< DualTVL1OpticalFlow > cv::optflow::createOptFlow_DualTVL1 \n(\n)\n\nPython:cv.optflow.createOptFlow_DualTVL1() -> retval\n\n#include <opencv2/optflow.hpp>\nCreates instance of cv::DenseOpticalFlow. \n\n◆ createOptFlow_Farneback()\n\nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_Farneback \n(\n)\n\nPython:cv.optflow.createOptFlow_Farneback() -> retval\n\n#include <opencv2/optflow.hpp>\nAdditional interface to the Farneback's algorithm - calcOpticalFlowFarneback() \n\n◆ createOptFlow_PCAFlow()\n\nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_PCAFlow \n(\n)\n\nPython:cv.optflow.createOptFlow_PCAFlow() -> retval\n\n#include <opencv2/optflow/pcaflow.hpp>\nCreates an instance of PCAFlow. \n\n◆ createOptFlow_SimpleFlow()\n\nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_SimpleFlow \n(\n)\n\nPython:cv.optflow.createOptFlow_SimpleFlow() -> retval\n\n#include <opencv2/optflow.hpp>\nAdditional interface to the SimpleFlow algorithm - calcOpticalFlowSF() \n\n◆ createOptFlow_SparseRLOF()\n\nPtr< SparseOpticalFlow > cv::optflow::createOptFlow_SparseRLOF \n(\n)\n\nPython:cv.optflow.createOptFlow_SparseRLOF() -> retval\n\n#include <opencv2/optflow/rlofflow.hpp>\nAdditional interface to the Sparse RLOF algorithm - optflow::calcOpticalFlowSparseRLOF() \n\n◆ createOptFlow_SparseToDense()\n\nPtr< DenseOpticalFlow > cv::optflow::createOptFlow_SparseToDense \n(\n)\n\nPython:cv.optflow.createOptFlow_SparseToDense() -> retval\n\n#include <opencv2/optflow.hpp>\nAdditional interface to the SparseToDenseFlow algorithm - calcOpticalFlowSparseToDense() \n\n◆ findCorrespondences()\n\ntemplate<int T> \n\nvoid cv::optflow::GPCForest< T >::findCorrespondences \n(\nInputArray \nimgFrom, \n\nInputArray \nimgTo, \n\nstd::vector< std::pair< Point2i, Point2i > > & \ncorr, \n\nconst GPCMatchingParams \nparams = GPCMatchingParams() \n\n)\n const\n\n#include <opencv2/optflow/sparse_matching_gpc.hpp>\nFind correspondences between two images. \nParameters\n\n[in]imgFromFirst image in a sequence. \n[in]imgToSecond image in a sequence. \n[out]corrOutput vector with pairs of corresponding points. \n[in]paramsAdditional matching parameters for fine-tuning. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ segmentMotion()\n\nvoid cv::motempl::segmentMotion \n(\nInputArray \nmhi, \n\nOutputArray \nsegmask, \n\nstd::vector< Rect > & \nboundingRects, \n\ndouble \ntimestamp, \n\ndouble \nsegThresh \n\n)\n\nPython:cv.motempl.segmentMotion(mhi, timestamp, segThresh[, segmask]) -> segmask, boundingRects\n\n#include <opencv2/optflow/motempl.hpp>\nSplits a motion history image into a few parts corresponding to separate independent motions (for example, left hand, right hand). \nParameters\n\nmhiMotion history image. \nsegmaskImage where the found mask should be stored, single-channel, 32-bit floating-point. \nboundingRectsVector containing ROIs of motion connected components. \ntimestampCurrent time in milliseconds or other units. \nsegThreshSegmentation threshold that is recommended to be equal to the interval between motion history \"steps\" or greater.\n\nThe function finds all of the motion segments and marks them in segmask with individual values (1,2,...). It also computes a vector with ROIs of motion connected components. After that the motion direction for every component can be calculated with calcGlobalOrientation using the extracted mask of the particular component. \n\n◆ updateMotionHistory()\n\nvoid cv::motempl::updateMotionHistory \n(\nInputArray \nsilhouette, \n\nInputOutputArray \nmhi, \n\ndouble \ntimestamp, \n\ndouble \nduration \n\n)\n\nPython:cv.motempl.updateMotionHistory(silhouette, mhi, timestamp, duration) -> mhi\n\n#include <opencv2/optflow/motempl.hpp>\nUpdates the motion history image by a moving silhouette. \nParameters\n\nsilhouetteSilhouette mask that has non-zero pixels where the motion occurs. \nmhiMotion history image that is updated by the function (single-channel, 32-bit floating-point). \ntimestampCurrent time in milliseconds or other units. \ndurationMaximal duration of the motion track in the same units as timestamp .\n\nThe function updates the motion history image as follows:\n\n\\[\\texttt{mhi} (x,y)= \\forkthree{\\texttt{timestamp}}{if \\(\\texttt{silhouette}(x,y) \\ne 0\\)}{0}{if \\(\\texttt{silhouette}(x,y) = 0\\) and \\(\\texttt{mhi} < (\\texttt{timestamp} - \\texttt{duration})\\)}{\\texttt{mhi}(x,y)}{otherwise}\\]\n\nThat is, MHI pixels where the motion occurs are set to the current timestamp , while the pixels where the motion happened last time a long time ago are cleared.\nThe function, together with calcMotionGradient and calcGlobalOrientation , implements a motion templates technique described in [66] and [38] . \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/df8/tutorial_root.html","content_type":"text/html","title":"OpenCV: OpenCV Tutorials","language":null},"page_content":"OpenCV: OpenCV Tutorials\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nOpenCV Tutorials\n\nIntroduction to OpenCV - build and install OpenCV on your computer\nThe Core Functionality (core module) - basic building blocks of the library\nImage Processing (imgproc module) - image processing functions\nApplication utils (highgui, imgcodecs, videoio modules) - application utils (GUI, image/video input/output)\nCamera calibration and 3D reconstruction (calib3d module) - extract 3D world information from 2D images\nObject Detection (objdetect module) - INSERT OBJDETECT MODULE INFO\n2D Features framework (feature2d module) - feature detectors, descriptors and matching framework\nDeep Neural Networks (dnn module) - infer neural networks using built-in dnn module\nGraph API (gapi module) - graph-based approach to computer vision algorithms building\nOther tutorials (ml, objdetect, photo, stitching, video) - other modules (ml, objdetect, stitching, video, photo)\nOpenCV iOS - running OpenCV on an iDevice\nGPU-Accelerated Computer Vision (cuda module) - utilizing power of video card to run CV algorithms \n\nGenerated on Mon Nov 11 2024 23:11:41 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/db/d29/group__cudawarping.html","content_type":"text/html","title":"OpenCV: Image Warping","language":null},"page_content":"OpenCV: Image Warping\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nFunctions \nImage WarpingCUDA-accelerated Computer Vision\n\nDetailed Description\n\nFunctions\nvoid cv::cuda::buildWarpAffineMaps (InputArray M, bool inverse, Size dsize, OutputArray xmap, OutputArray ymap, Stream &stream=Stream::Null())\n Builds transformation maps for affine transformation.  \n \nvoid cv::cuda::buildWarpAffineMaps (Mat M, bool inverse, Size dsize, GpuMat &xmap, GpuMat &ymap, Stream &stream=Stream::Null())\n \nvoid cv::cuda::buildWarpAffineMaps (UMat M, bool inverse, Size dsize, GpuMat &xmap, GpuMat &ymap, Stream &stream=Stream::Null())\n \nvoid cv::cuda::buildWarpPerspectiveMaps (InputArray M, bool inverse, Size dsize, OutputArray xmap, OutputArray ymap, Stream &stream=Stream::Null())\n Builds transformation maps for perspective transformation.  \n \nvoid cv::cuda::buildWarpPerspectiveMaps (Mat M, bool inverse, Size dsize, GpuMat &xmap, GpuMat &ymap, Stream &stream=Stream::Null())\n \nvoid cv::cuda::buildWarpPerspectiveMaps (UMat M, bool inverse, Size dsize, GpuMat &xmap, GpuMat &ymap, Stream &stream=Stream::Null())\n \nvoid cv::cuda::pyrDown (InputArray src, OutputArray dst, Stream &stream=Stream::Null())\n Smoothes an image and downsamples it.  \n \nvoid cv::cuda::pyrUp (InputArray src, OutputArray dst, Stream &stream=Stream::Null())\n Upsamples an image and then smoothes it.  \n \nvoid cv::cuda::remap (InputArray src, OutputArray dst, InputArray xmap, InputArray ymap, int interpolation, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n Applies a generic geometrical transformation to an image.  \n \nvoid cv::cuda::resize (InputArray src, OutputArray dst, Size dsize, double fx=0, double fy=0, int interpolation=INTER_LINEAR, Stream &stream=Stream::Null())\n Resizes an image.  \n \nvoid cv::cuda::rotate (InputArray src, OutputArray dst, Size dsize, double angle, double xShift=0, double yShift=0, int interpolation=INTER_LINEAR, Stream &stream=Stream::Null())\n Rotates an image around the origin (0,0) and then shifts it.  \n \nvoid cv::cuda::warpAffine (InputArray src, OutputArray dst, InputArray M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n Applies an affine transformation to an image.  \n \nvoid cv::cuda::warpAffine (InputArray src, OutputArray dst, Mat M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n \nvoid cv::cuda::warpAffine (InputArray src, OutputArray dst, UMat M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n \nvoid cv::cuda::warpPerspective (InputArray src, OutputArray dst, InputArray M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n Applies a perspective transformation to an image.  \n \nvoid cv::cuda::warpPerspective (InputArray src, OutputArray dst, Mat M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n \nvoid cv::cuda::warpPerspective (InputArray src, OutputArray dst, UMat M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, Scalar borderValue=Scalar(), Stream &stream=Stream::Null())\n \n\nFunction Documentation\n\n◆ buildWarpAffineMaps() [1/3]\n\nvoid cv::cuda::buildWarpAffineMaps \n(\nInputArray \nM, \n\nbool \ninverse, \n\nSize \ndsize, \n\nOutputArray \nxmap, \n\nOutputArray \nymap, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nBuilds transformation maps for affine transformation. \nParameters\n\nM2x3 Mat or UMat transformation matrix. \ninverseFlag specifying that M is an inverse transformation ( dst=>src ). \ndsizeSize of the destination image. \nxmapX values with CV_32FC1 type. \nymapY values with CV_32FC1 type. \nstreamStream for the asynchronous version.\n\nSee alsocuda::warpAffine , cuda::remap \n\n◆ buildWarpAffineMaps() [2/3]\n\nvoid cv::cuda::buildWarpAffineMaps \n(\nMat \nM, \n\nbool \ninverse, \n\nSize \ndsize, \n\nGpuMat & \nxmap, \n\nGpuMat & \nymap, \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ buildWarpAffineMaps() [3/3]\n\nvoid cv::cuda::buildWarpAffineMaps \n(\nUMat \nM, \n\nbool \ninverse, \n\nSize \ndsize, \n\nGpuMat & \nxmap, \n\nGpuMat & \nymap, \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ buildWarpPerspectiveMaps() [1/3]\n\nvoid cv::cuda::buildWarpPerspectiveMaps \n(\nInputArray \nM, \n\nbool \ninverse, \n\nSize \ndsize, \n\nOutputArray \nxmap, \n\nOutputArray \nymap, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nBuilds transformation maps for perspective transformation. \nParameters\n\nM3x3 Mat or UMat transformation matrix. \ninverseFlag specifying that M is an inverse transformation ( dst=>src ). \ndsizeSize of the destination image. \nxmapX values with CV_32FC1 type. \nymapY values with CV_32FC1 type. \nstreamStream for the asynchronous version.\n\nSee alsocuda::warpPerspective , cuda::remap \n\n◆ buildWarpPerspectiveMaps() [2/3]\n\nvoid cv::cuda::buildWarpPerspectiveMaps \n(\nMat \nM, \n\nbool \ninverse, \n\nSize \ndsize, \n\nGpuMat & \nxmap, \n\nGpuMat & \nymap, \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ buildWarpPerspectiveMaps() [3/3]\n\nvoid cv::cuda::buildWarpPerspectiveMaps \n(\nUMat \nM, \n\nbool \ninverse, \n\nSize \ndsize, \n\nGpuMat & \nxmap, \n\nGpuMat & \nymap, \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ pyrDown()\n\nvoid cv::cuda::pyrDown \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nSmoothes an image and downsamples it. \nParameters\n\nsrcSource image. \ndstDestination image. Will have Size((src.cols+1)/2, (src.rows+1)/2) size and the same type as src . \nstreamStream for the asynchronous version.\n\nSee alsopyrDown \n\n◆ pyrUp()\n\nvoid cv::cuda::pyrUp \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nUpsamples an image and then smoothes it. \nParameters\n\nsrcSource image. \ndstDestination image. Will have Size(src.cols*2, src.rows*2) size and the same type as src . \nstreamStream for the asynchronous version. \n\n◆ remap()\n\nvoid cv::cuda::remap \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \nxmap, \n\nInputArray \nymap, \n\nint \ninterpolation, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nApplies a generic geometrical transformation to an image. \nParameters\n\nsrcSource image. \ndstDestination image with the size the same as xmap and the type the same as src . \nxmapX values. Only CV_32FC1 type is supported. \nymapY values. Only CV_32FC1 type is supported. \ninterpolationInterpolation method (see resize ). INTER_NEAREST , INTER_LINEAR and INTER_CUBIC are supported for now. The extra flag WARP_RELATIVE_MAP can be ORed to the interpolation method (e.g. INTER_LINEAR | WARP_RELATIVE_MAP) \nborderModePixel extrapolation method (see borderInterpolate ). BORDER_REFLECT101 , BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now. \nborderValueValue used in case of a constant border. By default, it is 0. \nstreamStream for the asynchronous version.\n\nThe function transforms the source image using the specified map:\n\n\\[\\texttt{dst} (x,y) =  \\texttt{src} (xmap(x,y), ymap(x,y))\\]\n\nwith the WARP_RELATIVE_MAP flag :\n\n\\[\\texttt{dst} (x,y) =  \\texttt{src} (x+map_x(x,y),y+map_y(x,y))\\]\n\nValues of pixels with non-integer coordinates are computed using the bilinear interpolation.\nSee alsoremap \n\n◆ resize()\n\nvoid cv::cuda::resize \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nSize \ndsize, \n\ndouble \nfx = 0, \n\ndouble \nfy = 0, \n\nint \ninterpolation = INTER_LINEAR, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nResizes an image. \nParameters\n\nsrcSource image. \ndstDestination image with the same type as src . The size is dsize (when it is non-zero) or the size is computed from src.size() , fx , and fy . \ndsizeDestination image size. If it is zero, it is computed as: \n\\[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\]\n\n Either dsize or both fx and fy must be non-zero. \nfxScale factor along the horizontal axis. If it is zero, it is computed as: \n\\[\\texttt{(double)dsize.width/src.cols}\\]\n\nfyScale factor along the vertical axis. If it is zero, it is computed as: \n\\[\\texttt{(double)dsize.height/src.rows}\\]\n\ninterpolationInterpolation method. INTER_NEAREST , INTER_LINEAR and INTER_CUBIC are supported for now. \nstreamStream for the asynchronous version.\n\nSee alsoresize \n\n◆ rotate()\n\nvoid cv::cuda::rotate \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nSize \ndsize, \n\ndouble \nangle, \n\ndouble \nxShift = 0, \n\ndouble \nyShift = 0, \n\nint \ninterpolation = INTER_LINEAR, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nRotates an image around the origin (0,0) and then shifts it. \nParameters\n\nsrcSource image. Supports 1, 3 or 4 channels images with CV_8U , CV_16U or CV_32F depth. \ndstDestination image with the same type as src . The size is dsize . \ndsizeSize of the destination image. \nangleAngle of rotation in degrees. \nxShiftShift along the horizontal axis. \nyShiftShift along the vertical axis. \ninterpolationInterpolation method. Only INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC are supported. \nstreamStream for the asynchronous version.\n\nSee alsocuda::warpAffine \n\n◆ warpAffine() [1/3]\n\nvoid cv::cuda::warpAffine \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \nM, \n\nSize \ndsize, \n\nint \nflags = INTER_LINEAR, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nApplies an affine transformation to an image. \nParameters\n\nsrcSource image. CV_8U , CV_16U , CV_32S , or CV_32F depth and 1, 3, or 4 channels are supported. \ndstDestination image with the same type as src . The size is dsize . \nM2x3 Mat or UMat transformation matrix. \ndsizeSize of the destination image. \nflagsCombination of interpolation methods (see resize) and the optional flag WARP_INVERSE_MAP specifying that M is an inverse transformation ( dst=>src ). Only INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are supported. \nborderMode\nborderValue\nstreamStream for the asynchronous version.\n\nSee alsowarpAffine \n\n◆ warpAffine() [2/3]\n\nvoid cv::cuda::warpAffine \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nMat \nM, \n\nSize \ndsize, \n\nint \nflags = INTER_LINEAR, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpAffine() [3/3]\n\nvoid cv::cuda::warpAffine \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nUMat \nM, \n\nSize \ndsize, \n\nint \nflags = INTER_LINEAR, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpPerspective() [1/3]\n\nvoid cv::cuda::warpPerspective \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \nM, \n\nSize \ndsize, \n\nint \nflags = INTER_LINEAR, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudawarping.hpp>\nApplies a perspective transformation to an image. \nParameters\n\nsrcSource image. CV_8U , CV_16U , CV_32S , or CV_32F depth and 1, 3, or 4 channels are supported. \ndstDestination image with the same type as src . The size is dsize . \nM3x3 Mat or UMat transformation matrix. \ndsizeSize of the destination image. \nflagsCombination of interpolation methods (see resize ) and the optional flag WARP_INVERSE_MAP specifying that M is the inverse transformation ( dst => src ). Only INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are supported. \nborderMode\nborderValue\nstreamStream for the asynchronous version.\n\nSee alsowarpPerspective \n\n◆ warpPerspective() [2/3]\n\nvoid cv::cuda::warpPerspective \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nMat \nM, \n\nSize \ndsize, \n\nint \nflags = INTER_LINEAR, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpPerspective() [3/3]\n\nvoid cv::cuda::warpPerspective \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nUMat \nM, \n\nSize \ndsize, \n\nint \nflags = INTER_LINEAR, \n\nint \nborderMode = BORDER_CONSTANT, \n\nScalar \nborderValue = Scalar(), \n\nStream & \nstream = Stream::Null() \n\n)\n\ninline \n\n#include <opencv2/cudawarping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/d25/group__surface__matching.html","content_type":"text/html","title":"OpenCV: Surface Matching","language":null},"page_content":"OpenCV: Surface Matching\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nTypedefs |\nFunctions \nSurface Matching\n\nDetailed Description\n\nNote about the License and Patents\nThe following patents have been issued for methods embodied in this software: \"Recognition and pose determination of 3D objects in 3D scenes\nusing geometric point pair descriptors and the generalized Hough\nTransform\", Bertram Heinrich Drost, Markus Ulrich, EP Patent 2385483 (Nov. 21, 2012), assignee: MVTec Software GmbH, 81675 Muenchen (Germany); \"Recognition and pose determination of 3D objects in 3D\nscenes\", Bertram Heinrich Drost, Markus Ulrich, US Patent 8830229 (Sept. 9, 2014), assignee: MVTec Software GmbH, 81675 Muenchen (Germany). Further patents are pending. For further details, contact MVTec Software GmbH (info@.nosp@m.mvte.nosp@m.c.com).\nNote that restrictions imposed by these patents (and possibly others) exist independently of and may be in conflict with the freedoms granted in this license, which refers to copyright of the program, not patents for any methods that it implements. Both copyright and patent law must be obeyed to legally use and redistribute this program and it is not the purpose of this license to induce you to infringe any patents or other property right claims or to contest validity of any such claims. If you redistribute or use the program, then this license merely protects you from committing copyright infringement. It does not protect you from committing patent infringement. So, before you do anything with this program, make sure that you have permission to do so not merely in terms of copyright, but also in terms of patent law.\nPlease note that this license is not to be understood as a guarantee either. If you use the program according to this license, but in conflict with patent law, it does not mean that the licensor will refund you for any losses that you incur if you are sued for your patent infringement.\n\nIntroduction to Surface Matching\nCameras and similar devices with the capability of sensation of 3D structure are becoming more common. Thus, using depth and intensity information for matching 3D objects (or parts) are of crucial importance for computer vision. Applications range from industrial control to guiding everyday actions for visually impaired people. The task in recognition and pose estimation in range images aims to identify and localize a queried 3D free-form object by matching it to the acquired database.\nFrom an industrial perspective, enabling robots to automatically locate and pick up randomly placed and oriented objects from a bin is an important challenge in factory automation, replacing tedious and heavy manual labor. A system should be able to recognize and locate objects with a predefined shape and estimate the position with the precision necessary for a gripping robot to pick it up. This is where vision guided robotics takes the stage. Similar tools are also capable of guiding robots (and even people) through unstructured environments, leading to automated navigation. These properties make 3D matching from point clouds a ubiquitous necessity. Within this context, I will now describe the OpenCV implementation of a 3D object recognition and pose estimation algorithm using 3D features.\n\nSurface Matching Algorithm Through 3D Features\nThe state of the algorithms in order to achieve the task 3D matching is heavily based on [72], which is one of the first and main practical methods presented in this area. The approach is composed of extracting 3D feature points randomly from depth images or generic point clouds, indexing them and later in runtime querying them efficiently. Only the 3D structure is considered, and a trivial hash table is used for feature queries.\nWhile being fully aware that utilization of the nice CAD model structure in order to achieve a smart point sampling, I will be leaving that aside now in order to respect the generalizability of the methods (Typically for such algorithms training on a CAD model is not needed, and a point cloud would be sufficient). Below is the outline of the entire algorithm:\n\nOutline of the Algorithm\nAs explained, the algorithm relies on the extraction and indexing of point pair features, which are defined as follows:\n\n\\[\\bf{{F}}(\\bf{{m1}}, \\bf{{m2}}) = (||\\bf{{d}}||_2, <(\\bf{{n1}},\\bf{{d}}), <(\\bf{{n2}},\\bf{{d}}), <(\\bf{{n1}},\\bf{{n2}}))\\]\n\nwhere \\(\\bf{{m1}}\\) and \\(\\bf{{m2}}\\) are feature two selected points on the model (or scene), \\(\\bf{{d}}\\) is the difference vector, \\(\\bf{{n1}}\\) and \\(\\bf{{n2}}\\) are the normals at \\(\\bf{{m1}}\\) and \\(\\bf{m2}\\). During the training stage, this vector is quantized, indexed. In the test stage, same features are extracted from the scene and compared to the database. With a few tricks like separation of the rotational components, the pose estimation part can also be made efficient (check the reference for more details). A Hough-like voting and clustering is employed to estimate the object pose. To cluster the poses, the raw pose hypotheses are sorted in decreasing order of the number of votes. From the highest vote, a new cluster is created. If the next pose hypothesis is close to one of the existing clusters, the hypothesis is added to the cluster and the cluster center is updated as the average of the pose hypotheses within the cluster. If the next hypothesis is not close to any of the clusters, it creates a new cluster. The proximity testing is done with fixed thresholds in translation and rotation. Distance computation and averaging for translation are performed in the 3D Euclidean space, while those for rotation are performed using quaternion representation. After clustering, the clusters are sorted in decreasing order of the total number of votes which determines confidence of the estimated poses.\nThis pose is further refined using \\(ICP\\) in order to obtain the final pose.\nPPF presented above depends largely on robust computation of angles between 3D vectors. Even though not reported in the paper, the naive way of doing this ( \\(\\theta = cos^{-1}({\\bf{a}}\\cdot{\\bf{b}})\\) remains numerically unstable. A better way to do this is then use inverse tangents, like:\n\n\\[<(\\bf{n1},\\bf{n2})=tan^{-1}(||{\\bf{n1}  \\wedge \\bf{n2}}||_2, \\bf{n1} \\cdot \\bf{n2})\\]\n\nRough Computation of Object Pose Given PPF\nLet me summarize the following notation:\n\n\\(p^i_m\\): \\(i^{th}\\) point of the model ( \\(p^j_m\\) accordingly)\n\\(n^i_m\\): Normal of the \\(i^{th}\\) point of the model ( \\(n^j_m\\) accordingly)\n\\(p^i_s\\): \\(i^{th}\\) point of the scene ( \\(p^j_s\\) accordingly)\n\\(n^i_s\\): Normal of the \\(i^{th}\\) point of the scene ( \\(n^j_s\\) accordingly)\n\\(T_{m\\rightarrow g}\\): The transformation required to translate \\(p^i_m\\) to the origin and rotate its normal \\(n^i_m\\) onto the \\(x\\)-axis.\n\\(R_{m\\rightarrow g}\\): Rotational component of \\(T_{m\\rightarrow g}\\).\n\\(t_{m\\rightarrow g}\\): Translational component of \\(T_{m\\rightarrow g}\\).\n\\((p^i_m)^{'}\\): \\(i^{th}\\) point of the model transformed by \\(T_{m\\rightarrow g}\\). ( \\((p^j_m)^{'}\\) accordingly).\n\\({\\bf{R_{m\\rightarrow g}}}\\): Axis angle representation of rotation \\(R_{m\\rightarrow g}\\).\n\\(\\theta_{m\\rightarrow g}\\): The angular component of the axis angle representation \\({\\bf{R_{m\\rightarrow g}}}\\).\n\nThe transformation in a point pair feature is computed by first finding the transformation \\(T_{m\\rightarrow g}\\) from the first point, and applying the same transformation to the second one. Transforming each point, together with the normal, to the ground plane leaves us with an angle to find out, during a comparison with a new point pair.\nWe could now simply start writing\n\n\\[(p^i_m)^{'} = T_{m\\rightarrow g} p^i_m\\]\n\nwhere\n\n\\[T_{m\\rightarrow g} = -t_{m\\rightarrow g}R_{m\\rightarrow g}\\]\n\nNote that this is nothing but a stacked transformation. The translational component \\(t_{m\\rightarrow g}\\) reads\n\n\\[t_{m\\rightarrow g} = -R_{m\\rightarrow g}p^i_m\\]\n\nand the rotational being\n\n\\[\\theta_{m\\rightarrow g} = \\cos^{-1}(n^i_m \\cdot {\\bf{x}})\\\\\n {\\bf{R_{m\\rightarrow g}}} = n^i_m \\wedge {\\bf{x}}\\]\n\nin axis angle format. Note that bold refers to the vector form. After this transformation, the feature vectors of the model are registered onto the ground plane X and the angle with respect to \\(x=0\\) is called \\(\\alpha_m\\). Similarly, for the scene, it is called \\(\\alpha_s\\).\n\nHough-like Voting Scheme\nAs shown in the outline, PPF (point pair features) are extracted from the model, quantized, stored in the hashtable and indexed, during the training stage. During the runtime however, the similar operation is perfomed on the input scene with the exception that this time a similarity lookup over the hashtable is performed, instead of an insertion. This lookup also allows us to compute a transformation to the ground plane for the scene pairs. After this point, computing the rotational component of the pose reduces to computation of the difference \\(\\alpha=\\alpha_m-\\alpha_s\\). This component carries the cue about the object pose. A Hough-like voting scheme is performed over the local model coordinate vector and \\(\\alpha\\). The highest poses achieved for every scene point lets us recover the object pose.\n\nSource Code for PPF Matching\n// pc is the loaded point cloud of the model\n// (Nx6) and pcTest is a loaded point cloud of\n// the scene (Mx6)\nppf_match_3d::PPF3DDetector detector(0.03, 0.05);\ndetector.trainModel(pc);\nvector<Pose3DPtr> results;\ndetector.match(pcTest, results, 1.0/10.0, 0.05);\ncout << \"Poses: \" << endl;\n// print the poses\nfor (size_t i=0; i<results.size(); i++)\n{\n Pose3DPtr pose = results[i];\n    cout << \"Pose Result \" << i << endl;\n    pose->printPose();\n}\ncv::ppf_match_3d::Pose3DPtrPtr< Pose3D > Pose3DPtrDefinition pose_3d.hpp:59\ncv::pc@ pcDefinition container_avi.private.hpp:138\n\nPose Registration via ICP\nThe matching process terminates with the attainment of the pose. However, due to the multiple matching points, erroneous hypothesis, pose averaging and etc. such pose is very open to noise and many times is far from being perfect. Although the visual results obtained in that stage are pleasing, the quantitative evaluation shows \\(~10\\) degrees variation (error), which is an acceptable level of matching. Many times, the requirement might be set well beyond this margin and it is desired to refine the computed pose.\nFurthermore, in typical RGBD scenes and point clouds, 3D structure can capture only less than half of the model due to the visibility in the scene. Therefore, a robust pose refinement algorithm, which can register occluded and partially visible shapes quickly and correctly is not an unrealistic wish.\nAt this point, a trivial option would be to use the well known iterative closest point algorithm . However, utilization of the basic ICP leads to slow convergence, bad registration, outlier sensitivity and failure to register partial shapes. Thus, it is definitely not suited to the problem. For this reason, many variants have been proposed . Different variants contribute to different stages of the pose estimation process.\nICP is composed of \\(6\\) stages and the improvements I propose for each stage is summarized below.\n\nSampling\nTo improve convergence speed and computation time, it is common to use less points than the model actually has. However, sampling the correct points to register is an issue in itself. The naive way would be to sample uniformly and hope to get a reasonable subset. More smarter ways try to identify the critical points, which are found to highly contribute to the registration process. Gelfand et. al. exploit the covariance matrix in order to constrain the eigenspace, so that a set of points which affect both translation and rotation are used. This is a clever way of subsampling, which I will optionally be using in the implementation.\n\nCorrespondence Search\nAs the name implies, this step is actually the assignment of the points in the data and the model in a closest point fashion. Correct assignments will lead to a correct pose, where wrong assignments strongly degrade the result. In general, KD-trees are used in the search of nearest neighbors, to increase the speed. However this is not an optimality guarantee and many times causes wrong points to be matched. Luckily the assignments are corrected over iterations.\nTo overcome some of the limitations, Picky ICP [322] and BC-ICP (ICP using bi-unique correspondences) are two well-known methods. Picky ICP first finds the correspondences in the old-fashioned way and then among the resulting corresponding pairs, if more than one scene point \\(p_i\\) is assigned to the same model point \\(m_j\\), it selects \\(p_i\\) that corresponds to the minimum distance. BC-ICP on the other hand, allows multiple correspondences first and then resolves the assignments by establishing bi-unique correspondences. It also defines a novel no-correspondence outlier, which intrinsically eases the process of identifying outliers.\nFor reference, both methods are used. Because P-ICP is a bit faster, with not-so-significant performance drawback, it will be the method of choice in refinment of correspondences.\n\nWeighting of Pairs\nIn my implementation, I currently do not use a weighting scheme. But the common approaches involve normal compatibility* ( \\(w_i=n^1_i\\cdot n^2_j\\)) or assigning lower weights to point pairs with greater distances ( \\(w=1-\\frac{||dist(m_i,s_i)||_2}{dist_{max}}\\)).\n\nRejection of Pairs\nThe rejections are done using a dynamic thresholding based on a robust estimate of the standard deviation. In other words, in each iteration, I find the MAD estimate of the Std. Dev. I denote this as \\(mad_i\\). I reject the pairs with distances \\(d_i>\\tau mad_i\\). Here \\(\\tau\\) is the threshold of rejection and by default set to \\(3\\). The weighting is applied prior to Picky refinement, explained in the previous stage.\n\nError Metric\nAs described in , a linearization of point to plane as in [173] error metric is used. This both speeds up the registration process and improves convergence.\n\nMinimization\nEven though many non-linear optimizers (such as Levenberg Mardquardt) are proposed, due to the linearization in the previous step, pose estimation reduces to solving a linear system of equations. This is what I do exactly using cv::solve with DECOMP_SVD option.\n\nICP Algorithm\nHaving described the steps above, here I summarize the layout of the ICP algorithm.\n\nEfficient ICP Through Point Cloud Pyramids\nWhile the up-to-now-proposed variants deal well with some outliers and bad initializations, they require significant number of iterations. Yet, multi-resolution scheme can help reducing the number of iterations by allowing the registration to start from a coarse level and propagate to the lower and finer levels. Such approach both improves the performances and enhances the runtime.\nThe search is done through multiple levels, in a hierarchical fashion. The registration starts with a very coarse set of samples of the model. Iteratively, the points are densified and sought. After each iteration the previously estimated pose is used as an initial pose and refined with the ICP.\n\nVisual Results\n Results on Synthetic Data\nIn all of the results, the pose is initiated by PPF and the rest is left as: \\([\\theta_x, \\theta_y, \\theta_z, t_x, t_y, t_z]=[0]\\)\n\nSource Code for Pose Refinement Using ICP\nICP icp(200, 0.001f, 2.5f, 8);\n// Using the previously declared pc and pcTest\n// This will perform registration for every pose\n// contained in results\nicp.registerModelToScene(pc, pcTest, results);\n \n// results now contain the refined poses\n\nResults\nThis section is dedicated to the results of surface matching (point-pair-feature matching and a following ICP refinement):\n\nSeveral matches of a single frog model using ppf + icp\nMatches of different models for Mian dataset is presented below:\n\nMatches of different models for Mian dataset\nYou might checkout the video on youTube here.\n\nA Complete Sample\n\nParameter Tuning\nSurface matching module treats its parameters relative to the model diameter (diameter of the axis parallel bounding box), whenever it can. This makes the parameters independent from the model size. This is why, both model and scene cloud were subsampled such that all points have a minimum distance of \\(RelativeSamplingStep*DimensionRange\\), where \\(DimensionRange\\) is the distance along a given dimension. All three dimensions are sampled in similar manner. For example, if \\(RelativeSamplingStep\\) is set to 0.05 and the diameter of model is 1m (1000mm), the points sampled from the object's surface will be approximately 50 mm apart. From another point of view, if the sampling RelativeSamplingStep is set to 0.05, at most \\(20x20x20 = 8000\\) model points are generated (depending on how the model fills in the volume). Consequently this results in at most 8000x8000 pairs. In practice, because the models are not uniformly distributed over a rectangular prism, much less points are to be expected. Decreasing this value, results in more model points and thus a more accurate representation. However, note that number of point pair features to be computed is now quadratically increased as the complexity is O(N\\^2). This is especially a concern for 32 bit systems, where large models can easily overshoot the available memory. Typically, values in the range of 0.025 - 0.05 seem adequate for most of the applications, where the default value is 0.03. (Note that there is a difference in this paremeter with the one presented in [72] . In [72] a uniform cuboid is used for quantization and model diameter is used for reference of sampling. In my implementation, the cuboid is a rectangular prism, and each dimension is quantized independently. I do not take reference from the diameter but along the individual dimensions.\nIt would very wise to remove the outliers from the model and prepare an ideal model initially. This is because, the outliers directly affect the relative computations and degrade the matching accuracy.\nDuring runtime stage, the scene is again sampled by \\(RelativeSamplingStep\\), as described above. However this time, only a portion of the scene points are used as reference. This portion is controlled by the parameter \\(RelativeSceneSampleStep\\), where \\(SceneSampleStep = (int)(1.0/RelativeSceneSampleStep)\\). In other words, if the \\(RelativeSceneSampleStep = 1.0/5.0\\), the subsampled scene will once again be uniformly sampled to 1/5 of the number of points. Maximum value of this parameter is 1 and increasing this parameter also increases the stability, but decreases the speed. Again, because of the initial scene-independent relative sampling, fine tuning this parameter is not a big concern. This would only be an issue when the model shape occupies a volume uniformly, or when the model shape is condensed in a tiny place within the quantization volume (e.g. The octree representation would have too much empty cells).\n\\(RelativeDistanceStep\\) acts as a step of discretization over the hash table. The point pair features are quantized to be mapped to the buckets of the hashtable. This discretization involves a multiplication and a casting to the integer. Adjusting RelativeDistanceStep in theory controls the collision rate. Note that, more collisions on the hashtable results in less accurate estimations. Reducing this parameter increases the affect of quantization but starts to assign non-similar point pairs to the same bins. Increasing it however, wanes the ability to group the similar pairs. Generally, because during the sampling stage, the training model points are selected uniformly with a distance controlled by RelativeSamplingStep, RelativeDistanceStep is expected to equate to this value. Yet again, values in the range of 0.025-0.05 are sensible. This time however, when the model is dense, it is not advised to decrease this value. For noisy scenes, the value can be increased to improve the robustness of the matching against noisy points. \n\nClasses\nstruct  hashnode_i\n \nstruct  hashtable_int\n \nclass  cv::ppf_match_3d::ICP\n This class implements a very efficient and robust variant of the iterative closest point (ICP) algorithm. The task is to register a 3D model (or point cloud) against a set of noisy target data. The variants are put together by myself after certain tests. The task is to be able to match partial, noisy point clouds in cluttered scenes, quickly. You will find that my emphasis is on the performance, while retaining the accuracy. This implementation is based on Tolga Birdal's MATLAB implementation in here: http://www.mathworks.com/matlabcentral/fileexchange/47152-icp-registration-using-efficient-variants-and-multi-resolution-scheme The main contributions come from:  More...\n \nclass  cv::ppf_match_3d::Pose3D\n Class, allowing the storage of a pose. The data structure stores both the quaternions and the matrix forms. It supports IO functionality together with various helper methods to work with poses.  More...\n \nclass  cv::ppf_match_3d::PoseCluster3D\n When multiple poses (see Pose3D) are grouped together (contribute to the same transformation) pose clusters occur. This class is a general container for such groups of poses. It is possible to store, load and perform IO on these poses.  More...\n \nclass  cv::ppf_match_3d::PPF3DDetector\n Class, allowing the load and matching 3D models. Typical Use:  More...\n \nstruct  THash\n Struct, holding a node in the hashtable.  More...\n \n\nTypedefs\ntypedef uint cv::ppf_match_3d::KeyType\n \ntypedef Ptr< Pose3D > cv::ppf_match_3d::Pose3DPtr\n \ntypedef Ptr< PoseCluster3D > cv::ppf_match_3d::PoseCluster3DPtr\n \n\nFunctions\nMat cv::ppf_match_3d::addNoisePC (Mat pc, double scale)\n \nvoid cv::ppf_match_3d::computeBboxStd (Mat pc, Vec2f &xRange, Vec2f &yRange, Vec2f &zRange)\n \nint cv::ppf_match_3d::computeNormalsPC3d (const Mat &PC, Mat &PCNormals, const int NumNeighbors, const bool FlipViewpoint, const Vec3f &viewpoint)\n Compute the normals of an arbitrary point cloud computeNormalsPC3d uses a plane fitting approach to smoothly compute local normals. Normals are obtained through the eigenvector of the covariance matrix, corresponding to the smallest eigen value. If PCNormals is provided to be an Nx6 matrix, then no new allocation is made, instead the existing memory is overwritten.  \n \nvoid cv::ppf_match_3d::destroyFlann (void *flannIndex)\n \nvoid cv::ppf_match_3d::getRandomPose (Matx44d &Pose)\n \nhashtable_int * cv::ppf_match_3d::hashtable_int_clone (hashtable_int *hashtbl)\n \nhashtable_int * cv::ppf_match_3d::hashtableCreate (size_t size, size_t(*hashfunc)(uint))\n \nvoid cv::ppf_match_3d::hashtableDestroy (hashtable_int *hashtbl)\n \nvoid * cv::ppf_match_3d::hashtableGet (hashtable_int *hashtbl, KeyType key)\n \nhashnode_i * cv::ppf_match_3d::hashtableGetBucketHashed (hashtable_int *hashtbl, KeyType key)\n \nint cv::ppf_match_3d::hashtableInsert (hashtable_int *hashtbl, KeyType key, void *data)\n \nint cv::ppf_match_3d::hashtableInsertHashed (hashtable_int *hashtbl, KeyType key, void *data)\n \nvoid cv::ppf_match_3d::hashtablePrint (hashtable_int *hashtbl)\n \nhashtable_int * cv::ppf_match_3d::hashtableRead (FILE *f)\n \nint cv::ppf_match_3d::hashtableRemove (hashtable_int *hashtbl, KeyType key)\n \nint cv::ppf_match_3d::hashtableResize (hashtable_int *hashtbl, size_t size)\n \nint cv::ppf_match_3d::hashtableWrite (const hashtable_int *hashtbl, const size_t dataSize, FILE *f)\n \nvoid * cv::ppf_match_3d::indexPCFlann (Mat pc)\n \nMat cv::ppf_match_3d::loadPLYSimple (const char *fileName, int withNormals=0)\n Load a PLY file.  \n \nstatic uint cv::ppf_match_3d::next_power_of_two (uint value)\n Round up to the next highest power of 2.  \n \nMat cv::ppf_match_3d::normalizePCCoeff (Mat pc, float scale, float *Cx, float *Cy, float *Cz, float *MinVal, float *MaxVal)\n \nvoid cv::ppf_match_3d::queryPCFlann (void *flannIndex, Mat &pc, Mat &indices, Mat &distances)\n \nvoid cv::ppf_match_3d::queryPCFlann (void *flannIndex, Mat &pc, Mat &indices, Mat &distances, const int numNeighbors)\n \nMat cv::ppf_match_3d::samplePCByQuantization (Mat pc, Vec2f &xrange, Vec2f &yrange, Vec2f &zrange, float sample_step_relative, int weightByCenter=0)\n \nMat cv::ppf_match_3d::samplePCUniform (Mat PC, int sampleStep)\n \nMat cv::ppf_match_3d::samplePCUniformInd (Mat PC, int sampleStep, std::vector< int > &indices)\n \nMat cv::ppf_match_3d::transformPCPose (Mat pc, const Matx44d &Pose)\n \nMat cv::ppf_match_3d::transPCCoeff (Mat pc, float scale, float Cx, float Cy, float Cz, float MinVal, float MaxVal)\n \nvoid cv::ppf_match_3d::writePLY (Mat PC, const char *fileName)\n Write a point cloud to PLY file.  \n \nvoid cv::ppf_match_3d::writePLYVisibleNormals (Mat PC, const char *fileName)\n Used for debbuging pruposes, writes a point cloud to a PLY file with the tip of the normal vectors as visible red points.  \n \n\nTypedef Documentation\n\n◆ KeyType\n\ntypedef uint cv::ppf_match_3d::KeyType\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ Pose3DPtr\n\ntypedef Ptr<Pose3D> cv::ppf_match_3d::Pose3DPtr\n\n#include <opencv2/surface_matching/pose_3d.hpp>\n\n◆ PoseCluster3DPtr\n\ntypedef Ptr<PoseCluster3D> cv::ppf_match_3d::PoseCluster3DPtr\n\n#include <opencv2/surface_matching/pose_3d.hpp>\n\nFunction Documentation\n\n◆ addNoisePC()\n\nMat cv::ppf_match_3d::addNoisePC \n(\nMat \npc, \n\ndouble \nscale \n\n)\n\nPython:cv.ppf_match_3d.addNoisePC(pc, scale) -> retval\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nAdds a uniform noise in the given scale to the input point cloud Parameters\n\n[in]pcInput point cloud (CV_32F family). \n[in]scaleInput scale of the noise. The larger the scale, the more noisy the output \n\n◆ computeBboxStd()\n\nvoid cv::ppf_match_3d::computeBboxStd \n(\nMat \npc, \n\nVec2f & \nxRange, \n\nVec2f & \nyRange, \n\nVec2f & \nzRange \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ computeNormalsPC3d()\n\nint cv::ppf_match_3d::computeNormalsPC3d \n(\nconst Mat & \nPC, \n\nMat & \nPCNormals, \n\nconst int \nNumNeighbors, \n\nconst bool \nFlipViewpoint, \n\nconst Vec3f & \nviewpoint \n\n)\n\nPython:cv.ppf_match_3d.computeNormalsPC3d(PC, NumNeighbors, FlipViewpoint, viewpoint[, PCNormals]) -> retval, PCNormals\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nCompute the normals of an arbitrary point cloud computeNormalsPC3d uses a plane fitting approach to smoothly compute local normals. Normals are obtained through the eigenvector of the covariance matrix, corresponding to the smallest eigen value. If PCNormals is provided to be an Nx6 matrix, then no new allocation is made, instead the existing memory is overwritten. \nParameters\n\n[in]PCInput point cloud to compute the normals for. \n[out]PCNormalsOutput point cloud \n[in]NumNeighborsNumber of neighbors to take into account in a local region \n[in]FlipViewpointShould normals be flipped to a viewing direction? \n[in]viewpoint\n\nReturnsReturns 0 on success \n\n◆ destroyFlann()\n\nvoid cv::ppf_match_3d::destroyFlann \n(\nvoid * \nflannIndex)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ getRandomPose()\n\nvoid cv::ppf_match_3d::getRandomPose \n(\nMatx44d & \nPose)\n\nPython:cv.ppf_match_3d.getRandomPose(Pose) -> None\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nGenerate a random 4x4 pose matrix Parameters\n\n[out]PoseThe random pose \n\n◆ hashtable_int_clone()\n\nhashtable_int * cv::ppf_match_3d::hashtable_int_clone \n(\nhashtable_int * \nhashtbl)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableCreate()\n\nhashtable_int * cv::ppf_match_3d::hashtableCreate \n(\nsize_t \nsize, \n\nsize_t(*)(uint) \nhashfunc \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableDestroy()\n\nvoid cv::ppf_match_3d::hashtableDestroy \n(\nhashtable_int * \nhashtbl)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableGet()\n\nvoid * cv::ppf_match_3d::hashtableGet \n(\nhashtable_int * \nhashtbl, \n\nKeyType \nkey \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableGetBucketHashed()\n\nhashnode_i * cv::ppf_match_3d::hashtableGetBucketHashed \n(\nhashtable_int * \nhashtbl, \n\nKeyType \nkey \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableInsert()\n\nint cv::ppf_match_3d::hashtableInsert \n(\nhashtable_int * \nhashtbl, \n\nKeyType \nkey, \n\nvoid * \ndata \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableInsertHashed()\n\nint cv::ppf_match_3d::hashtableInsertHashed \n(\nhashtable_int * \nhashtbl, \n\nKeyType \nkey, \n\nvoid * \ndata \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtablePrint()\n\nvoid cv::ppf_match_3d::hashtablePrint \n(\nhashtable_int * \nhashtbl)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableRead()\n\nhashtable_int * cv::ppf_match_3d::hashtableRead \n(\nFILE * \nf)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableRemove()\n\nint cv::ppf_match_3d::hashtableRemove \n(\nhashtable_int * \nhashtbl, \n\nKeyType \nkey \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableResize()\n\nint cv::ppf_match_3d::hashtableResize \n(\nhashtable_int * \nhashtbl, \n\nsize_t \nsize \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ hashtableWrite()\n\nint cv::ppf_match_3d::hashtableWrite \n(\nconst hashtable_int * \nhashtbl, \n\nconst size_t \ndataSize, \n\nFILE * \nf \n\n)\n\n#include <opencv2/surface_matching/t_hash_int.hpp>\n\n◆ indexPCFlann()\n\nvoid * cv::ppf_match_3d::indexPCFlann \n(\nMat \npc)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ loadPLYSimple()\n\nMat cv::ppf_match_3d::loadPLYSimple \n(\nconst char * \nfileName, \n\nint \nwithNormals = 0 \n\n)\n\nPython:cv.ppf_match_3d.loadPLYSimple(fileName[, withNormals]) -> retval\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nLoad a PLY file. \nParameters\n\n[in]fileNameThe PLY model to read \n[in]withNormalsFlag wheather the input PLY contains normal information, and whether it should be loaded or not \n\nReturnsReturns the matrix on successful load \n\n◆ next_power_of_two()\n\nstatic uint cv::ppf_match_3d::next_power_of_two \n(\nuint \nvalue)\n\ninlinestatic \n\n#include <opencv2/surface_matching/t_hash_int.hpp>\nRound up to the next highest power of 2. \nfrom http://www-graphics.stanford.edu/~seander/bithacks.html \n\n◆ normalizePCCoeff()\n\nMat cv::ppf_match_3d::normalizePCCoeff \n(\nMat \npc, \n\nfloat \nscale, \n\nfloat * \nCx, \n\nfloat * \nCy, \n\nfloat * \nCz, \n\nfloat * \nMinVal, \n\nfloat * \nMaxVal \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ queryPCFlann() [1/2]\n\nvoid cv::ppf_match_3d::queryPCFlann \n(\nvoid * \nflannIndex, \n\nMat & \npc, \n\nMat & \nindices, \n\nMat & \ndistances \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ queryPCFlann() [2/2]\n\nvoid cv::ppf_match_3d::queryPCFlann \n(\nvoid * \nflannIndex, \n\nMat & \npc, \n\nMat & \nindices, \n\nMat & \ndistances, \n\nconst int \nnumNeighbors \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ samplePCByQuantization()\n\nMat cv::ppf_match_3d::samplePCByQuantization \n(\nMat \npc, \n\nVec2f & \nxrange, \n\nVec2f & \nyrange, \n\nVec2f & \nzrange, \n\nfloat \nsample_step_relative, \n\nint \nweightByCenter = 0 \n\n)\n\nPython:cv.ppf_match_3d.samplePCByQuantization(pc, xrange, yrange, zrange, sample_step_relative[, weightByCenter]) -> retval\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nSample a point cloud using uniform steps Parameters\n\n[in]pcInput point cloud \n[in]xrangeX components (min and max) of the bounding box of the model \n[in]yrangeY components (min and max) of the bounding box of the model \n[in]zrangeZ components (min and max) of the bounding box of the model \n[in]sample_step_relativeThe point cloud is sampled such that all points have a certain minimum distance. This minimum distance is determined relatively using the parameter sample_step_relative. \n[in]weightByCenterThe contribution of the quantized data points can be weighted by the distance to the origin. This parameter enables/disables the use of weighting. \n\nReturnsSampled point cloud \n\n◆ samplePCUniform()\n\nMat cv::ppf_match_3d::samplePCUniform \n(\nMat \nPC, \n\nint \nsampleStep \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ samplePCUniformInd()\n\nMat cv::ppf_match_3d::samplePCUniformInd \n(\nMat \nPC, \n\nint \nsampleStep, \n\nstd::vector< int > & \nindices \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ transformPCPose()\n\nMat cv::ppf_match_3d::transformPCPose \n(\nMat \npc, \n\nconst Matx44d & \nPose \n\n)\n\nPython:cv.ppf_match_3d.transformPCPose(pc, Pose) -> retval\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nTransforms the point cloud with a given a homogeneous 4x4 pose matrix (in double precision) Parameters\n\n[in]pcInput point cloud (CV_32F family). Point clouds with 3 or 6 elements per row are expected. In the case where the normals are provided, they are also rotated to be compatible with the entire transformation \n[in]Pose4x4 pose matrix, but linearized in row-major form. \n\nReturnsTransformed point cloud \n\n◆ transPCCoeff()\n\nMat cv::ppf_match_3d::transPCCoeff \n(\nMat \npc, \n\nfloat \nscale, \n\nfloat \nCx, \n\nfloat \nCy, \n\nfloat \nCz, \n\nfloat \nMinVal, \n\nfloat \nMaxVal \n\n)\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\n\n◆ writePLY()\n\nvoid cv::ppf_match_3d::writePLY \n(\nMat \nPC, \n\nconst char * \nfileName \n\n)\n\nPython:cv.ppf_match_3d.writePLY(PC, fileName) -> None\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nWrite a point cloud to PLY file. \nParameters\n\n[in]PCInput point cloud \n[in]fileNameThe PLY model file to write \n\n◆ writePLYVisibleNormals()\n\nvoid cv::ppf_match_3d::writePLYVisibleNormals \n(\nMat \nPC, \n\nconst char * \nfileName \n\n)\n\nPython:cv.ppf_match_3d.writePLYVisibleNormals(PC, fileName) -> None\n\n#include <opencv2/surface_matching/ppf_helpers.hpp>\nUsed for debbuging pruposes, writes a point cloud to a PLY file with the tip of the normal vectors as visible red points. \nParameters\n\n[in]PCInput point cloud \n[in]fileNameThe PLY model file to write \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d0/d05/group__cudaimgproc.html","content_type":"text/html","title":"OpenCV: Image Processing","language":null},"page_content":"OpenCV: Image Processing\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nEnumerations |\nFunctions \nImage ProcessingCUDA-accelerated Computer Vision\n\nModules\n Color space processing\n \n Histogram Calculation\n \n Structural Analysis and Shape Descriptors\n \n Hough Transform\n \n Feature Detection\n \n\nDetailed Description\n\nClasses\nclass  cv::cuda::CannyEdgeDetector\n Base class for Canny Edge Detector. :  More...\n \nclass  cv::cuda::TemplateMatching\n Base class for Template Matching. :  More...\n \n\nEnumerations\nenum  cv::cuda::ConnectedComponentsAlgorithmsTypes { \n  cv::cuda::CCL_DEFAULT = -1\n, \n  cv::cuda::CCL_BKE = 0\n\n }\n Connected Components Algorithm.  More...\n \n\nFunctions\nvoid cv::cuda::bilateralFilter (InputArray src, OutputArray dst, int kernel_size, float sigma_color, float sigma_spatial, int borderMode=BORDER_DEFAULT, Stream &stream=Stream::Null())\n Performs bilateral filtering of passed image.  \n \nvoid cv::cuda::blendLinear (InputArray img1, InputArray img2, InputArray weights1, InputArray weights2, OutputArray result, Stream &stream=Stream::Null())\n Performs linear blending of two images.  \n \nvoid cv::cuda::connectedComponents (InputArray image, OutputArray labels, int connectivity, int ltype, cv::cuda::ConnectedComponentsAlgorithmsTypes ccltype)\n Computes the Connected Components Labeled image of a binary image.  \n \nvoid cv::cuda::connectedComponents (InputArray image, OutputArray labels, int connectivity=8, int ltype=CV_32S)\n \nPtr< CannyEdgeDetector > cv::cuda::createCannyEdgeDetector (double low_thresh, double high_thresh, int apperture_size=3, bool L2gradient=false)\n Creates implementation for cuda::CannyEdgeDetector .  \n \nPtr< TemplateMatching > cv::cuda::createTemplateMatching (int srcType, int method, Size user_block_size=Size())\n Creates implementation for cuda::TemplateMatching .  \n \nvoid cv::cuda::meanShiftFiltering (InputArray src, OutputArray dst, int sp, int sr, TermCriteria criteria=TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 1), Stream &stream=Stream::Null())\n Performs mean-shift filtering for each point of the source image.  \n \nvoid cv::cuda::meanShiftProc (InputArray src, OutputArray dstr, OutputArray dstsp, int sp, int sr, TermCriteria criteria=TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 1), Stream &stream=Stream::Null())\n Performs a mean-shift procedure and stores information about processed points (their colors and positions) in two images.  \n \nvoid cv::cuda::meanShiftSegmentation (InputArray src, OutputArray dst, int sp, int sr, int minsize, TermCriteria criteria=TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 1), Stream &stream=Stream::Null())\n Performs a mean-shift segmentation of the source image and eliminates small segments.  \n \n\nEnumeration Type Documentation\n\n◆ ConnectedComponentsAlgorithmsTypes\n\nenum cv::cuda::ConnectedComponentsAlgorithmsTypes\n\n#include <opencv2/cudaimgproc.hpp>\nConnected Components Algorithm. \n\nEnumeratorCCL_DEFAULT BKE [11] algorithm for 8-way connectivity. \n\nCCL_BKE BKE [11] algorithm for 8-way connectivity. \n\nFunction Documentation\n\n◆ bilateralFilter()\n\nvoid cv::cuda::bilateralFilter \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nkernel_size, \n\nfloat \nsigma_color, \n\nfloat \nsigma_spatial, \n\nint \nborderMode = BORDER_DEFAULT, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nPerforms bilateral filtering of passed image. \nParameters\n\nsrcSource image. Supports only (channels != 2 && depth() != CV_8S && depth() != CV_32S && depth() != CV_64F). \ndstDestination imagwe. \nkernel_sizeKernel window size. \nsigma_colorFilter sigma in the color space. \nsigma_spatialFilter sigma in the coordinate space. \nborderModeBorder type. See borderInterpolate for details. BORDER_REFLECT101 , BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now. \nstreamStream for the asynchronous version.\n\nSee alsobilateralFilter \n\n◆ blendLinear()\n\nvoid cv::cuda::blendLinear \n(\nInputArray \nimg1, \n\nInputArray \nimg2, \n\nInputArray \nweights1, \n\nInputArray \nweights2, \n\nOutputArray \nresult, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nPerforms linear blending of two images. \nParameters\n\nimg1First image. Supports only CV_8U and CV_32F depth. \nimg2Second image. Must have the same size and the same type as img1 . \nweights1Weights for first image. Must have tha same size as img1 . Supports only CV_32F type. \nweights2Weights for second image. Must have tha same size as img2 . Supports only CV_32F type. \nresultDestination image. \nstreamStream for the asynchronous version. \n\n◆ connectedComponents() [1/2]\n\nvoid cv::cuda::connectedComponents \n(\nInputArray \nimage, \n\nOutputArray \nlabels, \n\nint \nconnectivity, \n\nint \nltype, \n\ncv::cuda::ConnectedComponentsAlgorithmsTypes \nccltype \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nComputes the Connected Components Labeled image of a binary image. \nThe function takes as input a binary image and performs Connected Components Labeling. The output is an image where each Connected Component is assigned a unique label (integer value). ltype specifies the output label image type, an important consideration based on the total number of labels or alternatively the total number of pixels in the source image. ccltype specifies the connected components labeling algorithm to use, currently BKE [11] is supported, see the ConnectedComponentsAlgorithmsTypes for details. Note that labels in the output are not required to be sequential.\nParameters\n\nimageThe 8-bit single-channel image to be labeled. \nlabelsDestination labeled image. \nconnectivityConnectivity to use for the labeling procedure. 8 for 8-way connectivity is supported. \nltypeOutput image label type. Currently CV_32S is supported. \nccltypeConnected components algorithm type (see the ConnectedComponentsAlgorithmsTypes).\n\nNoteA sample program demonstrating Connected Components Labeling in CUDA can be found at\nopencv_contrib_source_code/modules/cudaimgproc/samples/connected_components.cpp \n\n◆ connectedComponents() [2/2]\n\nvoid cv::cuda::connectedComponents \n(\nInputArray \nimage, \n\nOutputArray \nlabels, \n\nint \nconnectivity = 8, \n\nint \nltype = CV_32S \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts.\nParameters\n\nimageThe 8-bit single-channel image to be labeled. \nlabelsDestination labeled image. \nconnectivityConnectivity to use for the labeling procedure. 8 for 8-way connectivity is supported. \nltypeOutput image label type. Currently CV_32S is supported. \n\n◆ createCannyEdgeDetector()\n\nPtr< CannyEdgeDetector > cv::cuda::createCannyEdgeDetector \n(\ndouble \nlow_thresh, \n\ndouble \nhigh_thresh, \n\nint \napperture_size = 3, \n\nbool \nL2gradient = false \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nCreates implementation for cuda::CannyEdgeDetector . \nParameters\n\nlow_threshFirst threshold for the hysteresis procedure. \nhigh_threshSecond threshold for the hysteresis procedure. \napperture_sizeAperture size for the Sobel operator. \nL2gradientFlag indicating whether a more accurate \\(L_2\\) norm \\(=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\) should be used to compute the image gradient magnitude ( L2gradient=true ), or a faster default \\(L_1\\) norm \\(=|dI/dx|+|dI/dy|\\) is enough ( L2gradient=false ). \n\n◆ createTemplateMatching()\n\nPtr< TemplateMatching > cv::cuda::createTemplateMatching \n(\nint \nsrcType, \n\nint \nmethod, \n\nSize \nuser_block_size = Size() \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nCreates implementation for cuda::TemplateMatching . \nParameters\n\nsrcTypeInput source type. CV_32F and CV_8U depth images (1..4 channels) are supported for now. \nmethodSpecifies the way to compare the template with the image. \nuser_block_sizeYou can use field user_block_size to set specific block size. If you leave its default value Size(0,0) then automatic estimation of block size will be used (which is optimized for speed). By varying user_block_size you can reduce memory requirements at the cost of speed.\n\nThe following methods are supported for the CV_8U depth images for now:\n\nCV_TM_SQDIFF\nCV_TM_SQDIFF_NORMED\nCV_TM_CCORR\nCV_TM_CCORR_NORMED\nCV_TM_CCOEFF\nCV_TM_CCOEFF_NORMED\n\nThe following methods are supported for the CV_32F images for now:\n\nCV_TM_SQDIFF\nCV_TM_CCORR\n\nSee alsomatchTemplate \n\n◆ meanShiftFiltering()\n\nvoid cv::cuda::meanShiftFiltering \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nsp, \n\nint \nsr, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 1), \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nPerforms mean-shift filtering for each point of the source image. \nParameters\n\nsrcSource image. Only CV_8UC4 images are supported for now. \ndstDestination image containing the color of mapped points. It has the same size and type as src . \nspSpatial window radius. \nsrColor window radius. \ncriteriaTermination criteria. See TermCriteria. \nstreamStream for the asynchronous version.\n\nIt maps each point of the source image into another point. As a result, you have a new color and new position of each point. \n\n◆ meanShiftProc()\n\nvoid cv::cuda::meanShiftProc \n(\nInputArray \nsrc, \n\nOutputArray \ndstr, \n\nOutputArray \ndstsp, \n\nint \nsp, \n\nint \nsr, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 1), \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nPerforms a mean-shift procedure and stores information about processed points (their colors and positions) in two images. \nParameters\n\nsrcSource image. Only CV_8UC4 images are supported for now. \ndstrDestination image containing the color of mapped points. The size and type is the same as src . \ndstspDestination image containing the position of mapped points. The size is the same as src size. The type is CV_16SC2 . \nspSpatial window radius. \nsrColor window radius. \ncriteriaTermination criteria. See TermCriteria. \nstreamStream for the asynchronous version.\n\nSee alsocuda::meanShiftFiltering \n\n◆ meanShiftSegmentation()\n\nvoid cv::cuda::meanShiftSegmentation \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nint \nsp, \n\nint \nsr, \n\nint \nminsize, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 1), \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudaimgproc.hpp>\nPerforms a mean-shift segmentation of the source image and eliminates small segments. \nParameters\n\nsrcSource image. Only CV_8UC4 images are supported for now. \ndstSegmented image with the same size and type as src (host or gpu memory). \nspSpatial window radius. \nsrColor window radius. \nminsizeMinimum segment size. Smaller segments are merged. \ncriteriaTermination criteria. See TermCriteria. \nstreamStream for the asynchronous version. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/de7/group__videoio.html","content_type":"text/html","title":"OpenCV: Video I/O","language":null},"page_content":"OpenCV: Video I/O\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses \nVideo I/O\n\nRead and write video or images sequence with OpenCV.  \nMore...\n\nModules\n Flags for video I/O\n \n Additional flags for video I/O API backends\n \n Hardware-accelerated video decoding and encoding\n \n C API for video I/O\n \n iOS glue for video I/O\n \n WinRT glue for video I/O\n \n Query I/O API backends registry\n \n\nDetailed Description\nRead and write video or images sequence with OpenCV. \n\nSee also:\n\nVideo I/O with OpenCV Overview\nTutorials: Application utils (highgui, imgcodecs, videoio modules) \n\nClasses\nclass  cv::VideoCapture\n Class for video capturing from video files, image sequences or cameras.  More...\n \nclass  cv::VideoWriter\n Video writer class.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/df/d5b/group__fuzzy.html","content_type":"text/html","title":"OpenCV: Image processing based on fuzzy mathematics","language":null},"page_content":"OpenCV: Image processing based on fuzzy mathematics\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nEnumerations \nImage processing based on fuzzy mathematics\n\nModules\n Math with F0-transform support\n \n Math with F1-transform support\n \n Fuzzy image processing\n \n\nDetailed Description\nNamespace for all functions is ft. The module brings implementation of the last image processing algorithms based on fuzzy mathematics. Method are named based on the pattern FT_degree_dimension_method. \n\nEnumerations\nenum  { \n  cv::ft::LINEAR = 1\n, \n  cv::ft::SINUS = 2\n\n }\n \nenum  { \n  cv::ft::ONE_STEP = 1\n, \n  cv::ft::MULTI_STEP = 2\n, \n  cv::ft::ITERATIVE = 3\n\n }\n \n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/fuzzy/types.hpp>\n\nEnumeratorLINEAR Python: cv.ft.LINEARlinear (triangular) shape \n\nSINUS Python: cv.ft.SINUSsinusoidal shape \n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/fuzzy/types.hpp>\n\nEnumeratorONE_STEP Python: cv.ft.ONE_STEPprocessing in one step \n\nMULTI_STEP Python: cv.ft.MULTI_STEPprocessing in multiple step \n\nITERATIVE Python: cv.ft.ITERATIVEprocessing in several iterations \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/d6a/group__aruco.html","content_type":"text/html","title":"OpenCV: Aruco markers, module functionality was moved to objdetect module","language":null},"page_content":"OpenCV: Aruco markers, module functionality was moved to objdetect module\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations |\nFunctions \nAruco markers, module functionality was moved to objdetect module\n\nDetailed Description\nArUco Marker Detection, module functionality was moved to objdetect module See alsoArucoDetector, CharucoDetector, Board, GridBoard, CharucoBoard \n\nClasses\nstruct  cv::aruco::EstimateParameters\n Pose estimation parameters.  More...\n \n\nEnumerations\nenum  cv::aruco::PatternPositionType { \n  cv::aruco::ARUCO_CCW_CENTER\n, \n  cv::aruco::ARUCO_CW_TOP_LEFT_CORNER\n\n }\n rvec/tvec define the right handed coordinate system of the marker.  More...\n \n\nFunctions\ndouble cv::aruco::calibrateCameraAruco (InputArrayOfArrays corners, InputArray ids, InputArray counter, const Ptr< Board > &board, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, OutputArray stdDeviationsIntrinsics, OutputArray stdDeviationsExtrinsics, OutputArray perViewErrors, int flags=0, const TermCriteria &criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n Calibrate a camera using aruco markers.  \n \ndouble cv::aruco::calibrateCameraAruco (InputArrayOfArrays corners, InputArray ids, InputArray counter, const Ptr< Board > &board, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs=noArray(), OutputArrayOfArrays tvecs=noArray(), int flags=0, const TermCriteria &criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n It's the same function as calibrateCameraAruco but without calibration error estimation.  \n \ndouble cv::aruco::calibrateCameraCharuco (InputArrayOfArrays charucoCorners, InputArrayOfArrays charucoIds, const Ptr< CharucoBoard > &board, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, OutputArray stdDeviationsIntrinsics, OutputArray stdDeviationsExtrinsics, OutputArray perViewErrors, int flags=0, const TermCriteria &criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n Calibrate a camera using Charuco corners.  \n \ndouble cv::aruco::calibrateCameraCharuco (InputArrayOfArrays charucoCorners, InputArrayOfArrays charucoIds, const Ptr< CharucoBoard > &board, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs=noArray(), OutputArrayOfArrays tvecs=noArray(), int flags=0, const TermCriteria &criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n It's the same function as calibrateCameraCharuco but without calibration error estimation.  \n \nvoid cv::aruco::detectCharucoDiamond (InputArray image, InputArrayOfArrays markerCorners, InputArray markerIds, float squareMarkerLengthRate, OutputArrayOfArrays diamondCorners, OutputArray diamondIds, InputArray cameraMatrix=noArray(), InputArray distCoeffs=noArray(), Ptr< Dictionary > dictionary=makePtr< Dictionary >(getPredefinedDictionary(PredefinedDictionaryType::DICT_4X4_50)))\n Detect ChArUco Diamond markers.  \n \nvoid cv::aruco::detectMarkers (InputArray image, const Ptr< Dictionary > &dictionary, OutputArrayOfArrays corners, OutputArray ids, const Ptr< DetectorParameters > &parameters=makePtr< DetectorParameters >(), OutputArrayOfArrays rejectedImgPoints=noArray())\n detect markers  \n \nvoid cv::aruco::drawCharucoDiamond (const Ptr< Dictionary > &dictionary, Vec4i ids, int squareLength, int markerLength, OutputArray img, int marginSize=0, int borderBits=1)\n Draw a ChArUco Diamond marker.  \n \nvoid cv::aruco::drawPlanarBoard (const Ptr< Board > &board, Size outSize, OutputArray img, int marginSize, int borderBits)\n draw planar board  \n \nint cv::aruco::estimatePoseBoard (InputArrayOfArrays corners, InputArray ids, const Ptr< Board > &board, InputArray cameraMatrix, InputArray distCoeffs, InputOutputArray rvec, InputOutputArray tvec, bool useExtrinsicGuess=false)\n \nbool cv::aruco::estimatePoseCharucoBoard (InputArray charucoCorners, InputArray charucoIds, const Ptr< CharucoBoard > &board, InputArray cameraMatrix, InputArray distCoeffs, InputOutputArray rvec, InputOutputArray tvec, bool useExtrinsicGuess=false)\n Pose estimation for a ChArUco board given some of their corners.  \n \nvoid cv::aruco::estimatePoseSingleMarkers (InputArrayOfArrays corners, float markerLength, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvecs, OutputArray tvecs, OutputArray objPoints=noArray(), const Ptr< EstimateParameters > &estimateParameters=makePtr< EstimateParameters >())\n \nvoid cv::aruco::getBoardObjectAndImagePoints (const Ptr< Board > &board, InputArrayOfArrays detectedCorners, InputArray detectedIds, OutputArray objPoints, OutputArray imgPoints)\n get board object and image points  \n \nint cv::aruco::interpolateCornersCharuco (InputArrayOfArrays markerCorners, InputArray markerIds, InputArray image, const Ptr< CharucoBoard > &board, OutputArray charucoCorners, OutputArray charucoIds, InputArray cameraMatrix=noArray(), InputArray distCoeffs=noArray(), int minMarkers=2)\n Interpolate position of ChArUco board corners.  \n \nvoid cv::aruco::refineDetectedMarkers (InputArray image, const Ptr< Board > &board, InputOutputArrayOfArrays detectedCorners, InputOutputArray detectedIds, InputOutputArrayOfArrays rejectedCorners, InputArray cameraMatrix=noArray(), InputArray distCoeffs=noArray(), float minRepDistance=10.f, float errorCorrectionRate=3.f, bool checkAllOrders=true, OutputArray recoveredIdxs=noArray(), const Ptr< DetectorParameters > &parameters=makePtr< DetectorParameters >())\n refine detected markers  \n \nbool cv::aruco::testCharucoCornersCollinear (const Ptr< CharucoBoard > &board, InputArray charucoIds)\n \n\nEnumeration Type Documentation\n\n◆ PatternPositionType\n\nenum cv::aruco::PatternPositionType\n\n#include <opencv2/aruco/aruco_calib.hpp>\nrvec/tvec define the right handed coordinate system of the marker. \nPatternPositionType defines center this system and axes direction. Axis X (red color) - first coordinate, axis Y (green color) - second coordinate, axis Z (blue color) - third coordinate.\nDeprecated:Use Board::matchImagePoints and cv::solvePnP\nSee alsoestimatePoseSingleMarkers() \n\nEnumeratorARUCO_CCW_CENTER Python: cv.aruco.ARUCO_CCW_CENTERThe marker coordinate system is centered on the middle of the marker. \nThe coordinates of the four corners (CCW order) of the marker in its own coordinate system are: (-markerLength/2, markerLength/2, 0), (markerLength/2, markerLength/2, 0), (markerLength/2, -markerLength/2, 0), (-markerLength/2, -markerLength/2, 0). \n\nARUCO_CW_TOP_LEFT_CORNER Python: cv.aruco.ARUCO_CW_TOP_LEFT_CORNERThe marker coordinate system is centered on the top-left corner of the marker. \nThe coordinates of the four corners (CW order) of the marker in its own coordinate system are: (0, 0, 0), (markerLength, 0, 0), (markerLength, markerLength, 0), (0, markerLength, 0).\nThese pattern dots are convenient to use with a chessboard/ChArUco board. \n\nFunction Documentation\n\n◆ calibrateCameraAruco() [1/2]\n\ndouble cv::aruco::calibrateCameraAruco \n(\nInputArrayOfArrays \ncorners, \n\nInputArray \nids, \n\nInputArray \ncounter, \n\nconst Ptr< Board > & \nboard, \n\nSize \nimageSize, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nOutputArray \nstdDeviationsIntrinsics, \n\nOutputArray \nstdDeviationsExtrinsics, \n\nOutputArray \nperViewErrors, \n\nint \nflags = 0, \n\nconst TermCriteria & \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.aruco.calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecscv.aruco.calibrateCameraArucoExtended(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n\n#include <opencv2/aruco/aruco_calib.hpp>\nCalibrate a camera using aruco markers. \nParameters\n\ncornersvector of detected marker corners in all frames. The corners should have the same format returned by detectMarkers (see detectMarkers). \nidslist of identifiers for each marker in corners \ncounternumber of markers in each frame so that corners and ids can be split \nboardMarker Board layout \nimageSizeSize of the image used only to initialize the intrinsic camera matrix. \ncameraMatrixOutput 3x3 floating-point camera matrix \\(A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . If CV_CALIB_USE_INTRINSIC_GUESS and/or CV_CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be initialized before calling the function. \ndistCoeffsOutput vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\) of 4, 5, 8 or 12 elements \nrvecsOutput vector of rotation vectors (see Rodrigues ) estimated for each board view (e.g. std::vector<cv::Mat>>). That is, each k-th rotation vector together with the corresponding k-th translation vector (see the next output parameter description) brings the board pattern from the model coordinate space (in which object points are specified) to the world coordinate space, that is, a real position of the board pattern in the k-th pattern view (k=0.. M -1). \ntvecsOutput vector of translation vectors estimated for each pattern view. \nstdDeviationsIntrinsicsOutput vector of standard deviations estimated for intrinsic parameters. Order of deviations values:  \\((f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\ns_4, \\tau_x, \\tau_y)\\) If one of parameters is not estimated, it's deviation is equals to zero. \nstdDeviationsExtrinsicsOutput vector of standard deviations estimated for extrinsic parameters. Order of deviations values: \\((R_1, T_1, \\dotsc , R_M, T_M)\\) where M is number of pattern views, \\(R_i, T_i\\) are concatenated 1x3 vectors. \nperViewErrorsOutput vector of average re-projection errors estimated for each pattern view. \nflagsflags Different flags for the calibration process (see calibrateCamera for details). \ncriteriaTermination criteria for the iterative optimization algorithm.\n\nThis function calibrates a camera using an Aruco Board. The function receives a list of detected markers from several views of the Board. The process is similar to the chessboard calibration in calibrateCamera(). The function returns the final re-projection error.\nDeprecated:Use Board::matchImagePoints and cv::solvePnP \n\n◆ calibrateCameraAruco() [2/2]\n\ndouble cv::aruco::calibrateCameraAruco \n(\nInputArrayOfArrays \ncorners, \n\nInputArray \nids, \n\nInputArray \ncounter, \n\nconst Ptr< Board > & \nboard, \n\nSize \nimageSize, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs = noArray(), \n\nOutputArrayOfArrays \ntvecs = noArray(), \n\nint \nflags = 0, \n\nconst TermCriteria & \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.aruco.calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecscv.aruco.calibrateCameraArucoExtended(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n\n#include <opencv2/aruco/aruco_calib.hpp>\nIt's the same function as calibrateCameraAruco but without calibration error estimation. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Deprecated:Use Board::matchImagePoints and cv::solvePnP \n\n◆ calibrateCameraCharuco() [1/2]\n\ndouble cv::aruco::calibrateCameraCharuco \n(\nInputArrayOfArrays \ncharucoCorners, \n\nInputArrayOfArrays \ncharucoIds, \n\nconst Ptr< CharucoBoard > & \nboard, \n\nSize \nimageSize, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nOutputArray \nstdDeviationsIntrinsics, \n\nOutputArray \nstdDeviationsExtrinsics, \n\nOutputArray \nperViewErrors, \n\nint \nflags = 0, \n\nconst TermCriteria & \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.aruco.calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecscv.aruco.calibrateCameraCharucoExtended(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n\n#include <opencv2/aruco/aruco_calib.hpp>\nCalibrate a camera using Charuco corners. \nParameters\n\ncharucoCornersvector of detected charuco corners per frame \ncharucoIdslist of identifiers for each corner in charucoCorners per frame \nboardMarker Board layout \nimageSizeinput image size \ncameraMatrixOutput 3x3 floating-point camera matrix \\(A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . If CV_CALIB_USE_INTRINSIC_GUESS and/or CV_CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be initialized before calling the function. \ndistCoeffsOutput vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\) of 4, 5, 8 or 12 elements \nrvecsOutput vector of rotation vectors (see Rodrigues ) estimated for each board view (e.g. std::vector<cv::Mat>>). That is, each k-th rotation vector together with the corresponding k-th translation vector (see the next output parameter description) brings the board pattern from the model coordinate space (in which object points are specified) to the world coordinate space, that is, a real position of the board pattern in the k-th pattern view (k=0.. M -1). \ntvecsOutput vector of translation vectors estimated for each pattern view. \nstdDeviationsIntrinsicsOutput vector of standard deviations estimated for intrinsic parameters. Order of deviations values:  \\((f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\ns_4, \\tau_x, \\tau_y)\\) If one of parameters is not estimated, it's deviation is equals to zero. \nstdDeviationsExtrinsicsOutput vector of standard deviations estimated for extrinsic parameters. Order of deviations values: \\((R_1, T_1, \\dotsc , R_M, T_M)\\) where M is number of pattern views, \\(R_i, T_i\\) are concatenated 1x3 vectors. \nperViewErrorsOutput vector of average re-projection errors estimated for each pattern view. \nflagsflags Different flags for the calibration process (see calibrateCamera for details). \ncriteriaTermination criteria for the iterative optimization algorithm.\n\nThis function calibrates a camera using a set of corners of a Charuco Board. The function receives a list of detected corners and its identifiers from several views of the Board. The function returns the final re-projection error.\nDeprecated:Use CharucoBoard::matchImagePoints and cv::solvePnP \n\n◆ calibrateCameraCharuco() [2/2]\n\ndouble cv::aruco::calibrateCameraCharuco \n(\nInputArrayOfArrays \ncharucoCorners, \n\nInputArrayOfArrays \ncharucoIds, \n\nconst Ptr< CharucoBoard > & \nboard, \n\nSize \nimageSize, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs = noArray(), \n\nOutputArrayOfArrays \ntvecs = noArray(), \n\nint \nflags = 0, \n\nconst TermCriteria & \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.aruco.calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecscv.aruco.calibrateCameraCharucoExtended(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n\n#include <opencv2/aruco/aruco_calib.hpp>\nIt's the same function as calibrateCameraCharuco but without calibration error estimation. \nDeprecated:Use CharucoBoard::matchImagePoints and cv::solvePnP \n\n◆ detectCharucoDiamond()\n\nvoid cv::aruco::detectCharucoDiamond \n(\nInputArray \nimage, \n\nInputArrayOfArrays \nmarkerCorners, \n\nInputArray \nmarkerIds, \n\nfloat \nsquareMarkerLengthRate, \n\nOutputArrayOfArrays \ndiamondCorners, \n\nOutputArray \ndiamondIds, \n\nInputArray \ncameraMatrix = noArray(), \n\nInputArray \ndistCoeffs = noArray(), \n\nPtr< Dictionary > \ndictionary = makePtr< Dictionary >(getPredefinedDictionary(PredefinedDictionaryType::DICT_4X4_50)) \n\n)\n\nPython:cv.aruco.detectCharucoDiamond(image, markerCorners, markerIds, squareMarkerLengthRate[, diamondCorners[, diamondIds[, cameraMatrix[, distCoeffs[, dictionary]]]]]) -> diamondCorners, diamondIds\n\n#include <opencv2/aruco/charuco.hpp>\nDetect ChArUco Diamond markers. \nParameters\n\nimageinput image necessary for corner subpixel. \nmarkerCornerslist of detected marker corners from detectMarkers function. \nmarkerIdslist of marker ids in markerCorners. \nsquareMarkerLengthRaterate between square and marker length: squareMarkerLengthRate = squareLength/markerLength. The real units are not necessary. \ndiamondCornersoutput list of detected diamond corners (4 corners per diamond). The order is the same than in marker corners: top left, top right, bottom right and bottom left. Similar format than the corners returned by detectMarkers (e.g std::vector<std::vector<cv::Point2f> > ). \ndiamondIdsids of the diamonds in diamondCorners. The id of each diamond is in fact of type Vec4i, so each diamond has 4 ids, which are the ids of the aruco markers composing the diamond. \ncameraMatrixOptional camera calibration matrix. \ndistCoeffsOptional camera distortion coefficients. \ndictionarydictionary of markers indicating the type of markers.\n\nThis function detects Diamond markers from the previous detected ArUco markers. The diamonds are returned in the diamondCorners and diamondIds parameters. If camera calibration parameters are provided, the diamond search is based on reprojection. If not, diamond search is based on homography. Homography is faster than reprojection, but less accurate.\nDeprecated:Use CharucoDetector::detectDiamonds \n\n◆ detectMarkers()\n\nvoid cv::aruco::detectMarkers \n(\nInputArray \nimage, \n\nconst Ptr< Dictionary > & \ndictionary, \n\nOutputArrayOfArrays \ncorners, \n\nOutputArray \nids, \n\nconst Ptr< DetectorParameters > & \nparameters = makePtr< DetectorParameters >(), \n\nOutputArrayOfArrays \nrejectedImgPoints = noArray() \n\n)\n\nPython:cv.aruco.detectMarkers(image, dictionary[, corners[, ids[, parameters[, rejectedImgPoints]]]]) -> corners, ids, rejectedImgPoints\n\n#include <opencv2/aruco.hpp>\ndetect markers \nDeprecated:Use class ArucoDetector::detectMarkers \n\n◆ drawCharucoDiamond()\n\nvoid cv::aruco::drawCharucoDiamond \n(\nconst Ptr< Dictionary > & \ndictionary, \n\nVec4i \nids, \n\nint \nsquareLength, \n\nint \nmarkerLength, \n\nOutputArray \nimg, \n\nint \nmarginSize = 0, \n\nint \nborderBits = 1 \n\n)\n\nPython:cv.aruco.drawCharucoDiamond(dictionary, ids, squareLength, markerLength[, img[, marginSize[, borderBits]]]) -> img\n\n#include <opencv2/aruco/charuco.hpp>\nDraw a ChArUco Diamond marker. \nParameters\n\ndictionarydictionary of markers indicating the type of markers. \nidslist of 4 ids for each ArUco marker in the ChArUco marker. \nsquareLengthsize of the chessboard squares in pixels. \nmarkerLengthsize of the markers in pixels. \nimgoutput image with the marker. The size of this image will be 3*squareLength + 2*marginSize,. \nmarginSizeminimum margins (in pixels) of the marker in the output image \nborderBitswidth of the marker borders.\n\nThis function return the image of a ChArUco marker, ready to be printed.\nDeprecated:Use CharucoBoard::generateImage() \n\n◆ drawPlanarBoard()\n\nvoid cv::aruco::drawPlanarBoard \n(\nconst Ptr< Board > & \nboard, \n\nSize \noutSize, \n\nOutputArray \nimg, \n\nint \nmarginSize, \n\nint \nborderBits \n\n)\n\nPython:cv.aruco.drawPlanarBoard(board, outSize, marginSize, borderBits[, img]) -> img\n\n#include <opencv2/aruco.hpp>\ndraw planar board \nDeprecated:Use Board::generateImage \n\n◆ estimatePoseBoard()\n\nint cv::aruco::estimatePoseBoard \n(\nInputArrayOfArrays \ncorners, \n\nInputArray \nids, \n\nconst Ptr< Board > & \nboard, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputOutputArray \nrvec, \n\nInputOutputArray \ntvec, \n\nbool \nuseExtrinsicGuess = false \n\n)\n\nPython:cv.aruco.estimatePoseBoard(corners, ids, board, cameraMatrix, distCoeffs, rvec, tvec[, useExtrinsicGuess]) -> retval, rvec, tvec\n\n#include <opencv2/aruco.hpp>\nDeprecated:Use Board::matchImagePoints and cv::solvePnP \n\n◆ estimatePoseCharucoBoard()\n\nbool cv::aruco::estimatePoseCharucoBoard \n(\nInputArray \ncharucoCorners, \n\nInputArray \ncharucoIds, \n\nconst Ptr< CharucoBoard > & \nboard, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputOutputArray \nrvec, \n\nInputOutputArray \ntvec, \n\nbool \nuseExtrinsicGuess = false \n\n)\n\nPython:cv.aruco.estimatePoseCharucoBoard(charucoCorners, charucoIds, board, cameraMatrix, distCoeffs, rvec, tvec[, useExtrinsicGuess]) -> retval, rvec, tvec\n\n#include <opencv2/aruco.hpp>\nPose estimation for a ChArUco board given some of their corners. \nParameters\n\ncharucoCornersvector of detected charuco corners \ncharucoIdslist of identifiers for each corner in charucoCorners \nboardlayout of ChArUco board. \ncameraMatrixinput 3x3 floating-point camera matrix \\(A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) \ndistCoeffsvector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\) of 4, 5, 8 or 12 elements \nrvecOutput vector (e.g. cv::Mat) corresponding to the rotation vector of the board (see cv::Rodrigues). \ntvecOutput vector (e.g. cv::Mat) corresponding to the translation vector of the board. \nuseExtrinsicGuessdefines whether initial guess for rvec and tvec will be used or not.\n\nThis function estimates a Charuco board pose from some detected corners. The function checks if the input corners are enough and valid to perform pose estimation. If pose estimation is valid, returns true, else returns false. Deprecated:Use CharucoBoard::matchImagePoints and cv::solvePnP \nSee alsouse cv::drawFrameAxes to get world coordinate system axis for object points \n\n◆ estimatePoseSingleMarkers()\n\nvoid cv::aruco::estimatePoseSingleMarkers \n(\nInputArrayOfArrays \ncorners, \n\nfloat \nmarkerLength, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArray \nrvecs, \n\nOutputArray \ntvecs, \n\nOutputArray \nobjPoints = noArray(), \n\nconst Ptr< EstimateParameters > & \nestimateParameters = makePtr< EstimateParameters >() \n\n)\n\nPython:cv.aruco.estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs[, rvecs[, tvecs[, objPoints[, estimateParameters]]]]) -> rvecs, tvecs, objPoints\n\n#include <opencv2/aruco.hpp>\nDeprecated:Use cv::solvePnP \n\n◆ getBoardObjectAndImagePoints()\n\nvoid cv::aruco::getBoardObjectAndImagePoints \n(\nconst Ptr< Board > & \nboard, \n\nInputArrayOfArrays \ndetectedCorners, \n\nInputArray \ndetectedIds, \n\nOutputArray \nobjPoints, \n\nOutputArray \nimgPoints \n\n)\n\nPython:cv.aruco.getBoardObjectAndImagePoints(board, detectedCorners, detectedIds[, objPoints[, imgPoints]]) -> objPoints, imgPoints\n\n#include <opencv2/aruco.hpp>\nget board object and image points \nDeprecated:Use Board::matchImagePoints \n\n◆ interpolateCornersCharuco()\n\nint cv::aruco::interpolateCornersCharuco \n(\nInputArrayOfArrays \nmarkerCorners, \n\nInputArray \nmarkerIds, \n\nInputArray \nimage, \n\nconst Ptr< CharucoBoard > & \nboard, \n\nOutputArray \ncharucoCorners, \n\nOutputArray \ncharucoIds, \n\nInputArray \ncameraMatrix = noArray(), \n\nInputArray \ndistCoeffs = noArray(), \n\nint \nminMarkers = 2 \n\n)\n\nPython:cv.aruco.interpolateCornersCharuco(markerCorners, markerIds, image, board[, charucoCorners[, charucoIds[, cameraMatrix[, distCoeffs[, minMarkers]]]]]) -> retval, charucoCorners, charucoIds\n\n#include <opencv2/aruco/charuco.hpp>\nInterpolate position of ChArUco board corners. \nParameters\n\nmarkerCornersvector of already detected markers corners. For each marker, its four corners are provided, (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers, the dimensions of this array should be Nx4. The order of the corners should be clockwise. \nmarkerIdslist of identifiers for each marker in corners \nimageinput image necesary for corner refinement. Note that markers are not detected and should be sent in corners and ids parameters. \nboardlayout of ChArUco board. \ncharucoCornersinterpolated chessboard corners \ncharucoIdsinterpolated chessboard corners identifiers \ncameraMatrixoptional 3x3 floating-point camera matrix \\(A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) \ndistCoeffsoptional vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\) of 4, 5, 8 or 12 elements \nminMarkersnumber of adjacent markers that must be detected to return a charuco corner\n\nThis function receives the detected markers and returns the 2D position of the chessboard corners from a ChArUco board using the detected Aruco markers. If camera parameters are provided, the process is based in an approximated pose estimation, else it is based on local homography. Only visible corners are returned. For each corner, its corresponding identifier is also returned in charucoIds. The function returns the number of interpolated corners.\nDeprecated:Use CharucoDetector::detectBoard \n\n◆ refineDetectedMarkers()\n\nvoid cv::aruco::refineDetectedMarkers \n(\nInputArray \nimage, \n\nconst Ptr< Board > & \nboard, \n\nInputOutputArrayOfArrays \ndetectedCorners, \n\nInputOutputArray \ndetectedIds, \n\nInputOutputArrayOfArrays \nrejectedCorners, \n\nInputArray \ncameraMatrix = noArray(), \n\nInputArray \ndistCoeffs = noArray(), \n\nfloat \nminRepDistance = 10.f, \n\nfloat \nerrorCorrectionRate = 3.f, \n\nbool \ncheckAllOrders = true, \n\nOutputArray \nrecoveredIdxs = noArray(), \n\nconst Ptr< DetectorParameters > & \nparameters = makePtr< DetectorParameters >() \n\n)\n\nPython:cv.aruco.refineDetectedMarkers(image, board, detectedCorners, detectedIds, rejectedCorners[, cameraMatrix[, distCoeffs[, minRepDistance[, errorCorrectionRate[, checkAllOrders[, recoveredIdxs[, parameters]]]]]]]) -> detectedCorners, detectedIds, rejectedCorners, recoveredIdxs\n\n#include <opencv2/aruco.hpp>\nrefine detected markers \nDeprecated:Use class ArucoDetector::refineDetectedMarkers \n\n◆ testCharucoCornersCollinear()\n\nbool cv::aruco::testCharucoCornersCollinear \n(\nconst Ptr< CharucoBoard > & \nboard, \n\nInputArray \ncharucoIds \n\n)\n\nPython:cv.aruco.testCharucoCornersCollinear(board, charucoIds) -> retval\n\n#include <opencv2/aruco.hpp>\nDeprecated:Use CharucoBoard::checkCharucoCornersCollinear \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/d86/group__stereo.html","content_type":"text/html","title":"OpenCV: Stereo Correspondance Algorithms","language":null},"page_content":"OpenCV: Stereo Correspondance Algorithms\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations \nStereo Correspondance Algorithms\n\nDetailed Description\n\nClasses\nstruct  cv::stereo::MatchQuasiDense\n \nstruct  cv::stereo::PropagationParameters\n \nclass  cv::stereo::QuasiDenseStereo\n Class containing the methods needed for Quasi Dense Stereo computation.  More...\n \nclass  cv::stereo::StereoBinaryBM\n Class for computing stereo correspondence using the block matching algorithm, introduced and contributed to OpenCV by K. Konolige.  More...\n \nclass  cv::stereo::StereoBinarySGBM\n The class implements the modified H. Hirschmuller algorithm [126] that differs from the original one as follows:  More...\n \nclass  cv::stereo::StereoMatcher\n Filters off small noise blobs (speckles) in the disparity map.  More...\n \n\nEnumerations\nenum  { \n  cv::stereo::CV_SPECKLE_REMOVAL_ALGORITHM\n, \n  cv::stereo::CV_SPECKLE_REMOVAL_AVG_ALGORITHM\n\n }\n speckle removal algorithms. These algorithms have the purpose of removing small regions  More...\n \nenum  { \n  cv::stereo::CV_QUADRATIC_INTERPOLATION\n, \n  cv::stereo::CV_SIMETRICV_INTERPOLATION\n\n }\n subpixel interpolationm methods for disparities.  More...\n \n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/stereo.hpp>\nspeckle removal algorithms. These algorithms have the purpose of removing small regions \n\nEnumeratorCV_SPECKLE_REMOVAL_ALGORITHM Python: cv.stereo.CV_SPECKLE_REMOVAL_ALGORITHM\nCV_SPECKLE_REMOVAL_AVG_ALGORITHM Python: cv.stereo.CV_SPECKLE_REMOVAL_AVG_ALGORITHM\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/stereo.hpp>\nsubpixel interpolationm methods for disparities. \n\nEnumeratorCV_QUADRATIC_INTERPOLATION Python: cv.stereo.CV_QUADRATIC_INTERPOLATION\nCV_SIMETRICV_INTERPOLATION Python: cv.stereo.CV_SIMETRICV_INTERPOLATION\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d0/d61/group__cudacodec.html","content_type":"text/html","title":"OpenCV: Video Encoding/Decoding","language":null},"page_content":"OpenCV: Video Encoding/Decoding\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations |\nFunctions \nVideo Encoding/DecodingCUDA-accelerated Computer Vision\n\nDetailed Description\n\nClasses\nstruct  cv::cudacodec::EncodeQp\n \nclass  cv::cudacodec::EncoderCallback\n Interface for encoder callbacks.  More...\n \nstruct  cv::cudacodec::EncoderParams\n Different parameters for CUDA video encoder.  More...\n \nstruct  cv::cudacodec::FormatInfo\n Struct providing information about video file format. :  More...\n \nclass  cv::cudacodec::RawVideoSource\n Interface for video demultiplexing. :  More...\n \nclass  cv::cudacodec::VideoReader\n Video reader interface, see createVideoReader().  More...\n \nstruct  cv::cudacodec::VideoReaderInitParams\n VideoReader initialization parameters.  More...\n \nclass  cv::cudacodec::VideoWriter\n Video writer interface, see createVideoWriter().  More...\n \n\nEnumerations\nenum  cv::cudacodec::ChromaFormat { \n  cv::cudacodec::Monochrome = 0\n, \n  cv::cudacodec::YUV420\n, \n  cv::cudacodec::YUV422\n, \n  cv::cudacodec::YUV444\n, \n  cv::cudacodec::NumFormats\n\n }\n Chroma formats supported by cudacodec::VideoReader.  More...\n \nenum  cv::cudacodec::Codec { \n  cv::cudacodec::MPEG1 = 0\n, \n  cv::cudacodec::MPEG2\n, \n  cv::cudacodec::MPEG4\n, \n  cv::cudacodec::VC1\n, \n  cv::cudacodec::H264\n, \n  cv::cudacodec::JPEG\n, \n  cv::cudacodec::H264_SVC\n, \n  cv::cudacodec::H264_MVC\n, \n  cv::cudacodec::HEVC\n, \n  cv::cudacodec::VP8\n, \n  cv::cudacodec::VP9\n, \n  cv::cudacodec::AV1\n, \n  cv::cudacodec::NumCodecs\n, \n  cv::cudacodec::Uncompressed_YUV420 = (('I' << 24) | ('Y' << 16) | ('U' << 8) | ('V'))\n, \n  cv::cudacodec::Uncompressed_YV12 = (('Y' << 24) | ('V' << 16) | ('1' << 8) | ('2'))\n, \n  cv::cudacodec::Uncompressed_NV12 = (('N' << 24) | ('V' << 16) | ('1' << 8) | ('2'))\n, \n  cv::cudacodec::Uncompressed_YUYV = (('Y' << 24) | ('U' << 16) | ('Y' << 8) | ('V'))\n, \n  cv::cudacodec::Uncompressed_UYVY = (('U' << 24) | ('Y' << 16) | ('V' << 8) | ('Y'))\n\n }\n Video codecs supported by cudacodec::VideoReader and cudacodec::VideoWriter.  More...\n \nenum class  cv::cudacodec::ColorFormat { \n  cv::cudacodec::ColorFormat::UNDEFINED = 0\n, \n  cv::cudacodec::ColorFormat::BGRA = 1\n, \n  cv::cudacodec::ColorFormat::BGR = 2\n, \n  cv::cudacodec::ColorFormat::GRAY = 3\n, \n  cv::cudacodec::ColorFormat::NV_NV12 = 4\n, \n  cv::cudacodec::ColorFormat::RGB = 5\n, \n  cv::cudacodec::ColorFormat::RGBA = 6\n, \n  cv::cudacodec::ColorFormat::NV_YV12 = 8\n, \n  cv::cudacodec::ColorFormat::NV_IYUV = 9\n, \n  cv::cudacodec::ColorFormat::NV_YUV444 = 10\n, \n  cv::cudacodec::ColorFormat::NV_AYUV = 11\n\n }\n ColorFormat for the frame returned by VideoReader::nextFrame() and VideoReader::retrieve() or used to initialize a VideoWriter.  More...\n \nenum  cv::cudacodec::DeinterlaceMode { \n  cv::cudacodec::Weave = 0\n, \n  cv::cudacodec::Bob = 1\n, \n  cv::cudacodec::Adaptive = 2\n\n }\n Deinterlacing mode used by decoder.  More...\n \nenum  cv::cudacodec::EncodeMultiPass { \n  cv::cudacodec::ENC_MULTI_PASS_DISABLED = 0x0\n, \n  cv::cudacodec::ENC_TWO_PASS_QUARTER_RESOLUTION = 0x1\n, \n  cv::cudacodec::ENC_TWO_PASS_FULL_RESOLUTION = 0x2\n\n }\n Multi Pass Encoding.  More...\n \nenum  cv::cudacodec::EncodeParamsRcMode { \n  cv::cudacodec::ENC_PARAMS_RC_CONSTQP = 0x0\n, \n  cv::cudacodec::ENC_PARAMS_RC_VBR = 0x1\n, \n  cv::cudacodec::ENC_PARAMS_RC_CBR = 0x2\n\n }\n Rate Control Modes.  More...\n \nenum  cv::cudacodec::EncodePreset { \n  cv::cudacodec::ENC_PRESET_P1 = 1\n, \n  cv::cudacodec::ENC_PRESET_P2 = 2\n, \n  cv::cudacodec::ENC_PRESET_P3 = 3\n, \n  cv::cudacodec::ENC_PRESET_P4 = 4\n, \n  cv::cudacodec::ENC_PRESET_P5 = 5\n, \n  cv::cudacodec::ENC_PRESET_P6 = 6\n, \n  cv::cudacodec::ENC_PRESET_P7 = 7\n\n }\n Nvidia Encoding Presets. Performance degrades and quality improves as we move from P1 to P7.  More...\n \nenum  cv::cudacodec::EncodeProfile { \n  cv::cudacodec::ENC_CODEC_PROFILE_AUTOSELECT = 0\n, \n  cv::cudacodec::ENC_H264_PROFILE_BASELINE = 1\n, \n  cv::cudacodec::ENC_H264_PROFILE_MAIN = 2\n, \n  cv::cudacodec::ENC_H264_PROFILE_HIGH = 3\n, \n  cv::cudacodec::ENC_H264_PROFILE_HIGH_444 = 4\n, \n  cv::cudacodec::ENC_H264_PROFILE_STEREO = 5\n, \n  cv::cudacodec::ENC_H264_PROFILE_PROGRESSIVE_HIGH = 6\n, \n  cv::cudacodec::ENC_H264_PROFILE_CONSTRAINED_HIGH = 7\n, \n  cv::cudacodec::ENC_HEVC_PROFILE_MAIN = 8\n, \n  cv::cudacodec::ENC_HEVC_PROFILE_MAIN10 = 9\n, \n  cv::cudacodec::ENC_HEVC_PROFILE_FREXT = 10\n\n }\n Supported Encoder Profiles.  More...\n \nenum  cv::cudacodec::EncodeTuningInfo { \n  cv::cudacodec::ENC_TUNING_INFO_UNDEFINED = 0\n, \n  cv::cudacodec::ENC_TUNING_INFO_HIGH_QUALITY = 1\n, \n  cv::cudacodec::ENC_TUNING_INFO_LOW_LATENCY = 2\n, \n  cv::cudacodec::ENC_TUNING_INFO_ULTRA_LOW_LATENCY = 3\n, \n  cv::cudacodec::ENC_TUNING_INFO_LOSSLESS = 4\n, \n  cv::cudacodec::ENC_TUNING_INFO_COUNT\n\n }\n Tuning information.  More...\n \nenum class  cv::cudacodec::VideoReaderProps { \n  cv::cudacodec::VideoReaderProps::PROP_DECODED_FRAME_IDX = 0\n, \n  cv::cudacodec::VideoReaderProps::PROP_EXTRA_DATA_INDEX = 1\n, \n  cv::cudacodec::VideoReaderProps::PROP_RAW_PACKAGES_BASE_INDEX = 2\n, \n  cv::cudacodec::VideoReaderProps::PROP_NUMBER_OF_RAW_PACKAGES_SINCE_LAST_GRAB = 3\n, \n  cv::cudacodec::VideoReaderProps::PROP_RAW_MODE = 4\n, \n  cv::cudacodec::VideoReaderProps::PROP_LRF_HAS_KEY_FRAME = 5\n, \n  cv::cudacodec::VideoReaderProps::PROP_COLOR_FORMAT = 6\n, \n  cv::cudacodec::VideoReaderProps::PROP_UDP_SOURCE = 7\n, \n  cv::cudacodec::VideoReaderProps::PROP_ALLOW_FRAME_DROP = 8\n\n }\n cv::cudacodec::VideoReader generic properties identifier.  More...\n \n\nFunctions\nPtr< VideoReader > cv::cudacodec::createVideoReader (const Ptr< RawVideoSource > &source, const VideoReaderInitParams params=VideoReaderInitParams())\n \nPtr< VideoReader > cv::cudacodec::createVideoReader (const String &filename, const std::vector< int > &sourceParams={}, const VideoReaderInitParams params=VideoReaderInitParams())\n Creates video reader.  \n \nPtr< cudacodec::VideoWriter > cv::cudacodec::createVideoWriter (const String &fileName, const Size frameSize, const Codec codec, const double fps, const ColorFormat colorFormat, const EncoderParams &params, Ptr< EncoderCallback > encoderCallback=0, const cuda::Stream &stream=cuda::Stream::Null())\n Creates video writer.  \n \nPtr< cudacodec::VideoWriter > cv::cudacodec::createVideoWriter (const String &fileName, const Size frameSize, const Codec codec=Codec::H264, const double fps=25.0, const ColorFormat colorFormat=ColorFormat::BGR, Ptr< EncoderCallback > encoderCallback=0, const cuda::Stream &stream=cuda::Stream::Null())\n Creates video writer.  \n \nvoid cv::cudacodec::MapHist (const cuda::GpuMat &hist, Mat &histFull)\n Utility function demonstrating how to map the luma histogram when FormatInfo::videoFullRangeFlag == false.  \n \nbool cv::cudacodec::operator== (const EncoderParams &lhs, const EncoderParams &rhs)\n \n\nEnumeration Type Documentation\n\n◆ ChromaFormat\n\nenum cv::cudacodec::ChromaFormat\n\n#include <opencv2/cudacodec.hpp>\nChroma formats supported by cudacodec::VideoReader. \n\nEnumeratorMonochrome \nYUV420 \nYUV422 \nYUV444 \nNumFormats \n\n◆ Codec\n\nenum cv::cudacodec::Codec\n\n#include <opencv2/cudacodec.hpp>\nVideo codecs supported by cudacodec::VideoReader and cudacodec::VideoWriter. \nNote\nSupport will depend on your hardware, refer to the Nvidia Video Codec SDK Video Encode and Decode GPU Support Matrix for details. \n\nEnumeratorMPEG1 \nMPEG2 \nMPEG4 \nVC1 \nH264 \nJPEG \nH264_SVC \nH264_MVC \nHEVC \nVP8 \nVP9 \nAV1 \nNumCodecs \nUncompressed_YUV420 Y,U,V (4:2:0) \n\nUncompressed_YV12 Y,V,U (4:2:0) \n\nUncompressed_NV12 Y,UV (4:2:0) \n\nUncompressed_YUYV YUYV/YUY2 (4:2:2) \n\nUncompressed_UYVY UYVY (4:2:2) \n\n◆ ColorFormat\n\nenum class cv::cudacodec::ColorFormat\n\nstrong \n\n#include <opencv2/cudacodec.hpp>\nColorFormat for the frame returned by VideoReader::nextFrame() and VideoReader::retrieve() or used to initialize a VideoWriter. \n\nEnumeratorUNDEFINED \nBGRA OpenCV color format, can be used with both VideoReader and VideoWriter. \n\nBGR OpenCV color format, can be used with both VideoReader and VideoWriter. \n\nGRAY OpenCV color format, can be used with both VideoReader and VideoWriter. \n\nNV_NV12 Nvidia color format - equivalent to YUV - Semi-Planar YUV [Y plane followed by interleaved UV plane], can be used with both VideoReader and VideoWriter. \n\nRGB OpenCV color format, can only be used with VideoWriter. \n\nRGBA OpenCV color format, can only be used with VideoWriter. \n\nNV_YV12 Nvidia Buffer Format - Planar YUV [Y plane followed by V and U planes], use with VideoReader, can only be used with VideoWriter. \n\nNV_IYUV Nvidia Buffer Format - Planar YUV [Y plane followed by U and V planes], use with VideoReader, can only be used with VideoWriter. \n\nNV_YUV444 Nvidia Buffer Format - Planar YUV [Y plane followed by U and V planes], use with VideoReader, can only be used with VideoWriter. \n\nNV_AYUV Nvidia Buffer Format - 8 bit Packed A8Y8U8V8. This is a word-ordered format where a pixel is represented by a 32-bit word with V in the lowest 8 bits, U in the next 8 bits, Y in the 8 bits after that and A in the highest 8 bits, can only be used with VideoWriter. \n\n◆ DeinterlaceMode\n\nenum cv::cudacodec::DeinterlaceMode\n\n#include <opencv2/cudacodec.hpp>\nDeinterlacing mode used by decoder. \nParameters\n\nWeaveWeave both fields (no deinterlacing). For progressive content and for content that doesn't need deinterlacing. \nBobDrop one field. \nAdaptiveAdaptive deinterlacing needs more video memory than other deinterlacing modes. \n\nEnumeratorWeave \nBob \nAdaptive \n\n◆ EncodeMultiPass\n\nenum cv::cudacodec::EncodeMultiPass\n\n#include <opencv2/cudacodec.hpp>\nMulti Pass Encoding. \n\nEnumeratorENC_MULTI_PASS_DISABLED Single Pass. \n\nENC_TWO_PASS_QUARTER_RESOLUTION Two Pass encoding is enabled where first Pass is quarter resolution. \n\nENC_TWO_PASS_FULL_RESOLUTION Two Pass encoding is enabled where first Pass is full resolution. \n\n◆ EncodeParamsRcMode\n\nenum cv::cudacodec::EncodeParamsRcMode\n\n#include <opencv2/cudacodec.hpp>\nRate Control Modes. \n\nEnumeratorENC_PARAMS_RC_CONSTQP Constant QP mode. \n\nENC_PARAMS_RC_VBR Variable bitrate mode. \n\nENC_PARAMS_RC_CBR Constant bitrate mode. \n\n◆ EncodePreset\n\nenum cv::cudacodec::EncodePreset\n\n#include <opencv2/cudacodec.hpp>\nNvidia Encoding Presets. Performance degrades and quality improves as we move from P1 to P7. \n\nEnumeratorENC_PRESET_P1 \nENC_PRESET_P2 \nENC_PRESET_P3 \nENC_PRESET_P4 \nENC_PRESET_P5 \nENC_PRESET_P6 \nENC_PRESET_P7 \n\n◆ EncodeProfile\n\nenum cv::cudacodec::EncodeProfile\n\n#include <opencv2/cudacodec.hpp>\nSupported Encoder Profiles. \n\nEnumeratorENC_CODEC_PROFILE_AUTOSELECT \nENC_H264_PROFILE_BASELINE \nENC_H264_PROFILE_MAIN \nENC_H264_PROFILE_HIGH \nENC_H264_PROFILE_HIGH_444 \nENC_H264_PROFILE_STEREO \nENC_H264_PROFILE_PROGRESSIVE_HIGH \nENC_H264_PROFILE_CONSTRAINED_HIGH \nENC_HEVC_PROFILE_MAIN \nENC_HEVC_PROFILE_MAIN10 \nENC_HEVC_PROFILE_FREXT \n\n◆ EncodeTuningInfo\n\nenum cv::cudacodec::EncodeTuningInfo\n\n#include <opencv2/cudacodec.hpp>\nTuning information. \n\nEnumeratorENC_TUNING_INFO_UNDEFINED Undefined tuningInfo. Invalid value for encoding. \n\nENC_TUNING_INFO_HIGH_QUALITY Tune presets for latency tolerant encoding. \n\nENC_TUNING_INFO_LOW_LATENCY Tune presets for low latency streaming. \n\nENC_TUNING_INFO_ULTRA_LOW_LATENCY Tune presets for ultra low latency streaming. \n\nENC_TUNING_INFO_LOSSLESS Tune presets for lossless encoding. \n\nENC_TUNING_INFO_COUNT \n\n◆ VideoReaderProps\n\nenum class cv::cudacodec::VideoReaderProps\n\nstrong \n\n#include <opencv2/cudacodec.hpp>\ncv::cudacodec::VideoReader generic properties identifier. \n\nEnumeratorPROP_DECODED_FRAME_IDX Index for retrieving the decoded frame using retrieve(). \n\nPROP_EXTRA_DATA_INDEX Index for retrieving the extra data associated with a video source using retrieve(). \n\nPROP_RAW_PACKAGES_BASE_INDEX Base index for retrieving raw encoded data using retrieve(). \n\nPROP_NUMBER_OF_RAW_PACKAGES_SINCE_LAST_GRAB Number of raw packages recieved since the last call to grab(). \n\nPROP_RAW_MODE Status of raw mode. \n\nPROP_LRF_HAS_KEY_FRAME FFmpeg source only - Indicates whether the Last Raw Frame (LRF), output from VideoReader::retrieve() when VideoReader is initialized in raw mode, contains encoded data for a key frame. \n\nPROP_COLOR_FORMAT Set the ColorFormat of the decoded frame. This can be changed before every call to nextFrame() and retrieve(). \n\nPROP_UDP_SOURCE Status of VideoReaderInitParams::udpSource initialization. \n\nPROP_ALLOW_FRAME_DROP Status of VideoReaderInitParams::allowFrameDrop initialization. \n\nFunction Documentation\n\n◆ createVideoReader() [1/2]\n\nPtr< VideoReader > cv::cudacodec::createVideoReader \n(\nconst Ptr< RawVideoSource > & \nsource, \n\nconst VideoReaderInitParams \nparams = VideoReaderInitParams() \n\n)\n\n#include <opencv2/cudacodec.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nsourceRAW video source implemented by user. \nparamsInitializaton parameters. See cv::cudacodec::VideoReaderInitParams. \n\n◆ createVideoReader() [2/2]\n\nPtr< VideoReader > cv::cudacodec::createVideoReader \n(\nconst String & \nfilename, \n\nconst std::vector< int > & \nsourceParams = {}, \n\nconst VideoReaderInitParams \nparams = VideoReaderInitParams() \n\n)\n\n#include <opencv2/cudacodec.hpp>\nCreates video reader. \nParameters\n\nfilenameName of the input video file. \nsourceParamsPass through parameters for VideoCapure. VideoCapture with the FFMpeg back end (CAP_FFMPEG) is used to parse the video input. The sourceParams parameter allows to specify extra parameters encoded as pairs (paramId_1, paramValue_1, paramId_2, paramValue_2, ...). See cv::VideoCaptureProperties e.g. when streaming from an RTSP source CAP_PROP_OPEN_TIMEOUT_MSEC may need to be set. \nparamsInitializaton parameters. See cv::cudacodec::VideoReaderInitParams.\n\nFFMPEG is used to read videos. User can implement own demultiplexing with cudacodec::RawVideoSource \n\n◆ createVideoWriter() [1/2]\n\nPtr< cudacodec::VideoWriter > cv::cudacodec::createVideoWriter \n(\nconst String & \nfileName, \n\nconst Size \nframeSize, \n\nconst Codec \ncodec, \n\nconst double \nfps, \n\nconst ColorFormat \ncolorFormat, \n\nconst EncoderParams & \nparams, \n\nPtr< EncoderCallback > \nencoderCallback = 0, \n\nconst cuda::Stream & \nstream = cuda::Stream::Null() \n\n)\n\n#include <opencv2/cudacodec.hpp>\nCreates video writer. \nParameters\n\nfileNameName of the output video file. \nframeSizeSize of the input video frames. \ncodecSupports Codec::H264 and Codec::HEVC. \nfpsFramerate of the created video stream. \ncolorFormatOpenCv color format of the frames to be encoded. \nparamsAdditional encoding parameters. \nencoderCallbackCallbacks for video encoder. See cudacodec::EncoderCallback. Required for working with the encoded video stream. \nstreamStream for frame pre-processing. \n\n◆ createVideoWriter() [2/2]\n\nPtr< cudacodec::VideoWriter > cv::cudacodec::createVideoWriter \n(\nconst String & \nfileName, \n\nconst Size \nframeSize, \n\nconst Codec \ncodec = Codec::H264, \n\nconst double \nfps = 25.0, \n\nconst ColorFormat \ncolorFormat = ColorFormat::BGR, \n\nPtr< EncoderCallback > \nencoderCallback = 0, \n\nconst cuda::Stream & \nstream = cuda::Stream::Null() \n\n)\n\n#include <opencv2/cudacodec.hpp>\nCreates video writer. \nParameters\n\nfileNameName of the output video file. \nframeSizeSize of the input video frames. \ncodecSupports Codec::H264 and Codec::HEVC. \nfpsFramerate of the created video stream. \ncolorFormatOpenCv color format of the frames to be encoded. \nencoderCallbackCallbacks for video encoder. See cudacodec::EncoderCallback. Required for working with the encoded video stream. \nstreamStream for frame pre-processing. \n\n◆ MapHist()\n\nvoid cv::cudacodec::MapHist \n(\nconst cuda::GpuMat & \nhist, \n\nMat & \nhistFull \n\n)\n\n#include <opencv2/cudacodec.hpp>\nUtility function demonstrating how to map the luma histogram when FormatInfo::videoFullRangeFlag == false. \nParameters\n\nhistLuma histogram hist returned from VideoReader::nextFrame(GpuMat& frame, GpuMat& hist, Stream& stream). \nhistFullHost histogram equivelent to downloading hist after calling cuda::calcHist(InputArray frame, OutputArray hist, Stream& stream).\n\nNote\nThis function demonstrates how to map the luma histogram back so that it is equivalent to the result obtained from cuda::calcHist() if the returned frame was colorFormat::GRAY. \n\n◆ operator==()\n\nbool cv::cudacodec::operator== \n(\nconst EncoderParams & \nlhs, \n\nconst EncoderParams & \nrhs \n\n)\n\n#include <opencv2/cudacodec.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d8/d00/group__datasets.html","content_type":"text/html","title":"OpenCV: Framework for working with different datasets","language":null},"page_content":"OpenCV: Framework for working with different datasets\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nFunctions \nFramework for working with different datasets\n\nModules\n Action Recognition\n \n Face Recognition\n \n Gesture Recognition\n \n Human Pose Estimation\n \n Image Registration\n \n Image Segmentation\n \n Multiview Stereo Matching\n \n Object Recognition\n \n Pedestrian Detection\n \n SLAM\n \n Super Resolution\n \n Text Recognition\n \n Tracking\n \n\nDetailed Description\nThe datasets module includes classes for working with different datasets: load data, evaluate different algorithms on them, contains benchmarks, etc.\nIt is planned to have:\n\nbasic: loading code for all datasets to help start work with them.\nnext stage: quick benchmarks for all datasets to show how to solve them using OpenCV and implement evaluation code.\nfinally: implement on OpenCV state-of-the-art algorithms, which solve these tasks. \n\nClasses\nclass  cv::datasets::Dataset\n \nstruct  cv::datasets::Object\n \n\nFunctions\nvoid cv::datasets::createDirectory (const std::string &path)\n \nvoid cv::datasets::getDirList (const std::string &dirName, std::vector< std::string > &fileNames)\n \nvoid cv::datasets::split (const std::string &s, std::vector< std::string > &elems, char delim)\n \n\nFunction Documentation\n\n◆ createDirectory()\n\nvoid cv::datasets::createDirectory \n(\nconst std::string & \npath)\n\n#include <opencv2/datasets/util.hpp>\n\n◆ getDirList()\n\nvoid cv::datasets::getDirList \n(\nconst std::string & \ndirName, \n\nstd::vector< std::string > & \nfileNames \n\n)\n\n#include <opencv2/datasets/util.hpp>\n\n◆ split()\n\nvoid cv::datasets::split \n(\nconst std::string & \ns, \n\nstd::vector< std::string > & \nelems, \n\nchar \ndelim \n\n)\n\n#include <opencv2/datasets/util.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/da/d9b/group__features2d.html","content_type":"text/html","title":"OpenCV: 2D Features Framework","language":null},"page_content":"OpenCV: 2D Features Framework\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \n2D Features Framework\n\nModules\n Feature Detection and Description\n \n Descriptor Matchers\n \n Drawing Function of Keypoints and Matches\n \n Object Categorization\n \n Hardware Acceleration Layer\n \n\nDetailed Description\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/df/dfc/group__cudev.html","content_type":"text/html","title":"OpenCV: Device layer","language":null},"page_content":"OpenCV: Device layer\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nNamespaces |\nClasses |\nMacros |\nTypedefs |\nEnumerations |\nFunctions |\nVariables \nDevice layerCUDA-accelerated Computer Vision\n\nDetailed Description\n\nNamespaces\nnamespace  cv::cudev::functional_detail\n \nnamespace  cv::cudev::vec_math_detail\n \n\nClasses\nstruct  cv::cudev::abs_func< T >\n \nstruct  cv::cudev::abs_func< double >\n \nstruct  cv::cudev::abs_func< float >\n \nstruct  cv::cudev::abs_func< schar >\n \nstruct  cv::cudev::abs_func< short >\n \nstruct  cv::cudev::abs_func< uchar >\n \nstruct  cv::cudev::abs_func< uint >\n \nstruct  cv::cudev::abs_func< ushort >\n \nstruct  cv::cudev::absdiff_func< T >\n \nstruct  cv::cudev::acos_func< T >\n \nstruct  cv::cudev::acos_func< double >\n \nstruct  cv::cudev::acos_func< float >\n \nstruct  cv::cudev::acos_func< schar >\n \nstruct  cv::cudev::acos_func< short >\n \nstruct  cv::cudev::acos_func< uchar >\n \nstruct  cv::cudev::acos_func< uint >\n \nstruct  cv::cudev::acos_func< ushort >\n \nstruct  cv::cudev::acosh_func< T >\n \nstruct  cv::cudev::acosh_func< double >\n \nstruct  cv::cudev::acosh_func< float >\n \nstruct  cv::cudev::acosh_func< schar >\n \nstruct  cv::cudev::acosh_func< short >\n \nstruct  cv::cudev::acosh_func< uchar >\n \nstruct  cv::cudev::acosh_func< uint >\n \nstruct  cv::cudev::acosh_func< ushort >\n \nstruct  cv::cudev::AffineMapPtr\n \nstruct  cv::cudev::AffineMapPtrSz\n \nstruct  cv::cudev::ArrayWrapper< T, COUNT >\n \nstruct  cv::cudev::asin_func< T >\n \nstruct  cv::cudev::asin_func< double >\n \nstruct  cv::cudev::asin_func< float >\n \nstruct  cv::cudev::asin_func< schar >\n \nstruct  cv::cudev::asin_func< short >\n \nstruct  cv::cudev::asin_func< uchar >\n \nstruct  cv::cudev::asin_func< uint >\n \nstruct  cv::cudev::asin_func< ushort >\n \nstruct  cv::cudev::asinh_func< T >\n \nstruct  cv::cudev::asinh_func< double >\n \nstruct  cv::cudev::asinh_func< float >\n \nstruct  cv::cudev::asinh_func< schar >\n \nstruct  cv::cudev::asinh_func< short >\n \nstruct  cv::cudev::asinh_func< uchar >\n \nstruct  cv::cudev::asinh_func< uint >\n \nstruct  cv::cudev::asinh_func< ushort >\n \nstruct  cv::cudev::atan2_func< T >\n \nstruct  cv::cudev::atan2_func< double >\n \nstruct  cv::cudev::atan2_func< float >\n \nstruct  cv::cudev::atan2_func< schar >\n \nstruct  cv::cudev::atan2_func< short >\n \nstruct  cv::cudev::atan2_func< uchar >\n \nstruct  cv::cudev::atan2_func< uint >\n \nstruct  cv::cudev::atan2_func< ushort >\n \nstruct  cv::cudev::atan_func< T >\n \nstruct  cv::cudev::atan_func< double >\n \nstruct  cv::cudev::atan_func< float >\n \nstruct  cv::cudev::atan_func< schar >\n \nstruct  cv::cudev::atan_func< short >\n \nstruct  cv::cudev::atan_func< uchar >\n \nstruct  cv::cudev::atan_func< uint >\n \nstruct  cv::cudev::atan_func< ushort >\n \nstruct  cv::cudev::atanh_func< T >\n \nstruct  cv::cudev::atanh_func< double >\n \nstruct  cv::cudev::atanh_func< float >\n \nstruct  cv::cudev::atanh_func< schar >\n \nstruct  cv::cudev::atanh_func< short >\n \nstruct  cv::cudev::atanh_func< uchar >\n \nstruct  cv::cudev::atanh_func< uint >\n \nstruct  cv::cudev::atanh_func< ushort >\n \nstruct  cv::cudev::Avg< T >\n \nstruct  cv::cudev::BGR_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_GRAY_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HLS4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HLS4_FULL_func< float >\n \nstruct  cv::cudev::BGR_to_HLS4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HLS4_func< float >\n \nstruct  cv::cudev::BGR_to_HLS_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HLS_FULL_func< float >\n \nstruct  cv::cudev::BGR_to_HLS_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HLS_func< float >\n \nstruct  cv::cudev::BGR_to_HSV4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HSV4_FULL_func< float >\n \nstruct  cv::cudev::BGR_to_HSV4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HSV4_func< float >\n \nstruct  cv::cudev::BGR_to_HSV_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HSV_FULL_func< float >\n \nstruct  cv::cudev::BGR_to_HSV_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_HSV_func< float >\n \nstruct  cv::cudev::BGR_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_XYZ4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_XYZ_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_YCrCb4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_YCrCb_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_YUV4_func< SrcDepth >\n \nstruct  cv::cudev::BGR_to_YUV_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_GRAY_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HLS4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HLS4_FULL_func< float >\n \nstruct  cv::cudev::BGRA_to_HLS4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HLS4_func< float >\n \nstruct  cv::cudev::BGRA_to_HLS_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HLS_FULL_func< float >\n \nstruct  cv::cudev::BGRA_to_HLS_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HLS_func< float >\n \nstruct  cv::cudev::BGRA_to_HSV4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HSV4_FULL_func< float >\n \nstruct  cv::cudev::BGRA_to_HSV4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HSV4_func< float >\n \nstruct  cv::cudev::BGRA_to_HSV_FULL_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HSV_FULL_func< float >\n \nstruct  cv::cudev::BGRA_to_HSV_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_HSV_func< float >\n \nstruct  cv::cudev::BGRA_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_XYZ4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_XYZ_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_YCrCb4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_YCrCb_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_YUV4_func< SrcDepth >\n \nstruct  cv::cudev::BGRA_to_YUV_func< SrcDepth >\n \nstruct  cv::cudev::binary_function< _Arg1, _Arg2, _Result >\n \nstruct  cv::cudev::BinaryNegate< Predicate >\n \nstruct  cv::cudev::BinaryTransformPtr< Src1Ptr, Src2Ptr, Op >\n \nstruct  cv::cudev::BinaryTransformPtrSz< Src1Ptr, Src2Ptr, Op >\n \nstruct  cv::cudev::BinaryTupleAdapter< Op, n0, n1 >\n \nstruct  cv::cudev::Binder1st< Op >\n \nstruct  cv::cudev::Binder2nd< Op >\n \nstruct  cv::cudev::bit_and< T >\n \nstruct  cv::cudev::bit_lshift< T >\n \nstruct  cv::cudev::bit_not< T >\n \nstruct  cv::cudev::bit_or< T >\n \nstruct  cv::cudev::bit_rshift< T >\n \nstruct  cv::cudev::bit_xor< T >\n \nstruct  cv::cudev::Block\n \nstruct  cv::cudev::BrdBase< BrdImpl, SrcPtr >\n \nstruct  cv::cudev::BrdConstant< SrcPtr >\n \nstruct  cv::cudev::BrdReflect\n \nstruct  cv::cudev::BrdReflect101\n \nstruct  cv::cudev::BrdReplicate\n \nstruct  cv::cudev::BrdWrap\n \nstruct  cv::cudev::CommonAreaInterPtr< SrcPtr >\n \nstruct  cv::cudev::CommonAreaInterPtrSz< SrcPtr >\n \nstruct  cv::cudev::ConstantPtr< T >\n \nstruct  cv::cudev::ConstantPtrSz< T >\n \nstruct  cv::cudev::ConvertTuple< Tuple, CvtOp >\n \nstruct  cv::cudev::cos_func< T >\n \nstruct  cv::cudev::cos_func< double >\n \nstruct  cv::cudev::cos_func< float >\n \nstruct  cv::cudev::cos_func< schar >\n \nstruct  cv::cudev::cos_func< short >\n \nstruct  cv::cudev::cos_func< uchar >\n \nstruct  cv::cudev::cos_func< uint >\n \nstruct  cv::cudev::cos_func< ushort >\n \nstruct  cv::cudev::cosh_func< T >\n \nstruct  cv::cudev::cosh_func< double >\n \nstruct  cv::cudev::cosh_func< float >\n \nstruct  cv::cudev::cosh_func< schar >\n \nstruct  cv::cudev::cosh_func< short >\n \nstruct  cv::cudev::cosh_func< uchar >\n \nstruct  cv::cudev::cosh_func< uint >\n \nstruct  cv::cudev::cosh_func< ushort >\n \nstruct  cv::cudev::CountNonZeroExprBody< SrcPtr >\n \nstruct  cv::cudev::CubicInterPtr< SrcPtr >\n \nstruct  cv::cudev::CubicInterPtrSz< SrcPtr >\n \nstruct  cv::cudev::DefaultCopyPolicy\n \nstruct  cv::cudev::DefaultGlobReducePolicy\n \nstruct  cv::cudev::DefaultHistogramPolicy\n \nstruct  cv::cudev::DefaultReduceToVecPolicy\n \nstruct  cv::cudev::DefaultSplitMergePolicy\n \nstruct  cv::cudev::DefaultTransformPolicy\n \nstruct  cv::cudev::DefaultTransposePolicy\n \nstruct  cv::cudev::DerivXPtr< SrcPtr >\n \nstruct  cv::cudev::DerivXPtrSz< SrcPtr >\n \nstruct  cv::cudev::DerivYPtr< SrcPtr >\n \nstruct  cv::cudev::DerivYPtrSz< SrcPtr >\n \nstruct  cv::cudev::direction_func< T, angleInDegrees >\n \nstruct  cv::cudev::direction_interleaved_func< T2, angleInDegrees >\n \nstruct  cv::cudev::DisableIf< bool, T >\n \nstruct  cv::cudev::divides< T >\n \nstruct  cv::cudev::DynamicSharedMem< T >\n \nstruct  cv::cudev::DynamicSharedMem< double >\n \nstruct  cv::cudev::EnableIf< bool, T >\n \nstruct  cv::cudev::equal_to< T >\n \nstruct  cv::cudev::exp10_func< T >\n \nstruct  cv::cudev::exp10_func< double >\n \nstruct  cv::cudev::exp10_func< float >\n \nstruct  cv::cudev::exp10_func< schar >\n \nstruct  cv::cudev::exp10_func< short >\n \nstruct  cv::cudev::exp10_func< uchar >\n \nstruct  cv::cudev::exp10_func< uint >\n \nstruct  cv::cudev::exp10_func< ushort >\n \nstruct  cv::cudev::exp2_func< T >\n \nstruct  cv::cudev::exp2_func< double >\n \nstruct  cv::cudev::exp2_func< float >\n \nstruct  cv::cudev::exp2_func< schar >\n \nstruct  cv::cudev::exp2_func< short >\n \nstruct  cv::cudev::exp2_func< uchar >\n \nstruct  cv::cudev::exp2_func< uint >\n \nstruct  cv::cudev::exp2_func< ushort >\n \nstruct  cv::cudev::exp_func< T >\n \nstruct  cv::cudev::exp_func< double >\n \nstruct  cv::cudev::exp_func< float >\n \nstruct  cv::cudev::exp_func< schar >\n \nstruct  cv::cudev::exp_func< short >\n \nstruct  cv::cudev::exp_func< uchar >\n \nstruct  cv::cudev::exp_func< uint >\n \nstruct  cv::cudev::exp_func< ushort >\n \nstruct  cv::cudev::Expr< Body >\n \nstruct  cv::cudev::FindMaxValExprBody< SrcPtr >\n \nstruct  cv::cudev::FindMinMaxValExprBody< SrcPtr >\n \nstruct  cv::cudev::FindMinValExprBody< SrcPtr >\n \nstruct  cv::cudev::GlobPtr< T >\n Structure similar to cv::cudev::GlobPtrSz but containing only a pointer and row step.  More...\n \nstruct  cv::cudev::GlobPtrSz< T >\n Lightweight class encapsulating pitched memory on a GPU and passed to nvcc-compiled code (CUDA kernels).  More...\n \nclass  cv::cudev::GpuMat_< T >\n \nstruct  cv::cudev::GRAY_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::GRAY_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::greater< T >\n \nstruct  cv::cudev::greater_equal< T >\n \nstruct  cv::cudev::HistogramBody< BIN_COUNT, SrcPtr >\n \nstruct  cv::cudev::HLS4_to_BGR_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_BGR_FULL_func< float >\n \nstruct  cv::cudev::HLS4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_BGR_func< float >\n \nstruct  cv::cudev::HLS4_to_BGRA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_BGRA_FULL_func< float >\n \nstruct  cv::cudev::HLS4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_BGRA_func< float >\n \nstruct  cv::cudev::HLS4_to_RGB_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_RGB_FULL_func< float >\n \nstruct  cv::cudev::HLS4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_RGB_func< float >\n \nstruct  cv::cudev::HLS4_to_RGBA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_RGBA_FULL_func< float >\n \nstruct  cv::cudev::HLS4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::HLS4_to_RGBA_func< float >\n \nstruct  cv::cudev::HLS_to_BGR_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_BGR_FULL_func< float >\n \nstruct  cv::cudev::HLS_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_BGR_func< float >\n \nstruct  cv::cudev::HLS_to_BGRA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_BGRA_FULL_func< float >\n \nstruct  cv::cudev::HLS_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_BGRA_func< float >\n \nstruct  cv::cudev::HLS_to_RGB_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_RGB_FULL_func< float >\n \nstruct  cv::cudev::HLS_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_RGB_func< float >\n \nstruct  cv::cudev::HLS_to_RGBA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_RGBA_FULL_func< float >\n \nstruct  cv::cudev::HLS_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::HLS_to_RGBA_func< float >\n \nstruct  cv::cudev::HSV4_to_BGR_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_BGR_FULL_func< float >\n \nstruct  cv::cudev::HSV4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_BGR_func< float >\n \nstruct  cv::cudev::HSV4_to_BGRA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_BGRA_FULL_func< float >\n \nstruct  cv::cudev::HSV4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_BGRA_func< float >\n \nstruct  cv::cudev::HSV4_to_RGB_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_RGB_FULL_func< float >\n \nstruct  cv::cudev::HSV4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_RGB_func< float >\n \nstruct  cv::cudev::HSV4_to_RGBA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_RGBA_FULL_func< float >\n \nstruct  cv::cudev::HSV4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::HSV4_to_RGBA_func< float >\n \nstruct  cv::cudev::HSV_to_BGR_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_BGR_FULL_func< float >\n \nstruct  cv::cudev::HSV_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_BGR_func< float >\n \nstruct  cv::cudev::HSV_to_BGRA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_BGRA_FULL_func< float >\n \nstruct  cv::cudev::HSV_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_BGRA_func< float >\n \nstruct  cv::cudev::HSV_to_RGB_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_RGB_FULL_func< float >\n \nstruct  cv::cudev::HSV_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_RGB_func< float >\n \nstruct  cv::cudev::HSV_to_RGBA_FULL_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_RGBA_FULL_func< float >\n \nstruct  cv::cudev::HSV_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::HSV_to_RGBA_func< float >\n \nstruct  cv::cudev::hypot_func< T >\n \nstruct  cv::cudev::hypot_func< double >\n \nstruct  cv::cudev::hypot_func< float >\n \nstruct  cv::cudev::hypot_func< schar >\n \nstruct  cv::cudev::hypot_func< short >\n \nstruct  cv::cudev::hypot_func< uchar >\n \nstruct  cv::cudev::hypot_func< uint >\n \nstruct  cv::cudev::hypot_func< ushort >\n \nstruct  cv::cudev::identity< T >\n \nstruct  cv::cudev::InRangeComparator< T, cn, i >\n Functor that checks if a CUDA vector v is in the range between lowerb and upperb.  More...\n \nstruct  cv::cudev::InRangeCopier< T, cn, i >\n Functor that copies a cv::Scalar into a CUDA vector, e.g. a uchar3.  More...\n \nstruct  cv::cudev::InRangeFunc< T, cn >\n unary_function implementation of inRange  More...\n \nstruct  cv::cudev::Int2Type< A >\n \nstruct  cv::cudev::IntegerAreaInterPtr< SrcPtr >\n \nstruct  cv::cudev::IntegerAreaInterPtrSz< SrcPtr >\n \nstruct  cv::cudev::IntegralBody< SrcPtr >\n \nstruct  cv::cudev::IsBinaryFunction< F >\n \nstruct  cv::cudev::IsPowerOf2< N >\n \nstruct  cv::cudev::IsUnaryFunction< F >\n \nstruct  cv::cudev::Lab4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_LBGR_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_LBGRA_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_LRGB_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_LRGBA_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::Lab4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_LBGR_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_LBGRA_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_LRGB_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_LRGBA_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::Lab_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::LaplacianPtr< ksize, SrcPtr >\n \nstruct  cv::cudev::LaplacianPtr< 1, SrcPtr >\n \nstruct  cv::cudev::LaplacianPtr< 3, SrcPtr >\n \nstruct  cv::cudev::LaplacianPtrSz< ksize, SrcPtr >\n \nstruct  cv::cudev::LargerType< A, B >\n \nstruct  cv::cudev::LBGR_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::LBGR_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::LBGR_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::LBGR_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::LBGRA_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::LBGRA_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::LBGRA_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::LBGRA_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::less< T >\n \nstruct  cv::cudev::less_equal< T >\n \nstruct  cv::cudev::LinearInterPtr< SrcPtr >\n \nstruct  cv::cudev::LinearInterPtrSz< SrcPtr >\n \nstruct  cv::cudev::log10_func< T >\n \nstruct  cv::cudev::log10_func< double >\n \nstruct  cv::cudev::log10_func< float >\n \nstruct  cv::cudev::log10_func< schar >\n \nstruct  cv::cudev::log10_func< short >\n \nstruct  cv::cudev::log10_func< uchar >\n \nstruct  cv::cudev::log10_func< uint >\n \nstruct  cv::cudev::log10_func< ushort >\n \nstruct  cv::cudev::Log2< N, CURRENT_VAL, COUNT >\n \nstruct  cv::cudev::Log2< N, 0, COUNT >\n \nstruct  cv::cudev::log2_func< T >\n \nstruct  cv::cudev::log2_func< double >\n \nstruct  cv::cudev::log2_func< float >\n \nstruct  cv::cudev::log2_func< schar >\n \nstruct  cv::cudev::log2_func< short >\n \nstruct  cv::cudev::log2_func< uchar >\n \nstruct  cv::cudev::log2_func< uint >\n \nstruct  cv::cudev::log2_func< ushort >\n \nstruct  cv::cudev::log_func< T >\n \nstruct  cv::cudev::log_func< double >\n \nstruct  cv::cudev::log_func< float >\n \nstruct  cv::cudev::log_func< schar >\n \nstruct  cv::cudev::log_func< short >\n \nstruct  cv::cudev::log_func< uchar >\n \nstruct  cv::cudev::log_func< uint >\n \nstruct  cv::cudev::log_func< ushort >\n \nstruct  cv::cudev::logical_and< T >\n \nstruct  cv::cudev::logical_not< T >\n \nstruct  cv::cudev::logical_or< T >\n \nstruct  cv::cudev::LRGB_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::LRGB_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::LRGB_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::LRGB_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::LRGBA_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::LRGBA_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::LRGBA_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::LRGBA_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::LutPtr< SrcPtr, TablePtr >\n \nstruct  cv::cudev::LutPtrSz< SrcPtr, TablePtr >\n \nstruct  cv::cudev::Luv4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_LBGR_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_LBGRA_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_LRGB_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_LRGBA_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::Luv4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_LBGR_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_LBGRA_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_LRGB_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_LRGBA_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::Luv_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::magnitude_direction_interleaved_func< T2, angleInDegrees >\n \nstruct  cv::cudev::magnitude_func< T >\n \nstruct  cv::cudev::magnitude_interleaved_func< T2 >\n \nstruct  cv::cudev::magnitude_sqr_func< T >\n \nstruct  cv::cudev::magnitude_sqr_interleaved_func< T2 >\n \nstruct  cv::cudev::MakeVec< T, CN >\n \nstruct  cv::cudev::MakeVec< bool, 1 >\n \nstruct  cv::cudev::MakeVec< bool, 2 >\n \nstruct  cv::cudev::MakeVec< bool, 3 >\n \nstruct  cv::cudev::MakeVec< bool, 4 >\n \nstruct  cv::cudev::MakeVec< double, 1 >\n \nstruct  cv::cudev::MakeVec< double, 2 >\n \nstruct  cv::cudev::MakeVec< double, 3 >\n \nstruct  cv::cudev::MakeVec< double, 4 >\n \nstruct  cv::cudev::MakeVec< float, 1 >\n \nstruct  cv::cudev::MakeVec< float, 2 >\n \nstruct  cv::cudev::MakeVec< float, 3 >\n \nstruct  cv::cudev::MakeVec< float, 4 >\n \nstruct  cv::cudev::MakeVec< schar, 1 >\n \nstruct  cv::cudev::MakeVec< schar, 2 >\n \nstruct  cv::cudev::MakeVec< schar, 3 >\n \nstruct  cv::cudev::MakeVec< schar, 4 >\n \nstruct  cv::cudev::MakeVec< short, 1 >\n \nstruct  cv::cudev::MakeVec< short, 2 >\n \nstruct  cv::cudev::MakeVec< short, 3 >\n \nstruct  cv::cudev::MakeVec< short, 4 >\n \nstruct  cv::cudev::MakeVec< uchar, 1 >\n \nstruct  cv::cudev::MakeVec< uchar, 2 >\n \nstruct  cv::cudev::MakeVec< uchar, 3 >\n \nstruct  cv::cudev::MakeVec< uchar, 4 >\n \nstruct  cv::cudev::MakeVec< uint, 1 >\n \nstruct  cv::cudev::MakeVec< uint, 2 >\n \nstruct  cv::cudev::MakeVec< uint, 3 >\n \nstruct  cv::cudev::MakeVec< uint, 4 >\n \nstruct  cv::cudev::MakeVec< ushort, 1 >\n \nstruct  cv::cudev::MakeVec< ushort, 2 >\n \nstruct  cv::cudev::MakeVec< ushort, 3 >\n \nstruct  cv::cudev::MakeVec< ushort, 4 >\n \nstruct  cv::cudev::Max< T >\n \nstruct  cv::cudev::maximum< T >\n \nstruct  cv::cudev::maximum< double >\n \nstruct  cv::cudev::maximum< float >\n \nstruct  cv::cudev::maximum< schar >\n \nstruct  cv::cudev::maximum< short >\n \nstruct  cv::cudev::maximum< uchar >\n \nstruct  cv::cudev::maximum< uint >\n \nstruct  cv::cudev::maximum< ushort >\n \nstruct  cv::cudev::Min< T >\n \nstruct  cv::cudev::minimum< T >\n \nstruct  cv::cudev::minimum< double >\n \nstruct  cv::cudev::minimum< float >\n \nstruct  cv::cudev::minimum< schar >\n \nstruct  cv::cudev::minimum< short >\n \nstruct  cv::cudev::minimum< uchar >\n \nstruct  cv::cudev::minimum< uint >\n \nstruct  cv::cudev::minimum< ushort >\n \nstruct  cv::cudev::minus< T >\n \nstruct  cv::cudev::modulus< T >\n \nstruct  cv::cudev::multiplies< T >\n \nstruct  cv::cudev::NearestInterPtr< SrcPtr >\n \nstruct  cv::cudev::NearestInterPtrSz< SrcPtr >\n \nstruct  cv::cudev::negate< T >\n \nstruct  cv::cudev::NormHamming\n \nstruct  cv::cudev::NormL1< T >\n \nstruct  cv::cudev::NormL1< float >\n \nstruct  cv::cudev::NormL2\n \nstruct  cv::cudev::not_equal_to< T >\n \nstruct  cv::cudev::NullType\n \nstruct  cv::cudev::numeric_limits< T >\n \nstruct  cv::cudev::numeric_limits< bool >\n \nstruct  cv::cudev::numeric_limits< double >\n \nstruct  cv::cudev::numeric_limits< float >\n \nstruct  cv::cudev::numeric_limits< schar >\n \nstruct  cv::cudev::numeric_limits< short >\n \nstruct  cv::cudev::numeric_limits< uchar >\n \nstruct  cv::cudev::numeric_limits< uint >\n \nstruct  cv::cudev::numeric_limits< ushort >\n \nstruct  cv::cudev::PerspectiveMapPtr\n \nstruct  cv::cudev::PerspectiveMapPtrSz\n \nstruct  cv::cudev::plus< T >\n \nstruct  cv::cudev::pow_func< T >\n \nstruct  cv::cudev::pow_func< double >\n \nstruct  cv::cudev::project1st< T1, T2 >\n \nstruct  cv::cudev::project2nd< T1, T2 >\n \nstruct  cv::cudev::PtrTraits< Ptr2DSz >\n \nstruct  cv::cudev::PtrTraits< AffineMapPtrSz >\n \nstruct  cv::cudev::PtrTraits< BinaryTransformPtrSz< Src1Ptr, Src2Ptr, Op > >\n \nstruct  cv::cudev::PtrTraits< CommonAreaInterPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< ConstantPtrSz< T > >\n \nstruct  cv::cudev::PtrTraits< CubicInterPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< DerivXPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< DerivYPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< Expr< Body > >\n \nstruct  cv::cudev::PtrTraits< GlobPtrSz< T > >\n \nstruct  cv::cudev::PtrTraits< GpuMat_< T > >\n \nstruct  cv::cudev::PtrTraits< IntegerAreaInterPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< LaplacianPtrSz< ksize, SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< LinearInterPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< LutPtrSz< SrcPtr, TablePtr > >\n \nstruct  cv::cudev::PtrTraits< NearestInterPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< PerspectiveMapPtrSz >\n \nstruct  cv::cudev::PtrTraits< RemapPtr1Sz< SrcPtr, MapPtr > >\n \nstruct  cv::cudev::PtrTraits< RemapPtr2Sz< SrcPtr, MapXPtr, MapYPtr > >\n \nstruct  cv::cudev::PtrTraits< ResizePtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< ScharrXPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< ScharrYPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< SingleMaskChannelsSz< MaskPtr > >\n \nstruct  cv::cudev::PtrTraits< SobelXPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< SobelYPtrSz< SrcPtr > >\n \nstruct  cv::cudev::PtrTraits< Texture< T, R > >\n \nstruct  cv::cudev::PtrTraits< UnaryTransformPtrSz< SrcPtr, Op > >\n \nstruct  cv::cudev::PtrTraits< ZipPtrSz< PtrTuple > >\n \nstruct  cv::cudev::PtrTraitsBase< Ptr2DSz, Ptr2D >\n \nstruct  cv::cudev::PyrDownBody< SrcPtr >\n \nstruct  cv::cudev::PyrUpBody< SrcPtr >\n \nstruct  cv::cudev::ReduceToColumnBody< Reductor, SrcPtr >\n \nstruct  cv::cudev::ReduceToRowBody< Reductor, SrcPtr >\n \nstruct  cv::cudev::RemapPtr1< SrcPtr, MapPtr >\n \nstruct  cv::cudev::RemapPtr1Sz< SrcPtr, MapPtr >\n \nstruct  cv::cudev::RemapPtr2< SrcPtr, MapXPtr, MapYPtr >\n \nstruct  cv::cudev::RemapPtr2Sz< SrcPtr, MapXPtr, MapYPtr >\n \nstruct  cv::cudev::ResizePtr< SrcPtr >\n \nstruct  cv::cudev::ResizePtrSz< SrcPtr >\n \nstruct  cv::cudev::RGB_to_GRAY_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HLS4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HLS4_FULL_func< float >\n \nstruct  cv::cudev::RGB_to_HLS4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HLS4_func< float >\n \nstruct  cv::cudev::RGB_to_HLS_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HLS_FULL_func< float >\n \nstruct  cv::cudev::RGB_to_HLS_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HLS_func< float >\n \nstruct  cv::cudev::RGB_to_HSV4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HSV4_FULL_func< float >\n \nstruct  cv::cudev::RGB_to_HSV4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HSV4_func< float >\n \nstruct  cv::cudev::RGB_to_HSV_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HSV_FULL_func< float >\n \nstruct  cv::cudev::RGB_to_HSV_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_HSV_func< float >\n \nstruct  cv::cudev::RGB_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_XYZ4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_XYZ_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_YCrCb4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_YCrCb_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_YUV4_func< SrcDepth >\n \nstruct  cv::cudev::RGB_to_YUV_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_GRAY_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HLS4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HLS4_FULL_func< float >\n \nstruct  cv::cudev::RGBA_to_HLS4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HLS4_func< float >\n \nstruct  cv::cudev::RGBA_to_HLS_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HLS_FULL_func< float >\n \nstruct  cv::cudev::RGBA_to_HLS_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HLS_func< float >\n \nstruct  cv::cudev::RGBA_to_HSV4_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HSV4_FULL_func< float >\n \nstruct  cv::cudev::RGBA_to_HSV4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HSV4_func< float >\n \nstruct  cv::cudev::RGBA_to_HSV_FULL_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HSV_FULL_func< float >\n \nstruct  cv::cudev::RGBA_to_HSV_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_HSV_func< float >\n \nstruct  cv::cudev::RGBA_to_Lab4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_Lab_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_Luv4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_Luv_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_XYZ4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_XYZ_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_YCrCb4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_YCrCb_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_YUV4_func< SrcDepth >\n \nstruct  cv::cudev::RGBA_to_YUV_func< SrcDepth >\n \nstruct  cv::cudev::saturate_cast_fp16_func< T, D >\n \nstruct  cv::cudev::saturate_cast_fp16_func< float, short >\n \nstruct  cv::cudev::saturate_cast_fp16_func< short, float >\n \nstruct  cv::cudev::saturate_cast_func< T, D >\n \nstruct  cv::cudev::ScharrXPtr< SrcPtr >\n \nstruct  cv::cudev::ScharrXPtrSz< SrcPtr >\n \nstruct  cv::cudev::ScharrYPtr< SrcPtr >\n \nstruct  cv::cudev::ScharrYPtrSz< SrcPtr >\n \nstruct  cv::cudev::SelectIf< bool, ThenType, ElseType >\n \nstruct  cv::cudev::SelectIf< false, ThenType, ElseType >\n \nstruct  cv::cudev::sin_func< T >\n \nstruct  cv::cudev::sin_func< double >\n \nstruct  cv::cudev::sin_func< float >\n \nstruct  cv::cudev::sin_func< schar >\n \nstruct  cv::cudev::sin_func< short >\n \nstruct  cv::cudev::sin_func< uchar >\n \nstruct  cv::cudev::sin_func< uint >\n \nstruct  cv::cudev::sin_func< ushort >\n \nstruct  cv::cudev::SingleMaskChannels< MaskPtr >\n \nstruct  cv::cudev::SingleMaskChannelsSz< MaskPtr >\n \nstruct  cv::cudev::sinh_func< T >\n \nstruct  cv::cudev::sinh_func< double >\n \nstruct  cv::cudev::sinh_func< float >\n \nstruct  cv::cudev::sinh_func< schar >\n \nstruct  cv::cudev::sinh_func< short >\n \nstruct  cv::cudev::sinh_func< uchar >\n \nstruct  cv::cudev::sinh_func< uint >\n \nstruct  cv::cudev::sinh_func< ushort >\n \nstruct  cv::cudev::SobelXPtr< SrcPtr >\n \nstruct  cv::cudev::SobelXPtrSz< SrcPtr >\n \nstruct  cv::cudev::SobelYPtr< SrcPtr >\n \nstruct  cv::cudev::SobelYPtrSz< SrcPtr >\n \nstruct  cv::cudev::sqr_func< T >\n \nstruct  cv::cudev::sqrt_func< T >\n \nstruct  cv::cudev::sqrt_func< double >\n \nstruct  cv::cudev::sqrt_func< float >\n \nstruct  cv::cudev::sqrt_func< schar >\n \nstruct  cv::cudev::sqrt_func< short >\n \nstruct  cv::cudev::sqrt_func< uchar >\n \nstruct  cv::cudev::sqrt_func< uint >\n \nstruct  cv::cudev::sqrt_func< ushort >\n \nstruct  cv::cudev::Sum< T >\n \nstruct  cv::cudev::SumExprBody< SrcPtr >\n \nstruct  cv::cudev::tan_func< T >\n \nstruct  cv::cudev::tan_func< double >\n \nstruct  cv::cudev::tan_func< float >\n \nstruct  cv::cudev::tan_func< schar >\n \nstruct  cv::cudev::tan_func< short >\n \nstruct  cv::cudev::tan_func< uchar >\n \nstruct  cv::cudev::tan_func< uint >\n \nstruct  cv::cudev::tan_func< ushort >\n \nstruct  cv::cudev::tanh_func< T >\n \nstruct  cv::cudev::tanh_func< double >\n \nstruct  cv::cudev::tanh_func< float >\n \nstruct  cv::cudev::tanh_func< schar >\n \nstruct  cv::cudev::tanh_func< short >\n \nstruct  cv::cudev::tanh_func< uchar >\n \nstruct  cv::cudev::tanh_func< uint >\n \nstruct  cv::cudev::tanh_func< ushort >\n \nclass  cv::cudev::Texture< T, R >\n sharable smart CUDA texture object  More...\n \nclass  cv::cudev::TextureOff< T, R >\n sharable smart CUDA texture object with offset TextureOff is a smart sharable wrapper for a cudaTextureObject_t handle which ensures that the handle is destroyed after use.  More...\n \nstruct  cv::cudev::TextureOffPtr< T, R >\n \nstruct  cv::cudev::TexturePtr< T, R >\n Simple lightweight structures that encapsulate information about an image texture on the device. They are intended to be passed to nvcc-compiled code.  More...\n \nstruct  cv::cudev::TexturePtr< uint64, R >\n \nstruct  cv::cudev::ThreshBinaryFunc< T >\n \nstruct  cv::cudev::ThreshBinaryInvFunc< T >\n \nstruct  cv::cudev::ThreshToZeroFunc< T >\n \nstruct  cv::cudev::ThreshToZeroInvFunc< T >\n \nstruct  cv::cudev::ThreshTruncFunc< T >\n \nstruct  cv::cudev::TransposeBody< SrcPtr >\n \nstruct  cv::cudev::TupleTraits< T >\n \nstruct  cv::cudev::TupleTraits< tuple< P0, P1, P2, P3, P4, P5, P6, P7, P8, P9 > >\n \nstruct  cv::cudev::TypesEquals< A, B >\n \nstruct  cv::cudev::TypesEquals< A, A >\n \nstruct  cv::cudev::TypeTraits< T >\n \nstruct  cv::cudev::unary_function< _Arg, _Result >\n \nstruct  cv::cudev::UnaryNegate< Predicate >\n \nstruct  cv::cudev::UnaryTransformPtr< SrcPtr, Op >\n \nstruct  cv::cudev::UnaryTransformPtrSz< SrcPtr, Op >\n \nstruct  cv::cudev::UnaryTupleAdapter< Op, n >\n \nclass  cv::cudev::UniqueTexture< T, R >\n non-copyable smart CUDA texture object  More...\n \nstruct  cv::cudev::VecTraits< T >\n \nstruct  cv::cudev::VecTraits< char1 >\n \nstruct  cv::cudev::VecTraits< char2 >\n \nstruct  cv::cudev::VecTraits< char3 >\n \nstruct  cv::cudev::VecTraits< char4 >\n \nstruct  cv::cudev::VecTraits< double >\n \nstruct  cv::cudev::VecTraits< double1 >\n \nstruct  cv::cudev::VecTraits< double2 >\n \nstruct  cv::cudev::VecTraits< double3 >\n \nstruct  cv::cudev::VecTraits< double4 >\n \nstruct  cv::cudev::VecTraits< float >\n \nstruct  cv::cudev::VecTraits< float1 >\n \nstruct  cv::cudev::VecTraits< float2 >\n \nstruct  cv::cudev::VecTraits< float3 >\n \nstruct  cv::cudev::VecTraits< float4 >\n \nstruct  cv::cudev::VecTraits< int1 >\n \nstruct  cv::cudev::VecTraits< int2 >\n \nstruct  cv::cudev::VecTraits< int3 >\n \nstruct  cv::cudev::VecTraits< int4 >\n \nstruct  cv::cudev::VecTraits< schar >\n \nstruct  cv::cudev::VecTraits< short >\n \nstruct  cv::cudev::VecTraits< short1 >\n \nstruct  cv::cudev::VecTraits< short2 >\n \nstruct  cv::cudev::VecTraits< short3 >\n \nstruct  cv::cudev::VecTraits< short4 >\n \nstruct  cv::cudev::VecTraits< uchar >\n \nstruct  cv::cudev::VecTraits< uchar1 >\n \nstruct  cv::cudev::VecTraits< uchar2 >\n \nstruct  cv::cudev::VecTraits< uchar3 >\n \nstruct  cv::cudev::VecTraits< uchar4 >\n \nstruct  cv::cudev::VecTraits< uint >\n \nstruct  cv::cudev::VecTraits< uint1 >\n \nstruct  cv::cudev::VecTraits< uint2 >\n \nstruct  cv::cudev::VecTraits< uint3 >\n \nstruct  cv::cudev::VecTraits< uint4 >\n \nstruct  cv::cudev::VecTraits< ushort >\n \nstruct  cv::cudev::VecTraits< ushort1 >\n \nstruct  cv::cudev::VecTraits< ushort2 >\n \nstruct  cv::cudev::VecTraits< ushort3 >\n \nstruct  cv::cudev::VecTraits< ushort4 >\n \nstruct  cv::cudev::Warp\n \nstruct  cv::cudev::WithOutMask\n \nstruct  cv::cudev::XYZ4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::XYZ4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::XYZ4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::XYZ4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::XYZ_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::XYZ_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::XYZ_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::XYZ_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::YCrCb_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::YUV4_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::YUV4_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::YUV4_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::YUV4_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::YUV_to_BGR_func< SrcDepth >\n \nstruct  cv::cudev::YUV_to_BGRA_func< SrcDepth >\n \nstruct  cv::cudev::YUV_to_RGB_func< SrcDepth >\n \nstruct  cv::cudev::YUV_to_RGBA_func< SrcDepth >\n \nstruct  cv::cudev::ZipPtr< PtrTuple >\n \nstruct  cv::cudev::ZipPtr< tuple< Ptr0, Ptr1 > >\n \nstruct  cv::cudev::ZipPtr< tuple< Ptr0, Ptr1, Ptr2 > >\n \nstruct  cv::cudev::ZipPtr< tuple< Ptr0, Ptr1, Ptr2, Ptr3 > >\n \nstruct  cv::cudev::ZipPtrSz< PtrTuple >\n \n\nMacros\n#define CV_CUDEV_ARCH   0\n \n#define CV_CUDEV_BINARY_FUNCTION_INST(name,  func)\n \n#define CV_CUDEV_EXPR_BINARY_FUNC(name)\n \n#define CV_CUDEV_EXPR_BINOP_INST(op,  functor)\n \n#define CV_CUDEV_EXPR_CVTCOLOR_INST(name)\n \n#define CV_CUDEV_EXPR_UNARY_FUNC(name)\n \n#define CV_CUDEV_EXPR_UNOP_INST(op,  functor)\n \n#define CV_CUDEV_GRAY2RGB5x5_INST(name,  green_bits)       typedef cv::cudev::color_cvt_detail::Gray2RGB5x5<green_bits> name ## _func;\n \n#define CV_CUDEV_GRAY2RGB_INST(name,  dcn)\n \n#define CV_CUDEV_HLS2RGB_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_HSV2RGB_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_IMPLEMENT_SCALAR_BINARY_FUNC(func_name,  func,  input_type,  scalar_type,  output_type)\n \n#define CV_CUDEV_IMPLEMENT_SCALAR_BINARY_OP(op,  input_type,  scalar_type,  output_type)\n \n#define CV_CUDEV_IMPLEMENT_VEC_BINARY_FUNC(func_name,  func,  input_type,  output_type)\n \n#define CV_CUDEV_IMPLEMENT_VEC_BINARY_OP(op,  input_type,  output_type)\n \n#define CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(func_name,  func,  input_type,  output_type)\n \n#define CV_CUDEV_IMPLEMENT_VEC_UNARY_OP(op,  input_type,  output_type)\n \n#define CV_CUDEV_Lab2RGB_INST(name,  scn,  dcn,  sRGB,  blueIdx)\n \n#define CV_CUDEV_Luv2RGB_INST(name,  scn,  dcn,  sRGB,  blueIdx)\n \n#define CV_CUDEV_MAKE_VEC_INST(elem_type)\n \n#define CV_CUDEV_MINMAX_INST(type,  maxop,  minop)\n \n#define CV_CUDEV_RGB2GRAY_INST(name,  scn,  bidx)\n \n#define CV_CUDEV_RGB2HLS_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_RGB2HSV_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_RGB2Lab_INST(name,  scn,  dcn,  sRGB,  blueIdx)\n \n#define CV_CUDEV_RGB2Luv_INST(name,  scn,  dcn,  sRGB,  blueIdx)\n \n#define CV_CUDEV_RGB2RGB5x5_INST(name,  scn,  bidx,  green_bits)       typedef cv::cudev::color_cvt_detail::RGB2RGB5x5<scn, bidx, green_bits> name ## _func;\n \n#define CV_CUDEV_RGB2RGB_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_RGB2XYZ_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_RGB2YCrCb_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_RGB2YUV_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_RGB5x52GRAY_INST(name,  green_bits)       typedef cv::cudev::color_cvt_detail::RGB5x52Gray<green_bits> name ## _func;\n \n#define CV_CUDEV_RGB5x52RGB_INST(name,  dcn,  bidx,  green_bits)       typedef cv::cudev::color_cvt_detail::RGB5x52RGB<dcn, bidx, green_bits> name ## _func;\n \n#define CV_CUDEV_SAFE_CALL(expr)   cv::cudev::checkCudaError((expr), __FILE__, __LINE__, CV_Func)\n \n#define CV_CUDEV_UNARY_FUNCTION_INST(name,  func)\n \n#define CV_CUDEV_VEC_TRAITS_INST(type)\n \n#define CV_CUDEV_XYZ2RGB_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_YCrCb2RGB_INST(name,  scn,  dcn,  bidx)\n \n#define CV_CUDEV_YUV2RGB_INST(name,  scn,  dcn,  bidx)\n \n#define CV_LOG2_F   ((float)CV_LOG2)\n \n#define CV_PI_F   ((float)CV_PI)\n \n#define OPENCV_CUDEV_FUNCTIONAL_MAKE_IN_RANGE_COMPARATOR(i,  field)\n \n#define OPENCV_CUDEV_FUNCTIONAL_MAKE_IN_RANGE_COPIER(i,  field)\n \n\nTypedefs\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3, 0, 5 > cv::cudev::BGR555_to_BGR_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4, 0, 5 > cv::cudev::BGR555_to_BGRA_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52Gray< 5 > cv::cudev::BGR555_to_GRAY_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3, 2, 5 > cv::cudev::BGR555_to_RGB_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4, 2, 5 > cv::cudev::BGR555_to_RGBA_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3, 0, 6 > cv::cudev::BGR565_to_BGR_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4, 0, 6 > cv::cudev::BGR565_to_BGRA_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52Gray< 6 > cv::cudev::BGR565_to_GRAY_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3, 2, 6 > cv::cudev::BGR565_to_RGB_func\n \ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4, 2, 6 > cv::cudev::BGR565_to_RGBA_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3, 0, 5 > cv::cudev::BGR_to_BGR555_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3, 0, 6 > cv::cudev::BGR_to_BGR565_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4, 0, 5 > cv::cudev::BGRA_to_BGR555_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4, 0, 6 > cv::cudev::BGRA_to_BGR565_func\n \ntypedef R cv::cudev::TexturePtr< T, R >::elem_type\n \ntypedef R cv::cudev::TextureOffPtr< T, R >::elem_type\n \ntypedef cv::cudev::color_cvt_detail::Gray2RGB5x5< 5 > cv::cudev::GRAY_to_BGR555_func\n \ntypedef cv::cudev::color_cvt_detail::Gray2RGB5x5< 6 > cv::cudev::GRAY_to_BGR565_func\n \ntypedef float cv::cudev::TexturePtr< T, R >::index_type\n \ntypedef float cv::cudev::TexturePtr< uint64, R >::index_type\n \ntypedef float cv::cudev::TextureOffPtr< T, R >::index_type\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3, 2, 5 > cv::cudev::RGB_to_BGR555_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3, 2, 6 > cv::cudev::RGB_to_BGR565_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4, 2, 5 > cv::cudev::RGBA_to_BGR555_func\n \ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4, 2, 6 > cv::cudev::RGBA_to_BGR565_func\n \ntypedef R cv::cudev::TexturePtr< T, R >::value_type\n \n\nEnumerations\nenum  { \n  cv::cudev::LOG_WARP_SIZE = 5\n, \n  cv::cudev::WARP_SIZE = 1 << LOG_WARP_SIZE\n\n }\n \n\nFunctions\n cv::cudev::Texture< T, R >::Texture ()=default\n \n__host__ cv::cudev::Texture< T, R >::Texture (const int rows_, const int cols_, T *data, const size_t step, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n__host__ cv::cudev::Texture< T, R >::Texture (const size_t sizeInBytes, T *data, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n cv::cudev::Texture< T, R >::Texture (const Texture &)=default\n \n__host__ cv::cudev::Texture< T, R >::Texture (PtrStepSz< T > src, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n cv::cudev::Texture< T, R >::Texture (Texture &&)=default\n \n__host__ cv::cudev::TextureOff< T, R >::TextureOff (const int rows, const int cols, T *data, const size_t step, const int yoff_=0, const int xoff_=0, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n cv::cudev::TextureOff< T, R >::TextureOff (const TextureOff &)=default\n \n__host__ cv::cudev::TextureOff< T, R >::TextureOff (PtrStepSz< T > src, const int yoff_=0, const int xoff_=0, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n cv::cudev::TextureOff< T, R >::TextureOff (TextureOff &&)=default\n \n__host__ cv::cudev::TextureOffPtr< T, R >::TextureOffPtr (const cudaTextureObject_t tex_, const int yoff_, const int xoff_)\n \n__host__ cv::cudev::TexturePtr< T, R >::TexturePtr ()\n \n__host__ cv::cudev::TexturePtr< uint64, R >::TexturePtr ()\n \n__host__ cv::cudev::TexturePtr< T, R >::TexturePtr (const cudaTextureObject_t tex_)\n \n__host__ cv::cudev::TexturePtr< uint64, R >::TexturePtr (const cudaTextureObject_t tex_)\n \n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture () noexcept\n \n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture (const int rows, const int cols, T *data, const size_t step, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture (const size_t sizeInBytes, T *data, const bool normalizedCoords=false, const cudaTextureFilterMode filterMode=cudaFilterModePoint, const cudaTextureAddressMode addressMode=cudaAddressModeClamp, const cudaTextureReadMode readMode=cudaReadModeElementType)\n \n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture (UniqueTexture &&other) noexcept\n \n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture (UniqueTexture &)=delete\n \n__host__ cv::cudev::UniqueTexture< T, R >::~UniqueTexture ()\n \n__device__ __forceinline__ char1 cv::cudev::abs (const char1 &a)\n \n__device__ __forceinline__ char2 cv::cudev::abs (const char2 &a)\n \n__device__ __forceinline__ char3 cv::cudev::abs (const char3 &a)\n \n__device__ __forceinline__ char4 cv::cudev::abs (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::abs (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::abs (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::abs (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::abs (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::abs (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::abs (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::abs (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::abs (const float4 &a)\n \n__device__ __forceinline__ int1 cv::cudev::abs (const int1 &a)\n \n__device__ __forceinline__ int2 cv::cudev::abs (const int2 &a)\n \n__device__ __forceinline__ int3 cv::cudev::abs (const int3 &a)\n \n__device__ __forceinline__ int4 cv::cudev::abs (const int4 &a)\n \n__device__ __forceinline__ short1 cv::cudev::abs (const short1 &a)\n \n__device__ __forceinline__ short2 cv::cudev::abs (const short2 &a)\n \n__device__ __forceinline__ short3 cv::cudev::abs (const short3 &a)\n \n__device__ __forceinline__ short4 cv::cudev::abs (const short4 &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::abs (const uchar1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::abs (const uchar2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::abs (const uchar3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::abs (const uchar4 &a)\n \n__device__ __forceinline__ uint1 cv::cudev::abs (const uint1 &a)\n \n__device__ __forceinline__ uint2 cv::cudev::abs (const uint2 &a)\n \n__device__ __forceinline__ uint3 cv::cudev::abs (const uint3 &a)\n \n__device__ __forceinline__ uint4 cv::cudev::abs (const uint4 &a)\n \n__device__ __forceinline__ ushort1 cv::cudev::abs (const ushort1 &a)\n \n__device__ __forceinline__ ushort2 cv::cudev::abs (const ushort2 &a)\n \n__device__ __forceinline__ ushort3 cv::cudev::abs (const ushort3 &a)\n \n__device__ __forceinline__ ushort4 cv::cudev::abs (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, abs_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::abs_ (const SrcPtr &src)\n \ntemplate<class SrcPtr1 , class SrcPtr2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, absdiff_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::absdiff_ (const SrcPtr1 &src1, const SrcPtr2 &src2)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::acos (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::acos (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::acos (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::acos (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acos (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acos (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acos (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acos (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, acos_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::acos_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::acosh (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::acosh (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::acosh (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::acosh (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::acosh (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::acosh (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::acosh (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::acosh (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, acosh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::acosh_ (const SrcPtr &src)\n \nstatic __host__ AffineMapPtrSz cv::cudev::affineMap (Size dstSize, const GpuMat_< float > &warpMat)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::asin (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::asin (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::asin (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::asin (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asin (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asin (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asin (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asin (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, asin_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::asin_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::asinh (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::asinh (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::asinh (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::asinh (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::asinh (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::asinh (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::asinh (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::asinh (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, asinh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::asinh_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::atan (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::atan (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::atan (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::atan (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atan (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atan (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atan (const ushort4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const char1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const char2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const char3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const char4 &a, float s)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const double4 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const float4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const int1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const int2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const int3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const int4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const short1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const short2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const short3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const short4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const uchar1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const uchar2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const uchar3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const uchar4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const uint1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const uint2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const uint3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const uint4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (const ushort1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (const ushort2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (const ushort3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (const ushort4 &a, float s)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::atan2 (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::atan2 (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::atan2 (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::atan2 (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::atan2 (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::atan2 (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::atan2 (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::atan2 (float s, const ushort4 &b)\n \ntemplate<class SrcPtr1 , class SrcPtr2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, atan2_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::atan2_ (const SrcPtr1 &src1, const SrcPtr2 &src2)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, atan_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::atan_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::atanh (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::atanh (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::atanh (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::atanh (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::atanh (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::atanh (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::atanh (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::atanh (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, atanh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::atanh_ (const SrcPtr &src)\n \nstatic __device__ double cv::cudev::atomicAdd (double *address, double val)\n \n__device__ __forceinline__ float cv::cudev::atomicAdd (float *address, float val)\n \n__device__ __forceinline__ int cv::cudev::atomicAdd (int *address, int val)\n \n__device__ __forceinline__ uint cv::cudev::atomicAdd (uint *address, uint val)\n \nstatic __device__ double cv::cudev::atomicMax (double *address, double val)\n \nstatic __device__ float cv::cudev::atomicMax (float *address, float val)\n \n__device__ __forceinline__ int cv::cudev::atomicMax (int *address, int val)\n \n__device__ __forceinline__ uint cv::cudev::atomicMax (uint *address, uint val)\n \nstatic __device__ double cv::cudev::atomicMin (double *address, double val)\n \nstatic __device__ float cv::cudev::atomicMin (float *address, float val)\n \n__device__ __forceinline__ int cv::cudev::atomicMin (int *address, int val)\n \n__device__ __forceinline__ uint cv::cudev::atomicMin (uint *address, uint val)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_GRAY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_XYZ4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_XYZ_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YCrCb4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YCrCb_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YUV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YUV_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_GRAY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_XYZ4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_XYZ_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YCrCb4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YCrCb_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YUV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YUV_ (const SrcPtr &src)\n \ntemplate<int n0, int n1, class Op > \n__host__ __device__ BinaryTupleAdapter< Op, n0, n1 > cv::cudev::binaryTupleAdapter (const Op &op)\n \ntemplate<class Op > \n__host__ __device__ Binder1st< Op > cv::cudev::bind1st (const Op &op, const typename Op::first_argument_type &arg1)\n \ntemplate<class Op > \n__host__ __device__ Binder2nd< Op > cv::cudev::bind2nd (const Op &op, const typename Op::second_argument_type &arg2)\n \ntemplate<class InIt , class OutIt > \n__device__ static __forceinline__ void cv::cudev::blockCopy (InIt beg, InIt end, OutIt out)\n \ntemplate<class It , typename T > \n__device__ static __forceinline__ void cv::cudev::blockFill (It beg, It end, const T &value)\n \ntemplate<int N, typename P0 , typename P1 , typename P2 , typename P3 , typename P4 , typename P5 , typename P6 , typename P7 , typename P8 , typename P9 , typename R0 , typename R1 , typename R2 , typename R3 , typename R4 , typename R5 , typename R6 , typename R7 , typename R8 , typename R9 , class Op0 , class Op1 , class Op2 , class Op3 , class Op4 , class Op5 , class Op6 , class Op7 , class Op8 , class Op9 > \n__device__ __forceinline__ void cv::cudev::blockReduce (const tuple< P0, P1, P2, P3, P4, P5, P6, P7, P8, P9 > &smem, const tuple< R0, R1, R2, R3, R4, R5, R6, R7, R8, R9 > &val, uint tid, const tuple< Op0, Op1, Op2, Op3, Op4, Op5, Op6, Op7, Op8, Op9 > &op)\n \ntemplate<int N, typename T , class Op > \n__device__ __forceinline__ void cv::cudev::blockReduce (volatile T *smem, T &val, uint tid, const Op &op)\n \ntemplate<int N, typename KP0 , typename KP1 , typename KP2 , typename KP3 , typename KP4 , typename KP5 , typename KP6 , typename KP7 , typename KP8 , typename KP9 , typename KR0 , typename KR1 , typename KR2 , typename KR3 , typename KR4 , typename KR5 , typename KR6 , typename KR7 , typename KR8 , typename KR9 , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp0 , class Cmp1 , class Cmp2 , class Cmp3 , class Cmp4 , class Cmp5 , class Cmp6 , class Cmp7 , class Cmp8 , class Cmp9 > \n__device__ __forceinline__ void cv::cudev::blockReduceKeyVal (const tuple< KP0, KP1, KP2, KP3, KP4, KP5, KP6, KP7, KP8, KP9 > &skeys, const tuple< KR0, KR1, KR2, KR3, KR4, KR5, KR6, KR7, KR8, KR9 > &key, const tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > &svals, const tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > &val, uint tid, const tuple< Cmp0, Cmp1, Cmp2, Cmp3, Cmp4, Cmp5, Cmp6, Cmp7, Cmp8, Cmp9 > &cmp)\n \ntemplate<int N, typename K , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp > \n__device__ __forceinline__ void cv::cudev::blockReduceKeyVal (volatile K *skeys, K &key, const tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > &svals, const tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > &val, uint tid, const Cmp &cmp)\n \ntemplate<int N, typename K , typename V , class Cmp > \n__device__ __forceinline__ void cv::cudev::blockReduceKeyVal (volatile K *skeys, K &key, volatile V *svals, V &val, uint tid, const Cmp &cmp)\n \ntemplate<int THREADS_NUM, typename T > \n__device__ __forceinline__ T cv::cudev::blockScanExclusive (T data, volatile T *smem, uint tid)\n \ntemplate<int THREADS_NUM, typename T > \n__device__ T cv::cudev::blockScanInclusive (T data, volatile T *smem, uint tid)\n \ntemplate<class InIt , class OutIt , class UnOp > \n__device__ static __forceinline__ void cv::cudev::blockTransform (InIt beg, InIt end, OutIt out, const UnOp &op)\n \ntemplate<class InIt1 , class InIt2 , class OutIt , class BinOp > \n__device__ static __forceinline__ void cv::cudev::blockTransform (InIt1 beg1, InIt1 end1, InIt2 beg2, OutIt out, const BinOp &op)\n \ntemplate<class OutIt , typename T > \n__device__ static __forceinline__ void cv::cudev::blockYota (OutIt beg, OutIt end, T value)\n \ntemplate<class SrcPtr > \n__host__ BrdConstant< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdConstant (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ BrdConstant< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdConstant (const SrcPtr &src, typename PtrTraits< SrcPtr >::value_type val)\n \ntemplate<class SrcPtr > \n__host__ BrdBase< BrdReflect, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdReflect (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ BrdBase< BrdReflect101, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdReflect101 (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ BrdBase< BrdReplicate, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdReplicate (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ BrdBase< BrdWrap, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdWrap (const SrcPtr &src)\n \ntemplate<typename T , typename D > \n__device__ __forceinline__ D cv::cudev::cast_fp16 (T v)\n \ntemplate<> \n__device__ __forceinline__ short cv::cudev::cast_fp16< float, short > (float v)\n \ntemplate<> \n__device__ __forceinline__ float cv::cudev::cast_fp16< short, float > (short v)\n \n__host__ __forceinline__ void cv::cudev::checkCudaError (cudaError_t err, const char *file, const int line, const char *func)\n \ntemplate<typename T > \n__host__ ConstantPtr< T > cv::cudev::constantPtr (T value)\n \ntemplate<typename T > \nConstantPtrSz< T > __host__ cv::cudev::constantPtr (T value, int rows, int cols)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::cos (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::cos (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::cos (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::cos (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cos (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cos (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cos (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cos (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, cos_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::cos_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::cosh (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::cosh (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::cosh (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::cosh (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::cosh (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::cosh (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::cosh (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::cosh (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, cosh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::cosh_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< CountNonZeroExprBody< SrcPtr > > cv::cudev::countNonZero_ (const SrcPtr &src)\n \ntemplate<typename D , class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, saturate_cast_func< typename PtrTraits< SrcPtr >::value_type, D > > > cv::cudev::cvt_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< DerivXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::derivX_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ DerivXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::derivXPtr (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< DerivYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::derivY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ DerivYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::derivYPtr (const SrcPtr &src)\n \n__host__ __device__ __forceinline__ int cv::cudev::divUp (int total, int grain)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::exp (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::exp (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::exp (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::exp (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp (const ushort4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::exp10 (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::exp10 (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::exp10 (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::exp10 (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp10 (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp10 (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp10 (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp10 (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, exp10_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::exp10_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::exp2 (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::exp2 (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::exp2 (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::exp2 (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::exp2 (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::exp2 (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::exp2 (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::exp2 (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, exp2_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::exp2_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, exp_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::exp_ (const SrcPtr &src)\n \n__host__ cudaTextureObject_t cv::cudev::UniqueTexture< T, R >::get () const noexcept\n \ntemplate<class Ptr2DSz > \n__host__ int cv::cudev::getCols (const Ptr2DSz &ptr)\n \ntemplate<class Ptr2DSz > \n__host__ int cv::cudev::getRows (const Ptr2DSz &ptr)\n \ntemplate<typename T > \n__host__ GlobPtrSz< T > cv::cudev::globPtr (const GpuMat &mat)\n \ntemplate<typename T > \n__host__ GlobPtrSz< T > cv::cudev::globPtr (const GpuMat_< T > &mat)\n \ntemplate<typename T > \n__host__ __device__ GlobPtr< T > cv::cudev::globPtr (T *data, size_t step)\n \ntemplate<typename T > \n__host__ __device__ GlobPtrSz< T > cv::cudev::globPtr (T *data, size_t step, int rows, int cols)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, GRAY_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::GRAY_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, GRAY_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::GRAY_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridCalcSum (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridCalcSum (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridCalcSum_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridCalcSum_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtr &src, const GlobPtrSz< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridCopy (const SrcPtr &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtr &src, GpuMat_< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridCopy (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n__host__ void cv::cudev::gridCopy (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtr &src, const GlobPtrSz< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridCopy_ (const SrcPtr &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtr &src, GpuMat_< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridCopy_ (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n__host__ void cv::cudev::gridCopy_ (const SrcPtrTuple &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridCountNonZero (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridCountNonZero (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridCountNonZero_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridCountNonZero_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridFindMaxVal (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridFindMaxVal (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridFindMaxVal_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridFindMaxVal_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridFindMinMaxVal (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridFindMinMaxVal (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridFindMinMaxVal_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridFindMinMaxVal_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridFindMinVal (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridFindMinVal (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridFindMinVal_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridFindMinVal_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<int BIN_COUNT, class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridHistogram (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<int BIN_COUNT, class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridHistogram (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<int BIN_COUNT, class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridHistogram_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<int BIN_COUNT, class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridHistogram_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridIntegral (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMerge (const SrcPtrTuple &src, const GlobPtrSz< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename DstType > \n__host__ void cv::cudev::gridMerge (const SrcPtrTuple &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMerge (const SrcPtrTuple &src, GpuMat_< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtrTuple , typename DstType > \n__host__ void cv::cudev::gridMerge (const SrcPtrTuple &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMerge (const std::array< ArrayType, ArraySize > &src, const GlobPtrSz< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class ArrayType , size_t ArraySize, typename DstType > \n__host__ void cv::cudev::gridMerge (const std::array< ArrayType, ArraySize > &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class ArrayType , size_t ArraySize, typename DstType > \n__host__ void cv::cudev::gridMerge (const std::array< ArrayType, ArraySize > &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMerge_ (const SrcPtrTuple &src, const GlobPtrSz< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename DstType > \n__host__ void cv::cudev::gridMerge_ (const SrcPtrTuple &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMerge_ (const SrcPtrTuple &src, GpuMat_< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtrTuple , typename DstType > \n__host__ void cv::cudev::gridMerge_ (const SrcPtrTuple &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMergeArray (const std::array< ArrayType, ArraySize > &src, GpuMat_< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMergeArray_ (const std::array< ArrayType, ArraySize > &src, const GlobPtrSz< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType > \n__host__ void cv::cudev::gridMergeArray_ (const std::array< ArrayType, ArraySize > &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridMergeArray_ (const std::array< ArrayType, ArraySize > &src, GpuMat_< DstType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType > \n__host__ void cv::cudev::gridMergeArray_ (const std::array< ArrayType, ArraySize > &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridMinMaxLoc (const SrcPtr &src, GpuMat_< ResType > &valBuf, GpuMat_< int > &locBuf, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridMinMaxLoc (const SrcPtr &src, GpuMat_< ResType > &valBuf, GpuMat_< int > &locBuf, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridMinMaxLoc_ (const SrcPtr &src, GpuMat_< ResType > &valBuf, GpuMat_< int > &locBuf, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridMinMaxLoc_ (const SrcPtr &src, GpuMat_< ResType > &valBuf, GpuMat_< int > &locBuf, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridPyrDown (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Brd , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridPyrDown_ (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridPyrUp (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Reductor , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridReduceToColumn (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Reductor , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridReduceToColumn (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Reductor , class Policy , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridReduceToColumn_ (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Reductor , class Policy , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridReduceToColumn_ (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Reductor , class SrcPtr , typename ResType , class MaskPtr > \n__host__ void cv::cudev::gridReduceToRow (const SrcPtr &src, GpuMat_< ResType > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Reductor , class SrcPtr , typename ResType > \n__host__ void cv::cudev::gridReduceToRow (const SrcPtr &src, GpuMat_< ResType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , int COUNT, class MaskPtr > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[COUNT], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , int COUNT> \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[COUNT], Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , int COUNT, class MaskPtr > \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, GpuMat_< DstType >(&dst)[COUNT], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , int COUNT> \n__host__ void cv::cudev::gridSplit (const SrcPtr &src, GpuMat_< DstType >(&dst)[COUNT], Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, const tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[2], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[2], Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[3], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[3], Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[4], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GlobPtrSz< DstType >(&dst)[4], Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GpuMat_< DstType >(&dst)[2], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GpuMat_< DstType >(&dst)[2], Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GpuMat_< DstType >(&dst)[3], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GpuMat_< DstType >(&dst)[3], Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GpuMat_< DstType >(&dst)[4], const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridSplit_ (const SrcPtr &src, GpuMat_< DstType >(&dst)[4], Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType > &dst, const Op &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType > &dst, const Op &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType1 > &dst1, const GlobPtrSz< DstType2 > &dst2, const Op1 &op1, const Op2 &op2, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType2 > &dst1, const GlobPtrSz< DstType2 > &dst2, const Op1 &op1, const Op2 &op2, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType > &dst, const Op &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType > &dst, const Op &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType1 > &dst1, GpuMat_< DstType2 > &dst2, const Op1 &op1, const Op2 &op2, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 > \n__host__ void cv::cudev::gridTransformBinary (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType1 > &dst1, GpuMat_< DstType2 > &dst2, const Op1 &op1, const Op2 &op2, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType > &dst, const BinOp &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType > &dst, const BinOp &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType1 > &dst1, const GlobPtrSz< DstType2 > &dst2, const BinOp1 &op1, const BinOp2 &op2, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, const GlobPtrSz< DstType1 > &dst1, const GlobPtrSz< DstType2 > &dst2, const BinOp1 &op1, const BinOp2 &op2, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType > &dst, const BinOp &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType > &dst, const BinOp &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 , class MaskPtr > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType1 > &dst1, GpuMat_< DstType2 > &dst2, const BinOp1 &op1, const BinOp2 &op2, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 > \n__host__ void cv::cudev::gridTransformBinary_ (const SrcPtr1 &src1, const SrcPtr2 &src2, GpuMat_< DstType1 > &dst1, GpuMat_< DstType2 > &dst2, const BinOp1 &op1, const BinOp2 &op2, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, const OpTuple &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n__host__ void cv::cudev::gridTransformTuple_ (const SrcPtr &src, const tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > &dst, const OpTuple &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class Op , class MaskPtr > \n__host__ void cv::cudev::gridTransformUnary (const SrcPtr &src, const GlobPtrSz< DstType > &dst, const Op &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class Op > \n__host__ void cv::cudev::gridTransformUnary (const SrcPtr &src, const GlobPtrSz< DstType > &dst, const Op &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class Op , class MaskPtr > \n__host__ void cv::cudev::gridTransformUnary (const SrcPtr &src, GpuMat_< DstType > &dst, const Op &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType , class Op > \n__host__ void cv::cudev::gridTransformUnary (const SrcPtr &src, GpuMat_< DstType > &dst, const Op &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp , class MaskPtr > \n__host__ void cv::cudev::gridTransformUnary_ (const SrcPtr &src, const GlobPtrSz< DstType > &dst, const UnOp &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp > \n__host__ void cv::cudev::gridTransformUnary_ (const SrcPtr &src, const GlobPtrSz< DstType > &dst, const UnOp &op, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp , class MaskPtr > \n__host__ void cv::cudev::gridTransformUnary_ (const SrcPtr &src, GpuMat_< DstType > &dst, const UnOp &op, const MaskPtr &mask, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp > \n__host__ void cv::cudev::gridTransformUnary_ (const SrcPtr &src, GpuMat_< DstType > &dst, const UnOp &op, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridTranspose (const SrcPtr &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridTranspose (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridTranspose_ (const SrcPtr &src, const GlobPtrSz< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<class Policy , class SrcPtr , typename DstType > \n__host__ void cv::cudev::gridTranspose_ (const SrcPtr &src, GpuMat_< DstType > &dst, Stream &stream=Stream::Null())\n \ntemplate<int BIN_COUNT, class SrcPtr > \n__host__ Expr< HistogramBody< BIN_COUNT, SrcPtr > > cv::cudev::histogram_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGR_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGRA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGB_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGBA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGR_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGRA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGB_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGBA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGR_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGRA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGB_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGBA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGR_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGRA_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGB_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGBA_FULL_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const char1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const char2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const char3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const char4 &a, float s)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const double4 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const float4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const int1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const int2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const int3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const int4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const short1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const short2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const short3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const short4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const uchar1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const uchar2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const uchar3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const uchar4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const uint1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const uint2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const uint3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const uint4 &a, float s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (const ushort1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (const ushort2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (const ushort3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (const ushort4 &a, float s)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::hypot (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::hypot (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::hypot (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::hypot (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::hypot (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::hypot (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::hypot (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::hypot (float s, const ushort4 &b)\n \ntemplate<class SrcPtr1 , class SrcPtr2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, hypot_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::hypot_ (const SrcPtr1 &src1, const SrcPtr2 &src2)\n \ntemplate<class SrcPtr > \n__host__ Expr< IntegralBody< SrcPtr > > cv::cudev::integral_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ IntegerAreaInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interArea (const SrcPtr &src, Size areaSize)\n \ntemplate<class SrcPtr > \n__host__ CommonAreaInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interArea (const SrcPtr &src, Size2f areaSize)\n \ntemplate<class SrcPtr > \n__host__ CubicInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interCubic (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ LinearInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interLinear (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ NearestInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interNearest (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LBGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LBGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LRGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LRGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LBGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LBGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LRGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LRGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_RGBA_ (const SrcPtr &src)\n \ntemplate<int ksize, class SrcPtr > \n__host__ Expr< LaplacianPtrSz< ksize, typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::laplacian_ (const SrcPtr &src)\n \ntemplate<int ksize, class SrcPtr > \n__host__ LaplacianPtrSz< ksize, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::laplacianPtr (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Luv_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::log (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::log (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::log (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::log (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::log (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log (const ushort4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::log10 (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::log10 (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::log10 (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::log10 (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log10 (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log10 (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log10 (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log10 (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, log10_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::log10_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::log2 (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::log2 (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::log2 (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::log2 (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::log2 (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::log2 (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::log2 (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::log2 (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, log2_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::log2_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, log_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::log_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr , class TablePtr > \n__host__ Expr< LutPtrSz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< TablePtr >::ptr_type > > cv::cudev::lut_ (const SrcPtr &src, const TablePtr &tbl)\n \ntemplate<class SrcPtr , class TablePtr > \n__host__ LutPtrSz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< TablePtr >::ptr_type > cv::cudev::lutPtr (const SrcPtr &src, const TablePtr &tbl)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LBGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LBGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LRGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LRGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LBGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LBGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LRGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LRGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr1 , class SrcPtr2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, magnitude_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::magnitude_ (const SrcPtr1 &src1, const SrcPtr2 &src2)\n \ntemplate<class Body > \n__host__ Expr< Body > cv::cudev::makeExpr (const Body &body)\n \n__device__ __forceinline__ char1 cv::cudev::max (char s, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::max (char s, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::max (char s, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::max (char s, const char4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::max (const char1 &a, char s)\n \n__device__ __forceinline__ char1 cv::cudev::max (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const char1 &a, float s)\n \n__device__ __forceinline__ char2 cv::cudev::max (const char2 &a, char s)\n \n__device__ __forceinline__ char2 cv::cudev::max (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const char2 &a, float s)\n \n__device__ __forceinline__ char3 cv::cudev::max (const char3 &a, char s)\n \n__device__ __forceinline__ char3 cv::cudev::max (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const char3 &a, float s)\n \n__device__ __forceinline__ char4 cv::cudev::max (const char4 &a, char s)\n \n__device__ __forceinline__ char4 cv::cudev::max (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const char4 &a, float s)\n \n__device__ __forceinline__ double1 cv::cudev::max (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::max (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::max (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::max (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const double4 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const float4 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::max (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const int1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::max (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::max (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const int2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::max (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::max (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const int3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::max (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::max (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const int4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::max (const int4 &a, int s)\n \n__device__ __forceinline__ short1 cv::cudev::max (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const short1 &a, float s)\n \n__device__ __forceinline__ short1 cv::cudev::max (const short1 &a, short s)\n \n__device__ __forceinline__ short2 cv::cudev::max (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const short2 &a, float s)\n \n__device__ __forceinline__ short2 cv::cudev::max (const short2 &a, short s)\n \n__device__ __forceinline__ short3 cv::cudev::max (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const short3 &a, float s)\n \n__device__ __forceinline__ short3 cv::cudev::max (const short3 &a, short s)\n \n__device__ __forceinline__ short4 cv::cudev::max (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const short4 &a, float s)\n \n__device__ __forceinline__ short4 cv::cudev::max (const short4 &a, short s)\n \n__device__ __forceinline__ uchar1 cv::cudev::max (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const uchar1 &a, float s)\n \n__device__ __forceinline__ uchar1 cv::cudev::max (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::max (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const uchar2 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::max (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::max (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const uchar3 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::max (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::max (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const uchar4 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::max (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uint1 cv::cudev::max (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const uint1 &a, float s)\n \n__device__ __forceinline__ uint1 cv::cudev::max (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::max (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const uint2 &a, float s)\n \n__device__ __forceinline__ uint2 cv::cudev::max (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::max (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const uint3 &a, float s)\n \n__device__ __forceinline__ uint3 cv::cudev::max (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::max (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const uint4 &a, float s)\n \n__device__ __forceinline__ uint4 cv::cudev::max (const uint4 &a, uint s)\n \n__device__ __forceinline__ ushort1 cv::cudev::max (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::max (const ushort1 &a, float s)\n \n__device__ __forceinline__ ushort1 cv::cudev::max (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ ushort2 cv::cudev::max (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::max (const ushort2 &a, float s)\n \n__device__ __forceinline__ ushort2 cv::cudev::max (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ ushort3 cv::cudev::max (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::max (const ushort3 &a, float s)\n \n__device__ __forceinline__ ushort3 cv::cudev::max (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ ushort4 cv::cudev::max (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::max (const ushort4 &a, float s)\n \n__device__ __forceinline__ ushort4 cv::cudev::max (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::max (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::max (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::max (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::max (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::max (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::max (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::max (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::max (float s, const ushort4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::max (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::max (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::max (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::max (int s, const int4 &b)\n \n__device__ __forceinline__ short1 cv::cudev::max (short s, const short1 &b)\n \n__device__ __forceinline__ short2 cv::cudev::max (short s, const short2 &b)\n \n__device__ __forceinline__ short3 cv::cudev::max (short s, const short3 &b)\n \n__device__ __forceinline__ short4 cv::cudev::max (short s, const short4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::max (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::max (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::max (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::max (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::max (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::max (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::max (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::max (uint s, const uint4 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::max (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::max (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::max (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::max (ushort s, const ushort4 &b)\n \ntemplate<class SrcPtr1 , class SrcPtr2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, maximum< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::max_ (const SrcPtr1 &src1, const SrcPtr2 &src2)\n \ntemplate<class SrcPtr > \n__host__ Expr< FindMaxValExprBody< SrcPtr > > cv::cudev::maxVal_ (const SrcPtr &src)\n \n__device__ __forceinline__ char1 cv::cudev::min (char s, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::min (char s, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::min (char s, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::min (char s, const char4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::min (const char1 &a, char s)\n \n__device__ __forceinline__ char1 cv::cudev::min (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const char1 &a, float s)\n \n__device__ __forceinline__ char2 cv::cudev::min (const char2 &a, char s)\n \n__device__ __forceinline__ char2 cv::cudev::min (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const char2 &a, float s)\n \n__device__ __forceinline__ char3 cv::cudev::min (const char3 &a, char s)\n \n__device__ __forceinline__ char3 cv::cudev::min (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const char3 &a, float s)\n \n__device__ __forceinline__ char4 cv::cudev::min (const char4 &a, char s)\n \n__device__ __forceinline__ char4 cv::cudev::min (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const char4 &a, float s)\n \n__device__ __forceinline__ double1 cv::cudev::min (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::min (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::min (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::min (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const double4 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const float4 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::min (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const int1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::min (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::min (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const int2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::min (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::min (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const int3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::min (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::min (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const int4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::min (const int4 &a, int s)\n \n__device__ __forceinline__ short1 cv::cudev::min (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const short1 &a, float s)\n \n__device__ __forceinline__ short1 cv::cudev::min (const short1 &a, short s)\n \n__device__ __forceinline__ short2 cv::cudev::min (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const short2 &a, float s)\n \n__device__ __forceinline__ short2 cv::cudev::min (const short2 &a, short s)\n \n__device__ __forceinline__ short3 cv::cudev::min (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const short3 &a, float s)\n \n__device__ __forceinline__ short3 cv::cudev::min (const short3 &a, short s)\n \n__device__ __forceinline__ short4 cv::cudev::min (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const short4 &a, float s)\n \n__device__ __forceinline__ short4 cv::cudev::min (const short4 &a, short s)\n \n__device__ __forceinline__ uchar1 cv::cudev::min (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const uchar1 &a, float s)\n \n__device__ __forceinline__ uchar1 cv::cudev::min (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::min (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const uchar2 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::min (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::min (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const uchar3 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::min (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::min (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const uchar4 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::min (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uint1 cv::cudev::min (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const uint1 &a, float s)\n \n__device__ __forceinline__ uint1 cv::cudev::min (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::min (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const uint2 &a, float s)\n \n__device__ __forceinline__ uint2 cv::cudev::min (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::min (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const uint3 &a, float s)\n \n__device__ __forceinline__ uint3 cv::cudev::min (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::min (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const uint4 &a, float s)\n \n__device__ __forceinline__ uint4 cv::cudev::min (const uint4 &a, uint s)\n \n__device__ __forceinline__ ushort1 cv::cudev::min (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::min (const ushort1 &a, float s)\n \n__device__ __forceinline__ ushort1 cv::cudev::min (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ ushort2 cv::cudev::min (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::min (const ushort2 &a, float s)\n \n__device__ __forceinline__ ushort2 cv::cudev::min (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ ushort3 cv::cudev::min (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::min (const ushort3 &a, float s)\n \n__device__ __forceinline__ ushort3 cv::cudev::min (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ ushort4 cv::cudev::min (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::min (const ushort4 &a, float s)\n \n__device__ __forceinline__ ushort4 cv::cudev::min (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::min (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::min (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::min (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::min (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::min (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::min (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::min (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::min (float s, const ushort4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::min (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::min (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::min (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::min (int s, const int4 &b)\n \n__device__ __forceinline__ short1 cv::cudev::min (short s, const short1 &b)\n \n__device__ __forceinline__ short2 cv::cudev::min (short s, const short2 &b)\n \n__device__ __forceinline__ short3 cv::cudev::min (short s, const short3 &b)\n \n__device__ __forceinline__ short4 cv::cudev::min (short s, const short4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::min (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::min (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::min (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::min (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::min (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::min (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::min (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::min (uint s, const uint4 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::min (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::min (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::min (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::min (ushort s, const ushort4 &b)\n \ntemplate<class SrcPtr1 , class SrcPtr2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, minimum< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::min_ (const SrcPtr1 &src1, const SrcPtr2 &src2)\n \ntemplate<class SrcPtr > \n__host__ Expr< FindMinMaxValExprBody< SrcPtr > > cv::cudev::minMaxVal_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< FindMinValExprBody< SrcPtr > > cv::cudev::minVal_ (const SrcPtr &src)\n \ntemplate<class Predicate > \n__host__ __device__ UnaryNegate< Predicate > cv::cudev::not1 (const Predicate &pred)\n \ntemplate<class Predicate > \n__host__ __device__ BinaryNegate< Predicate > cv::cudev::not2 (const Predicate &pred)\n \n__host__ cv::cudev::UniqueTexture< T, R >::operator bool () const noexcept\n \n__host__ cv::cudev::Texture< T, R >::operator bool () const noexcept\n \n__host__ cv::cudev::TextureOff< T, R >::operator TextureOffPtr< T, R > () const\n \n__host__ cv::cudev::Texture< T, R >::operator TexturePtr< T, R > () const\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const char1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const char2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const char3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const char4 &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const double1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const double2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const double3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const double4 &a)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, logical_not< typename Body::value_type > > > cv::cudev::operator! (const Expr< Body > &src)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const float1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const float2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const float3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const float4 &a)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_not< T > > > cv::cudev::operator! (const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, logical_not< T > > > cv::cudev::operator! (const GpuMat_< T > &src)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const int1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const int2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const int3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const int4 &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const short1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const short2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const short3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const short4 &a)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, logical_not< T > > > cv::cudev::operator! (const Texture< T > &src)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const uchar1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const uchar2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const uchar3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const uchar4 &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const uint1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const uint2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const uint3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const uint4 &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator! (const ushort1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator! (const ushort2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator! (const ushort3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator! (const ushort4 &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< not_equal_to< typename Body::value_type > > > > cv::cudev::operator!= (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, not_equal_to< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator!= (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< not_equal_to< T > > > > cv::cudev::operator!= (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< not_equal_to< T > > > > cv::cudev::operator!= (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< not_equal_to< T > > > > cv::cudev::operator!= (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< not_equal_to< T > > > > cv::cudev::operator!= (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< not_equal_to< T > > > > cv::cudev::operator!= (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< not_equal_to< T > > > > cv::cudev::operator!= (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< not_equal_to< typename Body::value_type > > > > cv::cudev::operator!= (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator!= (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator!= (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator!= (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator!= (ushort s, const ushort4 &b)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< modulus< typename Body::value_type > > > > cv::cudev::operator% (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, modulus< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator% (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< modulus< T > > > > cv::cudev::operator% (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< modulus< T > > > > cv::cudev::operator% (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const GpuMat_< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< modulus< T > > > > cv::cudev::operator% (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< T > > > cv::cudev::operator% (const Texture< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< modulus< T > > > > cv::cudev::operator% (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< modulus< T > > > > cv::cudev::operator% (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< modulus< T > > > > cv::cudev::operator% (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< modulus< typename Body::value_type > > > > cv::cudev::operator% (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ char1 cv::cudev::operator& (char s, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::operator& (char s, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::operator& (char s, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::operator& (char s, const char4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::operator& (const char1 &a, char s)\n \n__device__ __forceinline__ char1 cv::cudev::operator& (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::operator& (const char2 &a, char s)\n \n__device__ __forceinline__ char2 cv::cudev::operator& (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::operator& (const char3 &a, char s)\n \n__device__ __forceinline__ char3 cv::cudev::operator& (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::operator& (const char4 &a, char s)\n \n__device__ __forceinline__ char4 cv::cudev::operator& (const char4 &a, const char4 &b)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_and< typename Body::value_type > > > > cv::cudev::operator& (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_and< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator& (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_and< T > > > > cv::cudev::operator& (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_and< T > > > > cv::cudev::operator& (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator& (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator& (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator& (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator& (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator& (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator& (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator& (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator& (const int4 &a, int s)\n \n__device__ __forceinline__ short1 cv::cudev::operator& (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ short1 cv::cudev::operator& (const short1 &a, short s)\n \n__device__ __forceinline__ short2 cv::cudev::operator& (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ short2 cv::cudev::operator& (const short2 &a, short s)\n \n__device__ __forceinline__ short3 cv::cudev::operator& (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ short3 cv::cudev::operator& (const short3 &a, short s)\n \n__device__ __forceinline__ short4 cv::cudev::operator& (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ short4 cv::cudev::operator& (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_and< T > > > > cv::cudev::operator& (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator& (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator& (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator& (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator& (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator& (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator& (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator& (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator& (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator& (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::operator& (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator& (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator& (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator& (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator& (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator& (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator& (const uint4 &a, uint s)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator& (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator& (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator& (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator& (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator& (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator& (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator& (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator& (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ int1 cv::cudev::operator& (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator& (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator& (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator& (int s, const int4 &b)\n \n__device__ __forceinline__ short1 cv::cudev::operator& (short s, const short1 &b)\n \n__device__ __forceinline__ short2 cv::cudev::operator& (short s, const short2 &b)\n \n__device__ __forceinline__ short3 cv::cudev::operator& (short s, const short3 &b)\n \n__device__ __forceinline__ short4 cv::cudev::operator& (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_and< T > > > > cv::cudev::operator& (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_and< T > > > > cv::cudev::operator& (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_and< T > > > > cv::cudev::operator& (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_and< typename Body::value_type > > > > cv::cudev::operator& (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator& (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator& (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator& (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator& (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::operator& (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator& (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator& (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator& (uint s, const uint4 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator& (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator& (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator& (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator& (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< logical_and< typename Body::value_type > > > > cv::cudev::operator&& (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, logical_and< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator&& (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< logical_and< T > > > > cv::cudev::operator&& (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< logical_and< T > > > > cv::cudev::operator&& (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< logical_and< T > > > > cv::cudev::operator&& (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< logical_and< T > > > > cv::cudev::operator&& (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< logical_and< T > > > > cv::cudev::operator&& (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< logical_and< T > > > > cv::cudev::operator&& (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< logical_and< typename Body::value_type > > > > cv::cudev::operator&& (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator&& (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator&& (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator&& (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator&& (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ R cv::cudev::TexturePtr< T, R >::operator() (index_type x) const\n \n__device__ __forceinline__ R cv::cudev::TexturePtr< uint64, R >::operator() (index_type x) const\n \n__device__ __forceinline__ R cv::cudev::TexturePtr< T, R >::operator() (index_type y, index_type x) const\n \n__device__ __forceinline__ R cv::cudev::TexturePtr< uint64, R >::operator() (index_type y, index_type x) const\n \n__device__ __forceinline__ R cv::cudev::TextureOffPtr< T, R >::operator() (index_type y, index_type x) const\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const char1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const char1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const char2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const char2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const char3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const char3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const char4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const char4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< multiplies< typename Body::value_type > > > > cv::cudev::operator* (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, multiplies< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator* (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< multiplies< T > > > > cv::cudev::operator* (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< multiplies< T > > > > cv::cudev::operator* (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const int1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const int2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const int3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const int4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const int4 &a, int s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const short1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const short1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const short2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const short2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const short3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const short3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const short4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const short4 &a, int s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< multiplies< T > > > > cv::cudev::operator* (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const uchar1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const uchar1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const uchar2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const uchar2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const uchar3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const uchar3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const uchar4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const uchar4 &a, int s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator* (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const uint1 &a, float s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator* (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator* (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const uint2 &a, float s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator* (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator* (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const uint3 &a, float s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator* (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator* (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const uint4 &a, float s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator* (const uint4 &a, uint s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (const ushort1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (const ushort1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (const ushort2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (const ushort2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (const ushort3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (const ushort3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (const ushort4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (const ushort4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator* (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator* (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator* (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator* (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator* (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator* (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator* (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator* (float s, const ushort4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (int s, const char1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (int s, const char2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (int s, const char3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (int s, const char4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (int s, const int4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (int s, const short1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (int s, const short2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (int s, const short3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (int s, const short4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (int s, const uchar1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (int s, const uchar2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (int s, const uchar3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (int s, const uchar4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator* (int s, const ushort1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator* (int s, const ushort2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator* (int s, const ushort3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator* (int s, const ushort4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< multiplies< T > > > > cv::cudev::operator* (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< multiplies< T > > > > cv::cudev::operator* (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< multiplies< T > > > > cv::cudev::operator* (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< multiplies< typename Body::value_type > > > > cv::cudev::operator* (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uint1 cv::cudev::operator* (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator* (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator* (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator* (uint s, const uint4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const char1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const char1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const char2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const char2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const char3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const char3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const char4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const char4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< plus< typename Body::value_type > > > > cv::cudev::operator+ (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, plus< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator+ (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< plus< T > > > > cv::cudev::operator+ (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< plus< T > > > > cv::cudev::operator+ (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const int1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const int2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const int3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const int4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const int4 &a, int s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const short1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const short1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const short2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const short2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const short3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const short3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const short4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const short4 &a, int s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< plus< T > > > > cv::cudev::operator+ (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< T > > > cv::cudev::operator+ (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const uchar1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const uchar1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const uchar2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const uchar2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const uchar3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const uchar3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const uchar4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const uchar4 &a, int s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator+ (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const uint1 &a, float s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator+ (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator+ (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const uint2 &a, float s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator+ (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator+ (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const uint3 &a, float s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator+ (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator+ (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const uint4 &a, float s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator+ (const uint4 &a, uint s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (const ushort1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (const ushort1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (const ushort2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (const ushort2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (const ushort3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (const ushort3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (const ushort4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (const ushort4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator+ (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator+ (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator+ (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator+ (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator+ (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator+ (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator+ (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator+ (float s, const ushort4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (int s, const char1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (int s, const char2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (int s, const char3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (int s, const char4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (int s, const int4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (int s, const short1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (int s, const short2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (int s, const short3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (int s, const short4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (int s, const uchar1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (int s, const uchar2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (int s, const uchar3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (int s, const uchar4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator+ (int s, const ushort1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator+ (int s, const ushort2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator+ (int s, const ushort3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator+ (int s, const ushort4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< plus< T > > > > cv::cudev::operator+ (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< plus< T > > > > cv::cudev::operator+ (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< plus< T > > > > cv::cudev::operator+ (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< plus< typename Body::value_type > > > > cv::cudev::operator+ (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uint1 cv::cudev::operator+ (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator+ (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator+ (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator+ (uint s, const uint4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::operator- (const char1 &a)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const char1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const char1 &a, int s)\n \n__device__ __forceinline__ char2 cv::cudev::operator- (const char2 &a)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const char2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const char2 &a, int s)\n \n__device__ __forceinline__ char3 cv::cudev::operator- (const char3 &a)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const char3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const char3 &a, int s)\n \n__device__ __forceinline__ char4 cv::cudev::operator- (const char4 &a)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const char4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const char4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const double1 &a)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const double2 &a)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const double3 &a)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const double4 &a)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< minus< typename Body::value_type > > > > cv::cudev::operator- (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, negate< typename Body::value_type > > > cv::cudev::operator- (const Expr< Body > &src)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, minus< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator- (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const float1 &a)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const float2 &a)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const float3 &a)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const float4 &a)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, negate< T > > > cv::cudev::operator- (const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< minus< T > > > > cv::cudev::operator- (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, negate< T > > > cv::cudev::operator- (const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< minus< T > > > > cv::cudev::operator- (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const int1 &a)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const int1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const int2 &a)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const int2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const int3 &a)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const int3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const int4 &a)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const int4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const int4 &a, int s)\n \n__device__ __forceinline__ short1 cv::cudev::operator- (const short1 &a)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const short1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const short1 &a, int s)\n \n__device__ __forceinline__ short2 cv::cudev::operator- (const short2 &a)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const short2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const short2 &a, int s)\n \n__device__ __forceinline__ short3 cv::cudev::operator- (const short3 &a)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const short3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const short3 &a, int s)\n \n__device__ __forceinline__ short4 cv::cudev::operator- (const short4 &a)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const short4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const short4 &a, int s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, negate< T > > > cv::cudev::operator- (const Texture< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< minus< T > > > > cv::cudev::operator- (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< T > > > cv::cudev::operator- (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const uchar1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const uchar1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const uchar2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const uchar2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const uchar3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const uchar3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const uchar4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const uchar4 &a, int s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator- (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const uint1 &a, float s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator- (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator- (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const uint2 &a, float s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator- (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator- (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const uint3 &a, float s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator- (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator- (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const uint4 &a, float s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator- (const uint4 &a, uint s)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (const ushort1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (const ushort1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (const ushort2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (const ushort2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (const ushort3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (const ushort3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (const ushort4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (const ushort4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator- (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator- (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator- (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator- (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator- (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator- (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator- (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator- (float s, const ushort4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (int s, const char1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (int s, const char2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (int s, const char3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (int s, const char4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (int s, const int4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (int s, const short1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (int s, const short2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (int s, const short3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (int s, const short4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (int s, const uchar1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (int s, const uchar2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (int s, const uchar3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (int s, const uchar4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator- (int s, const ushort1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator- (int s, const ushort2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator- (int s, const ushort3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator- (int s, const ushort4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< minus< T > > > > cv::cudev::operator- (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< minus< T > > > > cv::cudev::operator- (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< minus< T > > > > cv::cudev::operator- (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< minus< typename Body::value_type > > > > cv::cudev::operator- (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uint1 cv::cudev::operator- (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator- (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator- (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator- (uint s, const uint4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const char1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const char1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const char1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const char2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const char2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const char2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const char3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const char3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const char3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const char4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const char4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const char4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const double1 &a, double s)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const double2 &a, double s)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const double3 &a, double s)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< divides< typename Body::value_type > > > > cv::cudev::operator/ (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, divides< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator/ (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const float1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const float1 &a, float s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const float2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const float2 &a, float s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const float3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const float3 &a, float s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const float4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< divides< T > > > > cv::cudev::operator/ (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< divides< T > > > > cv::cudev::operator/ (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const int1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const int1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const int2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const int2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const int3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const int3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const int4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const int4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const int4 &a, int s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const short1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const short1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const short1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const short2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const short2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const short2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const short3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const short3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const short3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const short4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const short4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const short4 &a, int s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< divides< T > > > > cv::cudev::operator/ (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< T > > > cv::cudev::operator/ (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const uchar1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const uchar1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const uchar1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const uchar2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const uchar2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const uchar2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const uchar3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const uchar3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const uchar3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const uchar4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const uchar4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const uchar4 &a, int s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator/ (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const uint1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const uint1 &a, float s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator/ (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator/ (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const uint2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const uint2 &a, float s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator/ (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator/ (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const uint3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const uint3 &a, float s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator/ (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator/ (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const uint4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const uint4 &a, float s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator/ (const uint4 &a, uint s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (const ushort1 &a, double s)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (const ushort1 &a, float s)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (const ushort1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (const ushort2 &a, double s)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (const ushort2 &a, float s)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (const ushort2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (const ushort3 &a, double s)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (const ushort3 &a, float s)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (const ushort3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (const ushort4 &a, double s)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (const ushort4 &a, float s)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (const ushort4 &a, int s)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const char1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const char2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const char3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const char4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const double1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const double2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const double3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const double4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const float1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const float2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const float3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const float4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const int1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const int2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const int3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const int4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const short1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const short2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const short3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const short4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const uchar1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const uchar2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const uchar3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const uchar4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const uint1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const uint2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const uint3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const uint4 &b)\n \n__device__ __forceinline__ double1 cv::cudev::operator/ (double s, const ushort1 &b)\n \n__device__ __forceinline__ double2 cv::cudev::operator/ (double s, const ushort2 &b)\n \n__device__ __forceinline__ double3 cv::cudev::operator/ (double s, const ushort3 &b)\n \n__device__ __forceinline__ double4 cv::cudev::operator/ (double s, const ushort4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const char1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const char2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const char3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const char4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const float1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const float2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const float3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const float4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const int1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const int2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const int3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const int4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const short1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const short2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const short3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const short4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const uchar1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const uchar2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const uchar3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const uchar4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const uint1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const uint2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const uint3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const uint4 &b)\n \n__device__ __forceinline__ float1 cv::cudev::operator/ (float s, const ushort1 &b)\n \n__device__ __forceinline__ float2 cv::cudev::operator/ (float s, const ushort2 &b)\n \n__device__ __forceinline__ float3 cv::cudev::operator/ (float s, const ushort3 &b)\n \n__device__ __forceinline__ float4 cv::cudev::operator/ (float s, const ushort4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (int s, const char1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (int s, const char2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (int s, const char3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (int s, const char4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (int s, const int4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (int s, const short1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (int s, const short2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (int s, const short3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (int s, const short4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (int s, const uchar1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (int s, const uchar2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (int s, const uchar3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (int s, const uchar4 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator/ (int s, const ushort1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator/ (int s, const ushort2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator/ (int s, const ushort3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator/ (int s, const ushort4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< divides< T > > > > cv::cudev::operator/ (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< divides< T > > > > cv::cudev::operator/ (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< divides< T > > > > cv::cudev::operator/ (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< divides< typename Body::value_type > > > > cv::cudev::operator/ (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uint1 cv::cudev::operator/ (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator/ (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator/ (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator/ (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< less< typename Body::value_type > > > > cv::cudev::operator< (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, less< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator< (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< less< T > > > > cv::cudev::operator< (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< T > > > cv::cudev::operator< (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< T > > > cv::cudev::operator< (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< T > > > cv::cudev::operator< (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< less< T > > > > cv::cudev::operator< (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< T > > > cv::cudev::operator< (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< T > > > cv::cudev::operator< (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< T > > > cv::cudev::operator< (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< less< T > > > > cv::cudev::operator< (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< T > > > cv::cudev::operator< (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< T > > > cv::cudev::operator< (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< T > > > cv::cudev::operator< (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< less< T > > > > cv::cudev::operator< (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< less< T > > > > cv::cudev::operator< (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< less< T > > > > cv::cudev::operator< (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< less< typename Body::value_type > > > > cv::cudev::operator< (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator< (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator< (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator< (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator< (ushort s, const ushort4 &b)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_lshift< typename Body::value_type > > > > cv::cudev::operator<< (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_lshift< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator<< (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_lshift< T > > > > cv::cudev::operator<< (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_lshift< T > > > > cv::cudev::operator<< (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const GpuMat_< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_lshift< T > > > > cv::cudev::operator<< (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< (const Texture< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_lshift< T > > > > cv::cudev::operator<< (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_lshift< T > > > > cv::cudev::operator<< (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_lshift< T > > > > cv::cudev::operator<< (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_lshift< typename Body::value_type > > > > cv::cudev::operator<< (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< less_equal< typename Body::value_type > > > > cv::cudev::operator<= (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, less_equal< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator<= (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< less_equal< T > > > > cv::cudev::operator<= (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< less_equal< T > > > > cv::cudev::operator<= (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< less_equal< T > > > > cv::cudev::operator<= (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< less_equal< T > > > > cv::cudev::operator<= (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< less_equal< T > > > > cv::cudev::operator<= (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< less_equal< T > > > > cv::cudev::operator<= (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< less_equal< typename Body::value_type > > > > cv::cudev::operator<= (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator<= (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator<= (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator<= (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator<= (ushort s, const ushort4 &b)\n \nTexture & cv::cudev::Texture< T, R >::operator= (const Texture &)=default\n \nTextureOff & cv::cudev::TextureOff< T, R >::operator= (const TextureOff &)=default\n \n__host__ UniqueTexture & cv::cudev::UniqueTexture< T, R >::operator= (const UniqueTexture &)=delete\n \nTexture & cv::cudev::Texture< T, R >::operator= (Texture &&)=default\n \nTextureOff & cv::cudev::TextureOff< T, R >::operator= (TextureOff &&)=default\n \n__host__ UniqueTexture & cv::cudev::UniqueTexture< T, R >::operator= (UniqueTexture &&other) noexcept\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< equal_to< typename Body::value_type > > > > cv::cudev::operator== (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, equal_to< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator== (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< equal_to< T > > > > cv::cudev::operator== (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< equal_to< T > > > > cv::cudev::operator== (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< equal_to< T > > > > cv::cudev::operator== (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< equal_to< T > > > > cv::cudev::operator== (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< equal_to< T > > > > cv::cudev::operator== (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< equal_to< T > > > > cv::cudev::operator== (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< equal_to< typename Body::value_type > > > > cv::cudev::operator== (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator== (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator== (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator== (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator== (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< greater< typename Body::value_type > > > > cv::cudev::operator> (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, greater< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator> (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< greater< T > > > > cv::cudev::operator> (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< greater< T > > > > cv::cudev::operator> (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< greater< T > > > > cv::cudev::operator> (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< T > > > cv::cudev::operator> (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< greater< T > > > > cv::cudev::operator> (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< greater< T > > > > cv::cudev::operator> (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< greater< T > > > > cv::cudev::operator> (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< greater< typename Body::value_type > > > > cv::cudev::operator> (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator> (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator> (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator> (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator> (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< greater_equal< typename Body::value_type > > > > cv::cudev::operator>= (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, greater_equal< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator>= (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< greater_equal< T > > > > cv::cudev::operator>= (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< greater_equal< T > > > > cv::cudev::operator>= (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< greater_equal< T > > > > cv::cudev::operator>= (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< greater_equal< T > > > > cv::cudev::operator>= (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< greater_equal< T > > > > cv::cudev::operator>= (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< greater_equal< T > > > > cv::cudev::operator>= (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< greater_equal< typename Body::value_type > > > > cv::cudev::operator>= (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator>= (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator>= (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator>= (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator>= (ushort s, const ushort4 &b)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_rshift< typename Body::value_type > > > > cv::cudev::operator>> (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_rshift< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator>> (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_rshift< T > > > > cv::cudev::operator>> (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_rshift< T > > > > cv::cudev::operator>> (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const GpuMat_< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_rshift< T > > > > cv::cudev::operator>> (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> (const Texture< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_rshift< T > > > > cv::cudev::operator>> (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_rshift< T > > > > cv::cudev::operator>> (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_rshift< T > > > > cv::cudev::operator>> (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_rshift< typename Body::value_type > > > > cv::cudev::operator>> (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ char1 cv::cudev::operator^ (char s, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::operator^ (char s, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::operator^ (char s, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::operator^ (char s, const char4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::operator^ (const char1 &a, char s)\n \n__device__ __forceinline__ char1 cv::cudev::operator^ (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::operator^ (const char2 &a, char s)\n \n__device__ __forceinline__ char2 cv::cudev::operator^ (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::operator^ (const char3 &a, char s)\n \n__device__ __forceinline__ char3 cv::cudev::operator^ (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::operator^ (const char4 &a, char s)\n \n__device__ __forceinline__ char4 cv::cudev::operator^ (const char4 &a, const char4 &b)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_xor< typename Body::value_type > > > > cv::cudev::operator^ (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_xor< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator^ (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_xor< T > > > > cv::cudev::operator^ (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_xor< T > > > > cv::cudev::operator^ (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator^ (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator^ (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator^ (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator^ (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator^ (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator^ (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator^ (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator^ (const int4 &a, int s)\n \n__device__ __forceinline__ short1 cv::cudev::operator^ (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ short1 cv::cudev::operator^ (const short1 &a, short s)\n \n__device__ __forceinline__ short2 cv::cudev::operator^ (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ short2 cv::cudev::operator^ (const short2 &a, short s)\n \n__device__ __forceinline__ short3 cv::cudev::operator^ (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ short3 cv::cudev::operator^ (const short3 &a, short s)\n \n__device__ __forceinline__ short4 cv::cudev::operator^ (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ short4 cv::cudev::operator^ (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_xor< T > > > > cv::cudev::operator^ (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator^ (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator^ (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator^ (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator^ (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator^ (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator^ (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator^ (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator^ (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator^ (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::operator^ (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator^ (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator^ (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator^ (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator^ (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator^ (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator^ (const uint4 &a, uint s)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator^ (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator^ (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator^ (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator^ (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator^ (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator^ (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator^ (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator^ (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ int1 cv::cudev::operator^ (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator^ (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator^ (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator^ (int s, const int4 &b)\n \n__device__ __forceinline__ short1 cv::cudev::operator^ (short s, const short1 &b)\n \n__device__ __forceinline__ short2 cv::cudev::operator^ (short s, const short2 &b)\n \n__device__ __forceinline__ short3 cv::cudev::operator^ (short s, const short3 &b)\n \n__device__ __forceinline__ short4 cv::cudev::operator^ (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_xor< T > > > > cv::cudev::operator^ (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_xor< T > > > > cv::cudev::operator^ (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_xor< T > > > > cv::cudev::operator^ (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_xor< typename Body::value_type > > > > cv::cudev::operator^ (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator^ (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator^ (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator^ (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator^ (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::operator^ (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator^ (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator^ (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator^ (uint s, const uint4 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator^ (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator^ (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator^ (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator^ (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::operator| (char s, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::operator| (char s, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::operator| (char s, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::operator| (char s, const char4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::operator| (const char1 &a, char s)\n \n__device__ __forceinline__ char1 cv::cudev::operator| (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ char2 cv::cudev::operator| (const char2 &a, char s)\n \n__device__ __forceinline__ char2 cv::cudev::operator| (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ char3 cv::cudev::operator| (const char3 &a, char s)\n \n__device__ __forceinline__ char3 cv::cudev::operator| (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ char4 cv::cudev::operator| (const char4 &a, char s)\n \n__device__ __forceinline__ char4 cv::cudev::operator| (const char4 &a, const char4 &b)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_or< typename Body::value_type > > > > cv::cudev::operator| (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_or< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator| (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_or< T > > > > cv::cudev::operator| (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_or< T > > > > cv::cudev::operator| (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ int1 cv::cudev::operator| (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ int1 cv::cudev::operator| (const int1 &a, int s)\n \n__device__ __forceinline__ int2 cv::cudev::operator| (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator| (const int2 &a, int s)\n \n__device__ __forceinline__ int3 cv::cudev::operator| (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator| (const int3 &a, int s)\n \n__device__ __forceinline__ int4 cv::cudev::operator| (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator| (const int4 &a, int s)\n \n__device__ __forceinline__ short1 cv::cudev::operator| (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ short1 cv::cudev::operator| (const short1 &a, short s)\n \n__device__ __forceinline__ short2 cv::cudev::operator| (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ short2 cv::cudev::operator| (const short2 &a, short s)\n \n__device__ __forceinline__ short3 cv::cudev::operator| (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ short3 cv::cudev::operator| (const short3 &a, short s)\n \n__device__ __forceinline__ short4 cv::cudev::operator| (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ short4 cv::cudev::operator| (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_or< T > > > > cv::cudev::operator| (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator| (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator| (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator| (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator| (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator| (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator| (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator| (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator| (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uint1 cv::cudev::operator| (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::operator| (const uint1 &a, uint s)\n \n__device__ __forceinline__ uint2 cv::cudev::operator| (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator| (const uint2 &a, uint s)\n \n__device__ __forceinline__ uint3 cv::cudev::operator| (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator| (const uint3 &a, uint s)\n \n__device__ __forceinline__ uint4 cv::cudev::operator| (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator| (const uint4 &a, uint s)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator| (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator| (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator| (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator| (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator| (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator| (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator| (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator| (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ int1 cv::cudev::operator| (int s, const int1 &b)\n \n__device__ __forceinline__ int2 cv::cudev::operator| (int s, const int2 &b)\n \n__device__ __forceinline__ int3 cv::cudev::operator| (int s, const int3 &b)\n \n__device__ __forceinline__ int4 cv::cudev::operator| (int s, const int4 &b)\n \n__device__ __forceinline__ short1 cv::cudev::operator| (short s, const short1 &b)\n \n__device__ __forceinline__ short2 cv::cudev::operator| (short s, const short2 &b)\n \n__device__ __forceinline__ short3 cv::cudev::operator| (short s, const short3 &b)\n \n__device__ __forceinline__ short4 cv::cudev::operator| (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_or< T > > > > cv::cudev::operator| (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_or< T > > > > cv::cudev::operator| (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_or< T > > > > cv::cudev::operator| (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_or< typename Body::value_type > > > > cv::cudev::operator| (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator| (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator| (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator| (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator| (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uint1 cv::cudev::operator| (uint s, const uint1 &b)\n \n__device__ __forceinline__ uint2 cv::cudev::operator| (uint s, const uint2 &b)\n \n__device__ __forceinline__ uint3 cv::cudev::operator| (uint s, const uint3 &b)\n \n__device__ __forceinline__ uint4 cv::cudev::operator| (uint s, const uint4 &b)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator| (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator| (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator| (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator| (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (char s, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (char s, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (char s, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (char s, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const char1 &a, char s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const char1 &a, const char1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const char2 &a, char s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const char2 &a, const char2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const char3 &a, char s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const char3 &a, const char3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const char4 &a, char s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const char4 &a, const char4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const double1 &a, const double1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const double1 &a, double s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const double2 &a, const double2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const double2 &a, double s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const double3 &a, const double3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const double3 &a, double s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const double4 &a, const double4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const double4 &a, double s)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< logical_or< typename Body::value_type > > > > cv::cudev::operator|| (const Expr< Body > &a, typename Body::value_type val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| (const Expr< Body > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| (const Expr< Body > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| (const Expr< Body > &src1, const Texture< T > &src2)\n \ntemplate<class Body1 , class Body2 > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, logical_or< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator|| (const Expr< Body1 > &a, const Expr< Body2 > &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const float1 &a, const float1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const float1 &a, float s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const float2 &a, const float2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const float2 &a, float s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const float3 &a, const float3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const float3 &a, float s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const float4 &a, const float4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const float4 &a, float s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< logical_or< T > > > > cv::cudev::operator|| (const GlobPtrSz< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| (const GlobPtrSz< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const GlobPtrSz< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const GlobPtrSz< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const GlobPtrSz< T > &src1, const Texture< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< logical_or< T > > > > cv::cudev::operator|| (const GpuMat_< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| (const GpuMat_< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const GpuMat_< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const GpuMat_< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const GpuMat_< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const int1 &a, const int1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const int1 &a, int s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const int2 &a, const int2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const int2 &a, int s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const int3 &a, const int3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const int3 &a, int s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const int4 &a, const int4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const int4 &a, int s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const short1 &a, const short1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const short1 &a, short s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const short2 &a, const short2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const short2 &a, short s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const short3 &a, const short3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const short3 &a, short s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const short4 &a, const short4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const short4 &a, short s)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< logical_or< T > > > > cv::cudev::operator|| (const Texture< T > &src, T val)\n \ntemplate<typename T , class Body > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| (const Texture< T > &src1, const Expr< Body > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const Texture< T > &src1, const GlobPtrSz< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const Texture< T > &src1, const GpuMat_< T > &src2)\n \ntemplate<typename T > \n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| (const Texture< T > &src1, const Texture< T > &src2)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const uchar1 &a, const uchar1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const uchar1 &a, uchar s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const uchar2 &a, const uchar2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const uchar2 &a, uchar s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const uchar3 &a, const uchar3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const uchar3 &a, uchar s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const uchar4 &a, const uchar4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const uchar4 &a, uchar s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const uint1 &a, const uint1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const uint1 &a, uint s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const uint2 &a, const uint2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const uint2 &a, uint s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const uint3 &a, const uint3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const uint3 &a, uint s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const uint4 &a, const uint4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const uint4 &a, uint s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const ushort1 &a, const ushort1 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (const ushort1 &a, ushort s)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const ushort2 &a, const ushort2 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (const ushort2 &a, ushort s)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const ushort3 &a, const ushort3 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (const ushort3 &a, ushort s)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const ushort4 &a, const ushort4 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (const ushort4 &a, ushort s)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (double s, const double1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (double s, const double2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (double s, const double3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (double s, const double4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (float s, const float1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (float s, const float2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (float s, const float3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (float s, const float4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (int s, const int1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (int s, const int2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (int s, const int3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (int s, const int4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (short s, const short1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (short s, const short2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (short s, const short3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (short s, const short4 &b)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< logical_or< T > > > > cv::cudev::operator|| (T val, const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< logical_or< T > > > > cv::cudev::operator|| (T val, const GpuMat_< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< logical_or< T > > > > cv::cudev::operator|| (T val, const Texture< T > &src)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< logical_or< typename Body::value_type > > > > cv::cudev::operator|| (typename Body::value_type val, const Expr< Body > &a)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (uchar s, const uchar1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (uchar s, const uchar2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (uchar s, const uchar3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (uchar s, const uchar4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (uint s, const uint1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (uint s, const uint2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (uint s, const uint3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (uint s, const uint4 &b)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator|| (ushort s, const ushort1 &b)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator|| (ushort s, const ushort2 &b)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator|| (ushort s, const ushort3 &b)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator|| (ushort s, const ushort4 &b)\n \n__device__ __forceinline__ char1 cv::cudev::operator~ (const char1 &a)\n \n__device__ __forceinline__ char2 cv::cudev::operator~ (const char2 &a)\n \n__device__ __forceinline__ char3 cv::cudev::operator~ (const char3 &a)\n \n__device__ __forceinline__ char4 cv::cudev::operator~ (const char4 &a)\n \ntemplate<class Body > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, bit_not< typename Body::value_type > > > cv::cudev::operator~ (const Expr< Body > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_not< T > > > cv::cudev::operator~ (const GlobPtrSz< T > &src)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, bit_not< T > > > cv::cudev::operator~ (const GpuMat_< T > &src)\n \n__device__ __forceinline__ int1 cv::cudev::operator~ (const int1 &a)\n \n__device__ __forceinline__ int2 cv::cudev::operator~ (const int2 &a)\n \n__device__ __forceinline__ int3 cv::cudev::operator~ (const int3 &a)\n \n__device__ __forceinline__ int4 cv::cudev::operator~ (const int4 &a)\n \n__device__ __forceinline__ short1 cv::cudev::operator~ (const short1 &a)\n \n__device__ __forceinline__ short2 cv::cudev::operator~ (const short2 &a)\n \n__device__ __forceinline__ short3 cv::cudev::operator~ (const short3 &a)\n \n__device__ __forceinline__ short4 cv::cudev::operator~ (const short4 &a)\n \ntemplate<typename T > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, bit_not< T > > > cv::cudev::operator~ (const Texture< T > &src)\n \n__device__ __forceinline__ uchar1 cv::cudev::operator~ (const uchar1 &a)\n \n__device__ __forceinline__ uchar2 cv::cudev::operator~ (const uchar2 &a)\n \n__device__ __forceinline__ uchar3 cv::cudev::operator~ (const uchar3 &a)\n \n__device__ __forceinline__ uchar4 cv::cudev::operator~ (const uchar4 &a)\n \n__device__ __forceinline__ uint1 cv::cudev::operator~ (const uint1 &a)\n \n__device__ __forceinline__ uint2 cv::cudev::operator~ (const uint2 &a)\n \n__device__ __forceinline__ uint3 cv::cudev::operator~ (const uint3 &a)\n \n__device__ __forceinline__ uint4 cv::cudev::operator~ (const uint4 &a)\n \n__device__ __forceinline__ ushort1 cv::cudev::operator~ (const ushort1 &a)\n \n__device__ __forceinline__ ushort2 cv::cudev::operator~ (const ushort2 &a)\n \n__device__ __forceinline__ ushort3 cv::cudev::operator~ (const ushort3 &a)\n \n__device__ __forceinline__ ushort4 cv::cudev::operator~ (const ushort4 &a)\n \nstatic __host__ PerspectiveMapPtrSz cv::cudev::perspectiveMap (Size dstSize, const GpuMat_< float > &warpMat)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Binder2nd< pow_func< typename PtrTraits< SrcPtr >::value_type > > > > cv::cudev::pow_ (const SrcPtr &src, float power)\n \ntemplate<class SrcPtr > \n__host__ Expr< PyrDownBody< SrcPtr > > cv::cudev::pyrDown_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< PyrUpBody< SrcPtr > > cv::cudev::pyrUp_ (const SrcPtr &src)\n \ntemplate<class Reductor , class SrcPtr > \n__host__ Expr< ReduceToColumnBody< Reductor, SrcPtr > > cv::cudev::reduceToColumn_ (const SrcPtr &src)\n \ntemplate<class Reductor , class SrcPtr > \n__host__ Expr< ReduceToRowBody< Reductor, SrcPtr > > cv::cudev::reduceToRow_ (const SrcPtr &src)\n \ntemplate<class SrcPtr , class MapPtr > \n__host__ Expr< RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapPtr >::ptr_type > > cv::cudev::remap_ (const SrcPtr &src, const MapPtr &map)\n \ntemplate<class SrcPtr , class MapXPtr , class MapYPtr > \n__host__ Expr< RemapPtr2Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapXPtr >::ptr_type, typename PtrTraits< MapYPtr >::ptr_type > > cv::cudev::remap_ (const SrcPtr &src, const MapXPtr &mapx, const MapYPtr &mapy)\n \ntemplate<class SrcPtr , class MapPtr > \n__host__ RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapPtr >::ptr_type > cv::cudev::remapPtr (const SrcPtr &src, const MapPtr &map)\n \ntemplate<class SrcPtr , class MapXPtr , class MapYPtr > \n__host__ RemapPtr2Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapXPtr >::ptr_type, typename PtrTraits< MapYPtr >::ptr_type > cv::cudev::remapPtr (const SrcPtr &src, const MapXPtr &mapx, const MapYPtr &mapy)\n \ntemplate<int cn, typename T > \n__host__ GpuMat_< typename MakeVec< typename VecTraits< T >::elem_type, cn >::type > cv::cudev::reshape_ (const GpuMat_< T > &mat, int rows=0)\n \ntemplate<class SrcPtr > \n__host__ Expr< ResizePtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::resize_ (const SrcPtr &src, float fx, float fy)\n \ntemplate<class SrcPtr > \n__host__ ResizePtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::resizePtr (const SrcPtr &src, float fx, float fy)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_GRAY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_XYZ4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_XYZ_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YCrCb4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YCrCb_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YUV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YUV_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_GRAY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV4_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV_FULL_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Lab4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Lab_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Luv4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Luv_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_XYZ4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_XYZ_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YCrCb4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YCrCb_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YUV4_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YUV_ (const SrcPtr &src)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const char1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const char2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const char3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const char4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const double1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const double2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const double3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const double4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const float1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const float2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const float3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const float4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const int1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const int2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const int3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const int4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const short1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const short2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const short3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const short4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uchar1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uchar2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uchar3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uchar4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uint1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uint2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uint3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const uint4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const ushort1 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const ushort2 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const ushort3 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (const ushort4 &v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (double v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (float v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (int v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (schar v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (short v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (uchar v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (uint v)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::saturate_cast (ushort v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (double v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (float v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (int v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (short v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (uchar v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (uint v)\n \ntemplate<> \n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > (ushort v)\n \ntemplate<> \n__device__ __forceinline__ short cv::cudev::saturate_cast< short > (double v)\n \ntemplate<> \n__device__ __forceinline__ short cv::cudev::saturate_cast< short > (float v)\n \ntemplate<> \n__device__ __forceinline__ short cv::cudev::saturate_cast< short > (int v)\n \ntemplate<> \n__device__ __forceinline__ short cv::cudev::saturate_cast< short > (uint v)\n \ntemplate<> \n__device__ __forceinline__ short cv::cudev::saturate_cast< short > (ushort v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (double v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (float v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (int v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (schar v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (short v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (uint v)\n \ntemplate<> \n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > (ushort v)\n \ntemplate<> \n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > (double v)\n \ntemplate<> \n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > (float v)\n \ntemplate<> \n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > (int v)\n \ntemplate<> \n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > (schar v)\n \ntemplate<> \n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > (short v)\n \ntemplate<> \n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > (double v)\n \ntemplate<> \n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > (float v)\n \ntemplate<> \n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > (int v)\n \ntemplate<> \n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > (schar v)\n \ntemplate<> \n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > (short v)\n \ntemplate<> \n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > (uint v)\n \ntemplate<class SrcPtr > \n__host__ Expr< ScharrXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::scharrX_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ ScharrXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::scharrXPtr (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< ScharrYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::scharrY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ ScharrYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::scharrYPtr (const SrcPtr &src)\n \ntemplate<class Ptr2DSz > \n__host__ PtrTraits< Ptr2DSz >::ptr_type cv::cudev::shrinkPtr (const Ptr2DSz &ptr)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::sin (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::sin (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::sin (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::sin (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sin (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sin (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sin (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sin (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sin_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sin_ (const SrcPtr &src)\n \ntemplate<class MaskPtr > \n__host__ SingleMaskChannelsSz< typename PtrTraits< MaskPtr >::ptr_type > cv::cudev::singleMaskChannels (const MaskPtr &mask, int channels)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::sinh (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::sinh (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::sinh (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::sinh (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sinh (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sinh (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sinh (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sinh (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sinh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sinh_ (const SrcPtr &src)\n \ntemplate<typename T0 > \n__device__ __forceinline__ tuple< volatile T0 * > cv::cudev::smem_tuple (T0 *t0)\n \ntemplate<typename T0 , typename T1 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1)\n \ntemplate<typename T0 , typename T1 , typename T2 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3, T4 *t4)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3, T4 *t4, T5 *t5)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3, T4 *t4, T5 *t5, T6 *t6)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 , typename T7 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 *, volatile T7 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3, T4 *t4, T5 *t5, T6 *t6, T7 *t7)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 , typename T7 , typename T8 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 *, volatile T7 *, volatile T8 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3, T4 *t4, T5 *t5, T6 *t6, T7 *t7, T8 *t8)\n \ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 , typename T7 , typename T8 , typename T9 > \n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 *, volatile T7 *, volatile T8 *, volatile T9 * > cv::cudev::smem_tuple (T0 *t0, T1 *t1, T2 *t2, T3 *t3, T4 *t4, T5 *t5, T6 *t6, T7 *t7, T8 *t8, T9 *t9)\n \ntemplate<class SrcPtr > \n__host__ Expr< SobelXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::sobelX_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ SobelXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::sobelXPtr (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< SobelYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::sobelY_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ SobelYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::sobelYPtr (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sqr_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sqr_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::sqrt (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::sqrt (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::sqrt (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::sqrt (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::sqrt (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::sqrt (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::sqrt (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::sqrt (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sqrt_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sqrt_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< SumExprBody< SrcPtr > > cv::cudev::sum_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::tan (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::tan (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::tan (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::tan (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tan (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tan (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tan (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tan (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, tan_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::tan_ (const SrcPtr &src)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const char1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const char2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const char3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const char4 &a)\n \n__device__ __forceinline__ double1 cv::cudev::tanh (const double1 &a)\n \n__device__ __forceinline__ double2 cv::cudev::tanh (const double2 &a)\n \n__device__ __forceinline__ double3 cv::cudev::tanh (const double3 &a)\n \n__device__ __forceinline__ double4 cv::cudev::tanh (const double4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const float1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const float2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const float3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const float4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const int1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const int2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const int3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const int4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const short1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const short2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const short3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const short4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const uchar1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const uchar2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const uchar3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const uchar4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const uint1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const uint2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const uint3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const uint4 &a)\n \n__device__ __forceinline__ float1 cv::cudev::tanh (const ushort1 &a)\n \n__device__ __forceinline__ float2 cv::cudev::tanh (const ushort2 &a)\n \n__device__ __forceinline__ float3 cv::cudev::tanh (const ushort3 &a)\n \n__device__ __forceinline__ float4 cv::cudev::tanh (const ushort4 &a)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, tanh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::tanh_ (const SrcPtr &src)\n \ntemplate<typename T > \n__host__ __device__ ThreshBinaryFunc< T > cv::cudev::thresh_binary_func (T thresh, T maxVal)\n \ntemplate<typename T > \n__host__ __device__ ThreshBinaryInvFunc< T > cv::cudev::thresh_binary_inv_func (T thresh, T maxVal)\n \ntemplate<typename T > \n__host__ __device__ ThreshToZeroFunc< T > cv::cudev::thresh_to_zero_func (T thresh)\n \ntemplate<typename T > \n__host__ __device__ ThreshToZeroInvFunc< T > cv::cudev::thresh_to_zero_inv_func (T thresh)\n \ntemplate<typename T > \n__host__ __device__ ThreshTruncFunc< T > cv::cudev::thresh_trunc_func (T thresh)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshBinaryFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshBinary_ (const SrcPtr &src, typename PtrTraits< SrcPtr >::value_type thresh, typename PtrTraits< SrcPtr >::value_type maxVal)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshBinaryInvFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshBinaryInv_ (const SrcPtr &src, typename PtrTraits< SrcPtr >::value_type thresh, typename PtrTraits< SrcPtr >::value_type maxVal)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshToZeroFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshToZero_ (const SrcPtr &src, typename PtrTraits< SrcPtr >::value_type thresh)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshToZeroInvFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshToZeroInv_ (const SrcPtr &src, typename PtrTraits< SrcPtr >::value_type thresh)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshTruncFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshTrunc_ (const SrcPtr &src, typename PtrTraits< SrcPtr >::value_type thresh)\n \ntemplate<class Src1Ptr , class Src2Ptr , class Op > \n__host__ BinaryTransformPtrSz< typename PtrTraits< Src1Ptr >::ptr_type, typename PtrTraits< Src2Ptr >::ptr_type, Op > cv::cudev::transformPtr (const Src1Ptr &src1, const Src2Ptr &src2, const Op &op)\n \ntemplate<class SrcPtr , class Op > \n__host__ UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Op > cv::cudev::transformPtr (const SrcPtr &src, const Op &op)\n \ntemplate<class SrcPtr > \n__host__ Expr< TransposeBody< SrcPtr > > cv::cudev::transpose_ (const SrcPtr &src)\n \ntemplate<int n, class Op > \n__host__ __device__ UnaryTupleAdapter< Op, n > cv::cudev::unaryTupleAdapter (const Op &op)\n \n__device__ __forceinline__ uint cv::cudev::vabsdiff2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vabsdiff4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vadd2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vadd4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vavg2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vavg4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vavrg2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vavrg4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpeq2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpeq4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpge2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpge4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpgt2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpgt4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmple2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmple4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmplt2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmplt4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpne2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vcmpne4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vmax2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vmax4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vmin2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vmin4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vseteq2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vseteq4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetge2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetge4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetgt2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetgt4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetle2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetle4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetlt2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetlt4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetne2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsetne4 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsub2 (uint a, uint b)\n \n__device__ __forceinline__ uint cv::cudev::vsub4 (uint a, uint b)\n \ntemplate<class SrcPtr > \n__host__ Expr< RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, AffineMapPtr > > cv::cudev::warpAffine_ (const SrcPtr &src, Size dstSize, const GpuMat_< float > &warpMat)\n \ntemplate<class SrcPtr > \n__host__ RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, AffineMapPtr > cv::cudev::warpAffinePtr (const SrcPtr &src, Size dstSize, const GpuMat_< float > &warpMat)\n \ntemplate<class InIt , class OutIt > \n__device__ __forceinline__ OutIt cv::cudev::warpCopy (InIt beg, InIt end, OutIt out)\n \ntemplate<class It , typename T > \n__device__ __forceinline__ void cv::cudev::warpFill (It beg, It end, const T &value)\n \ntemplate<class SrcPtr > \n__host__ Expr< RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, PerspectiveMapPtr > > cv::cudev::warpPerspective_ (const SrcPtr &src, Size dstSize, const GpuMat_< float > &warpMat)\n \ntemplate<class SrcPtr > \n__host__ RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, PerspectiveMapPtr > cv::cudev::warpPerspectivePtr (const SrcPtr &src, Size dstSize, const GpuMat_< float > &warpMat)\n \ntemplate<typename P0 , typename P1 , typename P2 , typename P3 , typename P4 , typename P5 , typename P6 , typename P7 , typename P8 , typename P9 , typename R0 , typename R1 , typename R2 , typename R3 , typename R4 , typename R5 , typename R6 , typename R7 , typename R8 , typename R9 , class Op0 , class Op1 , class Op2 , class Op3 , class Op4 , class Op5 , class Op6 , class Op7 , class Op8 , class Op9 > \n__device__ __forceinline__ void cv::cudev::warpReduce (const tuple< P0, P1, P2, P3, P4, P5, P6, P7, P8, P9 > &smem, const tuple< R0, R1, R2, R3, R4, R5, R6, R7, R8, R9 > &val, uint tid, const tuple< Op0, Op1, Op2, Op3, Op4, Op5, Op6, Op7, Op8, Op9 > &op)\n \ntemplate<typename T , class Op > \n__device__ __forceinline__ void cv::cudev::warpReduce (volatile T *smem, T &val, uint tid, const Op &op)\n \ntemplate<typename KP0 , typename KP1 , typename KP2 , typename KP3 , typename KP4 , typename KP5 , typename KP6 , typename KP7 , typename KP8 , typename KP9 , typename KR0 , typename KR1 , typename KR2 , typename KR3 , typename KR4 , typename KR5 , typename KR6 , typename KR7 , typename KR8 , typename KR9 , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp0 , class Cmp1 , class Cmp2 , class Cmp3 , class Cmp4 , class Cmp5 , class Cmp6 , class Cmp7 , class Cmp8 , class Cmp9 > \n__device__ __forceinline__ void cv::cudev::warpReduceKeyVal (const tuple< KP0, KP1, KP2, KP3, KP4, KP5, KP6, KP7, KP8, KP9 > &skeys, const tuple< KR0, KR1, KR2, KR3, KR4, KR5, KR6, KR7, KR8, KR9 > &key, const tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > &svals, const tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > &val, uint tid, const tuple< Cmp0, Cmp1, Cmp2, Cmp3, Cmp4, Cmp5, Cmp6, Cmp7, Cmp8, Cmp9 > &cmp)\n \ntemplate<typename K , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp > \n__device__ __forceinline__ void cv::cudev::warpReduceKeyVal (volatile K *skeys, K &key, const tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > &svals, const tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > &val, uint tid, const Cmp &cmp)\n \ntemplate<typename K , typename V , class Cmp > \n__device__ __forceinline__ void cv::cudev::warpReduceKeyVal (volatile K *skeys, K &key, volatile V *svals, V &val, uint tid, const Cmp &cmp)\n \ntemplate<typename T > \n__device__ __forceinline__ T cv::cudev::warpScanExclusive (T data, volatile T *smem, uint tid)\n \ntemplate<typename T > \n__device__ T cv::cudev::warpScanInclusive (T data, volatile T *smem, uint tid)\n \ntemplate<class InIt , class OutIt , class UnOp > \n__device__ __forceinline__ OutIt cv::cudev::warpTransform (InIt beg, InIt end, OutIt out, const UnOp &op)\n \ntemplate<class InIt1 , class InIt2 , class OutIt , class BinOp > \n__device__ __forceinline__ OutIt cv::cudev::warpTransform (InIt1 beg1, InIt1 end1, InIt2 beg2, OutIt out, const BinOp &op)\n \ntemplate<typename OutIt , typename T > \n__device__ __forceinline__ void cv::cudev::warpYota (OutIt beg, OutIt end, T value)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_BGR_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_BGRA_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_RGB_ (const SrcPtr &src)\n \ntemplate<class SrcPtr > \n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_RGBA_ (const SrcPtr &src)\n \ntemplate<class Ptr0 , class Ptr1 > \n__host__ ZipPtrSz< tuple< typename PtrTraits< Ptr0 >::ptr_type, typename PtrTraits< Ptr1 >::ptr_type > > cv::cudev::zipPtr (const Ptr0 &ptr0, const Ptr1 &ptr1)\n \ntemplate<class Ptr0 , class Ptr1 , class Ptr2 > \n__host__ ZipPtrSz< tuple< typename PtrTraits< Ptr0 >::ptr_type, typename PtrTraits< Ptr1 >::ptr_type, typename PtrTraits< Ptr2 >::ptr_type > > cv::cudev::zipPtr (const Ptr0 &ptr0, const Ptr1 &ptr1, const Ptr2 &ptr2)\n \ntemplate<class Ptr0 , class Ptr1 , class Ptr2 , class Ptr3 > \n__host__ ZipPtrSz< tuple< typename PtrTraits< Ptr0 >::ptr_type, typename PtrTraits< Ptr1 >::ptr_type, typename PtrTraits< Ptr2 >::ptr_type, typename PtrTraits< Ptr3 >::ptr_type > > cv::cudev::zipPtr (const Ptr0 &ptr0, const Ptr1 &ptr1, const Ptr2 &ptr2, const Ptr3 &ptr3)\n \n\nVariables\nint cv::cudev::Texture< T, R >::cols = 0\n \nint cv::cudev::Texture< T, R >::rows = 0\n \nstd::shared_ptr< UniqueTexture< T, R > > cv::cudev::Texture< T, R >::texture = 0\n \n\nMacro Definition Documentation\n\n◆ CV_CUDEV_ARCH\n\n#define CV_CUDEV_ARCH   0\n\n#include <opencv2/cudev/common.hpp>\n\n◆ CV_CUDEV_BINARY_FUNCTION_INST\n\n#define CV_CUDEV_BINARY_FUNCTION_INST\n(\n \nname, \n\n \nfunc \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ CV_CUDEV_EXPR_BINARY_FUNC\n\n#define CV_CUDEV_EXPR_BINARY_FUNC\n(\n \nname)\n\n#include <opencv2/cudev/expr/binary_func.hpp>\nValue: template <class SrcPtr1, class SrcPtr2> \\\n    __host__ Expr<BinaryTransformPtrSz<typename PtrTraits<SrcPtr1>::ptr_type, typename PtrTraits<SrcPtr2>::ptr_type, name ## _func<typename LargerType<typename PtrTraits<SrcPtr1>::value_type, typename PtrTraits<SrcPtr2>::value_type>::type> > > \\\n    name ## _(const SrcPtr1& src1, const SrcPtr2& src2) \\\n    { \\\n return makeExpr(transformPtr(src1, src2, name ## _func<typename LargerType<typename PtrTraits<SrcPtr1>::value_type, typename PtrTraits<SrcPtr2>::value_type>::type>())); \\\n    }\n\n◆ CV_CUDEV_EXPR_BINOP_INST\n\n#define CV_CUDEV_EXPR_BINOP_INST\n(\n \nop, \n\n \nfunctor \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ CV_CUDEV_EXPR_CVTCOLOR_INST\n\n#define CV_CUDEV_EXPR_CVTCOLOR_INST\n(\n \nname)\n\n#include <opencv2/cudev/expr/color.hpp>\nValue: template <class SrcPtr> \\\n    __host__ Expr<UnaryTransformPtrSz<typename PtrTraits<SrcPtr>::ptr_type, name ## _func<typename VecTraits<typename PtrTraits<SrcPtr>::value_type>::elem_type> > > \\\n    name ## _(const SrcPtr& src) \\\n    { \\\n return makeExpr(transformPtr(src, name ## _func<typename VecTraits<typename PtrTraits<SrcPtr>::value_type>::elem_type>())); \\\n    }\n\n◆ CV_CUDEV_EXPR_UNARY_FUNC\n\n#define CV_CUDEV_EXPR_UNARY_FUNC\n(\n \nname)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\nValue: template <class SrcPtr> \\\n    __host__ Expr<UnaryTransformPtrSz<typename PtrTraits<SrcPtr>::ptr_type, name ## _func<typename PtrTraits<SrcPtr>::value_type> > > \\\n    name ## _(const SrcPtr& src) \\\n    { \\\n return makeExpr(transformPtr(src, name ## _func<typename PtrTraits<SrcPtr>::value_type>())); \\\n    }\n\n◆ CV_CUDEV_EXPR_UNOP_INST\n\n#define CV_CUDEV_EXPR_UNOP_INST\n(\n \nop, \n\n \nfunctor \n\n)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\nValue: template <typename T> \\\n    __host__ Expr<UnaryTransformPtrSz<typename PtrTraits<GpuMat_<T> >::ptr_type, functor<T> > > \\\n operator op(const GpuMat_<T>& src) \\\n    { \\\n return makeExpr(transformPtr(src, functor<T>())); \\\n    } \\\n template <typename T> \\\n    __host__ Expr<UnaryTransformPtrSz<typename PtrTraits<GlobPtrSz<T> >::ptr_type, functor<T> > > \\\n operator op(const GlobPtrSz<T>& src) \\\n    { \\\n return makeExpr(transformPtr(src, functor<T>())); \\\n    } \\\n template <typename T> \\\n    __host__ Expr<UnaryTransformPtrSz<typename PtrTraits<Texture<T> >::ptr_type, functor<T> > > \\\n operator op(const Texture<T>& src) \\\n    { \\\n return makeExpr(transformPtr(src, functor<T>())); \\\n    } \\\n template <class Body> \\\n    __host__ Expr<UnaryTransformPtrSz<typename PtrTraits<Body>::ptr_type, functor<typename Body::value_type> > > \\\n operator op(const Expr<Body>& src) \\\n    { \\\n return makeExpr(transformPtr(src.body, functor<typename Body::value_type>())); \\\n    }\ncv::cudev::makeExpr__host__ Expr< Body > makeExpr(const Body &body)Definition expr.hpp:63\ncv::cudev::transformPtr__host__ UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Op > transformPtr(const SrcPtr &src, const Op &op)Definition transform.hpp:88\n\n◆ CV_CUDEV_GRAY2RGB5x5_INST\n\n#define CV_CUDEV_GRAY2RGB5x5_INST\n(\n \nname, \n\n \ngreen_bits \n\n)\n       typedef cv::cudev::color_cvt_detail::Gray2RGB5x5<green_bits> name ## _func;\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ CV_CUDEV_GRAY2RGB_INST\n\n#define CV_CUDEV_GRAY2RGB_INST\n(\n \nname, \n\n \ndcn \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::Gray2RGB<SrcDepth, dcn> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::Gray2RGB\n\n◆ CV_CUDEV_HLS2RGB_INST\n\n#define CV_CUDEV_HLS2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::HLS2RGB<SrcDepth, scn, dcn, bidx, 180> \\\n    { \\\n    }; \\\n template <typename SrcDepth> struct name ## _FULL ## _func : cv::cudev::color_cvt_detail::HLS2RGB<SrcDepth, scn, dcn, bidx, 255> \\\n    { \\\n    }; \\\n template <> struct name ## _func<float> : cv::cudev::color_cvt_detail::HLS2RGB<float, scn, dcn, bidx, 360> \\\n    { \\\n    }; \\\n template <> struct name ## _FULL ## _func<float> : cv::cudev::color_cvt_detail::HLS2RGB<float, scn, dcn, bidx, 360> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::HLS2RGB\n\n◆ CV_CUDEV_HSV2RGB_INST\n\n#define CV_CUDEV_HSV2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::HSV2RGB<SrcDepth, scn, dcn, bidx, 180> \\\n    { \\\n    }; \\\n template <typename SrcDepth> struct name ## _FULL ## _func : cv::cudev::color_cvt_detail::HSV2RGB<SrcDepth, scn, dcn, bidx, 255> \\\n    { \\\n    }; \\\n template <> struct name ## _func<float> : cv::cudev::color_cvt_detail::HSV2RGB<float, scn, dcn, bidx, 360> \\\n    { \\\n    }; \\\n template <> struct name ## _FULL ## _func<float> : cv::cudev::color_cvt_detail::HSV2RGB<float, scn, dcn, bidx, 360> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::HSV2RGB\n\n◆ CV_CUDEV_IMPLEMENT_SCALAR_BINARY_FUNC\n\n#define CV_CUDEV_IMPLEMENT_SCALAR_BINARY_FUNC\n(\n \nfunc_name, \n\n \nfunc, \n\n \ninput_type, \n\n \nscalar_type, \n\n \noutput_type \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ CV_CUDEV_IMPLEMENT_SCALAR_BINARY_OP\n\n#define CV_CUDEV_IMPLEMENT_SCALAR_BINARY_OP\n(\n \nop, \n\n \ninput_type, \n\n \nscalar_type, \n\n \noutput_type \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ CV_CUDEV_IMPLEMENT_VEC_BINARY_FUNC\n\n#define CV_CUDEV_IMPLEMENT_VEC_BINARY_FUNC\n(\n \nfunc_name, \n\n \nfunc, \n\n \ninput_type, \n\n \noutput_type \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\nValue:    __device__ __forceinline__ output_type ## 1 func_name(const input_type ## 1 & a, const input_type ## 1 & b) \\\n    { \\\n return VecTraits<output_type ## 1>::make(func (a.x, b.x)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 2 func_name(const input_type ## 2 & a, const input_type ## 2 & b) \\\n    { \\\n return VecTraits<output_type ## 2>::make(func (a.x, b.x), func (a.y, b.y)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 3 func_name(const input_type ## 3 & a, const input_type ## 3 & b) \\\n    { \\\n return VecTraits<output_type ## 3>::make(func (a.x, b.x), func (a.y, b.y), func (a.z, b.z)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 4 func_name(const input_type ## 4 & a, const input_type ## 4 & b) \\\n    { \\\n return VecTraits<output_type ## 4>::make(func (a.x, b.x), func (a.y, b.y), func (a.z, b.z), func (a.w, b.w)); \\\n    }\n\n◆ CV_CUDEV_IMPLEMENT_VEC_BINARY_OP\n\n#define CV_CUDEV_IMPLEMENT_VEC_BINARY_OP\n(\n \nop, \n\n \ninput_type, \n\n \noutput_type \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\nValue:    __device__ __forceinline__ output_type ## 1 operator op(const input_type ## 1 & a, const input_type ## 1 & b) \\\n    { \\\n return VecTraits<output_type ## 1>::make(a.x op b.x); \\\n    } \\\n    __device__ __forceinline__ output_type ## 2 operator op(const input_type ## 2 & a, const input_type ## 2 & b) \\\n    { \\\n return VecTraits<output_type ## 2>::make(a.x op b.x, a.y op b.y); \\\n    } \\\n    __device__ __forceinline__ output_type ## 3 operator op(const input_type ## 3 & a, const input_type ## 3 & b) \\\n    { \\\n return VecTraits<output_type ## 3>::make(a.x op b.x, a.y op b.y, a.z op b.z); \\\n    } \\\n    __device__ __forceinline__ output_type ## 4 operator op(const input_type ## 4 & a, const input_type ## 4 & b) \\\n    { \\\n return VecTraits<output_type ## 4>::make(a.x op b.x, a.y op b.y, a.z op b.z, a.w op b.w); \\\n    }\n\n◆ CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC\n\n#define CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC\n(\n \nfunc_name, \n\n \nfunc, \n\n \ninput_type, \n\n \noutput_type \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\nValue:    __device__ __forceinline__ output_type ## 1 func_name(const input_type ## 1 & a) \\\n    { \\\n return VecTraits<output_type ## 1>::make(func (a.x)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 2 func_name(const input_type ## 2 & a) \\\n    { \\\n return VecTraits<output_type ## 2>::make(func (a.x), func (a.y)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 3 func_name(const input_type ## 3 & a) \\\n    { \\\n return VecTraits<output_type ## 3>::make(func (a.x), func (a.y), func (a.z)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 4 func_name(const input_type ## 4 & a) \\\n    { \\\n return VecTraits<output_type ## 4>::make(func (a.x), func (a.y), func (a.z), func (a.w)); \\\n    }\n\n◆ CV_CUDEV_IMPLEMENT_VEC_UNARY_OP\n\n#define CV_CUDEV_IMPLEMENT_VEC_UNARY_OP\n(\n \nop, \n\n \ninput_type, \n\n \noutput_type \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\nValue:    __device__ __forceinline__ output_type ## 1 operator op(const input_type ## 1 & a) \\\n    { \\\n return VecTraits<output_type ## 1>::make(op (a.x)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 2 operator op(const input_type ## 2 & a) \\\n    { \\\n return VecTraits<output_type ## 2>::make(op (a.x), op (a.y)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 3 operator op(const input_type ## 3 & a) \\\n    { \\\n return VecTraits<output_type ## 3>::make(op (a.x), op (a.y), op (a.z)); \\\n    } \\\n    __device__ __forceinline__ output_type ## 4 operator op(const input_type ## 4 & a) \\\n    { \\\n return VecTraits<output_type ## 4>::make(op (a.x), op (a.y), op (a.z), op (a.w)); \\\n    }\n\n◆ CV_CUDEV_Lab2RGB_INST\n\n#define CV_CUDEV_Lab2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nsRGB, \n\n \nblueIdx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::Lab2RGB<SrcDepth, scn, dcn, sRGB, blueIdx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::Lab2RGB\n\n◆ CV_CUDEV_Luv2RGB_INST\n\n#define CV_CUDEV_Luv2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nsRGB, \n\n \nblueIdx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::Luv2RGB<SrcDepth, scn, dcn, sRGB, blueIdx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::Luv2RGB\n\n◆ CV_CUDEV_MAKE_VEC_INST\n\n#define CV_CUDEV_MAKE_VEC_INST\n(\n \nelem_type)\n\n#include <opencv2/cudev/util/vec_traits.hpp>\nValue: template<> struct MakeVec<elem_type, 1> { typedef elem_type      type; }; \\\n template<> struct MakeVec<elem_type, 2> { typedef elem_type ## 2 type; }; \\\n template<> struct MakeVec<elem_type, 3> { typedef elem_type ## 3 type; }; \\\n template<> struct MakeVec<elem_type, 4> { typedef elem_type ## 4 type; };\n\n◆ CV_CUDEV_MINMAX_INST\n\n#define CV_CUDEV_MINMAX_INST\n(\n \ntype, \n\n \nmaxop, \n\n \nminop \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\nValue: template <> struct maximum<type> : binary_function<type, type, type> \\\n    { \\\n        __device__ __forceinline__ type operator ()(type a, type b) const {return maxop(a, b);} \\\n    }; \\\n template <> struct minimum<type> : binary_function<type, type, type> \\\n    { \\\n        __device__ __forceinline__ type operator ()(type a, type b) const {return minop(a, b);} \\\n    };\n\n◆ CV_CUDEV_RGB2GRAY_INST\n\n#define CV_CUDEV_RGB2GRAY_INST\n(\n \nname, \n\n \nscn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2Gray<SrcDepth, scn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2Gray\n\n◆ CV_CUDEV_RGB2HLS_INST\n\n#define CV_CUDEV_RGB2HLS_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2HLS<SrcDepth, scn, dcn, bidx, 180> \\\n    { \\\n    }; \\\n template <typename SrcDepth> struct name ## _FULL ## _func : cv::cudev::color_cvt_detail::RGB2HLS<SrcDepth, scn, dcn, bidx, 256> \\\n    { \\\n    }; \\\n template <> struct name ## _func<float> : cv::cudev::color_cvt_detail::RGB2HLS<float, scn, dcn, bidx, 360> \\\n    { \\\n    }; \\\n template <> struct name ## _FULL ## _func<float> : cv::cudev::color_cvt_detail::RGB2HLS<float, scn, dcn, bidx, 360> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2HLS\n\n◆ CV_CUDEV_RGB2HSV_INST\n\n#define CV_CUDEV_RGB2HSV_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2HSV<SrcDepth, scn, dcn, bidx, 180> \\\n    { \\\n    }; \\\n template <typename SrcDepth> struct name ## _FULL ## _func : cv::cudev::color_cvt_detail::RGB2HSV<SrcDepth, scn, dcn, bidx, 256> \\\n    { \\\n    }; \\\n template <> struct name ## _func<float> : cv::cudev::color_cvt_detail::RGB2HSV<float, scn, dcn, bidx, 360> \\\n    { \\\n    }; \\\n template <> struct name ## _FULL ## _func<float> : cv::cudev::color_cvt_detail::RGB2HSV<float, scn, dcn, bidx, 360> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2HSV\n\n◆ CV_CUDEV_RGB2Lab_INST\n\n#define CV_CUDEV_RGB2Lab_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nsRGB, \n\n \nblueIdx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2Lab<SrcDepth, scn, dcn, sRGB, blueIdx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2Lab\n\n◆ CV_CUDEV_RGB2Luv_INST\n\n#define CV_CUDEV_RGB2Luv_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nsRGB, \n\n \nblueIdx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2Luv<SrcDepth, scn, dcn, sRGB, blueIdx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2Luv\n\n◆ CV_CUDEV_RGB2RGB5x5_INST\n\n#define CV_CUDEV_RGB2RGB5x5_INST\n(\n \nname, \n\n \nscn, \n\n \nbidx, \n\n \ngreen_bits \n\n)\n       typedef cv::cudev::color_cvt_detail::RGB2RGB5x5<scn, bidx, green_bits> name ## _func;\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ CV_CUDEV_RGB2RGB_INST\n\n#define CV_CUDEV_RGB2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2RGB<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2RGB\n\n◆ CV_CUDEV_RGB2XYZ_INST\n\n#define CV_CUDEV_RGB2XYZ_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2XYZ<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2XYZ\n\n◆ CV_CUDEV_RGB2YCrCb_INST\n\n#define CV_CUDEV_RGB2YCrCb_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2YCrCb<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2YCrCb\n\n◆ CV_CUDEV_RGB2YUV_INST\n\n#define CV_CUDEV_RGB2YUV_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::RGB2YUV<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::RGB2YUV\n\n◆ CV_CUDEV_RGB5x52GRAY_INST\n\n#define CV_CUDEV_RGB5x52GRAY_INST\n(\n \nname, \n\n \ngreen_bits \n\n)\n       typedef cv::cudev::color_cvt_detail::RGB5x52Gray<green_bits> name ## _func;\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ CV_CUDEV_RGB5x52RGB_INST\n\n#define CV_CUDEV_RGB5x52RGB_INST\n(\n \nname, \n\n \ndcn, \n\n \nbidx, \n\n \ngreen_bits \n\n)\n       typedef cv::cudev::color_cvt_detail::RGB5x52RGB<dcn, bidx, green_bits> name ## _func;\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ CV_CUDEV_SAFE_CALL\n\n#define CV_CUDEV_SAFE_CALL\n(\n \nexpr)\n   cv::cudev::checkCudaError((expr), __FILE__, __LINE__, CV_Func)\n\n#include <opencv2/cudev/common.hpp>\n\n◆ CV_CUDEV_UNARY_FUNCTION_INST\n\n#define CV_CUDEV_UNARY_FUNCTION_INST\n(\n \nname, \n\n \nfunc \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ CV_CUDEV_VEC_TRAITS_INST\n\n#define CV_CUDEV_VEC_TRAITS_INST\n(\n \ntype)\n\n#include <opencv2/cudev/util/vec_traits.hpp>\n\n◆ CV_CUDEV_XYZ2RGB_INST\n\n#define CV_CUDEV_XYZ2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::XYZ2RGB<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::XYZ2RGB\n\n◆ CV_CUDEV_YCrCb2RGB_INST\n\n#define CV_CUDEV_YCrCb2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::YCrCb2RGB<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::YCrCb2RGB\n\n◆ CV_CUDEV_YUV2RGB_INST\n\n#define CV_CUDEV_YUV2RGB_INST\n(\n \nname, \n\n \nscn, \n\n \ndcn, \n\n \nbidx \n\n)\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\nValue: template <typename SrcDepth> struct name ## _func : cv::cudev::color_cvt_detail::YUV2RGB<SrcDepth, scn, dcn, bidx> \\\n    { \\\n    };\ncv::cudev::color_cvt_detail::YUV2RGB\n\n◆ CV_LOG2_F\n\n#define CV_LOG2_F   ((float)CV_LOG2)\n\n#include <opencv2/cudev/common.hpp>\n\n◆ CV_PI_F\n\n#define CV_PI_F   ((float)CV_PI)\n\n#include <opencv2/cudev/common.hpp>\n\n◆ OPENCV_CUDEV_FUNCTIONAL_MAKE_IN_RANGE_COMPARATOR\n\n#define OPENCV_CUDEV_FUNCTIONAL_MAKE_IN_RANGE_COMPARATOR\n(\n \ni, \n\n \nfield \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\nValue: template <typename T, int cn>                                           \\\n struct InRangeComparator<T, cn, i> {                                    \\\n        __device__ bool operator()(                                         \\\n const typename MakeVec<T, cn>::type& lowerb,                \\\n const typename MakeVec<T, cn>::type& upperb,                \\\n const typename MakeVec<T, cn>::type& v) const {             \\\n const bool in_range =                                           \\\n                    lowerb.field <= v.field && v.field <= upperb.field;     \\\n return in_range                                                 \\\n                   && InRangeComparator<T, cn, i - 1>{}(lowerb, upperb, v); \\\n        }                                                                   \\\n    };\n\n◆ OPENCV_CUDEV_FUNCTIONAL_MAKE_IN_RANGE_COPIER\n\n#define OPENCV_CUDEV_FUNCTIONAL_MAKE_IN_RANGE_COPIER\n(\n \ni, \n\n \nfield \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\nValue: template <typename T, int cn>                                        \\\n struct InRangeCopier<T, cn, i> {                                     \\\n void operator()(const Scalar& in,                                \\\n typename MakeVec<T, cn>::type& out) const {      \\\n const double in_rounded = (std::is_same<T, double>::value    \\\n                                       || std::is_same<T, float>::value) \\\n                                              ? in[i - 1]                \\\n                                              : std::round(in[i - 1]);   \\\n            out.field = static_cast<T>(in_rounded);                      \\\n            InRangeCopier<T, cn, i - 1>{}(in, out);                      \\\n        }                                                                \\\n    };\nstdSTL namespace.\n\nTypedef Documentation\n\n◆ BGR555_to_BGR_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3 , 0 , 5 > cv::cudev::BGR555_to_BGR_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR555_to_BGRA_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4 , 0 , 5 > cv::cudev::BGR555_to_BGRA_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR555_to_GRAY_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52Gray< 5 > cv::cudev::BGR555_to_GRAY_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR555_to_RGB_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3 , 2 , 5 > cv::cudev::BGR555_to_RGB_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR555_to_RGBA_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4 , 2 , 5 > cv::cudev::BGR555_to_RGBA_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR565_to_BGR_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3 , 0 , 6 > cv::cudev::BGR565_to_BGR_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR565_to_BGRA_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4 , 0 , 6 > cv::cudev::BGR565_to_BGRA_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR565_to_GRAY_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52Gray< 6 > cv::cudev::BGR565_to_GRAY_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR565_to_RGB_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 3 , 2 , 6 > cv::cudev::BGR565_to_RGB_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR565_to_RGBA_func\n\ntypedef cv::cudev::color_cvt_detail::RGB5x52RGB< 4 , 2 , 6 > cv::cudev::BGR565_to_RGBA_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR_to_BGR555_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3 , 0 , 5 > cv::cudev::BGR_to_BGR555_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGR_to_BGR565_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3 , 0 , 6 > cv::cudev::BGR_to_BGR565_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGRA_to_BGR555_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4 , 0 , 5 > cv::cudev::BGRA_to_BGR555_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ BGRA_to_BGR565_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4 , 0 , 6 > cv::cudev::BGRA_to_BGR565_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ elem_type [1/2]\n\ntemplate<class T , class R  = T> \n\ntypedef R cv::cudev::TexturePtr< T, R >::elem_type\n\n◆ elem_type [2/2]\n\ntemplate<class T , class R  = T> \n\ntypedef R cv::cudev::TextureOffPtr< T, R >::elem_type\n\n◆ GRAY_to_BGR555_func\n\ntypedef cv::cudev::color_cvt_detail::Gray2RGB5x5< 5 > cv::cudev::GRAY_to_BGR555_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ GRAY_to_BGR565_func\n\ntypedef cv::cudev::color_cvt_detail::Gray2RGB5x5< 6 > cv::cudev::GRAY_to_BGR565_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ index_type [1/3]\n\ntemplate<class T , class R  = T> \n\ntypedef float cv::cudev::TexturePtr< T, R >::index_type\n\n◆ index_type [2/3]\n\ntemplate<class R > \n\ntypedef float cv::cudev::TexturePtr< uint64, R >::index_type\n\n◆ index_type [3/3]\n\ntemplate<class T , class R  = T> \n\ntypedef float cv::cudev::TextureOffPtr< T, R >::index_type\n\n◆ RGB_to_BGR555_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3 , 2 , 5 > cv::cudev::RGB_to_BGR555_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ RGB_to_BGR565_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 3 , 2 , 6 > cv::cudev::RGB_to_BGR565_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ RGBA_to_BGR555_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4 , 2 , 5 > cv::cudev::RGBA_to_BGR555_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ RGBA_to_BGR565_func\n\ntypedef cv::cudev::color_cvt_detail::RGB2RGB5x5< 4 , 2 , 6 > cv::cudev::RGBA_to_BGR565_func\n\n#include <opencv2/cudev/functional/color_cvt.hpp>\n\n◆ value_type\n\ntemplate<class T , class R  = T> \n\ntypedef R cv::cudev::TexturePtr< T, R >::value_type\n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/cudev/warp/warp.hpp>\n\nEnumeratorLOG_WARP_SIZE \nWARP_SIZE \n\nFunction Documentation\n\n◆ Texture() [1/6]\n\ntemplate<class T , class R  = T> \n\ncv::cudev::Texture< T, R >::Texture \n(\n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ Texture() [2/6]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::Texture< T, R >::Texture \n(\nconst int \nrows_, \n\nconst int \ncols_, \n\nT * \ndata, \n\nconst size_t \nstep, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ Texture() [3/6]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::Texture< T, R >::Texture \n(\nconst size_t \nsizeInBytes, \n\nT * \ndata, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ Texture() [4/6]\n\ntemplate<class T , class R  = T> \n\ncv::cudev::Texture< T, R >::Texture \n(\nconst Texture< T, R > & \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ Texture() [5/6]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::Texture< T, R >::Texture \n(\nPtrStepSz< T > \nsrc, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ Texture() [6/6]\n\ntemplate<class T , class R  = T> \n\ncv::cudev::Texture< T, R >::Texture \n(\nTexture< T, R > && \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TextureOff() [1/4]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::TextureOff< T, R >::TextureOff \n(\nconst int \nrows, \n\nconst int \ncols, \n\nT * \ndata, \n\nconst size_t \nstep, \n\nconst int \nyoff_ = 0, \n\nconst int \nxoff_ = 0, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TextureOff() [2/4]\n\ntemplate<class T , class R  = T> \n\ncv::cudev::TextureOff< T, R >::TextureOff \n(\nconst TextureOff< T, R > & \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TextureOff() [3/4]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::TextureOff< T, R >::TextureOff \n(\nPtrStepSz< T > \nsrc, \n\nconst int \nyoff_ = 0, \n\nconst int \nxoff_ = 0, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TextureOff() [4/4]\n\ntemplate<class T , class R  = T> \n\ncv::cudev::TextureOff< T, R >::TextureOff \n(\nTextureOff< T, R > && \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TextureOffPtr()\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::TextureOffPtr< T, R >::TextureOffPtr \n(\nconst cudaTextureObject_t \ntex_, \n\nconst int \nyoff_, \n\nconst int \nxoff_ \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TexturePtr() [1/4]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::TexturePtr< T, R >::TexturePtr \n(\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TexturePtr() [2/4]\n\ntemplate<class R > \n\n__host__ cv::cudev::TexturePtr< uint64, R >::TexturePtr \n(\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TexturePtr() [3/4]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::TexturePtr< T, R >::TexturePtr \n(\nconst cudaTextureObject_t \ntex_)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ TexturePtr() [4/4]\n\ntemplate<class R > \n\n__host__ cv::cudev::TexturePtr< uint64, R >::TexturePtr \n(\nconst cudaTextureObject_t \ntex_)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ UniqueTexture() [1/5]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture \n(\n)\n\ninlinenoexcept \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ UniqueTexture() [2/5]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture \n(\nconst int \nrows, \n\nconst int \ncols, \n\nT * \ndata, \n\nconst size_t \nstep, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ UniqueTexture() [3/5]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture \n(\nconst size_t \nsizeInBytes, \n\nT * \ndata, \n\nconst bool \nnormalizedCoords = false, \n\nconst cudaTextureFilterMode \nfilterMode = cudaFilterModePoint, \n\nconst cudaTextureAddressMode \naddressMode = cudaAddressModeClamp, \n\nconst cudaTextureReadMode \nreadMode = cudaReadModeElementType \n\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ UniqueTexture() [4/5]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture \n(\nUniqueTexture< T, R > && \nother)\n\ninlinenoexcept \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ UniqueTexture() [5/5]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::UniqueTexture \n(\nUniqueTexture< T, R > & \n)\n\ndelete \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ ~UniqueTexture()\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::~UniqueTexture \n(\n)\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ abs() [1/32]\n\n__device__ __forceinline__ char1 cv::cudev::abs \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [2/32]\n\n__device__ __forceinline__ char2 cv::cudev::abs \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [3/32]\n\n__device__ __forceinline__ char3 cv::cudev::abs \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [4/32]\n\n__device__ __forceinline__ char4 cv::cudev::abs \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::abs \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::abs \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::abs \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::abs \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::abs \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::abs \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::abs \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::abs \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [13/32]\n\n__device__ __forceinline__ int1 cv::cudev::abs \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [14/32]\n\n__device__ __forceinline__ int2 cv::cudev::abs \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [15/32]\n\n__device__ __forceinline__ int3 cv::cudev::abs \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [16/32]\n\n__device__ __forceinline__ int4 cv::cudev::abs \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [17/32]\n\n__device__ __forceinline__ short1 cv::cudev::abs \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [18/32]\n\n__device__ __forceinline__ short2 cv::cudev::abs \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [19/32]\n\n__device__ __forceinline__ short3 cv::cudev::abs \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [20/32]\n\n__device__ __forceinline__ short4 cv::cudev::abs \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [21/32]\n\n__device__ __forceinline__ uchar1 cv::cudev::abs \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [22/32]\n\n__device__ __forceinline__ uchar2 cv::cudev::abs \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [23/32]\n\n__device__ __forceinline__ uchar3 cv::cudev::abs \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [24/32]\n\n__device__ __forceinline__ uchar4 cv::cudev::abs \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [25/32]\n\n__device__ __forceinline__ uint1 cv::cudev::abs \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [26/32]\n\n__device__ __forceinline__ uint2 cv::cudev::abs \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [27/32]\n\n__device__ __forceinline__ uint3 cv::cudev::abs \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [28/32]\n\n__device__ __forceinline__ uint4 cv::cudev::abs \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [29/32]\n\n__device__ __forceinline__ ushort1 cv::cudev::abs \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [30/32]\n\n__device__ __forceinline__ ushort2 cv::cudev::abs \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [31/32]\n\n__device__ __forceinline__ ushort3 cv::cudev::abs \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs() [32/32]\n\n__device__ __forceinline__ ushort4 cv::cudev::abs \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ abs_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, abs_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::abs_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ absdiff_()\n\ntemplate<class SrcPtr1 , class SrcPtr2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, absdiff_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::absdiff_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_func.hpp>\n\n◆ acos() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::acos \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::acos \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::acos \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::acos \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::acos \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::acos \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::acos \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::acos \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acos_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, acos_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::acos_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ acosh() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::acosh \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::acosh \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::acosh \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::acosh \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::acosh \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::acosh \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::acosh \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::acosh \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ acosh_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, acosh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::acosh_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ affineMap()\n\nstatic __host__ AffineMapPtrSz cv::cudev::affineMap \n(\nSize \ndstSize, \n\nconst GpuMat_< float > & \nwarpMat \n\n)\n\nstatic \n\n#include <opencv2/cudev/ptr2d/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ asin() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::asin \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::asin \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::asin \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::asin \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::asin \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::asin \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::asin \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::asin \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asin_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, asin_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::asin_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ asinh() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::asinh \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::asinh \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::asinh \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::asinh \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::asinh \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::asinh \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::asinh \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::asinh \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ asinh_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, asinh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::asinh_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ atan() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::atan \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::atan \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::atan \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::atan \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::atan \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::atan \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::atan \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::atan \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [1/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [2/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [3/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [4/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [5/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [6/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [7/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [8/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [9/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [10/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [11/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [12/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [13/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [14/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [15/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [16/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [17/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [18/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [19/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [20/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [21/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [22/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [23/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [24/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [25/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [26/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [27/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [28/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [29/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [30/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [31/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [32/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [33/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [34/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [35/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [36/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [37/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [38/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [39/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [40/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [41/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [42/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [43/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [44/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [45/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [46/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [47/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [48/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [49/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [50/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [51/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [52/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [53/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [54/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [55/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [56/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [57/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [58/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [59/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [60/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [61/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [62/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [63/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [64/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [65/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [66/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [67/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [68/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [69/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [70/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [71/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [72/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [73/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [74/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [75/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [76/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [77/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [78/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [79/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [80/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [81/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [82/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [83/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [84/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [85/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [86/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [87/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [88/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [89/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [90/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [91/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [92/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [93/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [94/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [95/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [96/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [97/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [98/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [99/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [100/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [101/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [102/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [103/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [104/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [105/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [106/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [107/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [108/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [109/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [110/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [111/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [112/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [113/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [114/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [115/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [116/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [117/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [118/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [119/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [120/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [121/152]\n\n__device__ __forceinline__ double1 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [122/152]\n\n__device__ __forceinline__ double2 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [123/152]\n\n__device__ __forceinline__ double3 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [124/152]\n\n__device__ __forceinline__ double4 cv::cudev::atan2 \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [125/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [126/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [127/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [128/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [129/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [130/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [131/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [132/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [133/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [134/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [135/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [136/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [137/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [138/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [139/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [140/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [141/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [142/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [143/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [144/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [145/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [146/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [147/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [148/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [149/152]\n\n__device__ __forceinline__ float1 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [150/152]\n\n__device__ __forceinline__ float2 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [151/152]\n\n__device__ __forceinline__ float3 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2() [152/152]\n\n__device__ __forceinline__ float4 cv::cudev::atan2 \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atan2_()\n\ntemplate<class SrcPtr1 , class SrcPtr2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, atan2_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::atan2_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_func.hpp>\n\n◆ atan_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, atan_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::atan_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ atanh() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::atanh \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::atanh \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::atanh \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::atanh \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::atanh \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::atanh \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::atanh \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::atanh \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ atanh_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, atanh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::atanh_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ atomicAdd() [1/4]\n\nstatic __device__ double cv::cudev::atomicAdd \n(\ndouble * \naddress, \n\ndouble \nval \n\n)\n\nstatic \n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicAdd() [2/4]\n\n__device__ __forceinline__ float cv::cudev::atomicAdd \n(\nfloat * \naddress, \n\nfloat \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicAdd() [3/4]\n\n__device__ __forceinline__ int cv::cudev::atomicAdd \n(\nint * \naddress, \n\nint \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicAdd() [4/4]\n\n__device__ __forceinline__ uint cv::cudev::atomicAdd \n(\nuint * \naddress, \n\nuint \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMax() [1/4]\n\nstatic __device__ double cv::cudev::atomicMax \n(\ndouble * \naddress, \n\ndouble \nval \n\n)\n\nstatic \n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMax() [2/4]\n\nstatic __device__ float cv::cudev::atomicMax \n(\nfloat * \naddress, \n\nfloat \nval \n\n)\n\nstatic \n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMax() [3/4]\n\n__device__ __forceinline__ int cv::cudev::atomicMax \n(\nint * \naddress, \n\nint \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMax() [4/4]\n\n__device__ __forceinline__ uint cv::cudev::atomicMax \n(\nuint * \naddress, \n\nuint \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMin() [1/4]\n\nstatic __device__ double cv::cudev::atomicMin \n(\ndouble * \naddress, \n\ndouble \nval \n\n)\n\nstatic \n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMin() [2/4]\n\nstatic __device__ float cv::cudev::atomicMin \n(\nfloat * \naddress, \n\nfloat \nval \n\n)\n\nstatic \n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMin() [3/4]\n\n__device__ __forceinline__ int cv::cudev::atomicMin \n(\nint * \naddress, \n\nint \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ atomicMin() [4/4]\n\n__device__ __forceinline__ uint cv::cudev::atomicMin \n(\nuint * \naddress, \n\nuint \nval \n\n)\n\n#include <opencv2/cudev/util/atomic.hpp>\n\n◆ BGR_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_GRAY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_GRAY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HLS4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HLS4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HLS_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HLS_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HLS_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HSV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HSV4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HSV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_HSV_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_HSV_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_XYZ4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_XYZ4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_XYZ_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_XYZ_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_YCrCb4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YCrCb4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_YCrCb_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YCrCb_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_YUV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YUV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGR_to_YUV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGR_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGR_to_YUV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_GRAY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_GRAY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HLS4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HLS4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HLS_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HLS_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HLS_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HSV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HSV4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HSV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_HSV_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_HSV_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_XYZ4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_XYZ4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_XYZ_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_XYZ_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_YCrCb4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YCrCb4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_YCrCb_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YCrCb_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_YUV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YUV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ BGRA_to_YUV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, BGRA_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::BGRA_to_YUV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ binaryTupleAdapter()\n\ntemplate<int n0, int n1, class Op > \n\n__host__ __device__ BinaryTupleAdapter< Op, n0, n1 > cv::cudev::binaryTupleAdapter \n(\nconst Op & \nop)\n\n#include <opencv2/cudev/functional/tuple_adapter.hpp>\n\n◆ bind1st()\n\ntemplate<class Op > \n\n__host__ __device__ Binder1st< Op > cv::cudev::bind1st \n(\nconst Op & \nop, \n\nconst typename Op::first_argument_type & \narg1 \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ bind2nd()\n\ntemplate<class Op > \n\n__host__ __device__ Binder2nd< Op > cv::cudev::bind2nd \n(\nconst Op & \nop, \n\nconst typename Op::second_argument_type & \narg2 \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ blockCopy()\n\ntemplate<class InIt , class OutIt > \n\n__device__ static __forceinline__ void cv::cudev::blockCopy \n(\nInIt \nbeg, \n\nInIt \nend, \n\nOutIt \nout \n\n)\n\nstatic \n\n#include <opencv2/cudev/block/block.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockFill()\n\ntemplate<class It , typename T > \n\n__device__ static __forceinline__ void cv::cudev::blockFill \n(\nIt \nbeg, \n\nIt \nend, \n\nconst T & \nvalue \n\n)\n\nstatic \n\n#include <opencv2/cudev/block/block.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockReduce() [1/2]\n\ntemplate<int N, typename P0 , typename P1 , typename P2 , typename P3 , typename P4 , typename P5 , typename P6 , typename P7 , typename P8 , typename P9 , typename R0 , typename R1 , typename R2 , typename R3 , typename R4 , typename R5 , typename R6 , typename R7 , typename R8 , typename R9 , class Op0 , class Op1 , class Op2 , class Op3 , class Op4 , class Op5 , class Op6 , class Op7 , class Op8 , class Op9 > \n\n__device__ __forceinline__ void cv::cudev::blockReduce \n(\nconst tuple< P0, P1, P2, P3, P4, P5, P6, P7, P8, P9 > & \nsmem, \n\nconst tuple< R0, R1, R2, R3, R4, R5, R6, R7, R8, R9 > & \nval, \n\nuint \ntid, \n\nconst tuple< Op0, Op1, Op2, Op3, Op4, Op5, Op6, Op7, Op8, Op9 > & \nop \n\n)\n\n#include <opencv2/cudev/block/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockReduce() [2/2]\n\ntemplate<int N, typename T , class Op > \n\n__device__ __forceinline__ void cv::cudev::blockReduce \n(\nvolatile T * \nsmem, \n\nT & \nval, \n\nuint \ntid, \n\nconst Op & \nop \n\n)\n\n#include <opencv2/cudev/block/reduce.hpp>\n\n◆ blockReduceKeyVal() [1/3]\n\ntemplate<int N, typename KP0 , typename KP1 , typename KP2 , typename KP3 , typename KP4 , typename KP5 , typename KP6 , typename KP7 , typename KP8 , typename KP9 , typename KR0 , typename KR1 , typename KR2 , typename KR3 , typename KR4 , typename KR5 , typename KR6 , typename KR7 , typename KR8 , typename KR9 , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp0 , class Cmp1 , class Cmp2 , class Cmp3 , class Cmp4 , class Cmp5 , class Cmp6 , class Cmp7 , class Cmp8 , class Cmp9 > \n\n__device__ __forceinline__ void cv::cudev::blockReduceKeyVal \n(\nconst tuple< KP0, KP1, KP2, KP3, KP4, KP5, KP6, KP7, KP8, KP9 > & \nskeys, \n\nconst tuple< KR0, KR1, KR2, KR3, KR4, KR5, KR6, KR7, KR8, KR9 > & \nkey, \n\nconst tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > & \nsvals, \n\nconst tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > & \nval, \n\nuint \ntid, \n\nconst tuple< Cmp0, Cmp1, Cmp2, Cmp3, Cmp4, Cmp5, Cmp6, Cmp7, Cmp8, Cmp9 > & \ncmp \n\n)\n\n#include <opencv2/cudev/block/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockReduceKeyVal() [2/3]\n\ntemplate<int N, typename K , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp > \n\n__device__ __forceinline__ void cv::cudev::blockReduceKeyVal \n(\nvolatile K * \nskeys, \n\nK & \nkey, \n\nconst tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > & \nsvals, \n\nconst tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > & \nval, \n\nuint \ntid, \n\nconst Cmp & \ncmp \n\n)\n\n#include <opencv2/cudev/block/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockReduceKeyVal() [3/3]\n\ntemplate<int N, typename K , typename V , class Cmp > \n\n__device__ __forceinline__ void cv::cudev::blockReduceKeyVal \n(\nvolatile K * \nskeys, \n\nK & \nkey, \n\nvolatile V * \nsvals, \n\nV & \nval, \n\nuint \ntid, \n\nconst Cmp & \ncmp \n\n)\n\n#include <opencv2/cudev/block/reduce.hpp>\n\n◆ blockScanExclusive()\n\ntemplate<int THREADS_NUM, typename T > \n\n__device__ __forceinline__ T cv::cudev::blockScanExclusive \n(\nT \ndata, \n\nvolatile T * \nsmem, \n\nuint \ntid \n\n)\n\n#include <opencv2/cudev/block/scan.hpp>\n\n◆ blockScanInclusive()\n\ntemplate<int THREADS_NUM, typename T > \n\n__device__ T cv::cudev::blockScanInclusive \n(\nT \ndata, \n\nvolatile T * \nsmem, \n\nuint \ntid \n\n)\n\n#include <opencv2/cudev/block/scan.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockTransform() [1/2]\n\ntemplate<class InIt , class OutIt , class UnOp > \n\n__device__ static __forceinline__ void cv::cudev::blockTransform \n(\nInIt \nbeg, \n\nInIt \nend, \n\nOutIt \nout, \n\nconst UnOp & \nop \n\n)\n\nstatic \n\n#include <opencv2/cudev/block/block.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockTransform() [2/2]\n\ntemplate<class InIt1 , class InIt2 , class OutIt , class BinOp > \n\n__device__ static __forceinline__ void cv::cudev::blockTransform \n(\nInIt1 \nbeg1, \n\nInIt1 \nend1, \n\nInIt2 \nbeg2, \n\nOutIt \nout, \n\nconst BinOp & \nop \n\n)\n\nstatic \n\n#include <opencv2/cudev/block/block.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ blockYota()\n\ntemplate<class OutIt , typename T > \n\n__device__ static __forceinline__ void cv::cudev::blockYota \n(\nOutIt \nbeg, \n\nOutIt \nend, \n\nT \nvalue \n\n)\n\nstatic \n\n#include <opencv2/cudev/block/block.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ brdConstant() [1/2]\n\ntemplate<class SrcPtr > \n\n__host__ BrdConstant< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdConstant \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/extrapolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ brdConstant() [2/2]\n\ntemplate<class SrcPtr > \n\n__host__ BrdConstant< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdConstant \n(\nconst SrcPtr & \nsrc, \n\ntypename PtrTraits< SrcPtr >::value_type \nval \n\n)\n\n#include <opencv2/cudev/ptr2d/extrapolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ brdReflect()\n\ntemplate<class SrcPtr > \n\n__host__ BrdBase< BrdReflect, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdReflect \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/extrapolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ brdReflect101()\n\ntemplate<class SrcPtr > \n\n__host__ BrdBase< BrdReflect101, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdReflect101 \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/extrapolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ brdReplicate()\n\ntemplate<class SrcPtr > \n\n__host__ BrdBase< BrdReplicate, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdReplicate \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/extrapolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ brdWrap()\n\ntemplate<class SrcPtr > \n\n__host__ BrdBase< BrdWrap, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::brdWrap \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/extrapolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ cast_fp16()\n\ntemplate<typename T , typename D > \n\n__device__ __forceinline__ D cv::cudev::cast_fp16 \n(\nT \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ cast_fp16< float, short >()\n\ntemplate<> \n\n__device__ __forceinline__ short cv::cudev::cast_fp16< float, short > \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ cast_fp16< short, float >()\n\ntemplate<> \n\n__device__ __forceinline__ float cv::cudev::cast_fp16< short, float > \n(\nshort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ checkCudaError()\n\n__host__ __forceinline__ void cv::cudev::checkCudaError \n(\ncudaError_t \nerr, \n\nconst char * \nfile, \n\nconst int \nline, \n\nconst char * \nfunc \n\n)\n\n#include <opencv2/cudev/common.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ constantPtr() [1/2]\n\ntemplate<typename T > \n\n__host__ ConstantPtr< T > cv::cudev::constantPtr \n(\nT \nvalue)\n\n#include <opencv2/cudev/ptr2d/constant.hpp>\n\n◆ constantPtr() [2/2]\n\ntemplate<typename T > \n\nConstantPtrSz< T > __host__ cv::cudev::constantPtr \n(\nT \nvalue, \n\nint \nrows, \n\nint \ncols \n\n)\n\n#include <opencv2/cudev/ptr2d/constant.hpp>\n\n◆ cos() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::cos \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::cos \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::cos \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::cos \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::cos \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::cos \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::cos \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::cos \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cos_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, cos_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::cos_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ cosh() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::cosh \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::cosh \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::cosh \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::cosh \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::cosh \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::cosh \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::cosh \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::cosh \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ cosh_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, cosh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::cosh_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ countNonZero_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< CountNonZeroExprBody< SrcPtr > > cv::cudev::countNonZero_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ cvt_()\n\ntemplate<typename D , class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, saturate_cast_func< typename PtrTraits< SrcPtr >::value_type, D > > > cv::cudev::cvt_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ derivX_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< DerivXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::derivX_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ derivXPtr()\n\ntemplate<class SrcPtr > \n\n__host__ DerivXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::derivXPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ derivY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< DerivYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::derivY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ derivYPtr()\n\ntemplate<class SrcPtr > \n\n__host__ DerivYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::derivYPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ divUp()\n\n__host__ __device__ __forceinline__ int cv::cudev::divUp \n(\nint \ntotal, \n\nint \ngrain \n\n)\n\n#include <opencv2/cudev/common.hpp>\n\n◆ exp() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::exp \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::exp \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::exp \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::exp \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::exp10 \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::exp10 \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::exp10 \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::exp10 \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp10 \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp10 \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp10 \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp10 \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp10_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, exp10_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::exp10_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ exp2() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::exp2 \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::exp2 \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::exp2 \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::exp2 \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::exp2 \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::exp2 \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::exp2 \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::exp2 \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ exp2_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, exp2_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::exp2_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ exp_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, exp_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::exp_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ get()\n\ntemplate<class T , class R  = T> \n\n__host__ cudaTextureObject_t cv::cudev::UniqueTexture< T, R >::get \n(\n)\n const\n\ninlinenoexcept \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ getCols()\n\ntemplate<class Ptr2DSz > \n\n__host__ int cv::cudev::getCols \n(\nconst Ptr2DSz & \nptr)\n\n#include <opencv2/cudev/ptr2d/traits.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ getRows()\n\ntemplate<class Ptr2DSz > \n\n__host__ int cv::cudev::getRows \n(\nconst Ptr2DSz & \nptr)\n\n#include <opencv2/cudev/ptr2d/traits.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ globPtr() [1/4]\n\ntemplate<typename T > \n\n__host__ GlobPtrSz< T > cv::cudev::globPtr \n(\nconst GpuMat & \nmat)\n\n#include <opencv2/cudev/ptr2d/glob.hpp>\n\n◆ globPtr() [2/4]\n\ntemplate<typename T > \n\n__host__ GlobPtrSz< T > cv::cudev::globPtr \n(\nconst GpuMat_< T > & \nmat)\n\n#include <opencv2/cudev/ptr2d/glob.hpp>\n\n◆ globPtr() [3/4]\n\ntemplate<typename T > \n\n__host__ __device__ GlobPtr< T > cv::cudev::globPtr \n(\nT * \ndata, \n\nsize_t \nstep \n\n)\n\n#include <opencv2/cudev/ptr2d/glob.hpp>\n\n◆ globPtr() [4/4]\n\ntemplate<typename T > \n\n__host__ __device__ GlobPtrSz< T > cv::cudev::globPtr \n(\nT * \ndata, \n\nsize_t \nstep, \n\nint \nrows, \n\nint \ncols \n\n)\n\n#include <opencv2/cudev/ptr2d/glob.hpp>\n\n◆ GRAY_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, GRAY_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::GRAY_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ GRAY_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, GRAY_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::GRAY_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ gridCalcSum() [1/2]\n\ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridCalcSum \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridCalcSum() [2/2]\n\ntemplate<class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridCalcSum \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridCalcSum_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridCalcSum_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCalcSum_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridCalcSum_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy() [1/14]\n\ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [2/14]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [3/14]\n\ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [4/14]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [5/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [6/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [7/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [8/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [9/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [10/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [11/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [12/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [13/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy() [14/14]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy_() [1/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [2/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [3/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [4/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [5/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [6/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [7/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [8/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [9/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [10/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [11/18]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCopy_() [12/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [13/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [14/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [15/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [16/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 , class MaskPtr > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [17/18]\n\ntemplate<class Policy , class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCopy_() [18/18]\n\ntemplate<class SrcPtrTuple , typename D0 , typename D1 , typename D2 , typename D3 > \n\n__host__ void cv::cudev::gridCopy_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/copy.hpp>\n\n◆ gridCountNonZero() [1/2]\n\ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridCountNonZero \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridCountNonZero() [2/2]\n\ntemplate<class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridCountNonZero \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridCountNonZero_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridCountNonZero_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridCountNonZero_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridCountNonZero_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridFindMaxVal() [1/2]\n\ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridFindMaxVal \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridFindMaxVal() [2/2]\n\ntemplate<class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridFindMaxVal \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridFindMaxVal_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridFindMaxVal_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridFindMaxVal_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridFindMaxVal_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridFindMinMaxVal() [1/2]\n\ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridFindMinMaxVal \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridFindMinMaxVal() [2/2]\n\ntemplate<class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridFindMinMaxVal \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridFindMinMaxVal_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridFindMinMaxVal_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridFindMinMaxVal_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridFindMinMaxVal_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridFindMinVal() [1/2]\n\ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridFindMinVal \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridFindMinVal() [2/2]\n\ntemplate<class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridFindMinVal \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridFindMinVal_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridFindMinVal_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridFindMinVal_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridFindMinVal_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridHistogram() [1/2]\n\ntemplate<int BIN_COUNT, class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridHistogram \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/histogram.hpp>\n\n◆ gridHistogram() [2/2]\n\ntemplate<int BIN_COUNT, class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridHistogram \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/histogram.hpp>\n\n◆ gridHistogram_() [1/2]\n\ntemplate<int BIN_COUNT, class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridHistogram_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/histogram.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridHistogram_() [2/2]\n\ntemplate<int BIN_COUNT, class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridHistogram_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/histogram.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridIntegral()\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridIntegral \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/integral.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMerge() [1/7]\n\ntemplate<class SrcPtrTuple , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMerge \n(\nconst SrcPtrTuple & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge() [2/7]\n\ntemplate<class SrcPtrTuple , typename DstType > \n\n__host__ void cv::cudev::gridMerge \n(\nconst SrcPtrTuple & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge() [3/7]\n\ntemplate<class SrcPtrTuple , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMerge \n(\nconst SrcPtrTuple & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge() [4/7]\n\ntemplate<class SrcPtrTuple , typename DstType > \n\n__host__ void cv::cudev::gridMerge \n(\nconst SrcPtrTuple & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge() [5/7]\n\ntemplate<class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMerge \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge() [6/7]\n\ntemplate<class ArrayType , size_t ArraySize, typename DstType > \n\n__host__ void cv::cudev::gridMerge \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge() [7/7]\n\ntemplate<class ArrayType , size_t ArraySize, typename DstType > \n\n__host__ void cv::cudev::gridMerge \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMerge_() [1/4]\n\ntemplate<class Policy , class SrcPtrTuple , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMerge_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMerge_() [2/4]\n\ntemplate<class Policy , class SrcPtrTuple , typename DstType > \n\n__host__ void cv::cudev::gridMerge_ \n(\nconst SrcPtrTuple & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMerge_() [3/4]\n\ntemplate<class Policy , class SrcPtrTuple , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMerge_ \n(\nconst SrcPtrTuple & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMerge_() [4/4]\n\ntemplate<class Policy , class SrcPtrTuple , typename DstType > \n\n__host__ void cv::cudev::gridMerge_ \n(\nconst SrcPtrTuple & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMergeArray()\n\ntemplate<class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMergeArray \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridMergeArray_() [1/4]\n\ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMergeArray_ \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMergeArray_() [2/4]\n\ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType > \n\n__host__ void cv::cudev::gridMergeArray_ \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMergeArray_() [3/4]\n\ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridMergeArray_ \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMergeArray_() [4/4]\n\ntemplate<class Policy , class ArrayType , size_t ArraySize, typename DstType > \n\n__host__ void cv::cudev::gridMergeArray_ \n(\nconst std::array< ArrayType, ArraySize > & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMinMaxLoc() [1/2]\n\ntemplate<class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridMinMaxLoc \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \nvalBuf, \n\nGpuMat_< int > & \nlocBuf, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridMinMaxLoc() [2/2]\n\ntemplate<class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridMinMaxLoc \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \nvalBuf, \n\nGpuMat_< int > & \nlocBuf, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\n◆ gridMinMaxLoc_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridMinMaxLoc_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \nvalBuf, \n\nGpuMat_< int > & \nlocBuf, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridMinMaxLoc_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridMinMaxLoc_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \nvalBuf, \n\nGpuMat_< int > & \nlocBuf, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridPyrDown()\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridPyrDown \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/pyramids.hpp>\n\n◆ gridPyrDown_()\n\ntemplate<class Brd , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridPyrDown_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/pyramids.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridPyrUp()\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridPyrUp \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/pyramids.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridReduceToColumn() [1/2]\n\ntemplate<class Reductor , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridReduceToColumn \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce_to_vec.hpp>\n\n◆ gridReduceToColumn() [2/2]\n\ntemplate<class Reductor , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridReduceToColumn \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce_to_vec.hpp>\n\n◆ gridReduceToColumn_() [1/2]\n\ntemplate<class Reductor , class Policy , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridReduceToColumn_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce_to_vec.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridReduceToColumn_() [2/2]\n\ntemplate<class Reductor , class Policy , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridReduceToColumn_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce_to_vec.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridReduceToRow() [1/2]\n\ntemplate<class Reductor , class SrcPtr , typename ResType , class MaskPtr > \n\n__host__ void cv::cudev::gridReduceToRow \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce_to_vec.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridReduceToRow() [2/2]\n\ntemplate<class Reductor , class SrcPtr , typename ResType > \n\n__host__ void cv::cudev::gridReduceToRow \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< ResType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/reduce_to_vec.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit() [1/10]\n\ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [2/10]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [3/10]\n\ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [4/10]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [5/10]\n\ntemplate<class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [6/10]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [7/10]\n\ntemplate<class SrcPtr , typename DstType , int COUNT, class MaskPtr > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[COUNT], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [8/10]\n\ntemplate<class SrcPtr , typename DstType , int COUNT> \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[COUNT], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [9/10]\n\ntemplate<class SrcPtr , typename DstType , int COUNT, class MaskPtr > \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[COUNT], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit() [10/10]\n\ntemplate<class SrcPtr , typename DstType , int COUNT> \n\n__host__ void cv::cudev::gridSplit \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[COUNT], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\n◆ gridSplit_() [1/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [2/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [3/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [4/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [5/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [6/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > &, GpuMat_< DstType > & > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [7/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[2], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [8/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[2], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [9/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[3], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [10/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[3], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [11/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[4], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [12/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGlobPtrSz< DstType >(&) \ndst[4], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [13/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[2], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [14/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[2], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [15/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[3], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [16/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[3], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [17/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class MaskPtr > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[4], \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridSplit_() [18/18]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridSplit_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType >(&) \ndst[4], \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/split_merge.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary() [1/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst Op & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [2/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst Op & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [3/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType1 > & \ndst1, \n\nconst GlobPtrSz< DstType2 > & \ndst2, \n\nconst Op1 & \nop1, \n\nconst Op2 & \nop2, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [4/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType2 > & \ndst1, \n\nconst GlobPtrSz< DstType2 > & \ndst2, \n\nconst Op1 & \nop1, \n\nconst Op2 & \nop2, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [5/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType > & \ndst, \n\nconst Op & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [6/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType , class Op > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType > & \ndst, \n\nconst Op & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [7/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType1 > & \ndst1, \n\nGpuMat_< DstType2 > & \ndst2, \n\nconst Op1 & \nop1, \n\nconst Op2 & \nop2, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary() [8/8]\n\ntemplate<class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class Op1 , class Op2 > \n\n__host__ void cv::cudev::gridTransformBinary \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType1 > & \ndst1, \n\nGpuMat_< DstType2 > & \ndst2, \n\nconst Op1 & \nop1, \n\nconst Op2 & \nop2, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformBinary_() [1/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst BinOp & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [2/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst BinOp & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [3/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType1 > & \ndst1, \n\nconst GlobPtrSz< DstType2 > & \ndst2, \n\nconst BinOp1 & \nop1, \n\nconst BinOp2 & \nop2, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [4/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nconst GlobPtrSz< DstType1 > & \ndst1, \n\nconst GlobPtrSz< DstType2 > & \ndst2, \n\nconst BinOp1 & \nop1, \n\nconst BinOp2 & \nop2, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [5/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType > & \ndst, \n\nconst BinOp & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [6/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType , class BinOp > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType > & \ndst, \n\nconst BinOp & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [7/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType1 > & \ndst1, \n\nGpuMat_< DstType2 > & \ndst2, \n\nconst BinOp1 & \nop1, \n\nconst BinOp2 & \nop2, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformBinary_() [8/8]\n\ntemplate<class Policy , class SrcPtr1 , class SrcPtr2 , typename DstType1 , typename DstType2 , class BinOp1 , class BinOp2 > \n\n__host__ void cv::cudev::gridTransformBinary_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2, \n\nGpuMat_< DstType1 > & \ndst1, \n\nGpuMat_< DstType2 > & \ndst2, \n\nconst BinOp1 & \nop1, \n\nconst BinOp2 & \nop2, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple() [1/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [2/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [3/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [4/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [5/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [6/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [7/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [8/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [9/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [10/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [11/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple() [12/12]\n\ntemplate<class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformTuple_() [1/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [2/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 > > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [3/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [4/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 > > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [5/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [6/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GlobPtrSz< D0 >, GlobPtrSz< D1 >, GlobPtrSz< D2 >, GlobPtrSz< D3 > > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [7/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [8/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [9/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [10/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [11/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformTuple_() [12/12]\n\ntemplate<class Policy , class SrcPtr , typename D0 , typename D1 , typename D2 , typename D3 , class OpTuple > \n\n__host__ void cv::cudev::gridTransformTuple_ \n(\nconst SrcPtr & \nsrc, \n\nconst tuple< GpuMat_< D0 > &, GpuMat_< D1 > &, GpuMat_< D2 > &, GpuMat_< D3 > & > & \ndst, \n\nconst OpTuple & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformUnary() [1/4]\n\ntemplate<class SrcPtr , typename DstType , class Op , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformUnary \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst Op & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformUnary() [2/4]\n\ntemplate<class SrcPtr , typename DstType , class Op > \n\n__host__ void cv::cudev::gridTransformUnary \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst Op & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformUnary() [3/4]\n\ntemplate<class SrcPtr , typename DstType , class Op , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformUnary \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst Op & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformUnary() [4/4]\n\ntemplate<class SrcPtr , typename DstType , class Op > \n\n__host__ void cv::cudev::gridTransformUnary \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst Op & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\n◆ gridTransformUnary_() [1/4]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformUnary_ \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst UnOp & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformUnary_() [2/4]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp > \n\n__host__ void cv::cudev::gridTransformUnary_ \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nconst UnOp & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformUnary_() [3/4]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp , class MaskPtr > \n\n__host__ void cv::cudev::gridTransformUnary_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst UnOp & \nop, \n\nconst MaskPtr & \nmask, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTransformUnary_() [4/4]\n\ntemplate<class Policy , class SrcPtr , typename DstType , class UnOp > \n\n__host__ void cv::cudev::gridTransformUnary_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nconst UnOp & \nop, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTranspose() [1/2]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridTranspose \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transpose.hpp>\n\n◆ gridTranspose() [2/2]\n\ntemplate<class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridTranspose \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transpose.hpp>\n\n◆ gridTranspose_() [1/2]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridTranspose_ \n(\nconst SrcPtr & \nsrc, \n\nconst GlobPtrSz< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transpose.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ gridTranspose_() [2/2]\n\ntemplate<class Policy , class SrcPtr , typename DstType > \n\n__host__ void cv::cudev::gridTranspose_ \n(\nconst SrcPtr & \nsrc, \n\nGpuMat_< DstType > & \ndst, \n\nStream & \nstream = Stream::Null() \n\n)\n\n#include <opencv2/cudev/grid/transpose.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ histogram_()\n\ntemplate<int BIN_COUNT, class SrcPtr > \n\n__host__ Expr< HistogramBody< BIN_COUNT, SrcPtr > > cv::cudev::histogram_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ HLS4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_BGR_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGR_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_BGRA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_BGRA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_RGB_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGB_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS4_to_RGBA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS4_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS4_to_RGBA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_BGR_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGR_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_BGRA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_BGRA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_RGB_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGB_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HLS_to_RGBA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HLS_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HLS_to_RGBA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_BGR_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGR_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_BGRA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_BGRA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_RGB_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGB_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV4_to_RGBA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV4_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV4_to_RGBA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_BGR_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGR_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGR_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_BGRA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_BGRA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_BGRA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_RGB_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGB_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGB_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ HSV_to_RGBA_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, HSV_to_RGBA_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::HSV_to_RGBA_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ hypot() [1/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [2/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [3/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [4/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [5/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [6/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [7/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [8/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [9/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [10/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [11/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [12/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [13/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [14/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [15/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [16/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [17/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [18/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [19/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [20/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [21/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [22/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [23/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [24/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [25/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [26/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [27/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [28/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [29/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [30/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [31/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [32/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [33/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [34/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [35/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [36/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [37/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [38/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [39/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [40/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [41/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [42/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [43/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [44/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [45/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [46/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [47/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [48/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [49/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [50/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [51/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [52/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [53/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [54/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [55/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [56/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [57/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [58/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [59/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [60/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [61/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [62/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [63/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [64/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [65/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [66/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [67/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [68/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [69/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [70/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [71/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [72/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [73/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [74/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [75/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [76/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [77/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [78/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [79/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [80/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [81/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [82/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [83/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [84/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [85/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [86/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [87/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [88/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [89/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [90/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [91/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [92/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [93/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [94/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [95/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [96/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [97/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [98/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [99/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [100/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [101/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [102/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [103/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [104/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [105/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [106/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [107/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [108/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [109/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [110/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [111/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [112/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [113/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [114/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [115/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [116/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [117/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [118/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [119/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [120/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [121/152]\n\n__device__ __forceinline__ double1 cv::cudev::hypot \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [122/152]\n\n__device__ __forceinline__ double2 cv::cudev::hypot \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [123/152]\n\n__device__ __forceinline__ double3 cv::cudev::hypot \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [124/152]\n\n__device__ __forceinline__ double4 cv::cudev::hypot \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [125/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [126/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [127/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [128/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [129/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [130/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [131/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [132/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [133/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [134/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [135/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [136/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [137/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [138/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [139/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [140/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [141/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [142/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [143/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [144/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [145/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [146/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [147/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [148/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [149/152]\n\n__device__ __forceinline__ float1 cv::cudev::hypot \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [150/152]\n\n__device__ __forceinline__ float2 cv::cudev::hypot \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [151/152]\n\n__device__ __forceinline__ float3 cv::cudev::hypot \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot() [152/152]\n\n__device__ __forceinline__ float4 cv::cudev::hypot \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ hypot_()\n\ntemplate<class SrcPtr1 , class SrcPtr2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, hypot_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::hypot_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_func.hpp>\n\n◆ integral_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< IntegralBody< SrcPtr > > cv::cudev::integral_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ interArea() [1/2]\n\ntemplate<class SrcPtr > \n\n__host__ IntegerAreaInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interArea \n(\nconst SrcPtr & \nsrc, \n\nSize \nareaSize \n\n)\n\n#include <opencv2/cudev/ptr2d/interpolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ interArea() [2/2]\n\ntemplate<class SrcPtr > \n\n__host__ CommonAreaInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interArea \n(\nconst SrcPtr & \nsrc, \n\nSize2f \nareaSize \n\n)\n\n#include <opencv2/cudev/ptr2d/interpolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ interCubic()\n\ntemplate<class SrcPtr > \n\n__host__ CubicInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interCubic \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/interpolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ interLinear()\n\ntemplate<class SrcPtr > \n\n__host__ LinearInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interLinear \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/interpolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ interNearest()\n\ntemplate<class SrcPtr > \n\n__host__ NearestInterPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::interNearest \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/interpolation.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ Lab4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_LBGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LBGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_LBGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LBGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_LRGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LRGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_LRGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_LRGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_LBGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LBGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_LBGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LBGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_LRGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LRGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_LRGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_LRGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Lab_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Lab_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Lab_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ laplacian_()\n\ntemplate<int ksize, class SrcPtr > \n\n__host__ Expr< LaplacianPtrSz< ksize, typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::laplacian_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ laplacianPtr()\n\ntemplate<int ksize, class SrcPtr > \n\n__host__ LaplacianPtrSz< ksize, typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::laplacianPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ LBGR_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGR_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGR_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGR_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGR_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGR_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGRA_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGRA_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGRA_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LBGRA_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LBGRA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LBGRA_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ log() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::log \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::log \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::log \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::log \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::log \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::log \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::log \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::log \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::log10 \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::log10 \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::log10 \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::log10 \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::log10 \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::log10 \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::log10 \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::log10 \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log10_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, log10_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::log10_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ log2() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::log2 \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::log2 \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::log2 \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::log2 \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::log2 \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::log2 \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::log2 \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::log2 \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ log2_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, log2_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::log2_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ log_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, log_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::log_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ LRGB_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGB_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGB_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGB_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGB_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGB_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGBA_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGBA_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGBA_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ LRGBA_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, LRGBA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::LRGBA_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ lut_()\n\ntemplate<class SrcPtr , class TablePtr > \n\n__host__ Expr< LutPtrSz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< TablePtr >::ptr_type > > cv::cudev::lut_ \n(\nconst SrcPtr & \nsrc, \n\nconst TablePtr & \ntbl \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ lutPtr()\n\ntemplate<class SrcPtr , class TablePtr > \n\n__host__ LutPtrSz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< TablePtr >::ptr_type > cv::cudev::lutPtr \n(\nconst SrcPtr & \nsrc, \n\nconst TablePtr & \ntbl \n\n)\n\n#include <opencv2/cudev/ptr2d/lut.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ Luv4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_LBGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LBGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_LBGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LBGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_LRGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LRGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_LRGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_LRGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_LBGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LBGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LBGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_LBGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LBGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LBGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_LRGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LRGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LRGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_LRGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_LRGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_LRGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ Luv_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Luv_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::Luv_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ magnitude_()\n\ntemplate<class SrcPtr1 , class SrcPtr2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, magnitude_func< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::magnitude_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_func.hpp>\n\n◆ makeExpr()\n\ntemplate<class Body > \n\n__host__ Expr< Body > cv::cudev::makeExpr \n(\nconst Body & \nbody)\n\n#include <opencv2/cudev/expr/expr.hpp>\n\n◆ max() [1/200]\n\n__device__ __forceinline__ char1 cv::cudev::max \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [2/200]\n\n__device__ __forceinline__ char2 cv::cudev::max \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [3/200]\n\n__device__ __forceinline__ char3 cv::cudev::max \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [4/200]\n\n__device__ __forceinline__ char4 cv::cudev::max \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [5/200]\n\n__device__ __forceinline__ char1 cv::cudev::max \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [6/200]\n\n__device__ __forceinline__ char1 cv::cudev::max \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [7/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [8/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [9/200]\n\n__device__ __forceinline__ char2 cv::cudev::max \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [10/200]\n\n__device__ __forceinline__ char2 cv::cudev::max \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [11/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [12/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [13/200]\n\n__device__ __forceinline__ char3 cv::cudev::max \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [14/200]\n\n__device__ __forceinline__ char3 cv::cudev::max \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [15/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [16/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [17/200]\n\n__device__ __forceinline__ char4 cv::cudev::max \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [18/200]\n\n__device__ __forceinline__ char4 cv::cudev::max \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [19/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [20/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [21/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [22/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [23/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [24/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [25/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [26/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [27/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [28/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [29/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [30/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [31/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [32/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [33/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [34/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [35/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [36/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [37/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [38/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [39/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [40/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [41/200]\n\n__device__ __forceinline__ int1 cv::cudev::max \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [42/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [43/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [44/200]\n\n__device__ __forceinline__ int1 cv::cudev::max \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [45/200]\n\n__device__ __forceinline__ int2 cv::cudev::max \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [46/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [47/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [48/200]\n\n__device__ __forceinline__ int2 cv::cudev::max \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [49/200]\n\n__device__ __forceinline__ int3 cv::cudev::max \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [50/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [51/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [52/200]\n\n__device__ __forceinline__ int3 cv::cudev::max \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [53/200]\n\n__device__ __forceinline__ int4 cv::cudev::max \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [54/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [55/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [56/200]\n\n__device__ __forceinline__ int4 cv::cudev::max \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [57/200]\n\n__device__ __forceinline__ short1 cv::cudev::max \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [58/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [59/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [60/200]\n\n__device__ __forceinline__ short1 cv::cudev::max \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [61/200]\n\n__device__ __forceinline__ short2 cv::cudev::max \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [62/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [63/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [64/200]\n\n__device__ __forceinline__ short2 cv::cudev::max \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [65/200]\n\n__device__ __forceinline__ short3 cv::cudev::max \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [66/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [67/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [68/200]\n\n__device__ __forceinline__ short3 cv::cudev::max \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [69/200]\n\n__device__ __forceinline__ short4 cv::cudev::max \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [70/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [71/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [72/200]\n\n__device__ __forceinline__ short4 cv::cudev::max \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [73/200]\n\n__device__ __forceinline__ uchar1 cv::cudev::max \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [74/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [75/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [76/200]\n\n__device__ __forceinline__ uchar1 cv::cudev::max \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [77/200]\n\n__device__ __forceinline__ uchar2 cv::cudev::max \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [78/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [79/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [80/200]\n\n__device__ __forceinline__ uchar2 cv::cudev::max \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [81/200]\n\n__device__ __forceinline__ uchar3 cv::cudev::max \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [82/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [83/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [84/200]\n\n__device__ __forceinline__ uchar3 cv::cudev::max \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [85/200]\n\n__device__ __forceinline__ uchar4 cv::cudev::max \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [86/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [87/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [88/200]\n\n__device__ __forceinline__ uchar4 cv::cudev::max \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [89/200]\n\n__device__ __forceinline__ uint1 cv::cudev::max \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [90/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [91/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [92/200]\n\n__device__ __forceinline__ uint1 cv::cudev::max \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [93/200]\n\n__device__ __forceinline__ uint2 cv::cudev::max \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [94/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [95/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [96/200]\n\n__device__ __forceinline__ uint2 cv::cudev::max \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [97/200]\n\n__device__ __forceinline__ uint3 cv::cudev::max \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [98/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [99/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [100/200]\n\n__device__ __forceinline__ uint3 cv::cudev::max \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [101/200]\n\n__device__ __forceinline__ uint4 cv::cudev::max \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [102/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [103/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [104/200]\n\n__device__ __forceinline__ uint4 cv::cudev::max \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [105/200]\n\n__device__ __forceinline__ ushort1 cv::cudev::max \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [106/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [107/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [108/200]\n\n__device__ __forceinline__ ushort1 cv::cudev::max \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [109/200]\n\n__device__ __forceinline__ ushort2 cv::cudev::max \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [110/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [111/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [112/200]\n\n__device__ __forceinline__ ushort2 cv::cudev::max \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [113/200]\n\n__device__ __forceinline__ ushort3 cv::cudev::max \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [114/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [115/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [116/200]\n\n__device__ __forceinline__ ushort3 cv::cudev::max \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [117/200]\n\n__device__ __forceinline__ ushort4 cv::cudev::max \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [118/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [119/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [120/200]\n\n__device__ __forceinline__ ushort4 cv::cudev::max \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [121/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [122/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [123/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [124/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [125/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [126/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [127/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [128/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [129/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [130/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [131/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [132/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [133/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [134/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [135/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [136/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [137/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [138/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [139/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [140/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [141/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [142/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [143/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [144/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [145/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [146/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [147/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [148/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [149/200]\n\n__device__ __forceinline__ double1 cv::cudev::max \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [150/200]\n\n__device__ __forceinline__ double2 cv::cudev::max \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [151/200]\n\n__device__ __forceinline__ double3 cv::cudev::max \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [152/200]\n\n__device__ __forceinline__ double4 cv::cudev::max \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [153/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [154/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [155/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [156/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [157/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [158/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [159/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [160/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [161/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [162/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [163/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [164/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [165/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [166/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [167/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [168/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [169/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [170/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [171/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [172/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [173/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [174/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [175/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [176/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [177/200]\n\n__device__ __forceinline__ float1 cv::cudev::max \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [178/200]\n\n__device__ __forceinline__ float2 cv::cudev::max \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [179/200]\n\n__device__ __forceinline__ float3 cv::cudev::max \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [180/200]\n\n__device__ __forceinline__ float4 cv::cudev::max \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [181/200]\n\n__device__ __forceinline__ int1 cv::cudev::max \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [182/200]\n\n__device__ __forceinline__ int2 cv::cudev::max \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [183/200]\n\n__device__ __forceinline__ int3 cv::cudev::max \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [184/200]\n\n__device__ __forceinline__ int4 cv::cudev::max \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [185/200]\n\n__device__ __forceinline__ short1 cv::cudev::max \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [186/200]\n\n__device__ __forceinline__ short2 cv::cudev::max \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [187/200]\n\n__device__ __forceinline__ short3 cv::cudev::max \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [188/200]\n\n__device__ __forceinline__ short4 cv::cudev::max \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [189/200]\n\n__device__ __forceinline__ uchar1 cv::cudev::max \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [190/200]\n\n__device__ __forceinline__ uchar2 cv::cudev::max \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [191/200]\n\n__device__ __forceinline__ uchar3 cv::cudev::max \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [192/200]\n\n__device__ __forceinline__ uchar4 cv::cudev::max \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [193/200]\n\n__device__ __forceinline__ uint1 cv::cudev::max \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [194/200]\n\n__device__ __forceinline__ uint2 cv::cudev::max \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [195/200]\n\n__device__ __forceinline__ uint3 cv::cudev::max \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [196/200]\n\n__device__ __forceinline__ uint4 cv::cudev::max \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [197/200]\n\n__device__ __forceinline__ ushort1 cv::cudev::max \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [198/200]\n\n__device__ __forceinline__ ushort2 cv::cudev::max \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [199/200]\n\n__device__ __forceinline__ ushort3 cv::cudev::max \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max() [200/200]\n\n__device__ __forceinline__ ushort4 cv::cudev::max \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ max_()\n\ntemplate<class SrcPtr1 , class SrcPtr2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, maximum< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::max_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ maxVal_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< FindMaxValExprBody< SrcPtr > > cv::cudev::maxVal_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ min() [1/200]\n\n__device__ __forceinline__ char1 cv::cudev::min \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [2/200]\n\n__device__ __forceinline__ char2 cv::cudev::min \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [3/200]\n\n__device__ __forceinline__ char3 cv::cudev::min \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [4/200]\n\n__device__ __forceinline__ char4 cv::cudev::min \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [5/200]\n\n__device__ __forceinline__ char1 cv::cudev::min \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [6/200]\n\n__device__ __forceinline__ char1 cv::cudev::min \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [7/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [8/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [9/200]\n\n__device__ __forceinline__ char2 cv::cudev::min \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [10/200]\n\n__device__ __forceinline__ char2 cv::cudev::min \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [11/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [12/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [13/200]\n\n__device__ __forceinline__ char3 cv::cudev::min \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [14/200]\n\n__device__ __forceinline__ char3 cv::cudev::min \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [15/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [16/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [17/200]\n\n__device__ __forceinline__ char4 cv::cudev::min \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [18/200]\n\n__device__ __forceinline__ char4 cv::cudev::min \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [19/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [20/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [21/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [22/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [23/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [24/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [25/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [26/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [27/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [28/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [29/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [30/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [31/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [32/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [33/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [34/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [35/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [36/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [37/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [38/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [39/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [40/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [41/200]\n\n__device__ __forceinline__ int1 cv::cudev::min \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [42/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [43/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [44/200]\n\n__device__ __forceinline__ int1 cv::cudev::min \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [45/200]\n\n__device__ __forceinline__ int2 cv::cudev::min \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [46/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [47/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [48/200]\n\n__device__ __forceinline__ int2 cv::cudev::min \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [49/200]\n\n__device__ __forceinline__ int3 cv::cudev::min \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [50/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [51/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [52/200]\n\n__device__ __forceinline__ int3 cv::cudev::min \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [53/200]\n\n__device__ __forceinline__ int4 cv::cudev::min \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [54/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [55/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [56/200]\n\n__device__ __forceinline__ int4 cv::cudev::min \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [57/200]\n\n__device__ __forceinline__ short1 cv::cudev::min \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [58/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [59/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [60/200]\n\n__device__ __forceinline__ short1 cv::cudev::min \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [61/200]\n\n__device__ __forceinline__ short2 cv::cudev::min \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [62/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [63/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [64/200]\n\n__device__ __forceinline__ short2 cv::cudev::min \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [65/200]\n\n__device__ __forceinline__ short3 cv::cudev::min \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [66/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [67/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [68/200]\n\n__device__ __forceinline__ short3 cv::cudev::min \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [69/200]\n\n__device__ __forceinline__ short4 cv::cudev::min \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [70/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [71/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [72/200]\n\n__device__ __forceinline__ short4 cv::cudev::min \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [73/200]\n\n__device__ __forceinline__ uchar1 cv::cudev::min \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [74/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [75/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [76/200]\n\n__device__ __forceinline__ uchar1 cv::cudev::min \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [77/200]\n\n__device__ __forceinline__ uchar2 cv::cudev::min \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [78/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [79/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [80/200]\n\n__device__ __forceinline__ uchar2 cv::cudev::min \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [81/200]\n\n__device__ __forceinline__ uchar3 cv::cudev::min \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [82/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [83/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [84/200]\n\n__device__ __forceinline__ uchar3 cv::cudev::min \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [85/200]\n\n__device__ __forceinline__ uchar4 cv::cudev::min \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [86/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [87/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [88/200]\n\n__device__ __forceinline__ uchar4 cv::cudev::min \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [89/200]\n\n__device__ __forceinline__ uint1 cv::cudev::min \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [90/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [91/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [92/200]\n\n__device__ __forceinline__ uint1 cv::cudev::min \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [93/200]\n\n__device__ __forceinline__ uint2 cv::cudev::min \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [94/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [95/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [96/200]\n\n__device__ __forceinline__ uint2 cv::cudev::min \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [97/200]\n\n__device__ __forceinline__ uint3 cv::cudev::min \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [98/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [99/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [100/200]\n\n__device__ __forceinline__ uint3 cv::cudev::min \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [101/200]\n\n__device__ __forceinline__ uint4 cv::cudev::min \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [102/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [103/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [104/200]\n\n__device__ __forceinline__ uint4 cv::cudev::min \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [105/200]\n\n__device__ __forceinline__ ushort1 cv::cudev::min \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [106/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [107/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [108/200]\n\n__device__ __forceinline__ ushort1 cv::cudev::min \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [109/200]\n\n__device__ __forceinline__ ushort2 cv::cudev::min \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [110/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [111/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [112/200]\n\n__device__ __forceinline__ ushort2 cv::cudev::min \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [113/200]\n\n__device__ __forceinline__ ushort3 cv::cudev::min \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [114/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [115/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [116/200]\n\n__device__ __forceinline__ ushort3 cv::cudev::min \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [117/200]\n\n__device__ __forceinline__ ushort4 cv::cudev::min \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [118/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [119/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [120/200]\n\n__device__ __forceinline__ ushort4 cv::cudev::min \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [121/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [122/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [123/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [124/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [125/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [126/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [127/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [128/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [129/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [130/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [131/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [132/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [133/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [134/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [135/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [136/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [137/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [138/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [139/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [140/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [141/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [142/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [143/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [144/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [145/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [146/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [147/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [148/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [149/200]\n\n__device__ __forceinline__ double1 cv::cudev::min \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [150/200]\n\n__device__ __forceinline__ double2 cv::cudev::min \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [151/200]\n\n__device__ __forceinline__ double3 cv::cudev::min \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [152/200]\n\n__device__ __forceinline__ double4 cv::cudev::min \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [153/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [154/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [155/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [156/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [157/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [158/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [159/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [160/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [161/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [162/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [163/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [164/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [165/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [166/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [167/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [168/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [169/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [170/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [171/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [172/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [173/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [174/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [175/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [176/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [177/200]\n\n__device__ __forceinline__ float1 cv::cudev::min \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [178/200]\n\n__device__ __forceinline__ float2 cv::cudev::min \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [179/200]\n\n__device__ __forceinline__ float3 cv::cudev::min \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [180/200]\n\n__device__ __forceinline__ float4 cv::cudev::min \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [181/200]\n\n__device__ __forceinline__ int1 cv::cudev::min \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [182/200]\n\n__device__ __forceinline__ int2 cv::cudev::min \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [183/200]\n\n__device__ __forceinline__ int3 cv::cudev::min \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [184/200]\n\n__device__ __forceinline__ int4 cv::cudev::min \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [185/200]\n\n__device__ __forceinline__ short1 cv::cudev::min \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [186/200]\n\n__device__ __forceinline__ short2 cv::cudev::min \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [187/200]\n\n__device__ __forceinline__ short3 cv::cudev::min \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [188/200]\n\n__device__ __forceinline__ short4 cv::cudev::min \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [189/200]\n\n__device__ __forceinline__ uchar1 cv::cudev::min \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [190/200]\n\n__device__ __forceinline__ uchar2 cv::cudev::min \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [191/200]\n\n__device__ __forceinline__ uchar3 cv::cudev::min \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [192/200]\n\n__device__ __forceinline__ uchar4 cv::cudev::min \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [193/200]\n\n__device__ __forceinline__ uint1 cv::cudev::min \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [194/200]\n\n__device__ __forceinline__ uint2 cv::cudev::min \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [195/200]\n\n__device__ __forceinline__ uint3 cv::cudev::min \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [196/200]\n\n__device__ __forceinline__ uint4 cv::cudev::min \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [197/200]\n\n__device__ __forceinline__ ushort1 cv::cudev::min \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [198/200]\n\n__device__ __forceinline__ ushort2 cv::cudev::min \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [199/200]\n\n__device__ __forceinline__ ushort3 cv::cudev::min \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min() [200/200]\n\n__device__ __forceinline__ ushort4 cv::cudev::min \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ min_()\n\ntemplate<class SrcPtr1 , class SrcPtr2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< SrcPtr1 >::ptr_type, typename PtrTraits< SrcPtr2 >::ptr_type, minimum< typename LargerType< typename PtrTraits< SrcPtr1 >::value_type, typename PtrTraits< SrcPtr2 >::value_type >::type > > > cv::cudev::min_ \n(\nconst SrcPtr1 & \nsrc1, \n\nconst SrcPtr2 & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ minMaxVal_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< FindMinMaxValExprBody< SrcPtr > > cv::cudev::minMaxVal_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ minVal_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< FindMinValExprBody< SrcPtr > > cv::cudev::minVal_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ not1()\n\ntemplate<class Predicate > \n\n__host__ __device__ UnaryNegate< Predicate > cv::cudev::not1 \n(\nconst Predicate & \npred)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ not2()\n\ntemplate<class Predicate > \n\n__host__ __device__ BinaryNegate< Predicate > cv::cudev::not2 \n(\nconst Predicate & \npred)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ operator bool() [1/2]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::UniqueTexture< T, R >::operator bool \n(\n)\n const\n\ninlineexplicitnoexcept \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator bool() [2/2]\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::Texture< T, R >::operator bool \n(\n)\n const\n\ninlineexplicitnoexcept \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator TextureOffPtr< T, R >()\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::TextureOff< T, R >::operator TextureOffPtr< T, R > \n(\n)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator TexturePtr< T, R >()\n\ntemplate<class T , class R  = T> \n\n__host__ cv::cudev::Texture< T, R >::operator TexturePtr< T, R > \n(\n)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator!() [1/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [2/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [3/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [4/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [5/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [6/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [7/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [8/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [9/36]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, logical_not< typename Body::value_type > > > cv::cudev::operator! \n(\nconst Expr< Body > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator!() [10/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [11/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [12/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [13/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [14/36]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_not< T > > > cv::cudev::operator! \n(\nconst GlobPtrSz< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator!() [15/36]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, logical_not< T > > > cv::cudev::operator! \n(\nconst GpuMat_< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator!() [16/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [17/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [18/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [19/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [20/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [21/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [22/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [23/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [24/36]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, logical_not< T > > > cv::cudev::operator! \n(\nconst Texture< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator!() [25/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [26/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [27/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [28/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [29/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [30/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [31/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [32/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [33/36]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator! \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [34/36]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator! \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [35/36]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator! \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!() [36/36]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator! \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< not_equal_to< typename Body::value_type > > > > cv::cudev::operator!= \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, not_equal_to< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator!= \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< not_equal_to< T > > > > cv::cudev::operator!= \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< not_equal_to< T > > > > cv::cudev::operator!= \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< not_equal_to< T > > > > cv::cudev::operator!= \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, not_equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator!= \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, not_equal_to< T > > > cv::cudev::operator!= \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< not_equal_to< T > > > > cv::cudev::operator!= \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< not_equal_to< T > > > > cv::cudev::operator!= \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< not_equal_to< T > > > > cv::cudev::operator!= \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< not_equal_to< typename Body::value_type > > > > cv::cudev::operator!= \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator!=() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator!= \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator!= \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator!= \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator!=() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator!= \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator%() [1/24]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< modulus< typename Body::value_type > > > > cv::cudev::operator% \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [2/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [3/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [4/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [5/24]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, modulus< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator% \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [6/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< modulus< T > > > > cv::cudev::operator% \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [7/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [8/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [9/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [10/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [11/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< modulus< T > > > > cv::cudev::operator% \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [12/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [13/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [14/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [15/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [16/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< modulus< T > > > > cv::cudev::operator% \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [17/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, modulus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator% \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [18/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [19/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [20/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, modulus< T > > > cv::cudev::operator% \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [21/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< modulus< T > > > > cv::cudev::operator% \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [22/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< modulus< T > > > > cv::cudev::operator% \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [23/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< modulus< T > > > > cv::cudev::operator% \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator%() [24/24]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< modulus< typename Body::value_type > > > > cv::cudev::operator% \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [1/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator& \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [2/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator& \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [3/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator& \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [4/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator& \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [5/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator& \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [6/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator& \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [7/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator& \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [8/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator& \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [9/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator& \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [10/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator& \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [11/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator& \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [12/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator& \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [13/96]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_and< typename Body::value_type > > > > cv::cudev::operator& \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [14/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [15/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [16/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [17/96]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_and< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator& \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [18/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_and< T > > > > cv::cudev::operator& \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [19/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [20/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [21/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [22/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [23/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_and< T > > > > cv::cudev::operator& \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [24/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [25/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [26/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [27/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [28/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator& \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [29/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator& \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [30/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator& \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [31/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator& \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [32/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator& \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [33/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator& \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [34/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator& \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [35/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator& \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [36/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator& \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [37/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator& \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [38/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator& \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [39/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator& \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [40/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator& \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [41/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator& \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [42/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator& \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [43/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator& \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [44/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_and< T > > > > cv::cudev::operator& \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [45/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator& \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [46/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [47/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [48/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_and< T > > > cv::cudev::operator& \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [49/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator& \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [50/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator& \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [51/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator& \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [52/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator& \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [53/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator& \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [54/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator& \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [55/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator& \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [56/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator& \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [57/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator& \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [58/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator& \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [59/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator& \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [60/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator& \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [61/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator& \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [62/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator& \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [63/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator& \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [64/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator& \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [65/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator& \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [66/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator& \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [67/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator& \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [68/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator& \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [69/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator& \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [70/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator& \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [71/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator& \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [72/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator& \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [73/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator& \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [74/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator& \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [75/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator& \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [76/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator& \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [77/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator& \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [78/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator& \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [79/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator& \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [80/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator& \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [81/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_and< T > > > > cv::cudev::operator& \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [82/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_and< T > > > > cv::cudev::operator& \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [83/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_and< T > > > > cv::cudev::operator& \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [84/96]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_and< typename Body::value_type > > > > cv::cudev::operator& \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&() [85/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator& \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [86/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator& \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [87/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator& \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [88/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator& \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [89/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator& \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [90/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator& \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [91/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator& \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [92/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator& \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [93/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator& \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [94/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator& \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [95/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator& \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&() [96/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator& \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< logical_and< typename Body::value_type > > > > cv::cudev::operator&& \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, logical_and< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator&& \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< logical_and< T > > > > cv::cudev::operator&& \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< logical_and< T > > > > cv::cudev::operator&& \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< logical_and< T > > > > cv::cudev::operator&& \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_and< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator&& \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_and< T > > > cv::cudev::operator&& \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< logical_and< T > > > > cv::cudev::operator&& \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< logical_and< T > > > > cv::cudev::operator&& \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< logical_and< T > > > > cv::cudev::operator&& \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< logical_and< typename Body::value_type > > > > cv::cudev::operator&& \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator&&() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator&& \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator&& \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator&& \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator&&() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator&& \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator()() [1/5]\n\ntemplate<class T , class R  = T> \n\n__device__ __forceinline__ R cv::cudev::TexturePtr< T, R >::operator() \n(\nindex_type \nx)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator()() [2/5]\n\ntemplate<class R > \n\n__device__ __forceinline__ R cv::cudev::TexturePtr< uint64, R >::operator() \n(\nindex_type \nx)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator()() [3/5]\n\ntemplate<class T , class R  = T> \n\n__device__ __forceinline__ R cv::cudev::TexturePtr< T, R >::operator() \n(\nindex_type \ny, \n\nindex_type \nx \n\n)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator()() [4/5]\n\ntemplate<class R > \n\n__device__ __forceinline__ R cv::cudev::TexturePtr< uint64, R >::operator() \n(\nindex_type \ny, \n\nindex_type \nx \n\n)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator()() [5/5]\n\ntemplate<class T , class R  = T> \n\n__device__ __forceinline__ R cv::cudev::TextureOffPtr< T, R >::operator() \n(\nindex_type \ny, \n\nindex_type \nx \n\n)\n const\n\ninline \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator*() [1/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [2/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [3/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [4/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst char1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [5/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [6/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [7/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [8/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst char2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [9/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [10/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [11/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [12/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst char3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [13/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [14/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [15/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [16/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst char4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [17/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [18/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [19/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [20/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [21/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [22/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [23/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [24/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [25/224]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< multiplies< typename Body::value_type > > > > cv::cudev::operator* \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [26/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [27/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [28/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [29/224]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, multiplies< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator* \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [30/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [31/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [32/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [33/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [34/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [35/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [36/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [37/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [38/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [39/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [40/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [41/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [42/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< multiplies< T > > > > cv::cudev::operator* \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [43/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [44/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [45/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [46/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [47/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< multiplies< T > > > > cv::cudev::operator* \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [48/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [49/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [50/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [51/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [52/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [53/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [54/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [55/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [56/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [57/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [58/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [59/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [60/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [61/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [62/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [63/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [64/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [65/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [66/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [67/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [68/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [69/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [70/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [71/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst short1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [72/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [73/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [74/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [75/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst short2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [76/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [77/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [78/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [79/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst short3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [80/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [81/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [82/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [83/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst short4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [84/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< multiplies< T > > > > cv::cudev::operator* \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [85/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, multiplies< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator* \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [86/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [87/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [88/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, multiplies< T > > > cv::cudev::operator* \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [89/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [90/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [91/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [92/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst uchar1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [93/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [94/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [95/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [96/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst uchar2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [97/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [98/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [99/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [100/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst uchar3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [101/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [102/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [103/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [104/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst uchar4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [105/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator* \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [106/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [107/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [108/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator* \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [109/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator* \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [110/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [111/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [112/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator* \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [113/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator* \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [114/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [115/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [116/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator* \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [117/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator* \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [118/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [119/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [120/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator* \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [121/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [122/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [123/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [124/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nconst ushort1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [125/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [126/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [127/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [128/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nconst ushort2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [129/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [130/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [131/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [132/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nconst ushort3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [133/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [134/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [135/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [136/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nconst ushort4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [137/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [138/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [139/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [140/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [141/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [142/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [143/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [144/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [145/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [146/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [147/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [148/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [149/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [150/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [151/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [152/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [153/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [154/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [155/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [156/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [157/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [158/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [159/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [160/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [161/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [162/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [163/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [164/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [165/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator* \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [166/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator* \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [167/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator* \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [168/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator* \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [169/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [170/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [171/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [172/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [173/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [174/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [175/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [176/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [177/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [178/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [179/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [180/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [181/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [182/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [183/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [184/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [185/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [186/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [187/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [188/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [189/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [190/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [191/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [192/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [193/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator* \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [194/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator* \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [195/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator* \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [196/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator* \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [197/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nint \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [198/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nint \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [199/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nint \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [200/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nint \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [201/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [202/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [203/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [204/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [205/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nint \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [206/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nint \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [207/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nint \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [208/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nint \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [209/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nint \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [210/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nint \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [211/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nint \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [212/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nint \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [213/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator* \n(\nint \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [214/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator* \n(\nint \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [215/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator* \n(\nint \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [216/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator* \n(\nint \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [217/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< multiplies< T > > > > cv::cudev::operator* \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [218/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< multiplies< T > > > > cv::cudev::operator* \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [219/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< multiplies< T > > > > cv::cudev::operator* \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [220/224]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< multiplies< typename Body::value_type > > > > cv::cudev::operator* \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator*() [221/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator* \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [222/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator* \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [223/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator* \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator*() [224/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator* \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [1/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [2/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [3/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [4/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst char1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [5/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [6/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [7/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [8/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst char2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [9/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [10/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [11/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [12/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst char3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [13/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [14/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [15/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [16/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst char4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [17/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [18/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [19/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [20/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [21/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [22/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [23/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [24/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [25/224]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< plus< typename Body::value_type > > > > cv::cudev::operator+ \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [26/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [27/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [28/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [29/224]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, plus< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator+ \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [30/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [31/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [32/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [33/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [34/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [35/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [36/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [37/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [38/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [39/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [40/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [41/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [42/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< plus< T > > > > cv::cudev::operator+ \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [43/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [44/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [45/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [46/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [47/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< plus< T > > > > cv::cudev::operator+ \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [48/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [49/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [50/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [51/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [52/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [53/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [54/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [55/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [56/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [57/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [58/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [59/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [60/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [61/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [62/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [63/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [64/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [65/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [66/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [67/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [68/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [69/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [70/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [71/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst short1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [72/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [73/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [74/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [75/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst short2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [76/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [77/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [78/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [79/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst short3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [80/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [81/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [82/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [83/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst short4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [84/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< plus< T > > > > cv::cudev::operator+ \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [85/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, plus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator+ \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [86/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [87/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [88/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, plus< T > > > cv::cudev::operator+ \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [89/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [90/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [91/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [92/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst uchar1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [93/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [94/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [95/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [96/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst uchar2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [97/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [98/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [99/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [100/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst uchar3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [101/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [102/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [103/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [104/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst uchar4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [105/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator+ \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [106/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [107/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [108/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator+ \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [109/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator+ \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [110/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [111/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [112/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator+ \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [113/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator+ \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [114/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [115/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [116/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator+ \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [117/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator+ \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [118/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [119/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [120/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator+ \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [121/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [122/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [123/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [124/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nconst ushort1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [125/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [126/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [127/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [128/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nconst ushort2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [129/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [130/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [131/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [132/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nconst ushort3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [133/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [134/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [135/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [136/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nconst ushort4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [137/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [138/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [139/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [140/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [141/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [142/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [143/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [144/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [145/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [146/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [147/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [148/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [149/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [150/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [151/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [152/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [153/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [154/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [155/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [156/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [157/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [158/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [159/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [160/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [161/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [162/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [163/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [164/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [165/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [166/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [167/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [168/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator+ \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [169/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [170/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [171/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [172/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [173/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [174/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [175/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [176/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [177/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [178/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [179/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [180/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [181/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [182/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [183/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [184/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [185/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [186/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [187/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [188/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [189/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [190/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [191/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [192/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [193/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [194/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [195/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [196/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator+ \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [197/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nint \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [198/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nint \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [199/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nint \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [200/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nint \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [201/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [202/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [203/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [204/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [205/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nint \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [206/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nint \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [207/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nint \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [208/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nint \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [209/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nint \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [210/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nint \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [211/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nint \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [212/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nint \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [213/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator+ \n(\nint \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [214/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator+ \n(\nint \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [215/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator+ \n(\nint \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [216/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator+ \n(\nint \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [217/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< plus< T > > > > cv::cudev::operator+ \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [218/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< plus< T > > > > cv::cudev::operator+ \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [219/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< plus< T > > > > cv::cudev::operator+ \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [220/224]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< plus< typename Body::value_type > > > > cv::cudev::operator+ \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator+() [221/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator+ \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [222/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator+ \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [223/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator+ \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator+() [224/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator+ \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [1/248]\n\n__device__ __forceinline__ char1 cv::cudev::operator- \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [2/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [3/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [4/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [5/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst char1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [6/248]\n\n__device__ __forceinline__ char2 cv::cudev::operator- \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [7/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [8/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [9/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [10/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst char2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [11/248]\n\n__device__ __forceinline__ char3 cv::cudev::operator- \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [12/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [13/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [14/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [15/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst char3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [16/248]\n\n__device__ __forceinline__ char4 cv::cudev::operator- \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [17/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [18/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [19/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [20/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst char4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [21/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [22/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [23/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [24/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [25/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [26/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [27/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [28/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [29/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [30/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [31/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [32/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [33/248]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< minus< typename Body::value_type > > > > cv::cudev::operator- \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [34/248]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, negate< typename Body::value_type > > > cv::cudev::operator- \n(\nconst Expr< Body > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator-() [35/248]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [36/248]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [37/248]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [38/248]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, minus< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator- \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [39/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [40/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [41/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [42/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [43/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [44/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [45/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [46/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [47/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [48/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [49/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [50/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [51/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [52/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [53/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [54/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [55/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, negate< T > > > cv::cudev::operator- \n(\nconst GlobPtrSz< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator-() [56/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< minus< T > > > > cv::cudev::operator- \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [57/248]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [58/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [59/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [60/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [61/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, negate< T > > > cv::cudev::operator- \n(\nconst GpuMat_< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator-() [62/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< minus< T > > > > cv::cudev::operator- \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [63/248]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [64/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [65/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [66/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [67/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [68/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [69/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [70/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [71/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [72/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [73/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [74/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [75/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [76/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [77/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [78/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [79/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [80/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [81/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [82/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [83/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [84/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [85/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [86/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [87/248]\n\n__device__ __forceinline__ short1 cv::cudev::operator- \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [88/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [89/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [90/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [91/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst short1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [92/248]\n\n__device__ __forceinline__ short2 cv::cudev::operator- \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [93/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [94/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [95/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [96/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst short2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [97/248]\n\n__device__ __forceinline__ short3 cv::cudev::operator- \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [98/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [99/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [100/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [101/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst short3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [102/248]\n\n__device__ __forceinline__ short4 cv::cudev::operator- \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [103/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [104/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [105/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [106/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst short4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [107/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, negate< T > > > cv::cudev::operator- \n(\nconst Texture< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator-() [108/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< minus< T > > > > cv::cudev::operator- \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [109/248]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, minus< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator- \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [110/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [111/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [112/248]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, minus< T > > > cv::cudev::operator- \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [113/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [114/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [115/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [116/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst uchar1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [117/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [118/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [119/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [120/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst uchar2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [121/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [122/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [123/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [124/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst uchar3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [125/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [126/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [127/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [128/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst uchar4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [129/248]\n\n__device__ __forceinline__ uint1 cv::cudev::operator- \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [130/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [131/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [132/248]\n\n__device__ __forceinline__ uint1 cv::cudev::operator- \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [133/248]\n\n__device__ __forceinline__ uint2 cv::cudev::operator- \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [134/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [135/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [136/248]\n\n__device__ __forceinline__ uint2 cv::cudev::operator- \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [137/248]\n\n__device__ __forceinline__ uint3 cv::cudev::operator- \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [138/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [139/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [140/248]\n\n__device__ __forceinline__ uint3 cv::cudev::operator- \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [141/248]\n\n__device__ __forceinline__ uint4 cv::cudev::operator- \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [142/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [143/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [144/248]\n\n__device__ __forceinline__ uint4 cv::cudev::operator- \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [145/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [146/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [147/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [148/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nconst ushort1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [149/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [150/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [151/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [152/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nconst ushort2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [153/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [154/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [155/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [156/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nconst ushort3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [157/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [158/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [159/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [160/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nconst ushort4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [161/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [162/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [163/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [164/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [165/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [166/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [167/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [168/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [169/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [170/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [171/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [172/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [173/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [174/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [175/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [176/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [177/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [178/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [179/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [180/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [181/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [182/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [183/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [184/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [185/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [186/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [187/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [188/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [189/248]\n\n__device__ __forceinline__ double1 cv::cudev::operator- \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [190/248]\n\n__device__ __forceinline__ double2 cv::cudev::operator- \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [191/248]\n\n__device__ __forceinline__ double3 cv::cudev::operator- \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [192/248]\n\n__device__ __forceinline__ double4 cv::cudev::operator- \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [193/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [194/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [195/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [196/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [197/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [198/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [199/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [200/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [201/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [202/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [203/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [204/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [205/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [206/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [207/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [208/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [209/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [210/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [211/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [212/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [213/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [214/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [215/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [216/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [217/248]\n\n__device__ __forceinline__ float1 cv::cudev::operator- \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [218/248]\n\n__device__ __forceinline__ float2 cv::cudev::operator- \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [219/248]\n\n__device__ __forceinline__ float3 cv::cudev::operator- \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [220/248]\n\n__device__ __forceinline__ float4 cv::cudev::operator- \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [221/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nint \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [222/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nint \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [223/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nint \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [224/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nint \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [225/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [226/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [227/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [228/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [229/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nint \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [230/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nint \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [231/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nint \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [232/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nint \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [233/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nint \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [234/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nint \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [235/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nint \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [236/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nint \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [237/248]\n\n__device__ __forceinline__ int1 cv::cudev::operator- \n(\nint \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [238/248]\n\n__device__ __forceinline__ int2 cv::cudev::operator- \n(\nint \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [239/248]\n\n__device__ __forceinline__ int3 cv::cudev::operator- \n(\nint \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [240/248]\n\n__device__ __forceinline__ int4 cv::cudev::operator- \n(\nint \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [241/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< minus< T > > > > cv::cudev::operator- \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [242/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< minus< T > > > > cv::cudev::operator- \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [243/248]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< minus< T > > > > cv::cudev::operator- \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [244/248]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< minus< typename Body::value_type > > > > cv::cudev::operator- \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator-() [245/248]\n\n__device__ __forceinline__ uint1 cv::cudev::operator- \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [246/248]\n\n__device__ __forceinline__ uint2 cv::cudev::operator- \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [247/248]\n\n__device__ __forceinline__ uint3 cv::cudev::operator- \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator-() [248/248]\n\n__device__ __forceinline__ uint4 cv::cudev::operator- \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [1/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [2/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst char1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [3/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst char1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [4/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst char1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [5/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [6/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst char2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [7/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst char2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [8/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst char2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [9/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [10/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst char3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [11/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst char3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [12/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst char3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [13/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [14/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst char4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [15/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst char4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [16/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst char4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [17/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [18/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [19/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [20/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [21/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [22/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [23/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [24/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [25/224]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< divides< typename Body::value_type > > > > cv::cudev::operator/ \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [26/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [27/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [28/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [29/224]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, divides< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator/ \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [30/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [31/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst float1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [32/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [33/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [34/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst float2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [35/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [36/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [37/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst float3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [38/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [39/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [40/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst float4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [41/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [42/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< divides< T > > > > cv::cudev::operator/ \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [43/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [44/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [45/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [46/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [47/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< divides< T > > > > cv::cudev::operator/ \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [48/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [49/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [50/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [51/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [52/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [53/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst int1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [54/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst int1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [55/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [56/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [57/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst int2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [58/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst int2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [59/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [60/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [61/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst int3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [62/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst int3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [63/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [64/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [65/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst int4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [66/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst int4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [67/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [68/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [69/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst short1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [70/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst short1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [71/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst short1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [72/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [73/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst short2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [74/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst short2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [75/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst short2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [76/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [77/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst short3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [78/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst short3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [79/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst short3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [80/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [81/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst short4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [82/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst short4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [83/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst short4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [84/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< divides< T > > > > cv::cudev::operator/ \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [85/224]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, divides< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator/ \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [86/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [87/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [88/224]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, divides< T > > > cv::cudev::operator/ \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [89/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [90/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst uchar1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [91/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst uchar1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [92/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst uchar1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [93/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [94/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst uchar2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [95/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst uchar2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [96/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst uchar2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [97/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [98/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst uchar3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [99/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst uchar3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [100/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst uchar3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [101/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [102/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst uchar4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [103/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst uchar4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [104/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst uchar4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [105/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator/ \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [106/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst uint1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [107/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst uint1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [108/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator/ \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [109/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator/ \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [110/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst uint2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [111/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst uint2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [112/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator/ \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [113/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator/ \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [114/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst uint3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [115/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst uint3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [116/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator/ \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [117/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator/ \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [118/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst uint4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [119/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst uint4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [120/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator/ \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [121/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [122/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\nconst ushort1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [123/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nconst ushort1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [124/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nconst ushort1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [125/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [126/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\nconst ushort2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [127/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nconst ushort2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [128/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nconst ushort2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [129/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [130/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\nconst ushort3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [131/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nconst ushort3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [132/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nconst ushort3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [133/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [134/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\nconst ushort4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [135/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nconst ushort4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [136/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nconst ushort4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [137/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [138/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [139/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [140/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [141/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [142/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [143/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [144/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [145/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [146/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [147/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [148/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [149/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [150/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [151/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [152/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [153/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [154/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [155/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [156/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [157/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [158/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [159/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [160/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [161/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [162/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [163/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [164/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [165/224]\n\n__device__ __forceinline__ double1 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [166/224]\n\n__device__ __forceinline__ double2 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [167/224]\n\n__device__ __forceinline__ double3 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [168/224]\n\n__device__ __forceinline__ double4 cv::cudev::operator/ \n(\ndouble \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [169/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [170/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [171/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [172/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [173/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [174/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [175/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [176/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [177/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [178/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [179/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [180/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [181/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [182/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [183/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [184/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [185/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [186/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [187/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [188/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [189/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [190/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [191/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [192/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [193/224]\n\n__device__ __forceinline__ float1 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [194/224]\n\n__device__ __forceinline__ float2 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [195/224]\n\n__device__ __forceinline__ float3 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [196/224]\n\n__device__ __forceinline__ float4 cv::cudev::operator/ \n(\nfloat \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [197/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nint \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [198/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nint \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [199/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nint \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [200/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nint \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [201/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [202/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [203/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [204/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [205/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nint \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [206/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nint \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [207/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nint \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [208/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nint \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [209/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nint \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [210/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nint \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [211/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nint \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [212/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nint \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [213/224]\n\n__device__ __forceinline__ int1 cv::cudev::operator/ \n(\nint \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [214/224]\n\n__device__ __forceinline__ int2 cv::cudev::operator/ \n(\nint \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [215/224]\n\n__device__ __forceinline__ int3 cv::cudev::operator/ \n(\nint \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [216/224]\n\n__device__ __forceinline__ int4 cv::cudev::operator/ \n(\nint \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [217/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< divides< T > > > > cv::cudev::operator/ \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [218/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< divides< T > > > > cv::cudev::operator/ \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [219/224]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< divides< T > > > > cv::cudev::operator/ \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [220/224]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< divides< typename Body::value_type > > > > cv::cudev::operator/ \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator/() [221/224]\n\n__device__ __forceinline__ uint1 cv::cudev::operator/ \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [222/224]\n\n__device__ __forceinline__ uint2 cv::cudev::operator/ \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [223/224]\n\n__device__ __forceinline__ uint3 cv::cudev::operator/ \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator/() [224/224]\n\n__device__ __forceinline__ uint4 cv::cudev::operator/ \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< less< typename Body::value_type > > > > cv::cudev::operator< \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, less< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator< \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< less< T > > > > cv::cudev::operator< \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< less< T > > > > cv::cudev::operator< \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< less< T > > > > cv::cudev::operator< \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator< \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less< T > > > cv::cudev::operator< \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< less< T > > > > cv::cudev::operator< \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< less< T > > > > cv::cudev::operator< \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< less< T > > > > cv::cudev::operator< \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< less< typename Body::value_type > > > > cv::cudev::operator< \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator< \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator< \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator< \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator< \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<<() [1/24]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_lshift< typename Body::value_type > > > > cv::cudev::operator<< \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [2/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [3/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [4/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [5/24]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_lshift< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator<< \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [6/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_lshift< T > > > > cv::cudev::operator<< \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [7/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [8/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [9/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [10/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [11/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_lshift< T > > > > cv::cudev::operator<< \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [12/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [13/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [14/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [15/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [16/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_lshift< T > > > > cv::cudev::operator<< \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [17/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_lshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<< \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [18/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [19/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [20/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_lshift< T > > > cv::cudev::operator<< \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [21/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_lshift< T > > > > cv::cudev::operator<< \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [22/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_lshift< T > > > > cv::cudev::operator<< \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [23/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_lshift< T > > > > cv::cudev::operator<< \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<<() [24/24]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_lshift< typename Body::value_type > > > > cv::cudev::operator<< \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< less_equal< typename Body::value_type > > > > cv::cudev::operator<= \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, less_equal< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator<= \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< less_equal< T > > > > cv::cudev::operator<= \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< less_equal< T > > > > cv::cudev::operator<= \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< less_equal< T > > > > cv::cudev::operator<= \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, less_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator<= \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, less_equal< T > > > cv::cudev::operator<= \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< less_equal< T > > > > cv::cudev::operator<= \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< less_equal< T > > > > cv::cudev::operator<= \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< less_equal< T > > > > cv::cudev::operator<= \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< less_equal< typename Body::value_type > > > > cv::cudev::operator<= \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator<=() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator<= \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator<= \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator<= \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator<=() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator<= \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator=() [1/6]\n\ntemplate<class T , class R  = T> \n\nTexture & cv::cudev::Texture< T, R >::operator= \n(\nconst Texture< T, R > & \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator=() [2/6]\n\ntemplate<class T , class R  = T> \n\nTextureOff & cv::cudev::TextureOff< T, R >::operator= \n(\nconst TextureOff< T, R > & \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator=() [3/6]\n\ntemplate<class T , class R  = T> \n\n__host__ UniqueTexture & cv::cudev::UniqueTexture< T, R >::operator= \n(\nconst UniqueTexture< T, R > & \n)\n\ndelete \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator=() [4/6]\n\ntemplate<class T , class R  = T> \n\nTexture & cv::cudev::Texture< T, R >::operator= \n(\nTexture< T, R > && \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator=() [5/6]\n\ntemplate<class T , class R  = T> \n\nTextureOff & cv::cudev::TextureOff< T, R >::operator= \n(\nTextureOff< T, R > && \n)\n\ndefault \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\n◆ operator=() [6/6]\n\ntemplate<class T , class R  = T> \n\n__host__ UniqueTexture & cv::cudev::UniqueTexture< T, R >::operator= \n(\nUniqueTexture< T, R > && \nother)\n\ninlinenoexcept \n\n#include <opencv2/cudev/ptr2d/texture.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ operator==() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< equal_to< typename Body::value_type > > > > cv::cudev::operator== \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, equal_to< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator== \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< equal_to< T > > > > cv::cudev::operator== \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< equal_to< T > > > > cv::cudev::operator== \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< equal_to< T > > > > cv::cudev::operator== \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, equal_to< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator== \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, equal_to< T > > > cv::cudev::operator== \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< equal_to< T > > > > cv::cudev::operator== \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< equal_to< T > > > > cv::cudev::operator== \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< equal_to< T > > > > cv::cudev::operator== \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< equal_to< typename Body::value_type > > > > cv::cudev::operator== \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator==() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator== \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator== \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator== \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator==() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator== \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< greater< typename Body::value_type > > > > cv::cudev::operator> \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, greater< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator> \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< greater< T > > > > cv::cudev::operator> \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< greater< T > > > > cv::cudev::operator> \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< greater< T > > > > cv::cudev::operator> \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator> \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater< T > > > cv::cudev::operator> \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< greater< T > > > > cv::cudev::operator> \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< greater< T > > > > cv::cudev::operator> \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< greater< T > > > > cv::cudev::operator> \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< greater< typename Body::value_type > > > > cv::cudev::operator> \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator> \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator> \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator> \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator> \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< greater_equal< typename Body::value_type > > > > cv::cudev::operator>= \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, greater_equal< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator>= \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< greater_equal< T > > > > cv::cudev::operator>= \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< greater_equal< T > > > > cv::cudev::operator>= \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< greater_equal< T > > > > cv::cudev::operator>= \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, greater_equal< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>= \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, greater_equal< T > > > cv::cudev::operator>= \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< greater_equal< T > > > > cv::cudev::operator>= \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< greater_equal< T > > > > cv::cudev::operator>= \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< greater_equal< T > > > > cv::cudev::operator>= \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< greater_equal< typename Body::value_type > > > > cv::cudev::operator>= \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>=() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator>= \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator>= \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator>= \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>=() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator>= \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator>>() [1/24]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_rshift< typename Body::value_type > > > > cv::cudev::operator>> \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [2/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [3/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [4/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [5/24]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_rshift< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator>> \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [6/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_rshift< T > > > > cv::cudev::operator>> \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [7/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [8/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [9/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [10/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [11/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_rshift< T > > > > cv::cudev::operator>> \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [12/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [13/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [14/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [15/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [16/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_rshift< T > > > > cv::cudev::operator>> \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [17/24]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_rshift< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator>> \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [18/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [19/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [20/24]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_rshift< T > > > cv::cudev::operator>> \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [21/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_rshift< T > > > > cv::cudev::operator>> \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [22/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_rshift< T > > > > cv::cudev::operator>> \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [23/24]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_rshift< T > > > > cv::cudev::operator>> \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator>>() [24/24]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_rshift< typename Body::value_type > > > > cv::cudev::operator>> \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [1/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator^ \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [2/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator^ \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [3/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator^ \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [4/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator^ \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [5/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator^ \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [6/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator^ \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [7/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator^ \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [8/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator^ \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [9/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator^ \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [10/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator^ \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [11/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator^ \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [12/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator^ \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [13/96]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_xor< typename Body::value_type > > > > cv::cudev::operator^ \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [14/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [15/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [16/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [17/96]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_xor< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator^ \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [18/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_xor< T > > > > cv::cudev::operator^ \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [19/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [20/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [21/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [22/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [23/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_xor< T > > > > cv::cudev::operator^ \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [24/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [25/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [26/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [27/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [28/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator^ \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [29/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator^ \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [30/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator^ \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [31/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator^ \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [32/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator^ \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [33/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator^ \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [34/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator^ \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [35/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator^ \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [36/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator^ \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [37/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator^ \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [38/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator^ \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [39/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator^ \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [40/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator^ \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [41/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator^ \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [42/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator^ \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [43/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator^ \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [44/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_xor< T > > > > cv::cudev::operator^ \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [45/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_xor< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator^ \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [46/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [47/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [48/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_xor< T > > > cv::cudev::operator^ \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [49/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator^ \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [50/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator^ \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [51/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator^ \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [52/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator^ \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [53/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator^ \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [54/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator^ \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [55/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator^ \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [56/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator^ \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [57/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator^ \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [58/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator^ \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [59/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator^ \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [60/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator^ \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [61/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator^ \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [62/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator^ \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [63/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator^ \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [64/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator^ \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [65/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator^ \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [66/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator^ \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [67/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator^ \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [68/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator^ \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [69/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator^ \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [70/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator^ \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [71/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator^ \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [72/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator^ \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [73/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator^ \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [74/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator^ \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [75/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator^ \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [76/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator^ \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [77/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator^ \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [78/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator^ \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [79/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator^ \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [80/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator^ \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [81/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_xor< T > > > > cv::cudev::operator^ \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [82/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_xor< T > > > > cv::cudev::operator^ \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [83/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_xor< T > > > > cv::cudev::operator^ \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [84/96]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_xor< typename Body::value_type > > > > cv::cudev::operator^ \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator^() [85/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator^ \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [86/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator^ \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [87/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator^ \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [88/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator^ \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [89/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator^ \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [90/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator^ \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [91/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator^ \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [92/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator^ \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [93/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator^ \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [94/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator^ \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [95/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator^ \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator^() [96/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator^ \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [1/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator| \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [2/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator| \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [3/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator| \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [4/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator| \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [5/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator| \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [6/96]\n\n__device__ __forceinline__ char1 cv::cudev::operator| \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [7/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator| \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [8/96]\n\n__device__ __forceinline__ char2 cv::cudev::operator| \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [9/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator| \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [10/96]\n\n__device__ __forceinline__ char3 cv::cudev::operator| \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [11/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator| \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [12/96]\n\n__device__ __forceinline__ char4 cv::cudev::operator| \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [13/96]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< bit_or< typename Body::value_type > > > > cv::cudev::operator| \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [14/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [15/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [16/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [17/96]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, bit_or< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator| \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [18/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< bit_or< T > > > > cv::cudev::operator| \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [19/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [20/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [21/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [22/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [23/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< bit_or< T > > > > cv::cudev::operator| \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [24/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [25/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [26/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [27/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [28/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator| \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [29/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator| \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [30/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator| \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [31/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator| \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [32/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator| \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [33/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator| \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [34/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator| \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [35/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator| \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [36/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator| \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [37/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator| \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [38/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator| \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [39/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator| \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [40/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator| \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [41/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator| \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [42/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator| \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [43/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator| \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [44/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< bit_or< T > > > > cv::cudev::operator| \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [45/96]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, bit_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator| \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [46/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [47/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [48/96]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, bit_or< T > > > cv::cudev::operator| \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [49/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator| \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [50/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator| \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [51/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator| \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [52/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator| \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [53/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator| \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [54/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator| \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [55/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator| \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [56/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator| \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [57/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator| \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [58/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator| \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [59/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator| \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [60/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator| \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [61/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator| \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [62/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator| \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [63/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator| \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [64/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator| \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [65/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator| \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [66/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator| \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [67/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator| \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [68/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator| \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [69/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator| \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [70/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator| \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [71/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator| \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [72/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator| \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [73/96]\n\n__device__ __forceinline__ int1 cv::cudev::operator| \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [74/96]\n\n__device__ __forceinline__ int2 cv::cudev::operator| \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [75/96]\n\n__device__ __forceinline__ int3 cv::cudev::operator| \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [76/96]\n\n__device__ __forceinline__ int4 cv::cudev::operator| \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [77/96]\n\n__device__ __forceinline__ short1 cv::cudev::operator| \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [78/96]\n\n__device__ __forceinline__ short2 cv::cudev::operator| \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [79/96]\n\n__device__ __forceinline__ short3 cv::cudev::operator| \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [80/96]\n\n__device__ __forceinline__ short4 cv::cudev::operator| \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [81/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< bit_or< T > > > > cv::cudev::operator| \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [82/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< bit_or< T > > > > cv::cudev::operator| \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [83/96]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< bit_or< T > > > > cv::cudev::operator| \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [84/96]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< bit_or< typename Body::value_type > > > > cv::cudev::operator| \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator|() [85/96]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator| \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [86/96]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator| \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [87/96]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator| \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [88/96]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator| \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [89/96]\n\n__device__ __forceinline__ uint1 cv::cudev::operator| \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [90/96]\n\n__device__ __forceinline__ uint2 cv::cudev::operator| \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [91/96]\n\n__device__ __forceinline__ uint3 cv::cudev::operator| \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [92/96]\n\n__device__ __forceinline__ uint4 cv::cudev::operator| \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [93/96]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator| \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [94/96]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator| \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [95/96]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator| \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator|() [96/96]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator| \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [1/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nchar \ns, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [2/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nchar \ns, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [3/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nchar \ns, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [4/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nchar \ns, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [5/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst char1 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [6/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst char1 & \na, \n\nconst char1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [7/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst char2 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [8/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst char2 & \na, \n\nconst char2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [9/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst char3 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [10/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst char3 & \na, \n\nconst char3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [11/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst char4 & \na, \n\nchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [12/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst char4 & \na, \n\nconst char4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [13/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst double1 & \na, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [14/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst double1 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [15/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst double2 & \na, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [16/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst double2 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [17/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst double3 & \na, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [18/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst double3 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [19/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst double4 & \na, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [20/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst double4 & \na, \n\ndouble \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [21/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder2nd< logical_or< typename Body::value_type > > > > cv::cudev::operator|| \n(\nconst Expr< Body > & \na, \n\ntypename Body::value_type \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [22/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| \n(\nconst Expr< Body > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [23/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| \n(\nconst Expr< Body > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [24/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| \n(\nconst Expr< Body > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [25/120]\n\ntemplate<class Body1 , class Body2 > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Body1 >::ptr_type, typename PtrTraits< Body2 >::ptr_type, logical_or< typename LargerType< typename PtrTraits< Body1 >::value_type, typename PtrTraits< Body2 >::value_type >::type > > > cv::cudev::operator|| \n(\nconst Expr< Body1 > & \na, \n\nconst Expr< Body2 > & \nb \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [26/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst float1 & \na, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [27/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst float1 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [28/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst float2 & \na, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [29/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst float2 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [30/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst float3 & \na, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [31/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst float3 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [32/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst float4 & \na, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [33/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst float4 & \na, \n\nfloat \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [34/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder2nd< logical_or< T > > > > cv::cudev::operator|| \n(\nconst GlobPtrSz< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [35/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [36/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [37/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [38/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst GlobPtrSz< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [39/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder2nd< logical_or< T > > > > cv::cudev::operator|| \n(\nconst GpuMat_< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [40/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [41/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [42/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [43/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst GpuMat_< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [44/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst int1 & \na, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [45/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst int1 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [46/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst int2 & \na, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [47/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst int2 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [48/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst int3 & \na, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [49/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst int3 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [50/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst int4 & \na, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [51/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst int4 & \na, \n\nint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [52/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst short1 & \na, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [53/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst short1 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [54/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst short2 & \na, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [55/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst short2 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [56/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst short3 & \na, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [57/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst short3 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [58/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst short4 & \na, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [59/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst short4 & \na, \n\nshort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [60/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder2nd< logical_or< T > > > > cv::cudev::operator|| \n(\nconst Texture< T > & \nsrc, \n\nT \nval \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [61/120]\n\ntemplate<typename T , class Body > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Body >::ptr_type, logical_or< typename LargerType< T, typename PtrTraits< Body >::value_type >::type > > > cv::cudev::operator|| \n(\nconst Texture< T > & \nsrc1, \n\nconst Expr< Body > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [62/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GlobPtrSz< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst Texture< T > & \nsrc1, \n\nconst GlobPtrSz< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [63/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< GpuMat_< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst Texture< T > & \nsrc1, \n\nconst GpuMat_< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [64/120]\n\ntemplate<typename T > \n\n__host__ Expr< BinaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, typename PtrTraits< Texture< T > >::ptr_type, logical_or< T > > > cv::cudev::operator|| \n(\nconst Texture< T > & \nsrc1, \n\nconst Texture< T > & \nsrc2 \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [65/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst uchar1 & \na, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [66/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst uchar1 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [67/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst uchar2 & \na, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [68/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst uchar2 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [69/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst uchar3 & \na, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [70/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst uchar3 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [71/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst uchar4 & \na, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [72/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst uchar4 & \na, \n\nuchar \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [73/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst uint1 & \na, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [74/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst uint1 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [75/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst uint2 & \na, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [76/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst uint2 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [77/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst uint3 & \na, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [78/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst uint3 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [79/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst uint4 & \na, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [80/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst uint4 & \na, \n\nuint \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [81/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst ushort1 & \na, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [82/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nconst ushort1 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [83/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst ushort2 & \na, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [84/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nconst ushort2 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [85/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst ushort3 & \na, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [86/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nconst ushort3 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [87/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst ushort4 & \na, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [88/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nconst ushort4 & \na, \n\nushort \ns \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [89/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\ndouble \ns, \n\nconst double1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [90/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\ndouble \ns, \n\nconst double2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [91/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\ndouble \ns, \n\nconst double3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [92/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\ndouble \ns, \n\nconst double4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [93/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nfloat \ns, \n\nconst float1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [94/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nfloat \ns, \n\nconst float2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [95/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nfloat \ns, \n\nconst float3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [96/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nfloat \ns, \n\nconst float4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [97/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nint \ns, \n\nconst int1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [98/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nint \ns, \n\nconst int2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [99/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nint \ns, \n\nconst int3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [100/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nint \ns, \n\nconst int4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [101/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nshort \ns, \n\nconst short1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [102/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nshort \ns, \n\nconst short2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [103/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nshort \ns, \n\nconst short3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [104/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nshort \ns, \n\nconst short4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [105/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, Binder1st< logical_or< T > > > > cv::cudev::operator|| \n(\nT \nval, \n\nconst GlobPtrSz< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [106/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, Binder1st< logical_or< T > > > > cv::cudev::operator|| \n(\nT \nval, \n\nconst GpuMat_< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [107/120]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, Binder1st< logical_or< T > > > > cv::cudev::operator|| \n(\nT \nval, \n\nconst Texture< T > & \nsrc \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [108/120]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, Binder1st< logical_or< typename Body::value_type > > > > cv::cudev::operator|| \n(\ntypename Body::value_type \nval, \n\nconst Expr< Body > & \na \n\n)\n\n#include <opencv2/cudev/expr/binary_op.hpp>\n\n◆ operator||() [109/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nuchar \ns, \n\nconst uchar1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [110/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nuchar \ns, \n\nconst uchar2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [111/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nuchar \ns, \n\nconst uchar3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [112/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nuchar \ns, \n\nconst uchar4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [113/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nuint \ns, \n\nconst uint1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [114/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nuint \ns, \n\nconst uint2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [115/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nuint \ns, \n\nconst uint3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [116/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nuint \ns, \n\nconst uint4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [117/120]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator|| \n(\nushort \ns, \n\nconst ushort1 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [118/120]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator|| \n(\nushort \ns, \n\nconst ushort2 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [119/120]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator|| \n(\nushort \ns, \n\nconst ushort3 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator||() [120/120]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator|| \n(\nushort \ns, \n\nconst ushort4 & \nb \n\n)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [1/28]\n\n__device__ __forceinline__ char1 cv::cudev::operator~ \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [2/28]\n\n__device__ __forceinline__ char2 cv::cudev::operator~ \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [3/28]\n\n__device__ __forceinline__ char3 cv::cudev::operator~ \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [4/28]\n\n__device__ __forceinline__ char4 cv::cudev::operator~ \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [5/28]\n\ntemplate<class Body > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Body >::ptr_type, bit_not< typename Body::value_type > > > cv::cudev::operator~ \n(\nconst Expr< Body > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator~() [6/28]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GlobPtrSz< T > >::ptr_type, bit_not< T > > > cv::cudev::operator~ \n(\nconst GlobPtrSz< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator~() [7/28]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< GpuMat_< T > >::ptr_type, bit_not< T > > > cv::cudev::operator~ \n(\nconst GpuMat_< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator~() [8/28]\n\n__device__ __forceinline__ int1 cv::cudev::operator~ \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [9/28]\n\n__device__ __forceinline__ int2 cv::cudev::operator~ \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [10/28]\n\n__device__ __forceinline__ int3 cv::cudev::operator~ \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [11/28]\n\n__device__ __forceinline__ int4 cv::cudev::operator~ \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [12/28]\n\n__device__ __forceinline__ short1 cv::cudev::operator~ \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [13/28]\n\n__device__ __forceinline__ short2 cv::cudev::operator~ \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [14/28]\n\n__device__ __forceinline__ short3 cv::cudev::operator~ \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [15/28]\n\n__device__ __forceinline__ short4 cv::cudev::operator~ \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [16/28]\n\ntemplate<typename T > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< Texture< T > >::ptr_type, bit_not< T > > > cv::cudev::operator~ \n(\nconst Texture< T > & \nsrc)\n\n#include <opencv2/cudev/expr/unary_op.hpp>\n\n◆ operator~() [17/28]\n\n__device__ __forceinline__ uchar1 cv::cudev::operator~ \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [18/28]\n\n__device__ __forceinline__ uchar2 cv::cudev::operator~ \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [19/28]\n\n__device__ __forceinline__ uchar3 cv::cudev::operator~ \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [20/28]\n\n__device__ __forceinline__ uchar4 cv::cudev::operator~ \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [21/28]\n\n__device__ __forceinline__ uint1 cv::cudev::operator~ \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [22/28]\n\n__device__ __forceinline__ uint2 cv::cudev::operator~ \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [23/28]\n\n__device__ __forceinline__ uint3 cv::cudev::operator~ \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [24/28]\n\n__device__ __forceinline__ uint4 cv::cudev::operator~ \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [25/28]\n\n__device__ __forceinline__ ushort1 cv::cudev::operator~ \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [26/28]\n\n__device__ __forceinline__ ushort2 cv::cudev::operator~ \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [27/28]\n\n__device__ __forceinline__ ushort3 cv::cudev::operator~ \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ operator~() [28/28]\n\n__device__ __forceinline__ ushort4 cv::cudev::operator~ \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ perspectiveMap()\n\nstatic __host__ PerspectiveMapPtrSz cv::cudev::perspectiveMap \n(\nSize \ndstSize, \n\nconst GpuMat_< float > & \nwarpMat \n\n)\n\nstatic \n\n#include <opencv2/cudev/ptr2d/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ pow_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Binder2nd< pow_func< typename PtrTraits< SrcPtr >::value_type > > > > cv::cudev::pow_ \n(\nconst SrcPtr & \nsrc, \n\nfloat \npower \n\n)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ pyrDown_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< PyrDownBody< SrcPtr > > cv::cudev::pyrDown_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ pyrUp_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< PyrUpBody< SrcPtr > > cv::cudev::pyrUp_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ reduceToColumn_()\n\ntemplate<class Reductor , class SrcPtr > \n\n__host__ Expr< ReduceToColumnBody< Reductor, SrcPtr > > cv::cudev::reduceToColumn_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ reduceToRow_()\n\ntemplate<class Reductor , class SrcPtr > \n\n__host__ Expr< ReduceToRowBody< Reductor, SrcPtr > > cv::cudev::reduceToRow_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ remap_() [1/2]\n\ntemplate<class SrcPtr , class MapPtr > \n\n__host__ Expr< RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapPtr >::ptr_type > > cv::cudev::remap_ \n(\nconst SrcPtr & \nsrc, \n\nconst MapPtr & \nmap \n\n)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ remap_() [2/2]\n\ntemplate<class SrcPtr , class MapXPtr , class MapYPtr > \n\n__host__ Expr< RemapPtr2Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapXPtr >::ptr_type, typename PtrTraits< MapYPtr >::ptr_type > > cv::cudev::remap_ \n(\nconst SrcPtr & \nsrc, \n\nconst MapXPtr & \nmapx, \n\nconst MapYPtr & \nmapy \n\n)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ remapPtr() [1/2]\n\ntemplate<class SrcPtr , class MapPtr > \n\n__host__ RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapPtr >::ptr_type > cv::cudev::remapPtr \n(\nconst SrcPtr & \nsrc, \n\nconst MapPtr & \nmap \n\n)\n\n#include <opencv2/cudev/ptr2d/remap.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ remapPtr() [2/2]\n\ntemplate<class SrcPtr , class MapXPtr , class MapYPtr > \n\n__host__ RemapPtr2Sz< typename PtrTraits< SrcPtr >::ptr_type, typename PtrTraits< MapXPtr >::ptr_type, typename PtrTraits< MapYPtr >::ptr_type > cv::cudev::remapPtr \n(\nconst SrcPtr & \nsrc, \n\nconst MapXPtr & \nmapx, \n\nconst MapYPtr & \nmapy \n\n)\n\n#include <opencv2/cudev/ptr2d/remap.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ reshape_()\n\ntemplate<int cn, typename T > \n\n__host__ GpuMat_< typename MakeVec< typename VecTraits< T >::elem_type, cn >::type > cv::cudev::reshape_ \n(\nconst GpuMat_< T > & \nmat, \n\nint \nrows = 0 \n\n)\n\n#include <opencv2/cudev/ptr2d/gpumat.hpp>\ncreates alternative GpuMat header for the same data, with different number of channels and/or different number of rows. see cvReshape. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ resize_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< ResizePtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::resize_ \n(\nconst SrcPtr & \nsrc, \n\nfloat \nfx, \n\nfloat \nfy \n\n)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ resizePtr()\n\ntemplate<class SrcPtr > \n\n__host__ ResizePtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::resizePtr \n(\nconst SrcPtr & \nsrc, \n\nfloat \nfx, \n\nfloat \nfy \n\n)\n\n#include <opencv2/cudev/ptr2d/resize.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ RGB_to_GRAY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_GRAY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HLS4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HLS4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HLS_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HLS_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HLS_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HSV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HSV4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HSV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_HSV_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_HSV_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_XYZ4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_XYZ4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_XYZ_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_XYZ_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_YCrCb4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YCrCb4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_YCrCb_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YCrCb_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_YUV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YUV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGB_to_YUV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGB_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGB_to_YUV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_GRAY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_GRAY_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_GRAY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HLS4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HLS4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HLS_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HLS_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HLS_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HLS_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HSV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HSV4_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV4_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV4_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HSV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_HSV_FULL_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_HSV_FULL_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_HSV_FULL_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_Lab4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Lab4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Lab4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_Lab_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Lab_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Lab_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_Luv4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Luv4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Luv4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_Luv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_Luv_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_Luv_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_XYZ4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_XYZ4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_XYZ4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_XYZ_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_XYZ_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_XYZ_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_YCrCb4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YCrCb4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YCrCb4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_YCrCb_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YCrCb_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YCrCb_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_YUV4_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YUV4_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YUV4_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ RGBA_to_YUV_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, RGBA_to_YUV_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::RGBA_to_YUV_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ saturate_cast() [1/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst char1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [2/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst char2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [3/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst char3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [4/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst char4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [5/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst double1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [6/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst double2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [7/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst double3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [8/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst double4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [9/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst float1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [10/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst float2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [11/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst float3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [12/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst float4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [13/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst int1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [14/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst int2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [15/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst int3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [16/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst int4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [17/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst short1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [18/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst short2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [19/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst short3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [20/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst short4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [21/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uchar1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [22/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uchar2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [23/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uchar3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [24/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uchar4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [25/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uint1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [26/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uint2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [27/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uint3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [28/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst uint4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [29/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst ushort1 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [30/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst ushort2 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [31/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst ushort3 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [32/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nconst ushort4 & \nv)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ saturate_cast() [33/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\ndouble \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [34/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [35/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [36/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nschar \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [37/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nshort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [38/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nuchar \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [39/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nuint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast() [40/40]\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::saturate_cast \n(\nushort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [1/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\ndouble \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [2/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [3/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\nint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [4/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\nshort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [5/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\nuchar \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [6/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\nuint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< schar >() [7/7]\n\ntemplate<> \n\n__device__ __forceinline__ schar cv::cudev::saturate_cast< schar > \n(\nushort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< short >() [1/5]\n\ntemplate<> \n\n__device__ __forceinline__ short cv::cudev::saturate_cast< short > \n(\ndouble \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< short >() [2/5]\n\ntemplate<> \n\n__device__ __forceinline__ short cv::cudev::saturate_cast< short > \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< short >() [3/5]\n\ntemplate<> \n\n__device__ __forceinline__ short cv::cudev::saturate_cast< short > \n(\nint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< short >() [4/5]\n\ntemplate<> \n\n__device__ __forceinline__ short cv::cudev::saturate_cast< short > \n(\nuint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< short >() [5/5]\n\ntemplate<> \n\n__device__ __forceinline__ short cv::cudev::saturate_cast< short > \n(\nushort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [1/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\ndouble \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [2/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [3/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\nint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [4/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\nschar \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [5/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\nshort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [6/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\nuint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uchar >() [7/7]\n\ntemplate<> \n\n__device__ __forceinline__ uchar cv::cudev::saturate_cast< uchar > \n(\nushort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uint >() [1/5]\n\ntemplate<> \n\n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > \n(\ndouble \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ saturate_cast< uint >() [2/5]\n\ntemplate<> \n\n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uint >() [3/5]\n\ntemplate<> \n\n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > \n(\nint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uint >() [4/5]\n\ntemplate<> \n\n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > \n(\nschar \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< uint >() [5/5]\n\ntemplate<> \n\n__device__ __forceinline__ uint cv::cudev::saturate_cast< uint > \n(\nshort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< ushort >() [1/6]\n\ntemplate<> \n\n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > \n(\ndouble \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< ushort >() [2/6]\n\ntemplate<> \n\n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > \n(\nfloat \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< ushort >() [3/6]\n\ntemplate<> \n\n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > \n(\nint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< ushort >() [4/6]\n\ntemplate<> \n\n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > \n(\nschar \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< ushort >() [5/6]\n\ntemplate<> \n\n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > \n(\nshort \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ saturate_cast< ushort >() [6/6]\n\ntemplate<> \n\n__device__ __forceinline__ ushort cv::cudev::saturate_cast< ushort > \n(\nuint \nv)\n\n#include <opencv2/cudev/util/saturate_cast.hpp>\n\n◆ scharrX_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< ScharrXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::scharrX_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ scharrXPtr()\n\ntemplate<class SrcPtr > \n\n__host__ ScharrXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::scharrXPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ scharrY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< ScharrYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::scharrY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ scharrYPtr()\n\ntemplate<class SrcPtr > \n\n__host__ ScharrYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::scharrYPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ shrinkPtr()\n\ntemplate<class Ptr2DSz > \n\n__host__ PtrTraits< Ptr2DSz >::ptr_type cv::cudev::shrinkPtr \n(\nconst Ptr2DSz & \nptr)\n\n#include <opencv2/cudev/ptr2d/traits.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ sin() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::sin \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::sin \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::sin \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::sin \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::sin \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::sin \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::sin \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::sin \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sin_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sin_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sin_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ singleMaskChannels()\n\ntemplate<class MaskPtr > \n\n__host__ SingleMaskChannelsSz< typename PtrTraits< MaskPtr >::ptr_type > cv::cudev::singleMaskChannels \n(\nconst MaskPtr & \nmask, \n\nint \nchannels \n\n)\n\n#include <opencv2/cudev/ptr2d/mask.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ sinh() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::sinh \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::sinh \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::sinh \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::sinh \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::sinh \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::sinh \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::sinh \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::sinh \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sinh_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sinh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sinh_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ smem_tuple() [1/10]\n\ntemplate<typename T0 > \n\n__device__ __forceinline__ tuple< volatile T0 * > cv::cudev::smem_tuple \n(\nT0 * \nt0)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [2/10]\n\ntemplate<typename T0 , typename T1 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [3/10]\n\ntemplate<typename T0 , typename T1 , typename T2 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [4/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [5/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3, \n\nT4 * \nt4 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [6/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3, \n\nT4 * \nt4, \n\nT5 * \nt5 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [7/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3, \n\nT4 * \nt4, \n\nT5 * \nt5, \n\nT6 * \nt6 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [8/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 , typename T7 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 *, volatile T7 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3, \n\nT4 * \nt4, \n\nT5 * \nt5, \n\nT6 * \nt6, \n\nT7 * \nt7 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [9/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 , typename T7 , typename T8 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 *, volatile T7 *, volatile T8 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3, \n\nT4 * \nt4, \n\nT5 * \nt5, \n\nT6 * \nt6, \n\nT7 * \nt7, \n\nT8 * \nt8 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ smem_tuple() [10/10]\n\ntemplate<typename T0 , typename T1 , typename T2 , typename T3 , typename T4 , typename T5 , typename T6 , typename T7 , typename T8 , typename T9 > \n\n__device__ __forceinline__ tuple< volatile T0 *, volatile T1 *, volatile T2 *, volatile T3 *, volatile T4 *, volatile T5 *, volatile T6 *, volatile T7 *, volatile T8 *, volatile T9 * > cv::cudev::smem_tuple \n(\nT0 * \nt0, \n\nT1 * \nt1, \n\nT2 * \nt2, \n\nT3 * \nt3, \n\nT4 * \nt4, \n\nT5 * \nt5, \n\nT6 * \nt6, \n\nT7 * \nt7, \n\nT8 * \nt8, \n\nT9 * \nt9 \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ sobelX_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< SobelXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::sobelX_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ sobelXPtr()\n\ntemplate<class SrcPtr > \n\n__host__ SobelXPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::sobelXPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ sobelY_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< SobelYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > > cv::cudev::sobelY_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ sobelYPtr()\n\ntemplate<class SrcPtr > \n\n__host__ SobelYPtrSz< typename PtrTraits< SrcPtr >::ptr_type > cv::cudev::sobelYPtr \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/ptr2d/deriv.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ sqr_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sqr_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sqr_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ sqrt() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::sqrt \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::sqrt \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::sqrt \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::sqrt \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::sqrt \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::sqrt \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::sqrt \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::sqrt \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ sqrt_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, sqrt_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::sqrt_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ sum_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< SumExprBody< SrcPtr > > cv::cudev::sum_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/reduction.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ tan() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::tan \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::tan \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::tan \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::tan \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::tan \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::tan \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::tan \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::tan \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tan_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, tan_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::tan_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ tanh() [1/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst char1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [2/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst char2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [3/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst char3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [4/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst char4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [5/32]\n\n__device__ __forceinline__ double1 cv::cudev::tanh \n(\nconst double1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [6/32]\n\n__device__ __forceinline__ double2 cv::cudev::tanh \n(\nconst double2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [7/32]\n\n__device__ __forceinline__ double3 cv::cudev::tanh \n(\nconst double3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [8/32]\n\n__device__ __forceinline__ double4 cv::cudev::tanh \n(\nconst double4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [9/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst float1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [10/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst float2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [11/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst float3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [12/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst float4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [13/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst int1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [14/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst int2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [15/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst int3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [16/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst int4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [17/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst short1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [18/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst short2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [19/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst short3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [20/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst short4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [21/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst uchar1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [22/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst uchar2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [23/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst uchar3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [24/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst uchar4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [25/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst uint1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [26/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst uint2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [27/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst uint3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [28/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst uint4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [29/32]\n\n__device__ __forceinline__ float1 cv::cudev::tanh \n(\nconst ushort1 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [30/32]\n\n__device__ __forceinline__ float2 cv::cudev::tanh \n(\nconst ushort2 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [31/32]\n\n__device__ __forceinline__ float3 cv::cudev::tanh \n(\nconst ushort3 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh() [32/32]\n\n__device__ __forceinline__ float4 cv::cudev::tanh \n(\nconst ushort4 & \na)\n\n#include <opencv2/cudev/util/vec_math.hpp>\n\n◆ tanh_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, tanh_func< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::tanh_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/unary_func.hpp>\n\n◆ thresh_binary_func()\n\ntemplate<typename T > \n\n__host__ __device__ ThreshBinaryFunc< T > cv::cudev::thresh_binary_func \n(\nT \nthresh, \n\nT \nmaxVal \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ thresh_binary_inv_func()\n\ntemplate<typename T > \n\n__host__ __device__ ThreshBinaryInvFunc< T > cv::cudev::thresh_binary_inv_func \n(\nT \nthresh, \n\nT \nmaxVal \n\n)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ thresh_to_zero_func()\n\ntemplate<typename T > \n\n__host__ __device__ ThreshToZeroFunc< T > cv::cudev::thresh_to_zero_func \n(\nT \nthresh)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ thresh_to_zero_inv_func()\n\ntemplate<typename T > \n\n__host__ __device__ ThreshToZeroInvFunc< T > cv::cudev::thresh_to_zero_inv_func \n(\nT \nthresh)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ thresh_trunc_func()\n\ntemplate<typename T > \n\n__host__ __device__ ThreshTruncFunc< T > cv::cudev::thresh_trunc_func \n(\nT \nthresh)\n\n#include <opencv2/cudev/functional/functional.hpp>\n\n◆ threshBinary_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshBinaryFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshBinary_ \n(\nconst SrcPtr & \nsrc, \n\ntypename PtrTraits< SrcPtr >::value_type \nthresh, \n\ntypename PtrTraits< SrcPtr >::value_type \nmaxVal \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ threshBinaryInv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshBinaryInvFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshBinaryInv_ \n(\nconst SrcPtr & \nsrc, \n\ntypename PtrTraits< SrcPtr >::value_type \nthresh, \n\ntypename PtrTraits< SrcPtr >::value_type \nmaxVal \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ threshToZero_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshToZeroFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshToZero_ \n(\nconst SrcPtr & \nsrc, \n\ntypename PtrTraits< SrcPtr >::value_type \nthresh \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ threshToZeroInv_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshToZeroInvFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshToZeroInv_ \n(\nconst SrcPtr & \nsrc, \n\ntypename PtrTraits< SrcPtr >::value_type \nthresh \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ threshTrunc_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, ThreshTruncFunc< typename PtrTraits< SrcPtr >::value_type > > > cv::cudev::threshTrunc_ \n(\nconst SrcPtr & \nsrc, \n\ntypename PtrTraits< SrcPtr >::value_type \nthresh \n\n)\n\n#include <opencv2/cudev/expr/per_element_func.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ transformPtr() [1/2]\n\ntemplate<class Src1Ptr , class Src2Ptr , class Op > \n\n__host__ BinaryTransformPtrSz< typename PtrTraits< Src1Ptr >::ptr_type, typename PtrTraits< Src2Ptr >::ptr_type, Op > cv::cudev::transformPtr \n(\nconst Src1Ptr & \nsrc1, \n\nconst Src2Ptr & \nsrc2, \n\nconst Op & \nop \n\n)\n\n#include <opencv2/cudev/ptr2d/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ transformPtr() [2/2]\n\ntemplate<class SrcPtr , class Op > \n\n__host__ UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, Op > cv::cudev::transformPtr \n(\nconst SrcPtr & \nsrc, \n\nconst Op & \nop \n\n)\n\n#include <opencv2/cudev/ptr2d/transform.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ transpose_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< TransposeBody< SrcPtr > > cv::cudev::transpose_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ unaryTupleAdapter()\n\ntemplate<int n, class Op > \n\n__host__ __device__ UnaryTupleAdapter< Op, n > cv::cudev::unaryTupleAdapter \n(\nconst Op & \nop)\n\n#include <opencv2/cudev/functional/tuple_adapter.hpp>\n\n◆ vabsdiff2()\n\n__device__ __forceinline__ uint cv::cudev::vabsdiff2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vabsdiff4()\n\n__device__ __forceinline__ uint cv::cudev::vabsdiff4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vadd2()\n\n__device__ __forceinline__ uint cv::cudev::vadd2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vadd4()\n\n__device__ __forceinline__ uint cv::cudev::vadd4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vavg2()\n\n__device__ __forceinline__ uint cv::cudev::vavg2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vavg4()\n\n__device__ __forceinline__ uint cv::cudev::vavg4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vavrg2()\n\n__device__ __forceinline__ uint cv::cudev::vavrg2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vavrg4()\n\n__device__ __forceinline__ uint cv::cudev::vavrg4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vcmpeq2()\n\n__device__ __forceinline__ uint cv::cudev::vcmpeq2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpeq4()\n\n__device__ __forceinline__ uint cv::cudev::vcmpeq4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpge2()\n\n__device__ __forceinline__ uint cv::cudev::vcmpge2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpge4()\n\n__device__ __forceinline__ uint cv::cudev::vcmpge4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpgt2()\n\n__device__ __forceinline__ uint cv::cudev::vcmpgt2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpgt4()\n\n__device__ __forceinline__ uint cv::cudev::vcmpgt4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmple2()\n\n__device__ __forceinline__ uint cv::cudev::vcmple2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmple4()\n\n__device__ __forceinline__ uint cv::cudev::vcmple4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmplt2()\n\n__device__ __forceinline__ uint cv::cudev::vcmplt2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmplt4()\n\n__device__ __forceinline__ uint cv::cudev::vcmplt4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpne2()\n\n__device__ __forceinline__ uint cv::cudev::vcmpne2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vcmpne4()\n\n__device__ __forceinline__ uint cv::cudev::vcmpne4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vmax2()\n\n__device__ __forceinline__ uint cv::cudev::vmax2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vmax4()\n\n__device__ __forceinline__ uint cv::cudev::vmax4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vmin2()\n\n__device__ __forceinline__ uint cv::cudev::vmin2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vmin4()\n\n__device__ __forceinline__ uint cv::cudev::vmin4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vseteq2()\n\n__device__ __forceinline__ uint cv::cudev::vseteq2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vseteq4()\n\n__device__ __forceinline__ uint cv::cudev::vseteq4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vsetge2()\n\n__device__ __forceinline__ uint cv::cudev::vsetge2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetge4()\n\n__device__ __forceinline__ uint cv::cudev::vsetge4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetgt2()\n\n__device__ __forceinline__ uint cv::cudev::vsetgt2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetgt4()\n\n__device__ __forceinline__ uint cv::cudev::vsetgt4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetle2()\n\n__device__ __forceinline__ uint cv::cudev::vsetle2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetle4()\n\n__device__ __forceinline__ uint cv::cudev::vsetle4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetlt2()\n\n__device__ __forceinline__ uint cv::cudev::vsetlt2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetlt4()\n\n__device__ __forceinline__ uint cv::cudev::vsetlt4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ vsetne2()\n\n__device__ __forceinline__ uint cv::cudev::vsetne2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vsetne4()\n\n__device__ __forceinline__ uint cv::cudev::vsetne4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vsub2()\n\n__device__ __forceinline__ uint cv::cudev::vsub2 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ vsub4()\n\n__device__ __forceinline__ uint cv::cudev::vsub4 \n(\nuint \na, \n\nuint \nb \n\n)\n\n#include <opencv2/cudev/util/simd_functions.hpp>\n\n◆ warpAffine_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, AffineMapPtr > > cv::cudev::warpAffine_ \n(\nconst SrcPtr & \nsrc, \n\nSize \ndstSize, \n\nconst GpuMat_< float > & \nwarpMat \n\n)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpAffinePtr()\n\ntemplate<class SrcPtr > \n\n__host__ RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, AffineMapPtr > cv::cudev::warpAffinePtr \n(\nconst SrcPtr & \nsrc, \n\nSize \ndstSize, \n\nconst GpuMat_< float > & \nwarpMat \n\n)\n\n#include <opencv2/cudev/ptr2d/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpCopy()\n\ntemplate<class InIt , class OutIt > \n\n__device__ __forceinline__ OutIt cv::cudev::warpCopy \n(\nInIt \nbeg, \n\nInIt \nend, \n\nOutIt \nout \n\n)\n\n#include <opencv2/cudev/warp/warp.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpFill()\n\ntemplate<class It , typename T > \n\n__device__ __forceinline__ void cv::cudev::warpFill \n(\nIt \nbeg, \n\nIt \nend, \n\nconst T & \nvalue \n\n)\n\n#include <opencv2/cudev/warp/warp.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpPerspective_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, PerspectiveMapPtr > > cv::cudev::warpPerspective_ \n(\nconst SrcPtr & \nsrc, \n\nSize \ndstSize, \n\nconst GpuMat_< float > & \nwarpMat \n\n)\n\n#include <opencv2/cudev/expr/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpPerspectivePtr()\n\ntemplate<class SrcPtr > \n\n__host__ RemapPtr1Sz< typename PtrTraits< SrcPtr >::ptr_type, PerspectiveMapPtr > cv::cudev::warpPerspectivePtr \n(\nconst SrcPtr & \nsrc, \n\nSize \ndstSize, \n\nconst GpuMat_< float > & \nwarpMat \n\n)\n\n#include <opencv2/cudev/ptr2d/warping.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpReduce() [1/2]\n\ntemplate<typename P0 , typename P1 , typename P2 , typename P3 , typename P4 , typename P5 , typename P6 , typename P7 , typename P8 , typename P9 , typename R0 , typename R1 , typename R2 , typename R3 , typename R4 , typename R5 , typename R6 , typename R7 , typename R8 , typename R9 , class Op0 , class Op1 , class Op2 , class Op3 , class Op4 , class Op5 , class Op6 , class Op7 , class Op8 , class Op9 > \n\n__device__ __forceinline__ void cv::cudev::warpReduce \n(\nconst tuple< P0, P1, P2, P3, P4, P5, P6, P7, P8, P9 > & \nsmem, \n\nconst tuple< R0, R1, R2, R3, R4, R5, R6, R7, R8, R9 > & \nval, \n\nuint \ntid, \n\nconst tuple< Op0, Op1, Op2, Op3, Op4, Op5, Op6, Op7, Op8, Op9 > & \nop \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpReduce() [2/2]\n\ntemplate<typename T , class Op > \n\n__device__ __forceinline__ void cv::cudev::warpReduce \n(\nvolatile T * \nsmem, \n\nT & \nval, \n\nuint \ntid, \n\nconst Op & \nop \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ warpReduceKeyVal() [1/3]\n\ntemplate<typename KP0 , typename KP1 , typename KP2 , typename KP3 , typename KP4 , typename KP5 , typename KP6 , typename KP7 , typename KP8 , typename KP9 , typename KR0 , typename KR1 , typename KR2 , typename KR3 , typename KR4 , typename KR5 , typename KR6 , typename KR7 , typename KR8 , typename KR9 , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp0 , class Cmp1 , class Cmp2 , class Cmp3 , class Cmp4 , class Cmp5 , class Cmp6 , class Cmp7 , class Cmp8 , class Cmp9 > \n\n__device__ __forceinline__ void cv::cudev::warpReduceKeyVal \n(\nconst tuple< KP0, KP1, KP2, KP3, KP4, KP5, KP6, KP7, KP8, KP9 > & \nskeys, \n\nconst tuple< KR0, KR1, KR2, KR3, KR4, KR5, KR6, KR7, KR8, KR9 > & \nkey, \n\nconst tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > & \nsvals, \n\nconst tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > & \nval, \n\nuint \ntid, \n\nconst tuple< Cmp0, Cmp1, Cmp2, Cmp3, Cmp4, Cmp5, Cmp6, Cmp7, Cmp8, Cmp9 > & \ncmp \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpReduceKeyVal() [2/3]\n\ntemplate<typename K , typename VP0 , typename VP1 , typename VP2 , typename VP3 , typename VP4 , typename VP5 , typename VP6 , typename VP7 , typename VP8 , typename VP9 , typename VR0 , typename VR1 , typename VR2 , typename VR3 , typename VR4 , typename VR5 , typename VR6 , typename VR7 , typename VR8 , typename VR9 , class Cmp > \n\n__device__ __forceinline__ void cv::cudev::warpReduceKeyVal \n(\nvolatile K * \nskeys, \n\nK & \nkey, \n\nconst tuple< VP0, VP1, VP2, VP3, VP4, VP5, VP6, VP7, VP8, VP9 > & \nsvals, \n\nconst tuple< VR0, VR1, VR2, VR3, VR4, VR5, VR6, VR7, VR8, VR9 > & \nval, \n\nuint \ntid, \n\nconst Cmp & \ncmp \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpReduceKeyVal() [3/3]\n\ntemplate<typename K , typename V , class Cmp > \n\n__device__ __forceinline__ void cv::cudev::warpReduceKeyVal \n(\nvolatile K * \nskeys, \n\nK & \nkey, \n\nvolatile V * \nsvals, \n\nV & \nval, \n\nuint \ntid, \n\nconst Cmp & \ncmp \n\n)\n\n#include <opencv2/cudev/warp/reduce.hpp>\n\n◆ warpScanExclusive()\n\ntemplate<typename T > \n\n__device__ __forceinline__ T cv::cudev::warpScanExclusive \n(\nT \ndata, \n\nvolatile T * \nsmem, \n\nuint \ntid \n\n)\n\n#include <opencv2/cudev/warp/scan.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpScanInclusive()\n\ntemplate<typename T > \n\n__device__ T cv::cudev::warpScanInclusive \n(\nT \ndata, \n\nvolatile T * \nsmem, \n\nuint \ntid \n\n)\n\n#include <opencv2/cudev/warp/scan.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpTransform() [1/2]\n\ntemplate<class InIt , class OutIt , class UnOp > \n\n__device__ __forceinline__ OutIt cv::cudev::warpTransform \n(\nInIt \nbeg, \n\nInIt \nend, \n\nOutIt \nout, \n\nconst UnOp & \nop \n\n)\n\n#include <opencv2/cudev/warp/warp.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpTransform() [2/2]\n\ntemplate<class InIt1 , class InIt2 , class OutIt , class BinOp > \n\n__device__ __forceinline__ OutIt cv::cudev::warpTransform \n(\nInIt1 \nbeg1, \n\nInIt1 \nend1, \n\nInIt2 \nbeg2, \n\nOutIt \nout, \n\nconst BinOp & \nop \n\n)\n\n#include <opencv2/cudev/warp/warp.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ warpYota()\n\ntemplate<typename OutIt , typename T > \n\n__device__ __forceinline__ void cv::cudev::warpYota \n(\nOutIt \nbeg, \n\nOutIt \nend, \n\nT \nvalue \n\n)\n\n#include <opencv2/cudev/warp/warp.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ XYZ4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ XYZ_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, XYZ_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::XYZ_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YCrCb_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YCrCb_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YCrCb_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV4_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV4_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV4_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV4_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV4_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV4_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV_to_BGR_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_BGR_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_BGR_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV_to_BGRA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_BGRA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_BGRA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV_to_RGB_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_RGB_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_RGB_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ YUV_to_RGBA_()\n\ntemplate<class SrcPtr > \n\n__host__ Expr< UnaryTransformPtrSz< typename PtrTraits< SrcPtr >::ptr_type, YUV_to_RGBA_func< typename VecTraits< typename PtrTraits< SrcPtr >::value_type >::elem_type > > > cv::cudev::YUV_to_RGBA_ \n(\nconst SrcPtr & \nsrc)\n\n#include <opencv2/cudev/expr/color.hpp>\n\n◆ zipPtr() [1/3]\n\ntemplate<class Ptr0 , class Ptr1 > \n\n__host__ ZipPtrSz< tuple< typename PtrTraits< Ptr0 >::ptr_type, typename PtrTraits< Ptr1 >::ptr_type > > cv::cudev::zipPtr \n(\nconst Ptr0 & \nptr0, \n\nconst Ptr1 & \nptr1 \n\n)\n\n#include <opencv2/cudev/ptr2d/zip.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ zipPtr() [2/3]\n\ntemplate<class Ptr0 , class Ptr1 , class Ptr2 > \n\n__host__ ZipPtrSz< tuple< typename PtrTraits< Ptr0 >::ptr_type, typename PtrTraits< Ptr1 >::ptr_type, typename PtrTraits< Ptr2 >::ptr_type > > cv::cudev::zipPtr \n(\nconst Ptr0 & \nptr0, \n\nconst Ptr1 & \nptr1, \n\nconst Ptr2 & \nptr2 \n\n)\n\n#include <opencv2/cudev/ptr2d/zip.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ zipPtr() [3/3]\n\ntemplate<class Ptr0 , class Ptr1 , class Ptr2 , class Ptr3 > \n\n__host__ ZipPtrSz< tuple< typename PtrTraits< Ptr0 >::ptr_type, typename PtrTraits< Ptr1 >::ptr_type, typename PtrTraits< Ptr2 >::ptr_type, typename PtrTraits< Ptr3 >::ptr_type > > cv::cudev::zipPtr \n(\nconst Ptr0 & \nptr0, \n\nconst Ptr1 & \nptr1, \n\nconst Ptr2 & \nptr2, \n\nconst Ptr3 & \nptr3 \n\n)\n\n#include <opencv2/cudev/ptr2d/zip.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nVariable Documentation\n\n◆ cols\n\ntemplate<class T , class R  = T> \n\nint cv::cudev::Texture< T, R >::cols = 0\n\n◆ rows\n\ntemplate<class T , class R  = T> \n\nint cv::cudev::Texture< T, R >::rows = 0\n\n◆ texture\n\ntemplate<class T , class R  = T> \n\nstd::shared_ptr<UniqueTexture<T, R> > cv::cudev::Texture< T, R >::texture = 0\n\nprotected \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d5/df6/group__dnn__objdetect.html","content_type":"text/html","title":"OpenCV: DNN used for object detection","language":null},"page_content":"OpenCV: DNN used for object detection\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nDNN used for object detection\n\nDetailed Description\n\nClasses\nclass  cv::dnn_objdetect::InferBbox\n A class to post process model predictions.  More...\n \nstruct  cv::dnn_objdetect::object\n Structure to hold the details pertaining to a single bounding box.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/dfc/group__freetype.html","content_type":"text/html","title":"OpenCV: Drawing UTF-8 strings with freetype/harfbuzz","language":null},"page_content":"OpenCV: Drawing UTF-8 strings with freetype/harfbuzz\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nDrawing UTF-8 strings with freetype/harfbuzz\n\nDetailed Description\nThis modules is to draw UTF-8 strings with freetype/harfbuzz.\n\nInstall freetype2 and harfbuzz in your system.\nCreate FreeType2 instance with createFreeType2() function.\nLoad font file with loadFontData() function.\nDraw text with putText() function.\n\nIf thickness parameter is negative, drawing glyph is filled.\nIf thickness parameter is positive, drawing glyph is outlined with thickness.\nIf line_type parameter is 16(or CV_AA), drawing glyph is smooth. \n\nClasses\nclass  cv::freetype::FreeType2\n \n\nFunctions\nPtr< FreeType2 > cv::freetype::createFreeType2 ()\n Create FreeType2 Instance.  \n \n\nFunction Documentation\n\n◆ createFreeType2()\n\nPtr< FreeType2 > cv::freetype::createFreeType2 \n(\n)\n\n#include <opencv2/freetype.hpp>\nCreate FreeType2 Instance. \nThe function createFreeType2 create instance to draw UTF-8 strings. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/d19/group__mcc.html","content_type":"text/html","title":"OpenCV: Macbeth Chart module","language":null},"page_content":"OpenCV: Macbeth Chart module\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nEnumerations \nMacbeth Chart module\n\nModules\n Color Correction Model\n \n\nDetailed Description\n\nIntroduction\nColorCharts are a tool for calibrating the color profile of camera, which not only depends on the intrinsic and extrinsic parameters of camera but also on the lighting conditions. This is done by taking the image of a chart, such that the value of its colors present in it known, in the image the color values changes depeding on many variables, this gives us the colors initially present and the colors that are present in the image, based on this information we can apply any suitable algorithm to find the actual color of all the objects present in the image. \n\nClasses\nclass  cv::mcc::CChecker\n checker object  More...\n \nclass  cv::mcc::CCheckerDetector\n A class to find the positions of the ColorCharts in the image.  More...\n \nclass  cv::mcc::CCheckerDraw\n checker draw  More...\n \nstruct  cv::mcc::DetectorParameters\n Parameters for the detectMarker process:  More...\n \n\nEnumerations\nenum  cv::mcc::TYPECHART { \n  cv::mcc::MCC24 = 0\n, \n  cv::mcc::SG140\n, \n  cv::mcc::VINYL18\n\n }\n enum to hold the type of the checker  More...\n \n\nEnumeration Type Documentation\n\n◆ TYPECHART\n\nenum cv::mcc::TYPECHART\n\n#include <opencv2/mcc/checker_model.hpp>\nenum to hold the type of the checker \nTYPECHART\n\nEnumeratorMCC24 Python: cv.mcc.MCC24Standard Macbeth Chart with 24 squares. \n\nSG140 Python: cv.mcc.SG140DigitalSG with 140 squares. \n\nVINYL18 Python: cv.mcc.VINYL18DKK color chart with 12 squares and 6 rectangle. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/df/d3a/group__phase__unwrapping.html","content_type":"text/html","title":"OpenCV: Phase Unwrapping API","language":null},"page_content":"OpenCV: Phase Unwrapping API\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nPhase Unwrapping API\n\nDetailed Description\nTwo-dimensional phase unwrapping is found in different applications like terrain elevation estimation in synthetic aperture radar (SAR), field mapping in magnetic resonance imaging or as a way of finding corresponding pixels in structured light reconstruction with sinusoidal patterns.\nGiven a phase map, wrapped between [-pi; pi], phase unwrapping aims at finding the \"true\" phase map by adding the right number of 2*pi to each pixel.\nThe problem is straightforward for perfect wrapped phase map, but real data are usually not noise-free. Among the different algorithms that were developed, quality-guided phase unwrapping methods are fast and efficient. They follow a path that unwraps high quality pixels first, avoiding error propagation from the start.\nIn this module, a quality-guided phase unwrapping is implemented following the approach described in [157] . \n\nClasses\nclass  cv::phase_unwrapping::HistogramPhaseUnwrapping\n Class implementing two-dimensional phase unwrapping based on [157] This algorithm belongs to the quality-guided phase unwrapping methods. First, it computes a reliability map from second differences between a pixel and its eight neighbours. Reliability values lie between 0 and 16*pi*pi. Then, this reliability map is used to compute the reliabilities of \"edges\". An edge is an entity defined by two pixels that are connected horizontally or vertically. Its reliability is found by adding the the reliabilities of the two pixels connected through it. Edges are sorted in a histogram based on their reliability values. This histogram is then used to unwrap pixels, starting from the highest quality pixel.  More...\n \nclass  cv::phase_unwrapping::PhaseUnwrapping\n Abstract base class for phase unwrapping.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/ded/group__ml.html","content_type":"text/html","title":"OpenCV: Machine Learning","language":null},"page_content":"OpenCV: Machine Learning\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nTypedefs |\nEnumerations |\nFunctions \nMachine Learning\n\nDetailed Description\nThe Machine Learning Library (MLL) is a set of classes and functions for statistical classification, regression, and clustering of data.\nMost of the classification and regression algorithms are implemented as C++ classes. As the algorithms have different sets of features (like an ability to handle missing measurements or categorical input variables), there is a little common ground between the classes. This common ground is defined by the class cv::ml::StatModel that all the other ML classes are derived from.\nSee detailed overview here: Machine Learning Overview. \n\nClasses\nclass  cv::ml::ANN_MLP\n Artificial Neural Networks - Multi-Layer Perceptrons.  More...\n \nclass  cv::ml::Boost\n Boosted tree classifier derived from DTrees.  More...\n \nclass  cv::ml::DTrees\n The class represents a single decision tree or a collection of decision trees.  More...\n \nclass  cv::ml::EM\n The class implements the Expectation Maximization algorithm.  More...\n \nclass  cv::ml::KNearest\n The class implements K-Nearest Neighbors model.  More...\n \nclass  cv::ml::LogisticRegression\n Implements Logistic Regression classifier.  More...\n \nclass  cv::ml::NormalBayesClassifier\n Bayes classifier for normally distributed data.  More...\n \nclass  cv::ml::ParamGrid\n The structure represents the logarithmic grid range of statmodel parameters.  More...\n \nclass  cv::ml::RTrees\n The class implements the random forest predictor.  More...\n \nstruct  cv::ml::SimulatedAnnealingSolverSystem\n This class declares example interface for system state used in simulated annealing optimization algorithm.  More...\n \nclass  cv::ml::StatModel\n Base class for statistical models in OpenCV ML.  More...\n \nclass  cv::ml::SVM\n Support Vector Machines.  More...\n \nclass  cv::ml::SVMSGD\n Stochastic Gradient Descent SVM classifier.  More...\n \nclass  cv::ml::TrainData\n Class encapsulating training data.  More...\n \n\nTypedefs\ntypedef ANN_MLP cv::ml::ANN_MLP_ANNEAL\n \n\nEnumerations\nenum  cv::ml::ErrorTypes { \n  cv::ml::TEST_ERROR = 0\n, \n  cv::ml::TRAIN_ERROR = 1\n\n }\n Error types  More...\n \nenum  cv::ml::SampleTypes { \n  cv::ml::ROW_SAMPLE = 0\n, \n  cv::ml::COL_SAMPLE = 1\n\n }\n Sample types.  More...\n \nenum  cv::ml::VariableTypes { \n  cv::ml::VAR_NUMERICAL =0\n, \n  cv::ml::VAR_ORDERED =0\n, \n  cv::ml::VAR_CATEGORICAL =1\n\n }\n Variable types.  More...\n \n\nFunctions\nvoid cv::ml::createConcentricSpheresTestSet (int nsamples, int nfeatures, int nclasses, OutputArray samples, OutputArray responses)\n Creates test set.  \n \nvoid cv::ml::randMVNormal (InputArray mean, InputArray cov, int nsamples, OutputArray samples)\n Generates sample from multivariate normal distribution.  \n \ntemplate<class SimulatedAnnealingSolverSystem > \nint cv::ml::simulatedAnnealingSolver (SimulatedAnnealingSolverSystem &solverSystem, double initialTemperature, double finalTemperature, double coolingRatio, size_t iterationsPerStep, double *lastTemperature=NULL, cv::RNG &rngEnergy=cv::theRNG())\n The class implements simulated annealing for optimization.  \n \n\nTypedef Documentation\n\n◆ ANN_MLP_ANNEAL\n\ntypedef ANN_MLP cv::ml::ANN_MLP_ANNEAL\n\n#include <opencv2/ml.hpp>\n\nEnumeration Type Documentation\n\n◆ ErrorTypes\n\nenum cv::ml::ErrorTypes\n\n#include <opencv2/ml.hpp>\nError types \n\nEnumeratorTEST_ERROR Python: cv.ml.TEST_ERROR\nTRAIN_ERROR Python: cv.ml.TRAIN_ERROR\n\n◆ SampleTypes\n\nenum cv::ml::SampleTypes\n\n#include <opencv2/ml.hpp>\nSample types. \n\nEnumeratorROW_SAMPLE Python: cv.ml.ROW_SAMPLEeach training sample is a row of samples \n\nCOL_SAMPLE Python: cv.ml.COL_SAMPLEeach training sample occupies a column of samples \n\n◆ VariableTypes\n\nenum cv::ml::VariableTypes\n\n#include <opencv2/ml.hpp>\nVariable types. \n\nEnumeratorVAR_NUMERICAL Python: cv.ml.VAR_NUMERICALsame as VAR_ORDERED \n\nVAR_ORDERED Python: cv.ml.VAR_ORDEREDordered variables \n\nVAR_CATEGORICAL Python: cv.ml.VAR_CATEGORICALcategorical variables \n\nFunction Documentation\n\n◆ createConcentricSpheresTestSet()\n\nvoid cv::ml::createConcentricSpheresTestSet \n(\nint \nnsamples, \n\nint \nnfeatures, \n\nint \nnclasses, \n\nOutputArray \nsamples, \n\nOutputArray \nresponses \n\n)\n\n#include <opencv2/ml.hpp>\nCreates test set. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ randMVNormal()\n\nvoid cv::ml::randMVNormal \n(\nInputArray \nmean, \n\nInputArray \ncov, \n\nint \nnsamples, \n\nOutputArray \nsamples \n\n)\n\n#include <opencv2/ml.hpp>\nGenerates sample from multivariate normal distribution. \nParameters\n\nmeanan average row vector \ncovsymmetric covariation matrix \nnsamplesreturned samples count \nsamplesreturned samples array \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ simulatedAnnealingSolver()\n\ntemplate<class SimulatedAnnealingSolverSystem > \n\nint cv::ml::simulatedAnnealingSolver \n(\nSimulatedAnnealingSolverSystem & \nsolverSystem, \n\ndouble \ninitialTemperature, \n\ndouble \nfinalTemperature, \n\ndouble \ncoolingRatio, \n\nsize_t \niterationsPerStep, \n\ndouble * \nlastTemperature = NULL, \n\ncv::RNG & \nrngEnergy = cv::theRNG() \n\n)\n\n#include <opencv2/ml.hpp>\nThe class implements simulated annealing for optimization. \n[147] for details\nParameters\n\nsolverSystemoptimization system (see SimulatedAnnealingSolverSystem) \ninitialTemperatureinitial temperature \nfinalTemperaturefinal temperature \ncoolingRatiotemperature step multiplies \niterationsPerStepnumber of iterations per temperature changing step \nlastTemperatureoptional output for last used temperature \nrngEnergyspecify custom random numbers generator (cv::theRNG() by default) \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/d90/group__structured__light.html","content_type":"text/html","title":"OpenCV: Structured Light API","language":null},"page_content":"OpenCV: Structured Light API\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations \nStructured Light API\n\nDetailed Description\nStructured light is considered one of the most effective techniques to acquire 3D models. This technique is based on projecting a light pattern and capturing the illuminated scene from one or more points of view. Since the pattern is coded, correspondences between image points and points of the projected pattern can be quickly found and 3D information easily retrieved.\nOne of the most commonly exploited coding strategies is based on trmatime-multiplexing. In this case, a set of patterns are successively projected onto the measuring surface. The codeword for a given pixel is usually formed by the sequence of illuminance values for that pixel across the projected patterns. Thus, the codification is called temporal because the bits of the codewords are multiplexed in time [233] .\nIn this module a time-multiplexing coding strategy based on Gray encoding is implemented following the (stereo) approach described in 3DUNDERWORLD algorithm [124] . For more details, see Structured Light tutorials. \n\nClasses\nclass  cv::structured_light::GrayCodePattern\n Class implementing the Gray-code pattern, based on [124].  More...\n \nclass  cv::structured_light::SinusoidalPattern\n Class implementing Fourier transform profilometry (FTP) , phase-shifting profilometry (PSP) and Fourier-assisted phase-shifting profilometry (FAPS) based on [62].  More...\n \nclass  cv::structured_light::StructuredLightPattern\n Abstract base class for generating and decoding structured light patterns.  More...\n \n\nEnumerations\nenum  { \n  cv::structured_light::FTP = 0\n, \n  cv::structured_light::PSP = 1\n, \n  cv::structured_light::FAPS = 2\n\n }\n Type of sinusoidal pattern profilometry methods.  More...\n \nenum  { cv::structured_light::DECODE_3D_UNDERWORLD = 0\n }\n Type of the decoding algorithm.  More...\n \n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/structured_light/sinusoidalpattern.hpp>\nType of sinusoidal pattern profilometry methods. \n\nEnumeratorFTP Python: cv.structured_light.FTP\nPSP Python: cv.structured_light.PSP\nFAPS Python: cv.structured_light.FAPS\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/structured_light/structured_light.hpp>\nType of the decoding algorithm. \n\nEnumeratorDECODE_3D_UNDERWORLD Python: cv.structured_light.DECODE_3D_UNDERWORLDKyriakos Herakleous, Charalambos Poullis. \"3DUNDERWORLD-SLS: An Open-Source Structured-Light Scanning System for Rapid Geometry Acquisition\", arXiv preprint arXiv:1406.6595 (2014). \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/db/dfe/group__plot.html","content_type":"text/html","title":"OpenCV: Plot function for Mat data","language":null},"page_content":"OpenCV: Plot function for Mat data\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nPlot function for Mat data\n\nDetailed Description\n\nClasses\nclass  cv::plot::Plot2d\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d0/de3/citelist.html","content_type":"text/html","title":"OpenCV: Bibliography","language":null},"page_content":"OpenCV: Bibliography\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nBibliography\n\n[1]\nRadhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Susstrunk. Slic superpixels compared to state-of-the-art superpixel methods. IEEE Trans. Pattern Anal. Mach. Intell., 34(11):2274–2282, nov 2012. \n\n[2]\nMotilal Agrawal, Kurt Konolige, and Morten Rufus Blas. Censure: Center surround extremas for realtime feature detection and matching. In Computer Vision–ECCV 2008, pages 102–115. Springer, 2008.\n\n[3]\nTimo Ahonen, Abdenour Hadid, and Matti Pietikäinen. Face recognition with local binary patterns. In Computer vision-eccv 2004, pages 469–481. Springer, 2004.\n\n[4]\nCuneyt Akinlar and Cihan Topal. Edlines: A real-time line segment detector with a false detection control. Pattern Recognition Letters, 32(13):1633–1642, 2011.\n\n[5]\nCuneyt Akinlar and Cihan Topal. Edpf: a real-time parameter-free edge segment detector with a false detection control. International Journal of Pattern Recognition and Artificial Intelligence, 26(01):1255002, 2012.\n\n[6]\nCuneyt Akinlar and Cihan Topal. Edcircles: A real-time circle detector with a false detection control. Pattern Recognition, 46(3):725–740, 2013.\n\n[7]\nYagiz Aksoy, Tunc Ozan Aydin, and Marc Pollefeys. Designing effective inter-pixel information flow for natural image matting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 29–37, 2017.\n\n[8]\nAlexandre Alahi, Raphael Ortiz, and Pierre Vandergheynst. Freak: Fast retina keypoint. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 510–517. IEEE, 2012.\n\n[9]\nPablo Fernández Alcantarilla, Adrien Bartoli, and Andrew J Davison. Kaze features. In Computer Vision–ECCV 2012, pages 214–227. Springer, 2012.\n\n[10]\nPablo Fernández Alcantarilla, Jesús Nuevo, and Adrien Bartoli. Fast explicit diffusion for accelerated features in nonlinear scale spaces. pages 13.1–13.11, 2013. \n\n[11]\nStefano Allegretti, Federico Bolelli, and Costantino Grana. Optimized block-based algorithms to label connected components on gpus. IEEE Transactions on Parallel and Distributed Systems, 31(2):423–438, 2019.\n\n[12]\nNicolas Andreff, Radu Horaud, and Bernard Espiau. On-line hand-eye calibration. In Proceedings of the 2Nd International Conference on 3-D Digital Imaging and Modeling, 3DIM'99, pages 430–436, Washington, DC, USA, 1999. IEEE Computer Society.\n\n[13]\nRelja Arandjelovic. Three things everyone should know to improve object retrieval. In Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), CVPR '12, pages 2911–2918, Washington, DC, USA, 2012. IEEE Computer Society.\n\n[14]\nBoris Babenko, Ming-Hsuan Yang, and Serge Belongie. Visual tracking with online multiple instance learning. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 983–990. IEEE, 2009.\n\n[15]\nDana H Ballard. Generalizing the hough transform to detect arbitrary shapes. Pattern recognition, 13(2):111–122, 1981.\n\n[16]\nDaniel Barath and Jiri Matas. Graph-cut ransac. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.\n\n[17]\nDaniel Barath, Maksym Ivashechkin, and Jiri Matas. Progressive napsac: sampling from gradually growing neighborhoods, 2019.\n\n[18]\nDaniel Barath, Jana Noskova, Maksym Ivashechkin, and Jiri Matas. Magsac++, a fast, reliable and accurate robust estimator. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.\n\n[19]\nJonathan T Barron and Ben Poole. The fast bilateral solver. In European Conference on Computer Vision (ECCV), pages 617–632. Springer International Publishing, 2016.\n\n[20]\nHerbert Bay, Tinne Tuytelaars, and Luc Van Gool. Surf: Speeded up robust features. Computer Vision–ECCV 2006, pages 404–417, 2006.\n\n[21]\nAsker M Bazen and Sabih H Gerez. Systematic methods for the computation of the directional fields and singular points of fingerprints. IEEE transactions on pattern analysis and machine intelligence, 24(7):905–919, 2002.\n\n[22]\nChristian Beecks, Merih Seran Uysal, and Thomas Seidl. Signature quadratic form distance. In CIVR, pages 438–445. ACM, 2010.\n\n[23]\nPeter N. Belhumeur, João P Hespanha, and David Kriegman. Eigenfaces vs. fisherfaces: Recognition using class specific linear projection. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 19(7):711–720, 1997.\n\n[24]\nAlexandre Benoit, Alice Caplier, Barthélémy Durette, and Jeanny Hérault. Using human visual system modeling for bio-inspired low level image processing. Computer vision and Image understanding, 114(7):758–773, 2010.\n\n[25]\nL Berger, V A Raghunathan, C Launay, D Ausserré, and Y Gallot. Coalescence in 2 dimensions: experiments on thin copolymer films and numerical simulations. The European Physical Journal B - Condensed Matter and Complex Systems, 2(1):93–99, 1998.\n\n[26]\nJiaWang Bian, Wen-Yan Lin, Yasuyuki Matsushita, Sai-Kit Yeung, Tan Dat Nguyen, and Ming-Ming Cheng. Gms: Grid-based motion statistics for fast, ultra-robust feature correspondence. In IEEE Conference on Computer Vision and Pattern Recognition, 2017.\n\n[27]\nJosef Bigun. Vision with direction. Springer, 2006.\n\n[28]\nStan Birchfield and Carlo Tomasi. A pixel dissimilarity measure that is insensitive to image sampling. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 20(4):401–406, 1998.\n\n[29]\nJose-Luis Blanco. A tutorial on se(3) transformation parameterizations and on-manifold optimization. Technical Report 012010, University of Malaga, 2010.\n\n[30]\nFederico Bolelli, Michele Cancilla, and Costantino Grana. Two More Strategies to Speed Up Connected Components Labeling Algorithms. In Image Analysis and Processing - ICIAP 2017, volume 10485, pages 48–58. Springer, 2017. \n\n[31]\nFederico Bolelli, Stefano Allegretti, Lorenzo Baraldi, and Costantino Grana. Spaghetti Labeling: Directed Acyclic Graphs for Block-Based Connected Components Labeling. IEEE Transactions on Image Processing, 29(1):1999–2012, 2019. \n\n[32]\nFederico Bolelli, Stefano Allegretti, and Costantino Grana. One dag to rule them all. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. \n\n[33]\nDavid S. Bolme, J. Ross Beveridge, Bruce A. Draper, and Man Lui Yui. Visual object tracking using adaptive correlation filters. In Conference on Computer Vision and Pattern Recognition (CVPR), 2010.\n\n[34]\nGunilla Borgefors. Distance transformations in digital images. Computer vision, graphics, and image processing, 34(3):344–371, 1986.\n\n[35]\nLéon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT'2010, pages 177–186. Springer, 2010.\n\n[36]\nJean-Yves Bouguet. Pyramidal implementation of the affine lucas kanade feature tracker description of the algorithm. Intel Corporation, 5, 2001.\n\n[37]\nJean-Yves Bouguet. Camera calibration tool box for matlab [eb/ol], 2004.\n\n[38]\nGR Bradski and J Davis. Motion segmentation and pose recognition with motion history gradients. In Applications of Computer Vision, 2000, Fifth IEEE Workshop on., pages 238–244. IEEE, 2000.\n\n[39]\nGary R Bradski. Computer vision face tracking for use in a perceptual user interface. 1998.\n\n[40]\nLeo Breiman, Jerome Friedman, Charles J Stone, and Richard A Olshen. Classification and regression trees. CRC press, 1984.\n\n[41]\nMatthew Brown and David G Lowe. Automatic panoramic image stitching using invariant features. International journal of computer vision, 74(1):59–73, 2007.\n\n[42]\nThomas Brox, Andres Bruhn, Nils Papenberg, and Joachim Weickert. High accuracy optical flow estimation based on a theory for warping. In Computer Vision-ECCV 2004, pages 25–36. Springer, 2004.\n\n[43]\nRoberto Brunelli and Tomaso Poggio. Face recognition through geometrical features. In Computer Vision—ECCV'92, pages 792–800. Springer, 1992.\n\n[44]\nAntoni Buades, Bartomeu Coll, and Jean-Michel Morel. Denoising image sequences does not require motion estimation. IEEE Conference on Advanced Video and Signal Based Surveillance, 2005., pages 70–74, 2005.\n\n[45]\nPeter J Burt and Edward H Adelson. A multiresolution spline with application to image mosaics. ACM Transactions on Graphics (TOG), 2(4):217–236, 1983.\n\n[46]\nGerPublished by ard J. Holzmann. Beyond Photography: The Digital Darkroom. Prentice Hall in 1988.\n\n[47]\nMichael Calonder, Vincent Lepetit, Christoph Strecha, and Pascal Fua. Brief: Binary robust independent elementary features. In Computer Vision–ECCV 2010, pages 778–792. Springer, 2010.\n\n[48]\nJohn Canny. A computational approach to edge detection. Pattern Analysis and Machine Intelligence, IEEE Transactions on, (6):679–698, 1986.\n\n[49]\nAntonin Chambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga, and Thomas Pock. An introduction to total variation for image analysis. Theoretical foundations and numerical methods for sparse recovery, 9:263–340, 2010.\n\n[50]\nChih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27, 2011.\n\n[51]\nFran c cois Chaumette and S. Hutchinson. Visual servo control, Part I: Basic approaches. IEEE Robotics and Automation Magazine, 13(4):82–90, 2006. \n\n[52]\nFran c cois Chaumette and S. Hutchinson. Visual servo control, Part I: Basic approaches. IEEE Robotics and Automation Magazine, 13(4):82–90, 2006. \n\n[53]\nFran c cois Chaumette and S. Hutchinson. Visual servo control, Part II: Advanced approaches. IEEE Robotics and Automation Magazine, 14(1):109–118, 2007. \n\n[54]\nMing-Ming Cheng, Ziming Zhang, Wen-Yan Lin, and Philip Torr. Bing: Binarized normed gradients for objectness estimation at 300fps. In IEEE CVPR, 2014.\n\n[55]\nDongliang Cheng, Brian Price, Scott Cohen, and Michael S Brown. Effective learning-based illuminant estimation using simple features. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1000–1008, 2015.\n\n[56]\nHojin Cho, Hyunjoon Lee, Henry Kang, and Seungyong Lee. Bilateral texture filtering. ACM Transactions on Graphics, 33(4):128:1–128:8, July 2014.\n\n[57]\nOndrej Chum and Jiri Matas. Matching with PROSAC - progressive sampling consensus. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2005.\n\n[58]\nOndrej Chum, Jiri Matas, and Josef Kittler. Locally optimized RANSAC. In DAGM, 2003.\n\n[59]\nOndrej Chum, Tomas Werner, and Jiri Matas. Epipolar geometry estimation via ransac benefits from the oriented epipolar constraint. In Proceedings of the 17th International Conference on Pattern Recognition. ICPR 2004, volume 1, pages 112–115 Vol.1, 2004.\n\n[60]\nOndrej Chum, Tomas Werner, and Jiri. Matas. Epipolar geometry estimation unaffected by the dominant plane. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2005.\n\n[61]\nToby Collins and Adrien Bartoli. Infinitesimal plane-based pose estimation. International Journal of Computer Vision, 109(3):252–286, 2014. \n\n[62]\nPengyu Cong, Zhiwei Xiong, Yueyi Zhang, Shenghui Zhao, and Feng Wu. Accurate dynamic 3d sensing with fourier-assisted phase shifting. IEEE Journal of Selected Topics in Signal Processing, 9(3):396–408, 2015.\n\n[63]\nNavneet Dalal and Bill Triggs. Histograms of oriented gradients for human detection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, pages 886–893. IEEE, 2005.\n\n[64]\nM. Danelljan, F.S. Khan, M. Felsberg, and J. van de Weijer. Adaptive color attributes for real-time visual tracking. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 1090–1097, June 2014. \n\n[65]\nKonstantinos Daniilidis. Hand-eye calibration using dual quaternions. International Journal of Robotics Research, 18:286–298, 1998.\n\n[66]\nJames W Davis and Aaron F Bobick. The representation and recognition of human movement using temporal templates. In Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on, pages 928–934. IEEE, 1997.\n\n[67]\nBrice Chaix De Lavarène, David Alleysson, Barthélémy Durette, and Jeanny Hérault. Efficient demosaicing through recursive filtering. In Image Processing, 2007. ICIP 2007. IEEE International Conference on, volume 2, pages II–189. IEEE, 2007.\n\n[68]\nPaul E Debevec and Jitendra Malik. Recovering high dynamic range radiance maps from photographs. In ACM SIGGRAPH 2008 classes, page 31. ACM, 2008.\n\n[69]\nFerdinando Di Martino, Vincenzo Loia, Irina Perfilieva, and Salvatore Sessa. An image coding/decoding method based on direct and inverse fuzzy transforms. International Journal of Approximate Reasoning, 48(1):110–131, 2008.\n\n[70]\nPiotr Dollár and C Lawrence Zitnick. Structured forests for fast edge detection. In Computer Vision (ICCV), 2013 IEEE International Conference on, pages 1841–1848. IEEE, 2013.\n\n[71]\nFrédéric Drago, Karol Myszkowski, Thomas Annen, and Norishige Chiba. Adaptive logarithmic mapping for displaying high contrast scenes. In Computer Graphics Forum, volume 22, pages 419–426. Wiley, 2003.\n\n[72]\nBertram Drost and Slobodan Ilic. 3d object detection and localization using multimodal point pair features. In 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), 2012 Second International Conference on, pages 9–16. IEEE, 2012.\n\n[73]\nTom Drummond and Roberto Cipolla. Real-time visual tracking of complex structures. IEEE Transactions on pattern analysis and machine intelligence, 24(7):932–946, 2002.\n\n[74]\nAlexander Duda and Udo Frese. Accurate detection and localization of checkerboard corners for calibration. In 29th British Machine Vision Conference. British Machine Vision Conference (BMVC-29), September 3-6, Newcastle, United Kingdom. BMVA Press, 2018.\n\n[75]\nRichard O Duda, Peter E Hart, and David G Stork. Pattern classification. John Wiley & Sons, 2012.\n\n[76]\nFrédo Durand and Julie Dorsey. Fast bilateral filtering for the display of high-dynamic-range images. In ACM Transactions on Graphics (TOG), volume 21, pages 257–266. ACM, 2002.\n\n[77]\nEthan Eade. Gauss-newton / levenberg-marquardt optimization, 2013.\n\n[78]\nEthan Eade. Lie groups for 2d and 3d transformation, 2017.\n\n[79]\nNiki Estner. Best way of segmenting veins in leaves.\n\n[80]\nGeorgios D Evangelidis and Emmanouil Z Psarakis. Parametric image alignment using enhanced correlation coefficient maximization. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 30(10):1858–1865, 2008.\n\n[81]\nZeev Farbman, Raanan Fattal, Dani Lischinski, and Richard Szeliski. Edge-preserving decompositions for multi-scale tone and detail manipulation. In ACM Transactions on Graphics (TOG), volume 27, page 67. ACM, 2008.\n\n[82]\nGunnar Farnebäck. Two-frame motion estimation based on polynomial expansion. In Image Analysis, pages 363–370. Springer, 2003. \n\n[83]\nSina Farsiu, Dirk Robinson, Michael Elad, and Peyman Milanfar. Fast and robust super-resolution. In Image Processing, 2003. ICIP 2003. Proceedings. 2003 International Conference on, volume 2, pages II–291. IEEE, 2003.\n\n[84]\nRaanan Fattal, Dani Lischinski, and Michael Werman. Gradient domain high dynamic range compression. In ACM Transactions on Graphics (TOG), volume 21, pages 249–256. ACM, 2002.\n\n[85]\nPedro Felzenszwalb and Daniel Huttenlocher. Distance transforms of sampled functions. Technical report, Cornell University, 2004.\n\n[86]\nPedro F Felzenszwalb and Daniel P Huttenlocher. Efficient graph-based image segmentation. volume 59, pages 167–181. Springer, 2004.\n\n[87]\nPedro F Felzenszwalb and Daniel P Huttenlocher. Efficient belief propagation for early vision. International journal of computer vision, 70(1):41–54, 2006.\n\n[88]\nPedro F Felzenszwalb, Ross B Girshick, and David McAllester. Cascade object detection with deformable part models. In Computer vision and pattern recognition (CVPR), 2010 IEEE conference on, pages 2241–2248. IEEE, 2010.\n\n[89]\nPedro F Felzenszwalb, Ross B Girshick, David McAllester, and Deva Ramanan. Object detection with discriminatively trained part-based models. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 32(9):1627–1645, 2010.\n\n[90]\nMartin A. Fischler and Robert C. Bolles. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. 24(6):381–395, jun 1981.\n\n[91]\nRonald A Fisher. The use of multiple measurements in taxonomic problems. Annals of eugenics, 7(2):179–188, 1936.\n\n[92]\nAndrew W Fitzgibbon and Robert B Fisher. A buyer's guide to conic fitting. In Proceedings of the 6th British conference on Machine vision (Vol. 2), pages 513–522. BMVA Press, 1995.\n\n[93]\nAndrew Fitzgibbon, Maurizio Pilu, and Robert B. Fisher. Direct least square fitting of ellipses. IEEE Transactions on Pattern Analysis and Machine Intelligence, 21(5):476–480, 1999. \n\n[94]\nPer-Erik Forssén. Maximally stable colour regions for recognition and matching. In Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on, pages 1–8. IEEE, 2007.\n\n[95]\nW FORSTNER. A fast operator for detection and precise location of distincs points, corners and center of circular features. In Proc. of the Intercommission Conference on Fast Processing of Photogrammetric Data, Interlaken, Switzerland, 1987, pages 281–305, 1987.\n\n[96]\nJerome Friedman, Trevor Hastie, and Robert Tibshirani. Additive logistic regression: a statistical view of boosting. 1998.\n\n[97]\nGuillermo Gallego and Anthony J. Yezzi. A compact formula for the derivative of a 3-d rotation in exponential coordinates. Journal of Mathematical Imaging and Vision, 51:378–384, 2014.\n\n[98]\nXiao-Shan Gao, Xiao-Rong Hou, Jianliang Tang, and Hang-Fei Cheng. Complete solution classification for the perspective-three-point problem. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 25(8):930–943, 2003.\n\n[99]\nS. Garrido-Jurado, R. Mu noz Salinas, F.J. Madrid-Cuevas, and M.J. Marín-Jiménez.\n\n[100]\nEduardo SL Gastal and Manuel M Oliveira. Domain transform for edge-aware image and video processing. In ACM Transactions on Graphics (TOG), volume 30, page 69. ACM, 2011.\n\n[101]\nEduardo SL Gastal and Manuel M Oliveira. Domain transform for edge-aware image and video processing. In ACM Transactions on Graphics (TOG), volume 30, page 69. ACM, 2011.\n\n[102]\nEduardo SL Gastal and Manuel M Oliveira. Adaptive manifolds for real-time high-dimensional filtering. ACM Transactions on Graphics (TOG), 31(4):33, 2012.\n\n[103]\nJonas Geistert, Tobias Senst, and Thomas Sikora. Robust local optical flow: Dense motion vector field interpolation. In Picture Coding Symposium, pages 1–5, 2016.\n\n[104]\nN. Genser, J. Seiler, F. Schilling, and A. Kaup. Signal and loss geometry aware frequency selective extrapolation for error concealment. In Proc. Picture Coding Symposium (PCS), pages 159–163, June 2018. \n\n[105]\nPascal Getreuer. Malvar-he-cutler linear image demosaicking. Image Processing on Line, 2011.\n\n[106]\nAndrew B Godbehere, Akihiro Matsukawa, and Ken Goldberg. Visual tracking of human visitors under variable-lighting conditions for a responsive audio art installation. In American Control Conference (ACC), 2012, pages 4305–4312. IEEE, 2012.\n\n[107]\nLluís Gómez and Dimosthenis Karatzas. Multi-script text extraction from natural scenes. In Proceedings of the 2013 12th International Conference on Document Analysis and Recognition, ICDAR '13, pages 467–471. IEEE Computer Society, 2013.\n\n[108]\nRafael C Gonzalez and others. Digital image fundamentals, digital imaging processing. 1987.\n\n[109]\nHelmut Grabner, Michael Grabner, and Horst Bischof. Real-time tracking via on-line boosting. In BMVC, volume 1, page 6, 2006.\n\n[110]\nCostantino Grana, Daniele Borghesani, and Rita Cucchiara. Optimized Block-Based Connected Components Labeling With Decision Trees. IEEE Transactions on Image Processing, 19(6):1596–1609, 2010. \n\n[111]\nS. Grosche, J. Seiler, and A. Kaup. Design techniques for incremental non-regular image sampling patterns. In Proc. IEEE International Conference on Imaging Systems and Techniques (IST), pages 1–6, Oct 2018. \n\n[112]\nS. Grosche, J. Seiler, and A. Kaup. Iterative optimization of quarter sampling masks for non-regular sampling sensors. In Proc. 25th IEEE International Conference on Image Processing (ICIP), pages 26–30, Oct 2018. \n\n[113]\nMatthias Grundmann, Vivek Kwatra, and Irfan Essa. Auto-directed video stabilization with robust l1 optimal camera paths. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 225–232. IEEE, 2011.\n\n[114]\nN Guil, José María Gonzalez-Linares, and Emilio L Zapata. Bidimensional shape detection using an invariant approach. Pattern Recognition, 32(6):1025–1038, 1999.\n\n[115]\nL. Guo, D. Xu, and Z. Qiang. Background subtraction using local svd binary pattern. In 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pages 1159–1167, June 2016. \n\n[116]\nChris Harris and Carl Stennett. Rapid-a video rate object tracker. In BMVC, pages 1–6, 1990.\n\n[117]\nRichard Hartley and Andrew Zisserman. Multiple view geometry in computer vision. Cambridge university press, 2003.\n\n[118]\nRichard I Hartley. Theory and practice of projective rectification. International Journal of Computer Vision, 35(2):115–127, 1999.\n\n[119]\nKaiming He and Jian Sun. Statistics of patch offsets for image completion. In Computer Vision–ECCV 2012, pages 16–29. Springer, 2012.\n\n[120]\nKaiming He and Jian Sun. Fast guided filter. arXiv preprint arXiv:1505.00996, 2015.\n\n[121]\nKaiming He, Jian Sun, and Xiaoou Tang. Guided image filtering. In Computer Vision–ECCV 2010, pages 1–14. Springer, 2010.\n\n[122]\nDavid Held, Sebastian Thrun, and Silvio Savarese. Learning to track at 100 fps with deep regression networks. In European Conference Computer Vision (ECCV), 2016.\n\n[123]\nJ. F. Henriques, R. Caseiro, P. Martins, and J. Batista. Exploiting the circulant structure of tracking-by-detection with kernels. In proceedings of the European Conference on Computer Vision, 2012.\n\n[124]\nKyriakos Herakleous and Charalambos Poullis. 3DUNDERWORLD-SLS: An Open-Source Structured-Light Scanning System for Rapid Geometry Acquisition. arXiv preprint arXiv:1406.6595, 2014.\n\n[125]\nJoel Hesch, Stergios Roumeliotis, and others. A direct least-squares (dls) method for pnp. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 383–390. IEEE, 2011.\n\n[126]\nHeiko Hirschmuller. Stereo processing by semiglobal matching and mutual information. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 30(2):328–341, 2008.\n\n[127]\nRadu Horaud and Fadi Dornaika. Hand-eye calibration. Int. J. Rob. Res., 14(3):195–210, June 1995. \n\n[128]\nXiaodi Hou and Liqing Zhang. Saliency detection: A spectral residual approach. In Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on, pages 1–8. IEEE, 2007.\n\n[129]\nL. Cormack H.R. Sheikh, Z. Wang and A.C. Bovik. Live image quality assessment database release 2. http://live.ece.utexas.edu/research/quality, 2005.\n\n[130]\nYinlin Hu, Yunsong Li, and Rui Song. Robust interpolation of correspondences for large displacement optical flow. In IEEE Conference on Computer Vision and Pattern Recognition, pages 481–489, 2017.\n\n[131]\nMing-Kuei Hu. Visual pattern recognition by moment invariants. Information Theory, IRE Transactions on, 8(2):179–187, 1962.\n\n[132]\nSeth A. Hutchinson, Gregory Hager, and Peter Corke. A tutorial on visual servo control. IEEE Trans. Robotics Autom., 12:651–670, 1996.\n\n[133]\nLluis Gomez i Bigorda and Dimosthenis Karatzas. A fast hierarchical method for multi-script and arbitrary oriented scene text extraction. CoRR, abs/1407.7504, 2014.\n\n[134]\nShahram Izadi, David Kim, Otmar Hilliges, David Molyneaux, Richard Newcombe, Pushmeet Kohli, Jamie Shotton, Steve Hodges, Dustin Freeman, Andrew Davison, and Andrew Fitzgibbon. Kinectfusion: Real-time 3d reconstruction and interaction using a moving depth camera. pages 559–568. ACM, October 2011.\n\n[135]\nBernd Jahne. Computer vision and applications: a guide for students and practitioners. Elsevier, 2000.\n\n[136]\nHerault Jeanny. Vision: Images, Signals and Neural Networks-Models of Neural Processing in Visual Perception. World Scientific, 2010.\n\n[137]\nQi Jia, Xin Fan, Zhongxuan Luo, Lianbo Song, and Tie Qiu. A fast ellipse detector using projective invariant pruning. IEEE Transactions on Image Processing, 26(8):3665–3679, 2017.\n\n[138]\nPakorn KaewTraKulPong and Richard Bowden. An improved adaptive background mixture model for real-time tracking with shadow detection. In Video-Based Surveillance Systems, pages 135–144. Springer, 2002.\n\n[139]\nPakorn KaewTraKulPong and Richard Bowden. An improved adaptive background mixture model for real-time tracking with shadow detection. In Video-Based Surveillance Systems, pages 135–144. Springer, 2002.\n\n[140]\nZdenek Kalal, Krystian Mikolajczyk, and Jiri Matas. Forward-backward error: Automatic detection of tracking failures. In Pattern Recognition (ICPR), 2010 20th International Conference on, pages 2756–2759. IEEE, 2010.\n\n[141]\nZdenek Kalal, Krystian Mikolajczyk, and Jiri Matas. Tracking-learning-detection. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 34(7):1409–1422, 2012.\n\n[142]\nTakeo Kanade. Picture processing system by computer complex and recognition of human faces. 1974.\n\n[143]\nJuho Kannala and Sami Brandt. A generic camera model and calibration method for conventional, wide-angle, and fish-eye lenses. IEEE transactions on pattern analysis and machine intelligence, 28:1335–40, 09 2006. \n\n[144]\nMichael Kass and Andrew Witkin. Analyzing oriented patterns. Computer vision, graphics, and image processing, 37(3):362–385, 1987.\n\n[145]\nTong Ke and Stergios Roumeliotis. An efficient algebraic solution to the perspective-three-point problem. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017.\n\n[146]\nKhurram Khurshid, Imran Siddiqi, Claudie Faure, and Nicole Vincent. Comparison of niblack inspired binarization methods for ancient documents. In IS&T/SPIE Electronic Imaging, pages 72470U–72470U. International Society for Optics and Photonics, 2009.\n\n[147]\nS. Kirkpatrick, C. D. Jr Gelatt, and M. P. Vecchi. Optimization by simulated annealing. Science, 220(4598):671–680, 1983.\n\n[148]\nVictor Klee and Michael C Laskowski. Finding the smallest triangles containing a given convex polygon. Journal of Algorithms, 6(3):359–375, 1985.\n\n[149]\nAdrian Ilie Kok-Lim Low. View frustum optimization to maximize object's image area. Journal of Graphics, (GPU, & Game) Tools (JGT), 8:3–15, 2003.\n\n[150]\nNeal Krawetz. Looks like it.\n\n[151]\nTill Kroeger, Radu Timofte, Dengxin Dai, and Luc Van Gool. Fast optical flow using dense inverse search. In Proceedings of the European Conference on Computer Vision (ECCV), 2016.\n\n[152]\nMartin Krulis, Jakub Lokoc, and Tomas Skopal. Efficient extraction of clustering-based feature signatures using GPU architectures. Multimedia Tools Appl., 75(13):8071–8103, 2016.\n\n[153]\nVivek Kwatra, Arno Schödl, Irfan Essa, Greg Turk, and Aaron Bobick. Graphcut textures: image and video synthesis using graph cuts. In ACM Transactions on Graphics (ToG), volume 22, pages 277–286. ACM, 2003.\n\n[154]\nCs425 lab: Intensity transformations and spatial filtering.\n\n[155]\nKuang-Chih Lee, Jeffrey Ho, and David Kriegman. Acquiring linear subspaces for face recognition under variable lighting. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 27(5):684–698, 2005.\n\n[156]\nJin Han Lee, Sehyung Lee, Guoxuan Zhang, Jongwoo Lim, Wan Kyun Chung, and Il Hong Suh. Outdoor place recognition in urban environments using straight lines. In 2014 IEEE International Conference on Robotics and Automation (ICRA), pages 5550–5557. IEEE, 2014.\n\n[157]\nHai Lei, Xin-yu Chang, Fei Wang, Xiao-Tang Hu, and Xiao-Dong Hu. A novel algorithm based on histogram processing of reliability for two-dimensional phase unwrapping. Optik-International Journal for Light and Electron Optics, 126(18):1640–1644, 2015.\n\n[158]\nVincent Lepetit, Francesc Moreno-Noguer, and Pascal Fua. Epnp: An accurate o (n) solution to the pnp problem. International journal of computer vision, 81(2):155–166, 2009.\n\n[159]\nStefan Leutenegger, Margarita Chli, and Roland Yves Siegwart. Brisk: Binary robust invariant scalable keypoints. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 2548–2555. IEEE, 2011.\n\n[160]\nMaxime Lhuillier and Long Quan. Robust dense matching using local and global geometric constraints. Proceedings-International Conference on Pattern Recognition, 15(1):968–972, 2000. \n\n[161]\nZhengqin Li and Jiansheng Chen. Superpixel segmentation using linear spectral clustering. June 2015.\n\n[162]\nLiyuan Li, Weimin Huang, Irene YH Gu, and Qi Tian. Foreground object detection from videos containing complex background. In Proceedings of the eleventh ACM international conference on Multimedia, pages 2–10. ACM, 2003.\n\n[163]\nAiguo Li, Lin Wang, and Defeng Wu. Simultaneous robot-world and hand-eye calibration using dual-quaternions and kronecker product. International Journal of Physical Sciences, 5:1530–1536, 2010.\n\n[164]\nXi Li, Weiming Hu, Chunhua Shen, Zhongfei Zhang, Anthony Dick, and Anton Van Den Hengel. A survey of appearance models in visual object tracking. ACM Transactions on Intelligent Systems and Technology (TIST), 4(4):58, 2013.\n\n[165]\nShengcai Liao, Xiangxin Zhu, Zhen Lei, Lun Zhang, and Stan Z Li. Learning multi-scale block local binary patterns for face recognition. In Advances in Biometrics, pages 828–837. Springer, 2007.\n\n[166]\nMinghui Liao, Baoguang Shi, Xiang Bai, Xinggang Wang, and Wenyu Liu. Textboxes: A fast text detector with a single deep neural network. In AAAI, 2017.\n\n[167]\nMinghui Liao, Zhaoyi Wan, Cong Yao, Kai Chen, and Xiang Bai. Real-time scene text detection with differentiable binarization. In Proc. AAAI, 2020.\n\n[168]\nRainer Lienhart and Jochen Maydt. An extended set of haar-like features for rapid object detection. In Image Processing. 2002. Proceedings. 2002 International Conference on, volume 1, pages I–900. IEEE, 2002.\n\n[169]\nJoseph J Lim, C Lawrence Zitnick, and Piotr Dollár. Sketch tokens: A learned mid-level representation for contour and object detection. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 3158–3165. IEEE, 2013.\n\n[170]\nYong-Jin Liu, Cheng-Chi Yu, Min-Jing Yu, and Ying He. Intrinsic manifold slic: A simple and efficient method for computing content-sensitive superpixels. volume PP, Washington, DC, USA, mar 2017. IEEE Computer Society. \n\n[171]\nSeng Cheong Loke, Bruce A MacDonald, Matthew Parsons, and Burkhard Claus Wünsche. Accelerated superpixel image segmentation with a parallelized dbscan algorithm. Journal of Real-Time Image Processing, pages 1–16, 2021.\n\n[172]\nH. Louhichi, T. Fournel, J. M. Lavest, and H. Ben Aissia. Self-calibration of scheimpflug cameras: an easy protocol. Meas. Sci. Technol., 18(8):2616–2622, 2007.\n\n[173]\nKok-Lim Low. Linear least-squares optimization for point-to-plane icp surface registration. Chapel Hill, University of North Carolina, 2004.\n\n[174]\nDavid G. Lowe. Distinctive image features from scale-invariant keypoints. Int. J. Comput. Vision, 60(2):91–110, November 2004. \n\n[175]\nStephanie Lowry and Henrik Andreasson. Logos: Local geometric support for high-outlier spatial verification. 2018 IEEE International Conference on Robotics and Automation (ICRA), pages 7262–7269, 2018. \n\n[176]\nCewu Lu, Li Xu, and Jiaya Jia. Contrast preserving decolorization. In Computational Photography (ICCP), 2012 IEEE International Conference on, pages 1–7. IEEE, 2012.\n\n[177]\nAlan Lukezic, Tom'as Voj'ir, Luka Cehovin Zajc, Jir'i Matas, and Matej Kristan. Discriminative correlation filter tracker with channel and spatial reliability. International Journal of Computer Vision, 2018.\n\n[178]\nYi Ma, Stefano Soatto, Jana Kosecka, and S. Shankar Sastry. An Invitation to 3-D Vision: From Images to Geometric Models. Springer, 2003.\n\n[179]\nK. Madsen, H. B. Nielsen, and O. Tingleff. Methods for non-linear least squares problems (2nd ed.), 2004.\n\n[180]\nElmar Mair, Gregory D. Hager, Darius Burschka, Michael Suppa, and Gerhard Hirzinger. Adaptive and generic corner detection based on the accelerated segment test. In European Conference on Computer Vision (ECCV'10), September 2010.\n\n[181]\nEzio Malis and Manuel Vargas. Deeper understanding of the homography decomposition for vision-based control. (RR-6303):90, 2007. \n\n[182]\nRafal Mantiuk, Karol Myszkowski, and Hans-Peter Seidel. A perceptual framework for contrast processing of high dynamic range images. ACM Transactions on Applied Perception (TAP), 3(3):286–308, 2006.\n\n[183]\nEric Marchand, Hideaki Uchiyama, and Fabien Spindler. Pose Estimation for Augmented Reality: A Hands-On Survey. IEEE Transactions on Visualization and Computer Graphics, 22(12):2633 – 2651, December 2016.\n\n[184]\nAleix M Martínez and Avinash C Kak. Pca versus lda. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 23(2):228–233, 2001.\n\n[185]\nJiri Matas and Ondrej Chum. Randomized ransac with sequential probability ratio test. Tenth IEEE International Conference on Computer Vision (ICCV) Volume 1, 2:1727–1732 Vol. 2, 2005.\n\n[186]\nJiri Matas, Charles Galambos, and Josef Kittler. Robust detection of lines using the progressive probabilistic hough transform. Computer Vision and Image Understanding, 78(1):119–137, 2000.\n\n[187]\nWolfram Mathematica. Ridge filter mathematica.\n\n[188]\nYasuyuki Matsushita, Eyal Ofek, Weina Ge, Xiaoou Tang, and Heung-Yeung Shum. Full-frame video stabilization with motion inpainting. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 28(7):1150–1163, 2006.\n\n[189]\nTom Mertens, Jan Kautz, and Frank Van Reeth. Exposure fusion. In Computer Graphics and Applications, 2007. PG'07. 15th Pacific Conference on, pages 382–390. IEEE, 2007.\n\n[190]\nKieron Messer, Josef Kittler, James Short, Guillaume Heusch, Fabien Cardinaux, Sebastien Marcel, Yann Rodriguez, Shiguang Shan, Yu Su, Wen Gao, and others. Performance characterisation of face recognition algorithms and their sensitivity to severe illumination changes. In Advances in Biometrics, pages 1–11. Springer, 2005.\n\n[191]\nFernand Meyer. Color image segmentation. In Image Processing and its Applications, 1992., International Conference on, pages 303–306. IET, 1992.\n\n[192]\nLaurence Meylan, David Alleysson, and Sabine Süsstrunk. Model of retinal local adaptation for the tone mapping of color filter array images. JOSA A, 24(9):2807–2816, 2007.\n\n[193]\nKrystian Mikolajczyk and Cordelia Schmid. Scale & affine invariant interest point detectors. International journal of computer vision, 60(1):63–86, 2004.\n\n[194]\nDongbo Min, Sunghwan Choi, Jiangbo Lu, Bumsub Ham, Kwanghoon Sohn, and Minh N Do. Fast global image smoothing based on weighted least squares. Image Processing, IEEE Transactions on, 23(12):5638–5653, 2014.\n\n[195]\nA. Mittal, A. K. Moorthy, and A. C. Bovik. Brisque software release. http://live.ece.utexas.edu/research/quality/BRISQUE_release.zip, 2011.\n\n[196]\nA. Mittal, A. K. Moorthy, and A. C. Bovik. No-reference image quality assessment in the spatial domain. IEEE Transactions on Image Processing, 21(12):4695–4708, 2012. \n\n[197]\nDennis Mitzel, Thomas Pock, Thomas Schoenemann, and Daniel Cremers. Video super resolution using duality based tv-l 1 optical flow. In Pattern Recognition, pages 432–441. Springer, 2009.\n\n[198]\nSebastian Montabone and Alvaro Soto. Human detection using a mobile platform and novel features derived from a visual saliency mechanism. In Image and Vision Computing, Vol. 28 Issue 3, pages 391–402. Elsevier, 2010.\n\n[199]\nAlexander Mordvintsev. Rof and tv-l1 denoising with primal-dual algorithm.\n\n[200]\nEric N. Mortensen and William A. Barrett. Intelligent scissors for image composition. In In Computer Graphics, SIGGRAPH Proceedings, pages 191–198, 1995.\n\n[201]\nMarius Muja and David G Lowe. Fast approximate nearest neighbors with automatic algorithm configuration. In VISAPP (1), pages 331–340, 2009.\n\n[202]\nD. Myatt, Philip Torr, Slawomir Nasuto, John Bishop, and R. Craddock. Napsac: High noise, high dimensional robust estimation - it's in the bag. In Proceedings of the British Machine Vision Conference (BMVC), 2002.\n\n[203]\nA. Zelensky K. Egiazarian M. Carli F. Battisti N. Ponomarenko, V. Lukin. Tid2008 - a database for evaluation of full-reference visual quality assessment metrics. Advances of Modern Radioelectronics, 10:30–45, 2009.\n\n[204]\nLukáš Neumann and Jiří Matas. Text localization in real-world images using efficiently pruned exhaustive search. In in Document Analysis and Recognition, 2011 International Conference on. IEEE, 2011, pages 687–691.\n\n[205]\nNeumann, Matas L., and J. Scene text localization and recognition. pages 3538–3545. IEEE, 2012.\n\n[206]\nRichard A. Newcombe, Dieter Fox, and Steven M. Seitz. Dynamicfusion: Reconstruction and tracking of non-rigid scenes in real-time. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.\n\n[207]\nWayne Niblack. An introduction to digital image processing. Strandberg Publishing Company, 1985.\n\n[208]\nDavid Nistér and Henrik Stewénius. Linear time maximally stable extremal regions. In Computer Vision–ECCV 2008, pages 183–196. Springer, 2008.\n\n[209]\nDavid Nistér. An efficient solution to the five-point relative pose problem. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 26(6):756–770, 2004.\n\n[210]\nMohammad Norouzi, Ali Punjani, and David J Fleet. Fast search in hamming space with multi-index hashing. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3108–3115. IEEE, 2012.\n\n[211]\nJoseph O'Rourke, Alok Aggarwal, Sanjeev Maddila, and Michael Baldwin. An optimal algorithm for finding minimal enclosing triangles. Journal of Algorithms, 7(2):258–269, 1986.\n\n[212]\nPhilippe Paillou. Detecting step edges in noisy sar images: a new linear operator. IEEE transactions on geoscience and remote sensing, 35(1):191–196, 1997.\n\n[213]\nF. C. Park and B. J. Martin. Robot sensor calibration: solving ax=xb on the euclidean group. IEEE Transactions on Robotics and Automation, 10(5):717–721, October 1994. \n\n[214]\nAdrian Penate-Sanchez, Juan Andrade-Cetto, and Francesc Moreno-Noguer. Exhaustive linearization for robust camera pose and focal length estimation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(10):2387–2400, 2013.\n\n[215]\nPatrick Pérez, Michel Gangnet, and Andrew Blake. Poisson image editing. In ACM Transactions on Graphics (TOG), volume 22, pages 313–318. ACM, 2003.\n\n[216]\nIrina Perfilieva and Pavel Vlasánek. Image reconstruction by means of F-transform. Knowledge-Based Systems, 70:55–63, 2014. \n\n[217]\nIrina Perfilieva, Petra Hod'áková, and Petr Hurtík. \\(<\\)-transform edge detector inspired by canny's algorithm. In Advances on Computational Intelligence, pages 230–239. Springer, 2012.\n\n[218]\nIrina Perfilieva, Petra Hodáková, and Petr Hurtík. Differentiation by the F-transform and application to edge detection. Fuzzy Sets and Systems, 2014.\n\n[219]\nIrina Perfilieva. Fuzzy transforms: Theory and applications. Fuzzy sets and systems, 157(8):993–1023, 2006.\n\n[220]\nE Persoon and King-Sun Fu. Shape discrimination using fourier descriptors. IEEE Transactions on Pattern Analysis and Machine Intelligence, 7(3):170–179, 1977.\n\n[221]\nJan Puzicha, Thomas Hofmann, and Joachim M Buhmann. Non-parametric similarity measures for unsupervised texture segmentation and image retrieval. In Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on, pages 267–272. IEEE, 1997.\n\n[222]\nRichard E. Woods Rafael C. Gonzalez. Digital Image Processing 4th Edition. Pearson, 2018.\n\n[223]\nSarunas J Raudys and Anil K. Jain. Small sample size effects in statistical pattern recognition: Recommendations for practitioners. IEEE Transactions on pattern analysis and machine intelligence, 13(3):252–264, 1991.\n\n[224]\nErik Reinhard and Kate Devlin. Dynamic range reduction inspired by photoreceptor physiology. Visualization and Computer Graphics, IEEE Transactions on, 11(1):13–24, 2005.\n\n[225]\nJerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, and Cordelia Schmid. Epicflow: Edge-preserving interpolation of correspondences for optical flow. In Computer Vision and Pattern Recognition (CVPR), IEEE Conference on, pages 1164–1172, 2015.\n\n[226]\nMartin Riedmiller and Heinrich Braun. A direct adaptive method for faster backpropagation learning: The rprop algorithm. In Neural Networks, 1993., IEEE International Conference on, pages 586–591. IEEE, 1993.\n\n[227]\nMark A Robertson, Sean Borman, and Robert L Stevenson. Dynamic range improvement through multiple exposures. In Image Processing, 1999. ICIP 99. Proceedings. 1999 International Conference on, volume 3, pages 159–163. IEEE, 1999.\n\n[228]\nEdward Rosten and Tom Drummond. Machine learning for high-speed corner detection. In Computer Vision–ECCV 2006, pages 430–443. Springer, 2006.\n\n[229]\nEthan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: an efficient alternative to sift or surf. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 2564–2571. IEEE, 2011.\n\n[230]\nYossi Rubner, Carlo Tomasi, and Leonidas J Guibas. The earth mover''s distance as a metric for image retrieval. 1998.\n\n[231]\nYossi Rubner, Carlo Tomasi, and Leonidas J Guibas. The earth mover's distance as a metric for image retrieval. International Journal of Computer Vision, 40(2):99–121, 2000.\n\n[232]\nSamuele Salti, Andrea Cavallaro, and Luigi Di Stefano. Adaptive appearance modeling for video tracking: survey and evaluation. Image Processing, IEEE Transactions on, 21(10):4334–4348, 2012.\n\n[233]\nJoaquim Salvi, Jordi Pagés, and Joan Batlle. Pattern codification strategies in structured light systems. Pattern Recognition, 37(4):827–849, April 2004.\n\n[234]\nJavier Sánchez Pérez, Enric Meinhardt-Llopis, and Gabriele Facciolo. Tv-l1 optical flow estimation. 2012.\n\n[235]\nJaakko Sauvola, Tapio Seppanen, Sami Haapakoski, and Matti Pietikainen. Adaptive document binarization. In Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on, volume 1, pages 147–152. IEEE, 1997.\n\n[236]\nMarios Savvides, B. V. K. Vijaya Kumar, and P. K. Khosla. Cancelable biometric filters for face recognition. Pattern Recognition, International Conference on, vol. 03, no. , pp. 922-925, 2004,, 03:922–925, 2004.\n\n[237]\nJ. Seiler, M. Jonscher, M. Schöberl, and A. Kaup. Resampling images to a regular grid from a non-regular subset of pixel positions using frequency selective reconstruction. IEEE Transactions on Image Processing, 24(11):4540–4555, Nov 2015. \n\n[238]\nTobias Senst, Volker Eiselein, and Thomas Sikora. Robust local optical flow for feature tracking. IEEE Transactions on Circuits and Systems for Video Technology, 22(9):1377–1387, 2012.\n\n[239]\nTobias Senst, Jonas Geistert, Ivo Keller, and Thomas Sikora. Robust local optical flow estimation using bilinear equations for sparse motion estimation. In 20th IEEE International Conference on Image Processing, pages 2499–2503, 2013.\n\n[240]\nTobias Senst, Thilo Borgmann, Ivo Keller, and Thomas Sikora. Cross based robust local optical flow. In 21th IEEE International Conference on Image Processing, pages 1967–1971, 2014.\n\n[241]\nTobias Senst, Jonas Geistert, and Thomas Sikora. Robust local optical flow: Long-range motions and varying illuminations. In IEEE International Conference on Image Processing, pages 4478–4482, 2016.\n\n[242]\nTobias Senst. Estimation and analysis of motion in video data. PhD thesis, Technical Univerity Berlin, 2019. \n\n[243]\nByung-Kuk Seo, Hanhoon Park, Jong-Il Park, Stefan Hinterstoisser, and Slobodan Ilic. Optimal local searching for fast and robust textureless 3d object tracking in highly cluttered backgrounds. IEEE transactions on visualization and computer graphics, 20(1):99–110, 2013.\n\n[244]\nMili Shah. Solving the robot-world/hand-eye calibration problem using the kronecker product. Journal of Mechanisms and Robotics, 5:031007, 2013.\n\n[245]\nJianbo Shi and Carlo Tomasi. Good features to track. In Computer Vision and Pattern Recognition, 1994. Proceedings CVPR'94., 1994 IEEE Computer Society Conference on, pages 593–600. IEEE, 1994.\n\n[246]\nK. Simonyan, A. Vedaldi, and A. Zisserman. Learning local feature descriptors using convex optimisation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014.\n\n[247]\nJack Sklansky. Finding the convex hull of a simple polygon. Pattern Recognition Letters, 1(2):79–83, 1982.\n\n[248]\nGregory G Slabaugh. Computing euler angles from a rotation matrix. Retrieved on August, 6:2000, 1999.\n\n[249]\nJoan Solà, Jérémie Deray, and Dinesh Atchuthan. A micro lie theory for state estimation in robotics. ArXiv, abs/1812.01537, 2018.\n\n[250]\nRobert Spangenberg, Tobias Langner, and Raúl Rojas. Weighted semi-global matching and center-symmetric census transform for robust driver assistance. In Computer Analysis of Images and Patterns, pages 34–41. Springer Berlin Heidelberg, 2013.\n\n[251]\nHenrik Stewenius, Christopher Engels, and David Nister. Recent developments on direct relative orientation. ISPRS Journal of Photogrammetry and Remote Sensing, 60:284–294, 06 2006.\n\n[252]\nHenrik Stewenius. Calibrated fivepoint solver.\n\n[253]\nDanail Stoyanov, Marco Visentini Scarzanella, Philip Pratt, and Guang-Zhong Yang. Real-time stereo reconstruction in robotically assisted minimally invasive surgery. In Tianzi Jiang, Nassir Navab, Josien P. W. Pluim, and Max A. Viergever, editors, Medical Image Computing and Computer-Assisted Intervention (MICCAI 2010), pages 275–282, Berlin, Heidelberg, 2010. Springer Berlin Heidelberg.\n\n[254]\nS.T. Strat, A. Benoit, and P. Lambert. Retina enhanced bag of words descriptors for video classification. In Signal Processing Conference (EUSIPCO), 2014 Proceedings of the 22nd European, pages 1307–1311, Sept 2014.\n\n[255]\nKlaus H. Strobl and Gerd Hirzinger. More accurate pinhole camera calibration with imperfect planar target. In 2011 IEEE International Conference on Computer Vision (ICCV), pages 1068–1075, Barcelona, Spain, Nov 2011. IEEE. \n\n[256]\nIago Suárez, Ghesn Sfeir, José M. Buenaposada, and Luis Baumela. BEBLID: Boosted Efficient Binary Local Image Descriptor. Pattern Recognition Letters, 133:366–372, 2020. \n\n[257]\nIago Suárez, José M. Buenaposada, and Luis Baumela. Revisiting binary local image description for resource limited devices. IEEE Robotics and Automation Letters, 6(4):8317–8324, 2021. \n\n[258]\nSatoshi Suzuki and others. Topological structural analysis of digitized binary images by border following. Computer Vision, Graphics, and Image Processing, 30(1):32–46, 1985.\n\n[259]\nRichard Szeliski. Image alignment and stitching: A tutorial. Foundations and Trends textregistered in Computer Graphics and Vision, 2(1):1–104, 2006.\n\n[260]\nRichard Szeliski. Computer vision: algorithms and applications. Springer, 2010.\n\n[261]\nV. Lepetit T. Trzcinski, M. Christoudias and P. Fua. Boosting binary keypoint descriptors. In Computer Vision and Pattern Recognition, 2013.\n\n[262]\nM. Christoudias T. Trzcinski and V. Lepetit. Learning image descriptors with boosting. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2013.\n\n[263]\nZhenjun Tang, Yumin Dai, and Xianquan Zhang. Perceptual hashing for color images using invariant moments. Appl. Math, 6(2S):643S–650S, 2012.\n\n[264]\nMichael Tao, Jiamin Bai, Pushmeet Kohli, and Sylvain Paris. Simpleflow: A non-iterative, sublinear optical flow algorithm. In Computer Graphics Forum, volume 31, pages 345–353. Wiley Online Library, 2012.\n\n[265]\nGabriel Taubin. Estimation of planar curves, surfaces, and nonplanar space curves defined by implicit equations with applications to edge and range image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 13(11):1115–1138, 1991. \n\n[266]\nC-H Teh and Roland T. Chin. On the detection of dominant points on digital curves. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 11(8):859–872, 1989.\n\n[267]\nAlexandru Telea. An image inpainting technique based on the fast marching method. Journal of graphics tools, 9(1):23–34, 2004.\n\n[268]\nGeorge Terzakis and Manolis Lourakis. A consistently fast and globally optimal solution to the perspective-n-point problem. In European Conference on Computer Vision, pages 478–494. Springer International Publishing, 2020.\n\n[269]\nContrast stretching.\n\n[270]\nE. Tola, V. Lepetit, and P. Fua. Daisy: An efficient dense descriptor applied to wide baseline stereo. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(5):815–830, May 2010.\n\n[271]\nFederico Tombari and Luigi Di Stefano. Interest points via maximal self-dissimilarities. In Asian Conference on Computer Vision – ACCV 2014, 2014.\n\n[272]\nCihan Topal and Cuneyt Akinlar. Edge drawing: a combined real-time edge and segment detector. Journal of Visual Communication and Image Representation, 23(6):862–872, 2012.\n\n[273]\nHastie Trevor, Tibshirani Robert, and Friedman Jerome. The elements of statistical learning: data mining, inference and prediction. New York: Springer-Verlag, 1(8):371–406, 2001.\n\n[274]\nR. Y. Tsai and R. K. Lenz. A new technique for fully autonomous and efficient 3d robotics hand/eye calibration. IEEE Transactions on Robotics and Automation, 5(3):345–358, June 1989. \n\n[275]\nChiara Turati, Viola Macchi Cassia, Francesca Simion, and Irene Leo. Newborns' face recognition: Role of inner and outer facial features. Child development, 77(2):297–311, 2006.\n\n[276]\nMatthew Turk and Alex Pentland. Eigenfaces for recognition. Journal of cognitive neuroscience, 3(1):71–86, 1991.\n\n[277]\nJasper RR Uijlings, Koen EA van de Sande, Theo Gevers, and Arnold WM Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154–171, 2013.\n\n[278]\nShinji Umeyama. Least-squares estimation of transformation parameters between two point patterns. IEEE Computer Architecture Letters, 13(04):376–380, 1991.\n\n[279]\nMatthew Uyttendaele, Ashley Eden, and R Skeliski. Eliminating ghosting and exposure artifacts in image mosaics. In Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, volume 2, pages II–509. IEEE, 2001.\n\n[280]\nAntoine Vacavant, Thierry Chateau, Alexis Wilhelm, and Laurent Lequièvre. A benchmark dataset for outdoor foreground/background extraction. In Computer Vision-ACCV 2012 Workshops, pages 291–300. Springer, 2013.\n\n[281]\nMarek Vajgl, Irina Perfilieva, and Petra Hod'áková. Advanced f-transform-based image fusion. Advances in Fuzzy Systems, 2012:4, 2012.\n\n[282]\nMichael Van den Bergh, Xavier Boix, Gemma Roig, Benjamin de Capitani, and Luc Van Gool. Seeds: Superpixels extracted via energy-driven sampling. In Computer Vision–ECCV 2012, pages 13–26. Springer, 2012.\n\n[283]\nLucas J Van Vliet and Piet W Verbeek. Estimators for orientation and anisotropy in digitized images. In ASCI, volume 95, pages 16–18, 1995.\n\n[284]\nLieven Vandenberghe. Qr factorization.\n\n[285]\nPaul Viola and Michael J. Jones. Rapid object detection using a boosted cascade of simple features. In Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, volume 1, pages I–511. IEEE, 2001.\n\n[286]\nPaul Viola and Michael J. Jones. Robust real-time face detection. International Journal of Computer Vision, 57(2):137–154, 2004.\n\n[287]\nPavel Vlasánek and Irina Perfilieva. Patch based inpainting method based on the f1-transform. In Soft Computing and Pattern Recognition (SoCPaR), 2015 7th International Conference of, pages 235–240. IEEE, 2015.\n\n[288]\nPavel Vlasánek and Irina Perfilieva. The f-transform in terms of image processing tools. Journal of Fuzzy Set Valued Analysis, 2016(1):54–62, 2016.\n\n[289]\nR Grompone Von Gioi, Jeremie Jakubowicz, Jean-Michel Morel, and Gregory Randall. Lsd: A fast line segment detector with a false detection control. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(4):722–732, 2010.\n\n[290]\nRafael Grompone von Gioi, Jérémie Jakubowicz, Jean-Michel Morel, and Gregory Randall. Lsd: a line segment detector. 2012.\n\n[291]\nBin Wang and Piotr Dudek. A fast self-tuning background subtraction algorithm. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on, pages 401–404. IEEE, 2014.\n\n[292]\nJohn Wang and Edwin Olson. AprilTag 2: Efficient and robust fiducial detection. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), October 2016.\n\n[293]\nGuofeng Wang, Bin Wang, Fan Zhong, Xueying Qin, and Baoquan Chen. Global optimal searching for textureless 3d object tracking. The Visual Computer, 31(6):979–988, 2015.\n\n[294]\nShenlong Wang, Sean Ryan Fanello, Christoph Rhemann, Shahram Izadi, and Pushmeet Kohli. The global patch collider. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.\n\n[295]\nGreg Ward. Fast, robust image registration for compositing high dynamic range photographs from hand-held exposures. Journal of graphics tools, 8(2):17–30, 2003.\n\n[296]\nPhilippe Weinzaepfel, Jerome Revaud, Zaid Harchaoui, and Cordelia Schmid. Deepflow: Large displacement optical flow with deep matching. In Computer Vision (ICCV), 2013 IEEE International Conference on, pages 1385–1392. IEEE, 2013.\n\n[297]\nGreg Welch and Gary Bishop. An introduction to the kalman filter, 1995.\n\n[298]\nSimon AJ Winder and Matthew Brown. Learning local image descriptors. In Computer Vision and Pattern Recognition, pages 1–8, 2007.\n\n[299]\nLaurenz Wiskott, J-M Fellous, N Kuiger, and Christoph Von Der Malsburg. Face recognition by elastic bunch graph matching. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 19(7):775–779, 1997.\n\n[300]\nChristian Wolf and J-M Jolion. Extraction and recognition of artificial text in multimedia documents. Pattern Analysis & Applications, 6(4):309–326, 2004.\n\n[301]\nKesheng Wu, Ekow Otoo, and Kenji Suzuki. Optimizing two-pass connected-component labeling algorithms. Pattern Analysis and Applications, 12(2):117–135, Jun 2009.\n\n[302]\nYi Wu, Jongwoo Lim, and Ming-Hsuan Yang. Online object tracking: A benchmark. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 2411–2418. IEEE, 2013.\n\n[303]\nJonas Wulff and Michael J. Black. Efficient sparse-to-dense optical flow estimation using a learned basis and layers. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) 2015, June 2015.\n\n[304]\nWang Xiangmin. Research on barcode recognition technology in a complex background. Master's thesis, Huazhong University of Science and Technology, 2015.\n\n[305]\nWei Xu and Jane Mulligan. Performance evaluation of color correction approaches for automatic multi-view image and video stitching. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 263–270. IEEE, 2010.\n\n[306]\nLi Xu, Cewu Lu, Yi Xu, and Jiaya Jia. Image smoothing via l 0 gradient minimization. In ACM Transactions on Graphics (TOG), volume 30, page 174. ACM, 2011.\n\n[307]\nY. Xu, P. Monasse, T. Géraud, and L. Najman. Tree-based morse regions: A topological approach to local feature detection. IEEE Transactions on Image Processing, 23(12):5612–5625, Dec 2014. \n\n[308]\nGuang-Zhong Yang, Peter Burger, David N Firmin, and SR Underwood. Structure adaptive anisotropic image filtering. Image and Vision Computing, 14(2):135–145, 1996.\n\n[309]\nQingxiong Yang, Liang Wang, and Narendra Ahuja. A constant-space belief propagation algorithm for stereo matching. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 1458–1465. IEEE, 2010.\n\n[310]\nZhenqiang Ying, Ge Li, and Wen Gao. A bio-inspired multi-exposure fusion framework for low-light image enhancement. arXiv preprint arXiv:1711.00591, 2017.\n\n[311]\nZhenqiang Ying, Ge Li, Yurui Ren, Ronggang Wang, and Wenmin Wang. A new image contrast enhancement algorithm using exposure fusion framework. In International Conference on Computer Analysis of Images and Patterns, pages 36–46. Springer, 2017.\n\n[312]\nGuoshen Yu and Jean-Michel Morel. Asift: An algorithm for fully affine invariant comparison. Image Processing On Line, 1:11–38, 2011. \n\n[313]\nHK Yuen, John Princen, John Illingworth, and Josef Kittler. Comparative study of hough transform methods for circle finding. Image and Vision Computing, 8(1):71–77, 1990.\n\n[314]\nChristopher Zach, Thomas Pock, and Horst Bischof. A duality based approach for realtime tv-l 1 optical flow. In Pattern Recognition, pages 214–223. Springer, 2007.\n\n[315]\nChristoph Zauner. Implementation and benchmarking of perceptual image hash functions. 2010.\n\n[316]\nLilian Zhang and Reinhard Koch. An efficient and robust line segment matching approach based on lbd descriptor and pairwise geometric consistency. Journal of Visual Communication and Image Representation, 24(7):794–805, 2013.\n\n[317]\nQi Zhang, Xiaoyong Shen, Li Xu, and Jiaya Jia. Rolling guidance filter. In Computer Vision–ECCV 2014, pages 815–830. Springer, 2014.\n\n[318]\nQi Zhang, Li Xu, and Jiaya Jia. 100+ times faster weighted median filter (wmf). In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2830–2837. IEEE, 2014.\n\n[319]\nZhengyou Zhang. A flexible new technique for camera calibration. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 22(11):1330–1334, 2000.\n\n[320]\nWenyi Zhao, Rama Chellappa, P Jonathon Phillips, and Azriel Rosenfeld. Face recognition: A literature survey. Acm Computing Surveys (CSUR), 35(4):399–458, 2003.\n\n[321]\nEric Christiansen David Kriegman Ziegler, Andrew and Serge J. Belongie. Locally uniform comparison image descriptor.\n\n[322]\nTimo Zinßer, Jochen Schmidt, and Heinrich Niemann. A refined icp algorithm for robust 3-d correspondence estimation. In Image Processing, 2003. ICIP 2003. Proceedings. 2003 International Conference on, volume 2, pages II–695. IEEE, 2003.\n\n[323]\nC. Lawrence Zitnick and Piotr Dollár. Edge boxes: Locating object proposals from edges. In ECCV, 2014.\n\n[324]\nZoran Zivkovic and Ferdinand van der Heijden. Efficient adaptive density estimation per image pixel for the task of background subtraction. Pattern recognition letters, 27(7):773–780, 2006.\n\n[325]\nZoran Zivkovic. Improved adaptive gaussian mixture model for background subtraction. In Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on, volume 2, pages 28–31. IEEE, 2004.\n\n[326]\nMarco Zuliani. Ransac for dummies with examples using the ransac toolbox for matlab & octave and more... 2014.\n\n[327]\nИ.С. Грузман, В.С. Киричук, В.П. Косых, Г.И. Перетягин, and А.А. Спектор. Цифровая обработка изображений в информационных системах. 2000.\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html","content_type":"text/html","title":"OpenCV: OpenCV-Python Tutorials","language":null},"page_content":"OpenCV: OpenCV-Python Tutorials\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nOpenCV-Python Tutorials\n\nIntroduction to OpenCV\nLearn how to setup OpenCV-Python on your computer!\n\nGui Features in OpenCV\nHere you will learn how to display and save images and videos, control mouse events and create trackbar.\n\nCore Operations\nIn this section you will learn basic operations on image like pixel editing, geometric transformations, code optimization, some mathematical tools etc.\n\nImage Processing in OpenCV\nIn this section you will learn different image processing functions inside OpenCV.\n\nFeature Detection and Description\nIn this section you will learn about feature detectors and descriptors\n\nVideo analysis (video module)\nIn this section you will learn different techniques to work with videos like object tracking etc.\n\nCamera Calibration and 3D Reconstruction\nIn this section we will learn about camera calibration, stereo imaging etc.\n\nMachine Learning\nIn this section you will learn different image processing functions inside OpenCV.\n\nComputational Photography\nIn this section you will learn different computational photography techniques like image denoising etc.\n\nObject Detection (objdetect module)\nIn this section you will learn object detection techniques like face detection etc.\n\nOpenCV-Python Bindings\nIn this section, we will see how OpenCV-Python bindings are generated \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d7/dfc/group__highgui.html","content_type":"text/html","title":"OpenCV: High-level GUI","language":null},"page_content":"OpenCV: High-level GUI\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nTypedefs |\nFunctions \nHigh-level GUI\n\nModules\n Flags related creating and manipulating HighGUI windows and mouse events\n \n OpenGL support\n \n Qt New Functions\n \n WinRT support\n \n\nDetailed Description\nWhile OpenCV was designed for use in full-scale applications and can be used within functionally rich UI frameworks (such as Qt*, WinForms*, or Cocoa*) or without any UI at all, sometimes there it is required to try functionality quickly and visualize the results. This is what the HighGUI module has been designed for.\nIt provides easy interface to:\n\nCreate and manipulate windows that can display images and \"remember\" their content (no need to handle repaint events from OS).\nAdd trackbars to the windows, handle simple mouse events as well as keyboard commands. \n\nTypedefs\ntypedef void(* cv::ButtonCallback) (int state, void *userdata)\n Callback function for a button created by cv::createButton.  \n \ntypedef void(* cv::MouseCallback) (int event, int x, int y, int flags, void *userdata)\n Callback function for mouse events. see cv::setMouseCallback.  \n \ntypedef void(* cv::OpenGlDrawCallback) (void *userdata)\n Callback function defined to be called every frame. See cv::setOpenGlDrawCallback.  \n \ntypedef void(* cv::TrackbarCallback) (int pos, void *userdata)\n Callback function for Trackbar see cv::createTrackbar.  \n \n\nFunctions\nint cv::createTrackbar (const String &trackbarname, const String &winname, int *value, int count, TrackbarCallback onChange=0, void *userdata=0)\n Creates a trackbar and attaches it to the specified window.  \n \nconst std::string cv::currentUIFramework ()\n HighGUI backend used.  \n \nvoid cv::destroyAllWindows ()\n Destroys all of the HighGUI windows.  \n \nvoid cv::destroyWindow (const String &winname)\n Destroys the specified window.  \n \nint cv::getMouseWheelDelta (int flags)\n Gets the mouse-wheel motion delta, when handling mouse-wheel events cv::EVENT_MOUSEWHEEL and cv::EVENT_MOUSEHWHEEL.  \n \nint cv::getTrackbarPos (const String &trackbarname, const String &winname)\n Returns the trackbar position.  \n \nRect cv::getWindowImageRect (const String &winname)\n Provides rectangle of image in the window.  \n \ndouble cv::getWindowProperty (const String &winname, int prop_id)\n Provides parameters of a window.  \n \nvoid cv::imshow (const String &winname, InputArray mat)\n Displays an image in the specified window.  \n \nvoid cv::moveWindow (const String &winname, int x, int y)\n Moves the window to the specified position.  \n \nvoid cv::namedWindow (const String &winname, int flags=WINDOW_AUTOSIZE)\n Creates a window.  \n \nint cv::pollKey ()\n Polls for a pressed key.  \n \nvoid cv::resizeWindow (const String &winname, const cv::Size &size)\n \nvoid cv::resizeWindow (const String &winname, int width, int height)\n Resizes the window to the specified size.  \n \nRect cv::selectROI (const String &windowName, InputArray img, bool showCrosshair=true, bool fromCenter=false, bool printNotice=true)\n Allows users to select a ROI on the given image.  \n \nRect cv::selectROI (InputArray img, bool showCrosshair=true, bool fromCenter=false, bool printNotice=true)\n \nvoid cv::selectROIs (const String &windowName, InputArray img, std::vector< Rect > &boundingBoxes, bool showCrosshair=true, bool fromCenter=false, bool printNotice=true)\n Allows users to select multiple ROIs on the given image.  \n \nvoid cv::setMouseCallback (const String &winname, MouseCallback onMouse, void *userdata=0)\n Sets mouse handler for the specified window.  \n \nvoid cv::setTrackbarMax (const String &trackbarname, const String &winname, int maxval)\n Sets the trackbar maximum position.  \n \nvoid cv::setTrackbarMin (const String &trackbarname, const String &winname, int minval)\n Sets the trackbar minimum position.  \n \nvoid cv::setTrackbarPos (const String &trackbarname, const String &winname, int pos)\n Sets the trackbar position.  \n \nvoid cv::setWindowProperty (const String &winname, int prop_id, double prop_value)\n Changes parameters of a window dynamically.  \n \nvoid cv::setWindowTitle (const String &winname, const String &title)\n Updates window title.  \n \nint cv::startWindowThread ()\n \nint cv::waitKey (int delay=0)\n Waits for a pressed key.  \n \nint cv::waitKeyEx (int delay=0)\n Similar to waitKey, but returns full key code.  \n \n\nTypedef Documentation\n\n◆ ButtonCallback\n\ntypedef void(* cv::ButtonCallback) (int state, void *userdata)\n\n#include <opencv2/highgui.hpp>\nCallback function for a button created by cv::createButton. \nParameters\n\nstatecurrent state of the button. It could be -1 for a push button, 0 or 1 for a check/radio box button. \nuserdataThe optional parameter. \n\n◆ MouseCallback\n\ntypedef void(* cv::MouseCallback) (int event, int x, int y, int flags, void *userdata)\n\n#include <opencv2/highgui.hpp>\nCallback function for mouse events. see cv::setMouseCallback. \nParameters\n\neventone of the cv::MouseEventTypes constants. \nxThe x-coordinate of the mouse event. \nyThe y-coordinate of the mouse event. \nflagsone of the cv::MouseEventFlags constants. \nuserdataThe optional parameter. \n\n◆ OpenGlDrawCallback\n\ntypedef void(* cv::OpenGlDrawCallback) (void *userdata)\n\n#include <opencv2/highgui.hpp>\nCallback function defined to be called every frame. See cv::setOpenGlDrawCallback. \nParameters\n\nuserdataThe optional parameter. \n\n◆ TrackbarCallback\n\ntypedef void(* cv::TrackbarCallback) (int pos, void *userdata)\n\n#include <opencv2/highgui.hpp>\nCallback function for Trackbar see cv::createTrackbar. \nParameters\n\nposcurrent position of the specified trackbar. \nuserdataThe optional parameter. \n\nFunction Documentation\n\n◆ createTrackbar()\n\nint cv::createTrackbar \n(\nconst String & \ntrackbarname, \n\nconst String & \nwinname, \n\nint * \nvalue, \n\nint \ncount, \n\nTrackbarCallback \nonChange = 0, \n\nvoid * \nuserdata = 0 \n\n)\n\n#include <opencv2/highgui.hpp>\nCreates a trackbar and attaches it to the specified window. \nThe function createTrackbar creates a trackbar (a slider or range control) with the specified name and range, assigns a variable value to be a position synchronized with the trackbar and specifies the callback function onChange to be called on the trackbar position change. The created trackbar is displayed in the specified window winname.\nNote[Qt Backend Only] winname can be empty if the trackbar should be attached to the control panel.\nClicking the label of each trackbar enables editing the trackbar values manually.\nParameters\n\ntrackbarnameName of the created trackbar. \nwinnameName of the window that will be used as a parent of the created trackbar. \nvalueOptional pointer to an integer variable whose value reflects the position of the slider. Upon creation, the slider position is defined by this variable. \ncountMaximal position of the slider. The minimal position is always 0. \nonChangePointer to the function to be called every time the slider changes position. This function should be prototyped as void Foo(int,void*); , where the first parameter is the trackbar position and the second parameter is the user data (see the next parameter). If the callback is the NULL pointer, no callbacks are called, but only value is updated. \nuserdataUser data that is passed as is to the callback. It can be used to handle trackbar events without using global variables. \n\n◆ currentUIFramework()\n\nconst std::string cv::currentUIFramework \n(\n)\n\nPython:cv.currentUIFramework() -> retval\n\n#include <opencv2/highgui.hpp>\nHighGUI backend used. \nThe function returns HighGUI backend name used: could be COCOA, GTK2/3, QT, WAYLAND or WIN32. Returns empty string if there is no available UI backend. \n\n◆ destroyAllWindows()\n\nvoid cv::destroyAllWindows \n(\n)\n\nPython:cv.destroyAllWindows() -> None\n\n#include <opencv2/highgui.hpp>\nDestroys all of the HighGUI windows. \nThe function destroyAllWindows destroys all of the opened HighGUI windows. \n\n◆ destroyWindow()\n\nvoid cv::destroyWindow \n(\nconst String & \nwinname)\n\nPython:cv.destroyWindow(winname) -> None\n\n#include <opencv2/highgui.hpp>\nDestroys the specified window. \nThe function destroyWindow destroys the window with the given name.\nParameters\n\nwinnameName of the window to be destroyed. \n\n◆ getMouseWheelDelta()\n\nint cv::getMouseWheelDelta \n(\nint \nflags)\n\n#include <opencv2/highgui.hpp>\nGets the mouse-wheel motion delta, when handling mouse-wheel events cv::EVENT_MOUSEWHEEL and cv::EVENT_MOUSEHWHEEL. \nFor regular mice with a scroll-wheel, delta will be a multiple of 120. The value 120 corresponds to a one notch rotation of the wheel or the threshold for action to be taken and one such action should occur for each delta. Some high-precision mice with higher-resolution freely-rotating wheels may generate smaller values.\nFor cv::EVENT_MOUSEWHEEL positive and negative values mean forward and backward scrolling, respectively. For cv::EVENT_MOUSEHWHEEL, where available, positive and negative values mean right and left scrolling, respectively.\nNoteMouse-wheel events are currently supported only on Windows and Cocoa.\nParameters\n\nflagsThe mouse callback flags parameter. \n\n◆ getTrackbarPos()\n\nint cv::getTrackbarPos \n(\nconst String & \ntrackbarname, \n\nconst String & \nwinname \n\n)\n\nPython:cv.getTrackbarPos(trackbarname, winname) -> retval\n\n#include <opencv2/highgui.hpp>\nReturns the trackbar position. \nThe function returns the current position of the specified trackbar.\nNote[Qt Backend Only] winname can be empty if the trackbar is attached to the control panel.\nParameters\n\ntrackbarnameName of the trackbar. \nwinnameName of the window that is the parent of the trackbar. \n\n◆ getWindowImageRect()\n\nRect cv::getWindowImageRect \n(\nconst String & \nwinname)\n\nPython:cv.getWindowImageRect(winname) -> retval\n\n#include <opencv2/highgui.hpp>\nProvides rectangle of image in the window. \nThe function getWindowImageRect returns the client screen coordinates, width and height of the image rendering area.\nParameters\n\nwinnameName of the window.\n\nSee alsoresizeWindow moveWindow\nNote[Wayland Backend Only] This function is not supported by the Wayland protocol limitation. \n\n◆ getWindowProperty()\n\ndouble cv::getWindowProperty \n(\nconst String & \nwinname, \n\nint \nprop_id \n\n)\n\nPython:cv.getWindowProperty(winname, prop_id) -> retval\n\n#include <opencv2/highgui.hpp>\nProvides parameters of a window. \nThe function getWindowProperty returns properties of a window.\nParameters\n\nwinnameName of the window. \nprop_idWindow property to retrieve. The following operation flags are available: (cv::WindowPropertyFlags)\n\nSee alsosetWindowProperty\nNote[Wayland Backend Only] This function is not supported. \n\n◆ imshow()\n\nvoid cv::imshow \n(\nconst String & \nwinname, \n\nInputArray \nmat \n\n)\n\nPython:cv.imshow(winname, mat) -> None\n\n#include <opencv2/highgui.hpp>\nDisplays an image in the specified window. \nThe function imshow displays an image in the specified window. If the window was created with the cv::WINDOW_AUTOSIZE flag, the image is shown with its original size, however it is still limited by the screen resolution. Otherwise, the image is scaled to fit the window. The function may scale the image, depending on its depth:\n\nIf the image is 8-bit unsigned, it is displayed as is.\nIf the image is 16-bit unsigned, the pixels are divided by 256. That is, the value range [0,255*256] is mapped to [0,255].\nIf the image is 32-bit or 64-bit floating-point, the pixel values are multiplied by 255. That is, the value range [0,1] is mapped to [0,255].\n32-bit integer images are not processed anymore due to ambiguouty of required transform. Convert to 8-bit unsigned matrix using a custom preprocessing specific to image's context.\n\nIf window was created with OpenGL support, cv::imshow also support ogl::Buffer , ogl::Texture2D and cuda::GpuMat as input.\nIf the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE.\nIf you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\"\", WINDOW_NORMAL) before the imshow.\nNoteThis function should be followed by a call to cv::waitKey or cv::pollKey to perform GUI housekeeping tasks that are necessary to actually show the given image and make the window respond to mouse and keyboard events. Otherwise, it won't display the image and the window might lock up. For example, waitKey(0) will display the window infinitely until any keypress (it is suitable for image display). waitKey(25) will display a frame and wait approximately 25 ms for a key press (suitable for displaying a video frame-by-frame). To remove the window, use cv::destroyWindow.\n\n[Windows Backend Only] Pressing Ctrl+C will copy the image to the clipboard. Pressing Ctrl+S will show a dialog to save the image. \n\n[Wayland Backend Only] Supoorting format is extended.\nIf the image is 8-bit signed, the pixels are biased by 128. That is, the value range [-128,127] is mapped to [0,255].\nIf the image is 16-bit signed, the pixels are divided by 256 and biased by 128. That is, the value range [-32768,32767] is mapped to [0,255].\n\nParameters\n\nwinnameName of the window. \nmatImage to be shown. \n\n◆ moveWindow()\n\nvoid cv::moveWindow \n(\nconst String & \nwinname, \n\nint \nx, \n\nint \ny \n\n)\n\nPython:cv.moveWindow(winname, x, y) -> None\n\n#include <opencv2/highgui.hpp>\nMoves the window to the specified position. \nParameters\n\nwinnameName of the window. \nxThe new x-coordinate of the window. \nyThe new y-coordinate of the window.\n\nNote[Wayland Backend Only] This function is not supported by the Wayland protocol limitation. \n\n◆ namedWindow()\n\nvoid cv::namedWindow \n(\nconst String & \nwinname, \n\nint \nflags = WINDOW_AUTOSIZE \n\n)\n\nPython:cv.namedWindow(winname[, flags]) -> None\n\n#include <opencv2/highgui.hpp>\nCreates a window. \nThe function namedWindow creates a window that can be used as a placeholder for images and trackbars. Created windows are referred to by their names.\nIf a window with the same name already exists, the function does nothing.\nYou can call cv::destroyWindow or cv::destroyAllWindows to close the window and de-allocate any associated memory usage. For a simple program, you do not really have to call these functions because all the resources and windows of the application are closed automatically by the operating system upon exit.\nNoteQt backend supports additional flags:\nWINDOW_NORMAL or WINDOW_AUTOSIZE: WINDOW_NORMAL enables you to resize the window, whereas WINDOW_AUTOSIZE adjusts automatically the window size to fit the displayed image (see imshow ), and you cannot change the window size manually.\nWINDOW_FREERATIO or WINDOW_KEEPRATIO: WINDOW_FREERATIO adjusts the image with no respect to its ratio, whereas WINDOW_KEEPRATIO keeps the image ratio.\nWINDOW_GUI_NORMAL or WINDOW_GUI_EXPANDED: WINDOW_GUI_NORMAL is the old way to draw the window without statusbar and toolbar, whereas WINDOW_GUI_EXPANDED is a new enhanced GUI. By default, flags == WINDOW_AUTOSIZE | WINDOW_KEEPRATIO | WINDOW_GUI_EXPANDED\n\nParameters\n\nwinnameName of the window in the window caption that may be used as a window identifier. \nflagsFlags of the window. The supported flags are: (cv::WindowFlags) \n\n◆ pollKey()\n\nint cv::pollKey \n(\n)\n\nPython:cv.pollKey() -> retval\n\n#include <opencv2/highgui.hpp>\nPolls for a pressed key. \nThe function pollKey polls for a key event without waiting. It returns the code of the pressed key or -1 if no key was pressed since the last invocation. To wait until a key was pressed, use waitKey.\nNoteThe functions waitKey and pollKey are the only methods in HighGUI that can fetch and handle GUI events, so one of them needs to be called periodically for normal event processing unless HighGUI is used within an environment that takes care of event processing.\n\nThe function only works if there is at least one HighGUI window created and the window is active. If there are several HighGUI windows, any of them can be active. \n\n◆ resizeWindow() [1/2]\n\nvoid cv::resizeWindow \n(\nconst String & \nwinname, \n\nconst cv::Size & \nsize \n\n)\n\nPython:cv.resizeWindow(winname, width, height) -> Nonecv.resizeWindow(winname, size) -> None\n\n#include <opencv2/highgui.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nwinnameWindow name. \nsizeThe new window size. \n\n◆ resizeWindow() [2/2]\n\nvoid cv::resizeWindow \n(\nconst String & \nwinname, \n\nint \nwidth, \n\nint \nheight \n\n)\n\nPython:cv.resizeWindow(winname, width, height) -> Nonecv.resizeWindow(winname, size) -> None\n\n#include <opencv2/highgui.hpp>\nResizes the window to the specified size. \nNoteThe specified window size is for the image area. Toolbars are not counted. Only windows created without cv::WINDOW_AUTOSIZE flag can be resized.\nParameters\n\nwinnameWindow name. \nwidthThe new window width. \nheightThe new window height. \n\n◆ selectROI() [1/2]\n\nRect cv::selectROI \n(\nconst String & \nwindowName, \n\nInputArray \nimg, \n\nbool \nshowCrosshair = true, \n\nbool \nfromCenter = false, \n\nbool \nprintNotice = true \n\n)\n\nPython:cv.selectROI(windowName, img[, showCrosshair[, fromCenter[, printNotice]]]) -> retvalcv.selectROI(img[, showCrosshair[, fromCenter[, printNotice]]]) -> retval\n\n#include <opencv2/highgui.hpp>\nAllows users to select a ROI on the given image. \nThe function creates a window and allows users to select a ROI using the mouse. Controls: use space or enter to finish selection, use key c to cancel selection (function will return the zero cv::Rect).\nParameters\n\nwindowNamename of the window where selection process will be shown. \nimgimage to select a ROI. \nshowCrosshairif true crosshair of selection rectangle will be shown. \nfromCenterif true center of selection will match initial mouse position. In opposite case a corner of selection rectangle will correspont to the initial mouse position. \nprintNoticeif true a notice to select ROI or cancel selection will be printed in console. \n\nReturnsselected ROI or empty rect if selection canceled.\nNoteThe function sets it's own mouse callback for specified window using cv::setMouseCallback(windowName, ...). After finish of work an empty callback will be set for the used window. \n\n◆ selectROI() [2/2]\n\nRect cv::selectROI \n(\nInputArray \nimg, \n\nbool \nshowCrosshair = true, \n\nbool \nfromCenter = false, \n\nbool \nprintNotice = true \n\n)\n\nPython:cv.selectROI(windowName, img[, showCrosshair[, fromCenter[, printNotice]]]) -> retvalcv.selectROI(img[, showCrosshair[, fromCenter[, printNotice]]]) -> retval\n\n#include <opencv2/highgui.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ selectROIs()\n\nvoid cv::selectROIs \n(\nconst String & \nwindowName, \n\nInputArray \nimg, \n\nstd::vector< Rect > & \nboundingBoxes, \n\nbool \nshowCrosshair = true, \n\nbool \nfromCenter = false, \n\nbool \nprintNotice = true \n\n)\n\nPython:cv.selectROIs(windowName, img[, showCrosshair[, fromCenter[, printNotice]]]) -> boundingBoxes\n\n#include <opencv2/highgui.hpp>\nAllows users to select multiple ROIs on the given image. \nThe function creates a window and allows users to select multiple ROIs using the mouse. Controls: use space or enter to finish current selection and start a new one, use esc to terminate multiple ROI selection process.\nParameters\n\nwindowNamename of the window where selection process will be shown. \nimgimage to select a ROI. \nboundingBoxesselected ROIs. \nshowCrosshairif true crosshair of selection rectangle will be shown. \nfromCenterif true center of selection will match initial mouse position. In opposite case a corner of selection rectangle will correspont to the initial mouse position. \nprintNoticeif true a notice to select ROI or cancel selection will be printed in console.\n\nNoteThe function sets it's own mouse callback for specified window using cv::setMouseCallback(windowName, ...). After finish of work an empty callback will be set for the used window. \n\n◆ setMouseCallback()\n\nvoid cv::setMouseCallback \n(\nconst String & \nwinname, \n\nMouseCallback \nonMouse, \n\nvoid * \nuserdata = 0 \n\n)\n\n#include <opencv2/highgui.hpp>\nSets mouse handler for the specified window. \nParameters\n\nwinnameName of the window. \nonMouseCallback function for mouse events. See OpenCV samples on how to specify and use the callback. \nuserdataThe optional parameter passed to the callback. \n\n◆ setTrackbarMax()\n\nvoid cv::setTrackbarMax \n(\nconst String & \ntrackbarname, \n\nconst String & \nwinname, \n\nint \nmaxval \n\n)\n\nPython:cv.setTrackbarMax(trackbarname, winname, maxval) -> None\n\n#include <opencv2/highgui.hpp>\nSets the trackbar maximum position. \nThe function sets the maximum position of the specified trackbar in the specified window.\nNote[Qt Backend Only] winname can be empty if the trackbar is attached to the control panel.\nParameters\n\ntrackbarnameName of the trackbar. \nwinnameName of the window that is the parent of trackbar. \nmaxvalNew maximum position. \n\n◆ setTrackbarMin()\n\nvoid cv::setTrackbarMin \n(\nconst String & \ntrackbarname, \n\nconst String & \nwinname, \n\nint \nminval \n\n)\n\nPython:cv.setTrackbarMin(trackbarname, winname, minval) -> None\n\n#include <opencv2/highgui.hpp>\nSets the trackbar minimum position. \nThe function sets the minimum position of the specified trackbar in the specified window.\nNote[Qt Backend Only] winname can be empty if the trackbar is attached to the control panel.\nParameters\n\ntrackbarnameName of the trackbar. \nwinnameName of the window that is the parent of trackbar. \nminvalNew minimum position. \n\n◆ setTrackbarPos()\n\nvoid cv::setTrackbarPos \n(\nconst String & \ntrackbarname, \n\nconst String & \nwinname, \n\nint \npos \n\n)\n\nPython:cv.setTrackbarPos(trackbarname, winname, pos) -> None\n\n#include <opencv2/highgui.hpp>\nSets the trackbar position. \nThe function sets the position of the specified trackbar in the specified window.\nNote[Qt Backend Only] winname can be empty if the trackbar is attached to the control panel.\nParameters\n\ntrackbarnameName of the trackbar. \nwinnameName of the window that is the parent of trackbar. \nposNew position. \n\n◆ setWindowProperty()\n\nvoid cv::setWindowProperty \n(\nconst String & \nwinname, \n\nint \nprop_id, \n\ndouble \nprop_value \n\n)\n\nPython:cv.setWindowProperty(winname, prop_id, prop_value) -> None\n\n#include <opencv2/highgui.hpp>\nChanges parameters of a window dynamically. \nThe function setWindowProperty enables changing properties of a window.\nParameters\n\nwinnameName of the window. \nprop_idWindow property to edit. The supported operation flags are: (cv::WindowPropertyFlags) \nprop_valueNew value of the window property. The supported flags are: (cv::WindowFlags)\n\nNote[Wayland Backend Only] This function is not supported. \n\n◆ setWindowTitle()\n\nvoid cv::setWindowTitle \n(\nconst String & \nwinname, \n\nconst String & \ntitle \n\n)\n\nPython:cv.setWindowTitle(winname, title) -> None\n\n#include <opencv2/highgui.hpp>\nUpdates window title. \nParameters\n\nwinnameName of the window. \ntitleNew title. \n\n◆ startWindowThread()\n\nint cv::startWindowThread \n(\n)\n\nPython:cv.startWindowThread() -> retval\n\n#include <opencv2/highgui.hpp>\n\n◆ waitKey()\n\nint cv::waitKey \n(\nint \ndelay = 0)\n\nPython:cv.waitKey([, delay]) -> retval\n\n#include <opencv2/highgui.hpp>\nWaits for a pressed key. \nThe function waitKey waits for a key event infinitely (when \\(\\texttt{delay}\\leq 0\\) ) or for delay milliseconds, when it is positive. Since the OS has a minimum time between switching threads, the function will not wait exactly delay ms, it will wait at least delay ms, depending on what else is running on your computer at that time. It returns the code of the pressed key or -1 if no key was pressed before the specified time had elapsed. To check for a key press but not wait for it, use pollKey.\nNoteThe functions waitKey and pollKey are the only methods in HighGUI that can fetch and handle GUI events, so one of them needs to be called periodically for normal event processing unless HighGUI is used within an environment that takes care of event processing.\n\nThe function only works if there is at least one HighGUI window created and the window is active. If there are several HighGUI windows, any of them can be active.\nParameters\n\ndelayDelay in milliseconds. 0 is the special value that means \"forever\". \n\n◆ waitKeyEx()\n\nint cv::waitKeyEx \n(\nint \ndelay = 0)\n\nPython:cv.waitKeyEx([, delay]) -> retval\n\n#include <opencv2/highgui.hpp>\nSimilar to waitKey, but returns full key code. \nNoteKey code is implementation specific and depends on used backend: QT/GTK/Win32/etc \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d7/d3f/group__cudaoptflow.html","content_type":"text/html","title":"OpenCV: Optical Flow","language":null},"page_content":"OpenCV: Optical Flow\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nOptical FlowCUDA-accelerated Computer Vision\n\nDetailed Description\n\nClasses\nclass  cv::cuda::BroxOpticalFlow\n Class computing the optical flow for two images using Brox et al Optical Flow algorithm ([42]).  More...\n \nclass  cv::cuda::DenseOpticalFlow\n Base interface for dense optical flow algorithms.  More...\n \nclass  cv::cuda::DensePyrLKOpticalFlow\n Class used for calculating a dense optical flow.  More...\n \nclass  cv::cuda::FarnebackOpticalFlow\n Class computing a dense optical flow using the Gunnar Farneback's algorithm.  More...\n \nclass  cv::cuda::NvidiaHWOpticalFlow\n Base Interface for optical flow algorithms using NVIDIA Optical Flow SDK.  More...\n \nclass  cv::cuda::NvidiaOpticalFlow_1_0\n Class for computing the optical flow vectors between two images using NVIDIA Optical Flow hardware and Optical Flow SDK 1.0.  More...\n \nclass  cv::cuda::NvidiaOpticalFlow_2_0\n Class for computing the optical flow vectors between two images using NVIDIA Optical Flow hardware and Optical Flow SDK 2.0.  More...\n \nclass  cv::cuda::OpticalFlowDual_TVL1\n Implementation of the Zach, Pock and Bischof Dual TV-L1 Optical Flow method.  More...\n \nclass  cv::cuda::SparseOpticalFlow\n Base interface for sparse optical flow algorithms.  More...\n \nclass  cv::cuda::SparsePyrLKOpticalFlow\n Class used for calculating a sparse optical flow.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/de0/group__dnn__superres.html","content_type":"text/html","title":"OpenCV: DNN used for super resolution","language":null},"page_content":"OpenCV: DNN used for super resolution\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nDNN used for super resolution\n\nDetailed Description\nThis module contains functionality for upscaling an image via convolutional neural networks. The following four models are implemented:\n\nEDSR https://arxiv.org/abs/1707.02921\nESPCN https://arxiv.org/abs/1609.05158\nFSRCNN https://arxiv.org/abs/1608.00367\nLapSRN https://arxiv.org/abs/1710.01992 \n\nClasses\nclass  cv::dnn_superres::DnnSuperResImpl\n A class to upscale images via convolutional neural networks. The following four models are implemented:  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d3/d81/tutorial_contrib_root.html","content_type":"text/html","title":"OpenCV: Tutorials for contrib modules","language":null},"page_content":"OpenCV: Tutorials for contrib modules\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nTutorials for contrib modules\n\nalphamat. Information Flow Alpha Matting\nbgsegm. Tutorials for bgsegm module\nbioinspired. Discovering the human retina and its use for image processing\ncannops. Ascend NPU Image Processing\nccalib. Multi-camera Calibration\nccalib. Omnidirectional Camera Calibration\ncvv. Interactive Visual Debugging of Computer Vision applications\ndnn_objdetect. Object Detection using CNNs\ndnn_superres. Super Resolution using CNNs\nface. Tutorials for face module\nface. Tutorial on Facial Landmark Detector API\nfuzzy. Fuzzy image processing tutorials\nhdf. The Hierarchical Data Format (hdf) I/O\njulia. Introduction to Julia OpenCV Binding\nline_descriptor. Line Features Tutorial\nmcc. Color Correction Model\nmcc. ColorChecker Detection\nphase_unwrapping. Phase Unwrapping tutorial\nsfm. Structure From Motion\nstereo. Quasi Dense Stereo (stereo module)\nstructured_light. Structured Light tutorials\ntext. Text module\ntracking. Customizing the CN Tracker\ntracking. Introduction to OpenCV Tracker\ntracking. Using MultiTracker\nviz. OpenCV Viz\nximgproc. Disparity map post-filtering\nximgproc. Structured forests for fast edge detection\nximgproc. Structured forest training\nxphoto. Image Inpainting\nxphoto. Oil painting effect\nxphoto. Training the learning-based white balance algorithm \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d3/ddc/group__ccalib.html","content_type":"text/html","title":"OpenCV: Custom Calibration Pattern for 3D reconstruction","language":null},"page_content":"OpenCV: Custom Calibration Pattern for 3D reconstruction\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nNamespaces |\nClasses |\nMacros |\nEnumerations |\nFunctions \nCustom Calibration Pattern for 3D reconstruction\n\nDetailed Description\n\nNamespaces\nnamespace  cv::omnidir::internal\n \n\nClasses\nclass  cv::ccalib::CustomPattern\n \nclass  cv::multicalib::MultiCameraCalibration\n Class for multiple camera calibration that supports pinhole camera and omnidirection camera. For omnidirectional camera model, please refer to omnidir.hpp in ccalib module. It first calibrate each camera individually, then a bundle adjustment like optimization is applied to refine extrinsic parameters. So far, it only support \"random\" pattern for calibration, see randomPattern.hpp in ccalib module for details. Images that are used should be named by \"cameraIdx-timestamp.*\", several images with the same timestamp means that they are the same pattern that are photographed. cameraIdx should start from 0.  More...\n \nclass  cv::randpattern::RandomPatternCornerFinder\n Class for finding features points and corresponding 3D in world coordinate of a \"random\" pattern, which can be to be used in calibration. It is useful when pattern is partly occluded or only a part of pattern can be observed in multiple cameras calibration. The pattern can be generated by RandomPatternGenerator class described in this file.  More...\n \nclass  cv::randpattern::RandomPatternGenerator\n \n\nMacros\n#define HEAD   -1\n \n#define INVALID   -2\n \n\nEnumerations\nenum  { \n  cv::omnidir::CALIB_USE_GUESS = 1\n, \n  cv::omnidir::CALIB_FIX_SKEW = 2\n, \n  cv::omnidir::CALIB_FIX_K1 = 4\n, \n  cv::omnidir::CALIB_FIX_K2 = 8\n, \n  cv::omnidir::CALIB_FIX_P1 = 16\n, \n  cv::omnidir::CALIB_FIX_P2 = 32\n, \n  cv::omnidir::CALIB_FIX_XI = 64\n, \n  cv::omnidir::CALIB_FIX_GAMMA = 128\n, \n  cv::omnidir::CALIB_FIX_CENTER = 256\n\n }\n \nenum  { \n  cv::omnidir::RECTIFY_PERSPECTIVE = 1\n, \n  cv::omnidir::RECTIFY_CYLINDRICAL = 2\n, \n  cv::omnidir::RECTIFY_LONGLATI = 3\n, \n  cv::omnidir::RECTIFY_STEREOGRAPHIC = 4\n\n }\n \nenum  { \n  cv::omnidir::XYZRGB = 1\n, \n  cv::omnidir::XYZ = 2\n\n }\n \n\nFunctions\ndouble cv::omnidir::calibrate (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size size, InputOutputArray K, InputOutputArray xi, InputOutputArray D, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, int flags, TermCriteria criteria, OutputArray idx=noArray())\n Perform omnidirectional camera calibration, the default depth of outputs is CV_64F.  \n \nvoid cv::omnidir::initUndistortRectifyMap (InputArray K, InputArray D, InputArray xi, InputArray R, InputArray P, const cv::Size &size, int m1type, OutputArray map1, OutputArray map2, int flags)\n Computes undistortion and rectification maps for omnidirectional camera image transform by a rotation R. It output two maps that are used for cv::remap(). If D is empty then zero distortion is used, if R or P is empty then identity matrices are used.  \n \nvoid cv::omnidir::projectPoints (InputArray objectPoints, OutputArray imagePoints, const Affine3d &affine, InputArray K, double xi, InputArray D, OutputArray jacobian=noArray())\n \nvoid cv::omnidir::projectPoints (InputArray objectPoints, OutputArray imagePoints, InputArray rvec, InputArray tvec, InputArray K, double xi, InputArray D, OutputArray jacobian=noArray())\n Projects points for omnidirectional camera using CMei's model.  \n \ndouble cv::omnidir::stereoCalibrate (InputOutputArrayOfArrays objectPoints, InputOutputArrayOfArrays imagePoints1, InputOutputArrayOfArrays imagePoints2, const Size &imageSize1, const Size &imageSize2, InputOutputArray K1, InputOutputArray xi1, InputOutputArray D1, InputOutputArray K2, InputOutputArray xi2, InputOutputArray D2, OutputArray rvec, OutputArray tvec, OutputArrayOfArrays rvecsL, OutputArrayOfArrays tvecsL, int flags, TermCriteria criteria, OutputArray idx=noArray())\n Stereo calibration for omnidirectional camera model. It computes the intrinsic parameters for two cameras and the extrinsic parameters between two cameras. The default depth of outputs is CV_64F.  \n \nvoid cv::omnidir::stereoReconstruct (InputArray image1, InputArray image2, InputArray K1, InputArray D1, InputArray xi1, InputArray K2, InputArray D2, InputArray xi2, InputArray R, InputArray T, int flag, int numDisparities, int SADWindowSize, OutputArray disparity, OutputArray image1Rec, OutputArray image2Rec, const Size &newSize=Size(), InputArray Knew=cv::noArray(), OutputArray pointCloud=cv::noArray(), int pointType=XYZRGB)\n Stereo 3D reconstruction from a pair of images.  \n \nvoid cv::omnidir::stereoRectify (InputArray R, InputArray T, OutputArray R1, OutputArray R2)\n Stereo rectification for omnidirectional camera model. It computes the rectification rotations for two cameras.  \n \nvoid cv::omnidir::undistortImage (InputArray distorted, OutputArray undistorted, InputArray K, InputArray D, InputArray xi, int flags, InputArray Knew=cv::noArray(), const Size &new_size=Size(), InputArray R=Mat::eye(3, 3, CV_64F))\n Undistort omnidirectional images to perspective images.  \n \nvoid cv::omnidir::undistortPoints (InputArray distorted, OutputArray undistorted, InputArray K, InputArray D, InputArray xi, InputArray R)\n Undistort 2D image points for omnidirectional camera using CMei's model.  \n \n\nMacro Definition Documentation\n\n◆ HEAD\n\n#define HEAD   -1\n\n#include <opencv2/ccalib/multicalib.hpp>\n\n◆ INVALID\n\n#define INVALID   -2\n\n#include <opencv2/ccalib/multicalib.hpp>\n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/ccalib/omnidir.hpp>\n\nEnumeratorCALIB_USE_GUESS Python: cv.omnidir.CALIB_USE_GUESS\nCALIB_FIX_SKEW Python: cv.omnidir.CALIB_FIX_SKEW\nCALIB_FIX_K1 Python: cv.omnidir.CALIB_FIX_K1\nCALIB_FIX_K2 Python: cv.omnidir.CALIB_FIX_K2\nCALIB_FIX_P1 Python: cv.omnidir.CALIB_FIX_P1\nCALIB_FIX_P2 Python: cv.omnidir.CALIB_FIX_P2\nCALIB_FIX_XI Python: cv.omnidir.CALIB_FIX_XI\nCALIB_FIX_GAMMA Python: cv.omnidir.CALIB_FIX_GAMMA\nCALIB_FIX_CENTER Python: cv.omnidir.CALIB_FIX_CENTER\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/ccalib/omnidir.hpp>\n\nEnumeratorRECTIFY_PERSPECTIVE Python: cv.omnidir.RECTIFY_PERSPECTIVE\nRECTIFY_CYLINDRICAL Python: cv.omnidir.RECTIFY_CYLINDRICAL\nRECTIFY_LONGLATI Python: cv.omnidir.RECTIFY_LONGLATI\nRECTIFY_STEREOGRAPHIC Python: cv.omnidir.RECTIFY_STEREOGRAPHIC\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/ccalib/omnidir.hpp>\n\nEnumeratorXYZRGB Python: cv.omnidir.XYZRGB\nXYZ Python: cv.omnidir.XYZ\n\nFunction Documentation\n\n◆ calibrate()\n\ndouble cv::omnidir::calibrate \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints, \n\nSize \nsize, \n\nInputOutputArray \nK, \n\nInputOutputArray \nxi, \n\nInputOutputArray \nD, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nint \nflags, \n\nTermCriteria \ncriteria, \n\nOutputArray \nidx = noArray() \n\n)\n\nPython:cv.omnidir.calibrate(objectPoints, imagePoints, size, K, xi, D, flags, criteria[, rvecs[, tvecs[, idx]]]) -> retval, K, xi, D, rvecs, tvecs, idx\n\n#include <opencv2/ccalib/omnidir.hpp>\nPerform omnidirectional camera calibration, the default depth of outputs is CV_64F. \nParameters\n\nobjectPointsVector of vector of Vec3f object points in world (pattern) coordinate. It also can be vector of Mat with size 1xN/Nx1 and type CV_32FC3. Data with depth of 64_F is also acceptable. \nimagePointsVector of vector of Vec2f corresponding image points of objectPoints. It must be the same size and the same type with objectPoints. \nsizeImage size of calibration images. \nKOutput calibrated camera matrix. \nxiOutput parameter xi for CMei's model \nDOutput distortion parameters \\((k_1, k_2, p_1, p_2)\\) \nrvecsOutput rotations for each calibration images \ntvecsOutput translation for each calibration images \nflagsThe flags that control calibrate \ncriteriaTermination criteria for optimization \nidxIndices of images that pass initialization, which are really used in calibration. So the size of rvecs is the same as idx.total(). \n\n◆ initUndistortRectifyMap()\n\nvoid cv::omnidir::initUndistortRectifyMap \n(\nInputArray \nK, \n\nInputArray \nD, \n\nInputArray \nxi, \n\nInputArray \nR, \n\nInputArray \nP, \n\nconst cv::Size & \nsize, \n\nint \nm1type, \n\nOutputArray \nmap1, \n\nOutputArray \nmap2, \n\nint \nflags \n\n)\n\nPython:cv.omnidir.initUndistortRectifyMap(K, D, xi, R, P, size, m1type, flags[, map1[, map2]]) -> map1, map2\n\n#include <opencv2/ccalib/omnidir.hpp>\nComputes undistortion and rectification maps for omnidirectional camera image transform by a rotation R. It output two maps that are used for cv::remap(). If D is empty then zero distortion is used, if R or P is empty then identity matrices are used. \nParameters\n\nKCamera matrix \\(K = \\vecthreethree{f_x}{s}{c_x}{0}{f_y}{c_y}{0}{0}{_1}\\), with depth CV_32F or CV_64F \nDInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2)\\), with depth CV_32F or CV_64F \nxiThe parameter xi for CMei's model \nRRotation transform between the original and object space : 3x3 1-channel, or vector: 3x1/1x3, with depth CV_32F or CV_64F \nPNew camera matrix (3x3) or new projection matrix (3x4) \nsizeUndistorted image size. \nm1typeType of the first output map that can be CV_32FC1 or CV_16SC2 . See convertMaps() for details. \nmap1The first output map. \nmap2The second output map. \nflagsFlags indicates the rectification type, RECTIFY_PERSPECTIVE, RECTIFY_CYLINDRICAL, RECTIFY_LONGLATI and RECTIFY_STEREOGRAPHIC are supported. \n\n◆ projectPoints() [1/2]\n\nvoid cv::omnidir::projectPoints \n(\nInputArray \nobjectPoints, \n\nOutputArray \nimagePoints, \n\nconst Affine3d & \naffine, \n\nInputArray \nK, \n\ndouble \nxi, \n\nInputArray \nD, \n\nOutputArray \njacobian = noArray() \n\n)\n\nPython:cv.omnidir.projectPoints(objectPoints, rvec, tvec, K, xi, D[, imagePoints[, jacobian]]) -> imagePoints, jacobian\n\n#include <opencv2/ccalib/omnidir.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ projectPoints() [2/2]\n\nvoid cv::omnidir::projectPoints \n(\nInputArray \nobjectPoints, \n\nOutputArray \nimagePoints, \n\nInputArray \nrvec, \n\nInputArray \ntvec, \n\nInputArray \nK, \n\ndouble \nxi, \n\nInputArray \nD, \n\nOutputArray \njacobian = noArray() \n\n)\n\nPython:cv.omnidir.projectPoints(objectPoints, rvec, tvec, K, xi, D[, imagePoints[, jacobian]]) -> imagePoints, jacobian\n\n#include <opencv2/ccalib/omnidir.hpp>\nProjects points for omnidirectional camera using CMei's model. \nThis module was accepted as a GSoC 2015 project for OpenCV, authored by Baisheng Lai, mentored by Bo Li. \nParameters\n\nobjectPointsObject points in world coordinate, vector of vector of Vec3f or Mat of 1xN/Nx1 3-channel of type CV_32F and N is the number of points. 64F is also acceptable. \nimagePointsOutput array of image points, vector of vector of Vec2f or 1xN/Nx1 2-channel of type CV_32F. 64F is also acceptable. \nrvecvector of rotation between world coordinate and camera coordinate, i.e., om \ntvecvector of translation between pattern coordinate and camera coordinate \nKCamera matrix \\(K = \\vecthreethree{f_x}{s}{c_x}{0}{f_y}{c_y}{0}{0}{_1}\\). \nDInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2)\\). \nxiThe parameter xi for CMei's model \njacobianOptional output 2Nx16 of type CV_64F jacobian matrix, contains the derivatives of image pixel points wrt parameters including \\(om, T, f_x, f_y, s, c_x, c_y, xi, k_1, k_2, p_1, p_2\\). This matrix will be used in calibration by optimization.\n\nThe function projects object 3D points of world coordinate to image pixels, parameter by intrinsic and extrinsic parameters. Also, it optionally compute a by-product: the jacobian matrix containing contains the derivatives of image pixel points wrt intrinsic and extrinsic parameters. \n\n◆ stereoCalibrate()\n\ndouble cv::omnidir::stereoCalibrate \n(\nInputOutputArrayOfArrays \nobjectPoints, \n\nInputOutputArrayOfArrays \nimagePoints1, \n\nInputOutputArrayOfArrays \nimagePoints2, \n\nconst Size & \nimageSize1, \n\nconst Size & \nimageSize2, \n\nInputOutputArray \nK1, \n\nInputOutputArray \nxi1, \n\nInputOutputArray \nD1, \n\nInputOutputArray \nK2, \n\nInputOutputArray \nxi2, \n\nInputOutputArray \nD2, \n\nOutputArray \nrvec, \n\nOutputArray \ntvec, \n\nOutputArrayOfArrays \nrvecsL, \n\nOutputArrayOfArrays \ntvecsL, \n\nint \nflags, \n\nTermCriteria \ncriteria, \n\nOutputArray \nidx = noArray() \n\n)\n\nPython:cv.omnidir.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, imageSize1, imageSize2, K1, xi1, D1, K2, xi2, D2, flags, criteria[, rvec[, tvec[, rvecsL[, tvecsL[, idx]]]]]) -> retval, objectPoints, imagePoints1, imagePoints2, K1, xi1, D1, K2, xi2, D2, rvec, tvec, rvecsL, tvecsL, idx\n\n#include <opencv2/ccalib/omnidir.hpp>\nStereo calibration for omnidirectional camera model. It computes the intrinsic parameters for two cameras and the extrinsic parameters between two cameras. The default depth of outputs is CV_64F. \nParameters\n\nobjectPointsObject points in world (pattern) coordinate. Its type is vector<vector<Vec3f> >. It also can be vector of Mat with size 1xN/Nx1 and type CV_32FC3. Data with depth of 64_F is also acceptable. \nimagePoints1The corresponding image points of the first camera, with type vector<vector<Vec2f> >. It must be the same size and the same type as objectPoints. \nimagePoints2The corresponding image points of the second camera, with type vector<vector<Vec2f> >. It must be the same size and the same type as objectPoints. \nimageSize1Image size of calibration images of the first camera. \nimageSize2Image size of calibration images of the second camera. \nK1Output camera matrix for the first camera. \nxi1Output parameter xi of Mei's model for the first camera \nD1Output distortion parameters \\((k_1, k_2, p_1, p_2)\\) for the first camera \nK2Output camera matrix for the first camera. \nxi2Output parameter xi of CMei's model for the second camera \nD2Output distortion parameters \\((k_1, k_2, p_1, p_2)\\) for the second camera \nrvecOutput rotation between the first and second camera \ntvecOutput translation between the first and second camera \nrvecsLOutput rotation for each image of the first camera \ntvecsLOutput translation for each image of the first camera \nflagsThe flags that control stereoCalibrate \ncriteriaTermination criteria for optimization \nidxIndices of image pairs that pass initialization, which are really used in calibration. So the size of rvecs is the same as idx.total(). @ \n\n◆ stereoReconstruct()\n\nvoid cv::omnidir::stereoReconstruct \n(\nInputArray \nimage1, \n\nInputArray \nimage2, \n\nInputArray \nK1, \n\nInputArray \nD1, \n\nInputArray \nxi1, \n\nInputArray \nK2, \n\nInputArray \nD2, \n\nInputArray \nxi2, \n\nInputArray \nR, \n\nInputArray \nT, \n\nint \nflag, \n\nint \nnumDisparities, \n\nint \nSADWindowSize, \n\nOutputArray \ndisparity, \n\nOutputArray \nimage1Rec, \n\nOutputArray \nimage2Rec, \n\nconst Size & \nnewSize = Size(), \n\nInputArray \nKnew = cv::noArray(), \n\nOutputArray \npointCloud = cv::noArray(), \n\nint \npointType = XYZRGB \n\n)\n\nPython:cv.omnidir.stereoReconstruct(image1, image2, K1, D1, xi1, K2, D2, xi2, R, T, flag, numDisparities, SADWindowSize[, disparity[, image1Rec[, image2Rec[, newSize[, Knew[, pointCloud[, pointType]]]]]]]) -> disparity, image1Rec, image2Rec, pointCloud\n\n#include <opencv2/ccalib/omnidir.hpp>\nStereo 3D reconstruction from a pair of images. \nParameters\n\nimage1The first input image \nimage2The second input image \nK1Input camera matrix of the first camera \nD1Input distortion parameters \\((k_1, k_2, p_1, p_2)\\) for the first camera \nxi1Input parameter xi for the first camera for CMei's model \nK2Input camera matrix of the second camera \nD2Input distortion parameters \\((k_1, k_2, p_1, p_2)\\) for the second camera \nxi2Input parameter xi for the second camera for CMei's model \nRRotation between the first and second camera \nTTranslation between the first and second camera \nflagFlag of rectification type, RECTIFY_PERSPECTIVE or RECTIFY_LONGLATI \nnumDisparitiesThe parameter 'numDisparities' in StereoSGBM, see StereoSGBM for details. \nSADWindowSizeThe parameter 'SADWindowSize' in StereoSGBM, see StereoSGBM for details. \ndisparityDisparity map generated by stereo matching \nimage1RecRectified image of the first image \nimage2Recrectified image of the second image \nnewSizeImage size of rectified image, see omnidir::undistortImage \nKnewNew camera matrix of rectified image, see omnidir::undistortImage \npointCloudPoint cloud of 3D reconstruction, with type CV_64FC3 \npointTypePoint cloud type, it can be XYZRGB or XYZ \n\n◆ stereoRectify()\n\nvoid cv::omnidir::stereoRectify \n(\nInputArray \nR, \n\nInputArray \nT, \n\nOutputArray \nR1, \n\nOutputArray \nR2 \n\n)\n\nPython:cv.omnidir.stereoRectify(R, T[, R1[, R2]]) -> R1, R2\n\n#include <opencv2/ccalib/omnidir.hpp>\nStereo rectification for omnidirectional camera model. It computes the rectification rotations for two cameras. \nParameters\n\nRRotation between the first and second camera \nTTranslation between the first and second camera \nR1Output 3x3 rotation matrix for the first camera \nR2Output 3x3 rotation matrix for the second camera \n\n◆ undistortImage()\n\nvoid cv::omnidir::undistortImage \n(\nInputArray \ndistorted, \n\nOutputArray \nundistorted, \n\nInputArray \nK, \n\nInputArray \nD, \n\nInputArray \nxi, \n\nint \nflags, \n\nInputArray \nKnew = cv::noArray(), \n\nconst Size & \nnew_size = Size(), \n\nInputArray \nR = Mat::eye(3, 3, CV_64F) \n\n)\n\nPython:cv.omnidir.undistortImage(distorted, K, D, xi, flags[, undistorted[, Knew[, new_size[, R]]]]) -> undistorted\n\n#include <opencv2/ccalib/omnidir.hpp>\nUndistort omnidirectional images to perspective images. \nParameters\n\ndistortedThe input omnidirectional image. \nundistortedThe output undistorted image. \nKCamera matrix \\(K = \\vecthreethree{f_x}{s}{c_x}{0}{f_y}{c_y}{0}{0}{_1}\\). \nDInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2)\\). \nxiThe parameter xi for CMei's model. \nflagsFlags indicates the rectification type, RECTIFY_PERSPECTIVE, RECTIFY_CYLINDRICAL, RECTIFY_LONGLATI and RECTIFY_STEREOGRAPHIC \nKnewCamera matrix of the distorted image. If it is not assigned, it is just K. \nnew_sizeThe new image size. By default, it is the size of distorted. \nRRotation matrix between the input and output images. By default, it is identity matrix. \n\n◆ undistortPoints()\n\nvoid cv::omnidir::undistortPoints \n(\nInputArray \ndistorted, \n\nOutputArray \nundistorted, \n\nInputArray \nK, \n\nInputArray \nD, \n\nInputArray \nxi, \n\nInputArray \nR \n\n)\n\nPython:cv.omnidir.undistortPoints(distorted, K, D, xi, R[, undistorted]) -> undistorted\n\n#include <opencv2/ccalib/omnidir.hpp>\nUndistort 2D image points for omnidirectional camera using CMei's model. \nParameters\n\ndistortedArray of distorted image points, vector of Vec2f or 1xN/Nx1 2-channel Mat of type CV_32F, 64F depth is also acceptable \nKCamera matrix \\(K = \\vecthreethree{f_x}{s}{c_x}{0}{f_y}{c_y}{0}{0}{_1}\\). \nDDistortion coefficients \\((k_1, k_2, p_1, p_2)\\). \nxiThe parameter xi for CMei's model \nRRotation trainsform between the original and object space : 3x3 1-channel, or vector: 3x1/1x3 1-channel or 1x1 3-channel \nundistortedarray of normalized object points, vector of Vec2f/Vec2d or 1xN/Nx1 2-channel Mat with the same depth of distorted points. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dd/deb/group__bioinspired.html","content_type":"text/html","title":"OpenCV: Biologically inspired vision models and derivated tools","language":null},"page_content":"OpenCV: Biologically inspired vision models and derivated tools\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations \nBiologically inspired vision models and derivated tools\n\nDetailed Description\nThe module provides biological visual systems models (human visual system and others). It also provides derivated objects that take advantage of those bio-inspired models.\nBioinspired Module Retina Introduction \n\nClasses\nclass  cv::bioinspired::Retina\n class which allows the Gipsa/Listic Labs model to be used with OpenCV.  More...\n \nclass  cv::bioinspired::RetinaFastToneMapping\n a wrapper class which allows the tone mapping algorithm of Meylan&al(2007) to be used with OpenCV.  More...\n \nstruct  cv::bioinspired::RetinaParameters\n retina model parameters structure  More...\n \nstruct  cv::bioinspired::SegmentationParameters\n parameter structure that stores the transient events detector setup parameters  More...\n \nclass  cv::bioinspired::TransientAreasSegmentationModule\n class which provides a transient/moving areas segmentation module  More...\n \n\nEnumerations\nenum  { \n  cv::bioinspired::RETINA_COLOR_RANDOM\n, \n  cv::bioinspired::RETINA_COLOR_DIAGONAL\n, \n  cv::bioinspired::RETINA_COLOR_BAYER\n\n }\n \n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/bioinspired/retina.hpp>\n\nEnumeratorRETINA_COLOR_RANDOM Python: cv.bioinspired.RETINA_COLOR_RANDOMeach pixel position is either R, G or B in a random choice \n\nRETINA_COLOR_DIAGONAL Python: cv.bioinspired.RETINA_COLOR_DIAGONALcolor sampling is RGBRGBRGB..., line 2 BRGBRGBRG..., line 3, GBRGBRGBR... \n\nRETINA_COLOR_BAYER Python: cv.bioinspired.RETINA_COLOR_BAYERstandard bayer sampling \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d8/d8c/group__sfm.html","content_type":"text/html","title":"OpenCV: Structure From Motion","language":null},"page_content":"OpenCV: Structure From Motion\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nStructure From Motion\n\nModules\n Conditioning\n \n Fundamental\n \n Input/Output\n \n Numeric\n \n Projection\n \n Robust Estimation\n \n Triangulation\n \n Reconstruction\n \n Simple Pipeline\n \n\nDetailed Description\nThe opencv_sfm module contains algorithms to perform 3d reconstruction from 2d images.\nThe core of the module is based on a light version of Libmv originally developed by Sameer Agarwal and Keir Mierle.\nWhats is libmv? \nlibmv, also known as the Library for Multiview Reconstruction (or LMV), is the computer vision backend for Blender's motion tracking abilities. Unlike other vision libraries with general ambitions, libmv is focused on algorithms for match moving, specifically targeting Blender as the primary customer. Dense reconstruction, reconstruction from unorganized photo collections, image recognition, and other tasks are not a focus of libmv.\nDevelopment \nlibmv is officially under the Blender umbrella, and so is developed on developer.blender.org. The source repository can get checked out independently from Blender.\nThis module has been originally developed as a project for Google Summer of Code 2012-2015.\nNote\nNotice that it is compiled only when Eigen, GLog and GFlags are correctly installed.\n Check installation instructions in the following tutorial: SFM module installation \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d0/d1e/gapi.html","content_type":"text/html","title":"OpenCV: Graph API","language":null},"page_content":"OpenCV: Graph API\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nGraph API\n\nIntroduction\nOpenCV Graph API (or G-API) is a new OpenCV module targeted to make regular image processing fast and portable. These two goals are achieved by introducing a new graph-based model of execution.\nG-API is a special module in OpenCV – in contrast with the majority of other main modules, this one acts as a framework rather than some specific CV algorithm. G-API provides means to define CV operations, construct graphs (in form of expressions) using it, and finally implement and run the operations for a particular backend.\nNoteG-API is a new module and now is in active development. It's API is volatile at the moment and there may be minor but compatibility-breaking changes in the future.\n\nContents\nG-API documentation is organized into the following chapters:\n\nWhy Graph API?\nThe motivation behind G-API and its goals.\n\nHigh-level design overview\nGeneral overview of G-API architecture and its major internal components.\n\nKernel API\nLearn how to introduce new operations in G-API and implement it for various backends.\n\nImplementation details\nLow-level implementation details of G-API, for those who want to contribute.\n\nAPI Reference: functions and classes\nG-API framework\nCore G-API classes, data types, backends, etc.\n\nG-API Core functionality\nCore G-API operations - arithmetic, boolean, and other matrix operations;\n\nG-API Image processing functionality\nImage processing functions: color space conversions, various filters, etc.\n\nG-API Video processing functionality\nVideo processing functionality.\n\nG-API Drawing and composition functionality\nDrawing and composition functionality\n\nAPI Example\nA very basic example of G-API pipeline is shown below:\n#include <opencv2/videoio.hpp>\n#include <opencv2/highgui.hpp>\n#include <opencv2/gapi.hpp>\n#include <opencv2/gapi/core.hpp>\n#include <opencv2/gapi/imgproc.hpp>\n \nint main(int argc, char *argv[])\n{\n cv::VideoCapture cap;\n if (argc > 1) cap.open(argv[1]);\n else cap.open(0);\n CV_Assert(cap.isOpened());\n \n cv::GMat in;\n cv::GMat vga      = cv::gapi::resize(in, cv::Size(), 0.5, 0.5);\n cv::GMat gray     = cv::gapi::BGR2Gray(vga);\n cv::GMat blurred  = cv::gapi::blur(gray, cv::Size(5,5));\n cv::GMat edges    = cv::gapi::Canny(blurred, 32, 128, 3);\n cv::GMat b,g,r;\n    std::tie(b,g,r)   = cv::gapi::split3(vga);\n cv::GMat out      = cv::gapi::merge3(b, g | edges, r);\n cv::GComputation ac(in, out);\n \n cv::Mat input_frame;\n cv::Mat output_frame;\n CV_Assert(cap.read(input_frame));\n do\n    {\n        ac.apply(input_frame, output_frame);\n cv::imshow(\"output\", output_frame);\n    } while (cap.read(input_frame) && cv::waitKey(30) < 0);\n \n return 0;\n}\ncv::GComputationGComputation class represents a captured computation graph. GComputation objects form boundaries for ...Definition gcomputation.hpp:121\ncv::GMatGMat class represents image or tensor data in the graph.Definition gmat.hpp:68\ncv::Matn-dimensional dense array classDefinition mat.hpp:828\ncv::Size_Template class for specifying the size of an image or rectangle.Definition types.hpp:335\ncv::VideoCaptureClass for video capturing from video files, image sequences or cameras.Definition videoio.hpp:735\ncv::VideoCapture::readvirtual bool read(OutputArray image)Grabs, decodes and returns the next video frame.\ncv::VideoCapture::openvirtual bool open(const String &filename, int apiPreference=CAP_ANY)Opens a video file or a capturing device or an IP video stream for video capturing.\ncv::VideoCapture::isOpenedvirtual bool isOpened() constReturns true if video capturing has been initialized already.\ncore.hpp\nimgproc.hpp\ngapi.hpp\nCV_Assert#define CV_Assert(expr)Checks a condition at runtime and throws exception if it fails.Definition base.hpp:359\ncv::gapi::BGR2GrayGMat BGR2Gray(const GMat &src)Converts an image from BGR color space to gray-scaled.\ncv::gapi::CannyGMat Canny(const GMat &image, double threshold1, double threshold2, int apertureSize=3, bool L2gradient=false)Finds edges in an image using the Canny algorithm.\ncv::gapi::blurGMat blur(const GMat &src, const Size &ksize, const Point &anchor=Point(-1,-1), int borderType=BORDER_DEFAULT, const Scalar &borderValue=Scalar(0))Blurs an image using the normalized box filter.\ncv::gapi::split3std::tuple< GMat, GMat, GMat > split3(const GMat &src)Divides a 3-channel matrix into 3 single-channel matrices.\ncv::gapi::resizeGMat resize(const GMat &src, const Size &dsize, double fx=0, double fy=0, int interpolation=INTER_LINEAR)Resizes an image.\ncv::gapi::merge3GMat merge3(const GMat &src1, const GMat &src2, const GMat &src3)Creates one 3-channel matrix out of 3 single-channel ones.\ncv::imshowvoid imshow(const String &winname, InputArray mat)Displays an image in the specified window.\ncv::waitKeyint waitKey(int delay=0)Waits for a pressed key.\nhighgui.hpp\nmainint main(int argc, char *argv[])Definition highgui_qt.cpp:3\nvideoio.hpp\nG-API is a separate OpenCV module so its header files have to be included explicitly. The first four lines of main() create and initialize OpenCV's standard video capture object, which fetches video frames from either an attached camera or a specified file.\nG-API pipeline is constructed next. In fact, it is a series of G-API operation calls on cv::GMat data. The important aspect of G-API is that this code block is just a declaration of actions, but not the actions themselves. No processing happens at this point, G-API only tracks which operations form pipeline and how it is connected. G-API Data objects (here it is cv::GMat) are used to connect operations each other. in is an empty cv::GMat signalling that it is a beginning of computation.\nAfter G-API code is written, it is captured into a call graph with instantiation of cv::GComputation object. This object takes input/output data references (in this example, in and out cv::GMat objects, respectively) as parameters and reconstructs the call graph based on all the data flow between in and out.\ncv::GComputation is a thin object in sense that it just captures which operations form up a computation. However, it can be used to execute computations – in the following processing loop, every captured frame (a cv::Mat input_frame) is passed to cv::GComputation::apply().\n\nExample pipeline running on sample video 'vtest.avi'\ncv::GComputation::apply() is a polimorphic method which accepts a variadic number of arguments. Since this computation is defined on one input, one output, a special overload of cv::GComputation::apply() is used to pass input data and get output data.\nInternally, cv::GComputation::apply() compiles the captured graph for the given input parameters and executes the compiled graph on data immediately.\nThere is a number important concepts can be outlines with this example:\nGraph declaration and graph execution are distinct steps;\nGraph is built implicitly from a sequence of G-API expressions;\nG-API supports function-like calls – e.g. cv::gapi::resize(), and operators, e.g operator|() which is used to compute bitwise OR;\nG-API syntax aims to look pure: every operation call within a graph yields a new result, thus forming a directed acyclic graph (DAG);\nGraph declaration is not bound to any data – real data objects (cv::Mat) come into picture after the graph is already declared.\n\nSee tutorials and porting examples to learn more on various G-API features and concepts. \n\nGenerated on Mon Nov 11 2024 23:11:40 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dc/d20/group__quality.html","content_type":"text/html","title":"OpenCV: Image Quality Analysis (IQA) API","language":null},"page_content":"OpenCV: Image Quality Analysis (IQA) API\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nImage Quality Analysis (IQA) API\n\nDetailed Description\n\nClasses\nclass  cv::quality::QualityBase\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/d61/group__text.html","content_type":"text/html","title":"OpenCV: Scene Text Detection and Recognition","language":null},"page_content":"OpenCV: Scene Text Detection and Recognition\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nScene Text Detection and Recognition\n\nModules\n Scene Text Detection\n \n Scene Text Recognition\n \n\nDetailed Description\nThe opencv_text module provides different algorithms for text detection and recognition in natural scene images. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d6/df4/group__cannops.html","content_type":"text/html","title":"OpenCV: Ascend-accelerated Computer Vision","language":null},"page_content":"OpenCV: Ascend-accelerated Computer Vision\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nAscend-accelerated Computer Vision\n\nModules\n Core part\n \n Operations for Ascend Backend.\n \n\nDetailed Description\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/d0d/group__photo.html","content_type":"text/html","title":"OpenCV: Computational Photography","language":null},"page_content":"OpenCV: Computational Photography\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nComputational Photography\n\nModules\n Inpainting\n \n Denoising\n \n HDR imaging\n \n Contrast Preserving Decolorization\n \n Seamless Cloning\n \n Non-Photorealistic Rendering\n \n\nDetailed Description\nThis module includes photo processing algorithms \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/df/dff/group__cvv.html","content_type":"text/html","title":"OpenCV: GUI for Interactive Visual Debugging of Computer Vision Programs","language":null},"page_content":"OpenCV: GUI for Interactive Visual Debugging of Computer Vision Programs\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nNamespaces |\nClasses |\nFunctions \nGUI for Interactive Visual Debugging of Computer Vision Programs\n\nDetailed Description\nNamespace for all functions is cvv, i.e. cvv::showImage().\nCompilation:\n\nFor development, i.e. for cvv GUI to show up, compile your code using cvv with g++ -DCVVISUAL_DEBUGMODE*.\nFor release, i.e. cvv calls doing nothing, compile your code without above flag.\n\nSee cvv tutorial for a commented example application using cvv. \n\nNamespaces\nnamespace  cvv::impl\n \n\nClasses\nclass  cvv::FinalShowCaller\n RAII-class to call finalShow() in it's dtor.  More...\n \n\nFunctions\nstatic void cvv::debugDMatch (cv::InputArray img1, std::vector< cv::KeyPoint > keypoints1, cv::InputArray img2, std::vector< cv::KeyPoint > keypoints2, std::vector< cv::DMatch > matches, const impl::CallMetaData &data, const char *description=nullptr, const char *view=nullptr, bool useTrainDescriptor=true)\n Add a filled in DMatch <dmatch> to debug GUI.  \n \nstatic void cvv::debugDMatch (cv::InputArray img1, std::vector< cv::KeyPoint > keypoints1, cv::InputArray img2, std::vector< cv::KeyPoint > keypoints2, std::vector< cv::DMatch > matches, const impl::CallMetaData &data, const std::string &description, const std::string &view, bool useTrainDescriptor=true)\n \nstatic void cvv::debugFilter (cv::InputArray original, cv::InputArray result, impl::CallMetaData metaData, const ::std::string &description, const ::std::string &view=\"\")\n \nstatic void cvv::debugFilter (cv::InputArray original, cv::InputArray result, impl::CallMetaData metaData=impl::CallMetaData(), const char *description=nullptr, const char *view=nullptr)\n Use the debug-framework to compare two images (from which the second is intended to be the result of a filter applied to the first).  \n \nstatic bool cvv::debugMode ()\n Returns whether debug-mode is active for this TU and thread.  \n \nvoid cvv::finalShow ()\n Passes the control to the debug-window for a last time.  \n \nstatic void cvv::setDebugFlag (bool active)\n Enable or disable cvv for current translation unit and thread.  \n \nstatic void cvv::showImage (cv::InputArray img, impl::CallMetaData metaData, const ::std::string &description, const ::std::string &view=\"\")\n \nstatic void cvv::showImage (cv::InputArray img, impl::CallMetaData metaData=impl::CallMetaData(), const char *description=nullptr, const char *view=nullptr)\n Add a single image to debug GUI (similar to imshow <>).  \n \n\nFunction Documentation\n\n◆ debugDMatch() [1/2]\n\nstatic void cvv::debugDMatch \n(\ncv::InputArray \nimg1, \n\nstd::vector< cv::KeyPoint > \nkeypoints1, \n\ncv::InputArray \nimg2, \n\nstd::vector< cv::KeyPoint > \nkeypoints2, \n\nstd::vector< cv::DMatch > \nmatches, \n\nconst impl::CallMetaData & \ndata, \n\nconst char * \ndescription = nullptr, \n\nconst char * \nview = nullptr, \n\nbool \nuseTrainDescriptor = true \n\n)\n\ninlinestatic \n\n#include <opencv2/cvv/dmatch.hpp>\nAdd a filled in DMatch <dmatch> to debug GUI. \nThe matches can are visualized for interactive inspection in different GUI views (one similar to an interactive :draw_matches:drawMatches<>).\nParameters\n\nimg1First image used in DMatch <dmatch>. \nkeypoints1Keypoints of first image. \nimg2Second image used in DMatch. \nkeypoints2Keypoints of second image. \nmatches\ndataSee showImage \ndescriptionSee showImage \nviewSee showImage \nuseTrainDescriptorUse DMatch <dmatch>'s train descriptor index instead of query descriptor index. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ debugDMatch() [2/2]\n\nstatic void cvv::debugDMatch \n(\ncv::InputArray \nimg1, \n\nstd::vector< cv::KeyPoint > \nkeypoints1, \n\ncv::InputArray \nimg2, \n\nstd::vector< cv::KeyPoint > \nkeypoints2, \n\nstd::vector< cv::DMatch > \nmatches, \n\nconst impl::CallMetaData & \ndata, \n\nconst std::string & \ndescription, \n\nconst std::string & \nview, \n\nbool \nuseTrainDescriptor = true \n\n)\n\ninlinestatic \n\n#include <opencv2/cvv/dmatch.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ debugFilter() [1/2]\n\nstatic void cvv::debugFilter \n(\ncv::InputArray \noriginal, \n\ncv::InputArray \nresult, \n\nimpl::CallMetaData \nmetaData, \n\nconst ::std::string & \ndescription, \n\nconst ::std::string & \nview = \"\" \n\n)\n\ninlinestatic \n\n#include <opencv2/cvv/filter.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ debugFilter() [2/2]\n\nstatic void cvv::debugFilter \n(\ncv::InputArray \noriginal, \n\ncv::InputArray \nresult, \n\nimpl::CallMetaData \nmetaData = impl::CallMetaData(), \n\nconst char * \ndescription = nullptr, \n\nconst char * \nview = nullptr \n\n)\n\ninlinestatic \n\n#include <opencv2/cvv/filter.hpp>\nUse the debug-framework to compare two images (from which the second is intended to be the result of a filter applied to the first). \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ debugMode()\n\nstatic bool cvv::debugMode \n(\n)\n\ninlinestatic \n\n#include <opencv2/cvv/debug_mode.hpp>\nReturns whether debug-mode is active for this TU and thread. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ finalShow()\n\nvoid cvv::finalShow \n(\n)\n\ninline \n\n#include <opencv2/cvv/final_show.hpp>\nPasses the control to the debug-window for a last time. \nThis function must be called once after all cvv calls if any. As an alternative create an instance of FinalShowCaller, which calls finalShow() in its destructor (RAII-style). \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ setDebugFlag()\n\nstatic void cvv::setDebugFlag \n(\nbool \nactive)\n\ninlinestatic \n\n#include <opencv2/cvv/debug_mode.hpp>\nEnable or disable cvv for current translation unit and thread. \n(disabled this way has higher - but still low - overhead compared to using the compile flags). Parameters\n\nactive\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ showImage() [1/2]\n\nstatic void cvv::showImage \n(\ncv::InputArray \nimg, \n\nimpl::CallMetaData \nmetaData, \n\nconst ::std::string & \ndescription, \n\nconst ::std::string & \nview = \"\" \n\n)\n\ninlinestatic \n\n#include <opencv2/cvv/show_image.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ showImage() [2/2]\n\nstatic void cvv::showImage \n(\ncv::InputArray \nimg, \n\nimpl::CallMetaData \nmetaData = impl::CallMetaData(), \n\nconst char * \ndescription = nullptr, \n\nconst char * \nview = nullptr \n\n)\n\ninlinestatic \n\n#include <opencv2/cvv/show_image.hpp>\nAdd a single image to debug GUI (similar to imshow <>). \nParameters\n\nimgImage to show in debug GUI. \nmetaDataProperly initialized CallMetaData struct, i.e. information about file, line and function name for GUI. Use CVVISUAL_LOCATION macro. \ndescriptionHuman readable description to provide context to image. \nviewPreselect view that will be used to visualize this image in GUI. Other views can still be selected in GUI later on. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/db4/group__xfeatures2d.html","content_type":"text/html","title":"OpenCV: Extra 2D Features Framework","language":null},"page_content":"OpenCV: Extra 2D Features Framework\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nExtra 2D Features Framework\n\nModules\n Experimental 2D Features Algorithms\n \n Non-free 2D Features Algorithms\n \n Experimental 2D Features Matching Algorithm\n \n\nDetailed Description\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d5/d8e/group__cudaarithm.html","content_type":"text/html","title":"OpenCV: Operations on Matrices","language":null},"page_content":"OpenCV: Operations on Matrices\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nOperations on MatricesCUDA-accelerated Computer Vision\n\nModules\n Core Operations on Matrices\n \n Per-element Operations\n \n Matrix Reductions\n \n Arithm Operations on Matrices\n \n\nDetailed Description\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d2/d17/group__ovis.html","content_type":"text/html","title":"OpenCV: OGRE 3D Visualiser","language":null},"page_content":"OpenCV: OGRE 3D Visualiser\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations |\nFunctions \nOGRE 3D Visualiser\n\nDetailed Description\novis is a simplified rendering wrapper around ogre3d. The Ogre terminology is used in the API and Ogre Script is assumed to be used for advanced customization.\nBesides the API you see here, there are several environment variables that control the behavior of ovis. They are documented in createWindow.\n\nLoading geometry\nYou can create geometry on the fly or by loading Ogre .mesh files.\n\nBlender\nFor converting/ creating geometry Blender is recommended.\nBlender 2.7x is better tested, but Blender 2.8x should work too\ninstall blender2ogre matching your Blender version\ndownload the Ogre MSVC SDK which contains OgreXMLConverter.exe (in bin/) and set the path in the blender2ogre settings\nget ogre-meshviewer to enable the preview function in blender2ogre as well as for verifying the exported files\nin case the exported materials are not exactly how you want them, consult the Ogre Manual\n\nAssimp\nWhen using Ogre 1.12.9 or later, enabling the Assimp plugin allows to load arbitrary geometry. Simply pass bunny.obj instead of bunny.mesh as meshname in WindowScene::createEntity.\nYou should still use ogre-meshviewer to verify that the geometry is converted correctly. \n\nClasses\nclass  cv::ovis::WindowScene\n \n\nEnumerations\nenum  cv::ovis::EntityProperty { \n  cv::ovis::ENTITY_MATERIAL\n, \n  cv::ovis::ENTITY_SCALE\n, \n  cv::ovis::ENTITY_AABB_WORLD\n, \n  cv::ovis::ENTITY_ANIMBLEND_MODE\n, \n  cv::ovis::ENTITY_CAST_SHADOWS\n\n }\n \nenum  cv::ovis::MaterialProperty { \n  cv::ovis::MATERIAL_POINT_SIZE\n, \n  cv::ovis::MATERIAL_LINE_WIDTH\n, \n  cv::ovis::MATERIAL_OPACITY\n, \n  cv::ovis::MATERIAL_EMISSIVE\n, \n  cv::ovis::MATERIAL_DIFFUSE\n, \n  cv::ovis::MATERIAL_TEXTURE0\n, \n  cv::ovis::MATERIAL_TEXTURE = MATERIAL_TEXTURE0\n, \n  cv::ovis::MATERIAL_TEXTURE1\n, \n  cv::ovis::MATERIAL_TEXTURE2\n, \n  cv::ovis::MATERIAL_TEXTURE3\n\n }\n \nenum  cv::ovis::SceneSettings { \n  cv::ovis::SCENE_SEPARATE = 1\n, \n  cv::ovis::SCENE_INTERACTIVE = 2\n, \n  cv::ovis::SCENE_SHOW_CS_CROSS = 4\n, \n  cv::ovis::SCENE_AA = 8\n, \n  cv::ovis::SCENE_OFFSCREEN = 16\n, \n  cv::ovis::SCENE_SHADOWS = 32\n\n }\n \n\nFunctions\nvoid cv::ovis::addResourceLocation (const String &path)\n \nvoid cv::ovis::createGridMesh (const String &name, const Size2f &size, const Size &segments=Size(1, 1))\n \nvoid cv::ovis::createPlaneMesh (const String &name, const Size2f &size, InputArray image=noArray())\n \nvoid cv::ovis::createPointCloudMesh (const String &name, InputArray vertices, InputArray colors=noArray())\n \nvoid cv::ovis::createTriangleMesh (const String &name, InputArray vertices, InputArray normals=noArray(), InputArray indices=noArray())\n \nPtr< WindowScene > cv::ovis::createWindow (const String &title, const Size &size, int flags=SCENE_INTERACTIVE|SCENE_AA)\n \nvoid cv::ovis::setMaterialProperty (const String &name, const String &prop, const Scalar &value)\n \nvoid cv::ovis::setMaterialProperty (const String &name, int prop, const Scalar &value)\n \nvoid cv::ovis::setMaterialProperty (const String &name, int prop, const String &value)\n This is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts.  \n \nvoid cv::ovis::setMaterialProperty (const String &name, int prop, InputArray value)\n \nvoid cv::ovis::updateTexture (const String &name, InputArray image)\n \nint cv::ovis::waitKey (int delay=0)\n \n\nEnumeration Type Documentation\n\n◆ EntityProperty\n\nenum cv::ovis::EntityProperty\n\n#include <opencv2/ovis.hpp>\n\nEnumeratorENTITY_MATERIAL \nENTITY_SCALE \nENTITY_AABB_WORLD \nENTITY_ANIMBLEND_MODE \nENTITY_CAST_SHADOWS \n\n◆ MaterialProperty\n\nenum cv::ovis::MaterialProperty\n\n#include <opencv2/ovis.hpp>\n\nEnumeratorMATERIAL_POINT_SIZE \nMATERIAL_LINE_WIDTH \nMATERIAL_OPACITY \nMATERIAL_EMISSIVE \nMATERIAL_DIFFUSE \nMATERIAL_TEXTURE0 \nMATERIAL_TEXTURE \nMATERIAL_TEXTURE1 \nMATERIAL_TEXTURE2 \nMATERIAL_TEXTURE3 \n\n◆ SceneSettings\n\nenum cv::ovis::SceneSettings\n\n#include <opencv2/ovis.hpp>\n\nEnumeratorSCENE_SEPARATE the window will use a separate scene. The scene will be shared otherwise. \n\nSCENE_INTERACTIVE allow the user to control the camera. \n\nSCENE_SHOW_CS_CROSS draw coordinate system crosses for debugging \n\nSCENE_AA Apply anti-aliasing. The first window determines the setting for all windows. \n\nSCENE_OFFSCREEN Render off-screen without a window. Allows separate AA setting. Requires manual update via WindowScene::update. \n\nSCENE_SHADOWS Enable real-time shadows in the scene. All entities cast shadows by default. Control via ENTITY_CAST_SHADOWS. \n\nFunction Documentation\n\n◆ addResourceLocation()\n\nvoid cv::ovis::addResourceLocation \n(\nconst String & \npath)\n\n#include <opencv2/ovis.hpp>\nAdd an additional resource location that is search for meshes, textures and materials\nmust be called before the first createWindow. If give path does not exist, retries inside Ogre Media Directory. Parameters\n\npathfolder or Zip archive. \n\n◆ createGridMesh()\n\nvoid cv::ovis::createGridMesh \n(\nconst String & \nname, \n\nconst Size2f & \nsize, \n\nconst Size & \nsegments = Size(1, 1) \n\n)\n\n#include <opencv2/ovis.hpp>\ncreates a grid\ncreates a material with the same name Parameters\n\nnamename of the mesh \nsizeextents of the grid \nsegmentsnumber of segments per side \n\n◆ createPlaneMesh()\n\nvoid cv::ovis::createPlaneMesh \n(\nconst String & \nname, \n\nconst Size2f & \nsize, \n\nInputArray \nimage = noArray() \n\n)\n\n#include <opencv2/ovis.hpp>\ncreate a 2D plane, X right, Y down, Z up\ncreates a material with the same name Parameters\n\nnamename of the mesh \nsizesize in world units \nimageoptional texture \n\n◆ createPointCloudMesh()\n\nvoid cv::ovis::createPointCloudMesh \n(\nconst String & \nname, \n\nInputArray \nvertices, \n\nInputArray \ncolors = noArray() \n\n)\n\n#include <opencv2/ovis.hpp>\ncreates a point cloud mesh\ncreates a material with the same name Parameters\n\nnamename of the mesh \nverticesfloat vector of positions \ncolorsuchar vector of colors \n\n◆ createTriangleMesh()\n\nvoid cv::ovis::createTriangleMesh \n(\nconst String & \nname, \n\nInputArray \nvertices, \n\nInputArray \nnormals = noArray(), \n\nInputArray \nindices = noArray() \n\n)\n\n#include <opencv2/ovis.hpp>\ncreates a triangle mesh from vertex-vertex or face-vertex representation\ncreates a material with the same name Parameters\n\nnamename of the mesh \nverticesfloat vector of positions \nnormalsfloat vector of normals \nindicesint vector of indices \n\n◆ createWindow()\n\nPtr< WindowScene > cv::ovis::createWindow \n(\nconst String & \ntitle, \n\nconst Size & \nsize, \n\nint \nflags = SCENE_INTERACTIVE|SCENE_AA \n\n)\n\n#include <opencv2/ovis.hpp>\ncreate a new rendering window/ viewport Parameters\n\ntitlewindow title \nsizesize of the window \nflagsa combination of SceneSettings\n\nFurthermore, the behavior is controlled by the following environment variables\nOPENCV_OVIS_VERBOSE_LOG: print all of OGRE log output\nOPENCV_OVIS_RENDERSYSTEM: the name of the OGRE RenderSystem to use\nOPENCV_OVIS_NOVSYNC: disable VSYNC for all windows \n\n◆ setMaterialProperty() [1/4]\n\nvoid cv::ovis::setMaterialProperty \n(\nconst String & \nname, \n\nconst String & \nprop, \n\nconst Scalar & \nvalue \n\n)\n\n#include <opencv2/ovis.hpp>\nset the shader property of a material to the given value Parameters\n\nnamematerial name \npropproperty name \nvaluethe value \n\n◆ setMaterialProperty() [2/4]\n\nvoid cv::ovis::setMaterialProperty \n(\nconst String & \nname, \n\nint \nprop, \n\nconst Scalar & \nvalue \n\n)\n\n#include <opencv2/ovis.hpp>\nset the property of a material to the given value Parameters\n\nnamematerial name \npropMaterialProperty \nvaluethe value \n\n◆ setMaterialProperty() [3/4]\n\nvoid cv::ovis::setMaterialProperty \n(\nconst String & \nname, \n\nint \nprop, \n\nconst String & \nvalue \n\n)\n\n#include <opencv2/ovis.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ setMaterialProperty() [4/4]\n\nvoid cv::ovis::setMaterialProperty \n(\nconst String & \nname, \n\nint \nprop, \n\nInputArray \nvalue \n\n)\n\n#include <opencv2/ovis.hpp>\nset the texture of a material to the given value Parameters\n\nnamematerial name \npropMaterialProperty \nvaluethe texture data \n\n◆ updateTexture()\n\nvoid cv::ovis::updateTexture \n(\nconst String & \nname, \n\nInputArray \nimage \n\n)\n\n#include <opencv2/ovis.hpp>\nDeprecated:use setMaterialProperty \n\n◆ waitKey()\n\nint cv::ovis::waitKey \n(\nint \ndelay = 0)\n\n#include <opencv2/ovis.hpp>\nupdate all windows and wait for keyboard event\nParameters\n\ndelay0 is the special value that means \"forever\". Any positive number returns after sync to blank (typically 16ms). \n\nReturnsthe code of the pressed key or -1 if no key was pressed \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/df8/group__tracking.html","content_type":"text/html","title":"OpenCV: Tracking API","language":null},"page_content":"OpenCV: Tracking API\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses \nTracking API\n\nModules\n Tracking API implementation details\n \n Legacy Tracking API\n \n\nDetailed Description\nTracking is an important issue for many computer vision applications in real world scenario. The development in this area is very fragmented and this API is an interface useful for plug several algorithms and compare them. \n\nClasses\nclass  cv::TrackerCSRT\n the CSRT tracker  More...\n \nclass  cv::TrackerKCF\n the KCF (Kernelized Correlation Filter) tracker  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/dfb/intro.html","content_type":"text/html","title":"OpenCV: Introduction","language":null},"page_content":"OpenCV: Introduction\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nIntroduction\n\nOpenCV (Open Source Computer Vision Library: http://opencv.org) is an open-source library that includes several hundreds of computer vision algorithms. The document describes the so-called OpenCV 2.x API, which is essentially a C++ API, as opposed to the C-based OpenCV 1.x API (C API is deprecated and not tested with \"C\" compiler since OpenCV 2.4 releases)\nOpenCV has a modular structure, which means that the package includes several shared or static libraries. The following modules are available:\n\nCore functionality (core) - a compact module defining basic data structures, including the dense multi-dimensional array Mat and basic functions used by all other modules.\nImage Processing (imgproc) - an image processing module that includes linear and non-linear image filtering, geometrical image transformations (resize, affine and perspective warping, generic table-based remapping), color space conversion, histograms, and so on.\nImage file reading and writing (imgcodecs) - includes functions for reading and writing image files in various formats.\nVideo I/O (videoio) - an easy-to-use interface to video capturing and video codecs.\nHigh-level GUI (highgui) - an easy-to-use interface to simple UI capabilities.\nVideo Analysis (video) - a video analysis module that includes motion estimation, background subtraction, and object tracking algorithms.\nCamera Calibration and 3D Reconstruction (calib3d) - basic multiple-view geometry algorithms, single and stereo camera calibration, object pose estimation, stereo correspondence algorithms, and elements of 3D reconstruction.\n2D Features Framework (features2d) - salient feature detectors, descriptors, and descriptor matchers.\nObject Detection (objdetect) - detection of objects and instances of the predefined classes (for example, faces, eyes, mugs, people, cars, and so on).\nDeep Neural Network module (dnn) - Deep Neural Network module.\nMachine Learning (ml) - The Machine Learning module includes a set of classes and functions for statistical classification, regression, and clustering of data.\nComputational Photography (photo) - advanced photo processing techniques like denoising, inpainting.\nImages stitching (stitching) - functions for image stitching and panorama creation.\n... some other helper modules, such as FLANN and Google test wrappers, Python bindings, and others.\n\nThe further chapters of the document describe functionality of each module. But first, make sure to get familiar with the common API concepts used thoroughly in the library.\n\nAPI Concepts\n\ncv Namespace\nAll the OpenCV classes and functions are placed into the cv namespace. Therefore, to access this functionality from your code, use the cv:: specifier or using namespace cv; directive:\n#include \"opencv2/core.hpp\"\n...\ncv::Mat H = cv::findHomography(points1, points2, cv::RANSAC, 5);\n...\ncore.hpp\ncv::findHomographyMat findHomography(InputArray srcPoints, InputArray dstPoints, int method=0, double ransacReprojThreshold=3, OutputArray mask=noArray(), const int maxIters=2000, const double confidence=0.995)Finds a perspective transformation between two planes.\ncv::RANSAC@ RANSACRANSAC algorithm.Definition calib3d.hpp:448\n or : #include \"opencv2/core.hpp\"\nusing namespace cv;\n...\nMat H = findHomography(points1, points2, RANSAC, 5 );\n...\ncv::Matn-dimensional dense array classDefinition mat.hpp:828\ncvDefinition core.hpp:107\n Some of the current or future OpenCV external names may conflict with STL or other libraries. In this case, use explicit namespace specifiers to resolve the name conflicts: Mat a(100, 100, CV_32F);\nrandu(a, Scalar::all(1), Scalar::all(std::rand()));\ncv::log(a, a);\na /= std::log(2.);\nCV_32F#define CV_32FDefinition interface.h:78\n\nAutomatic Memory Management\nOpenCV handles all the memory automatically.\nFirst of all, std::vector, cv::Mat, and other data structures used by the functions and methods have destructors that deallocate the underlying memory buffers when needed. This means that the destructors do not always deallocate the buffers as in case of Mat. They take into account possible data sharing. A destructor decrements the reference counter associated with the matrix data buffer. The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is really copied. Instead, the reference counter is incremented to memorize that there is another owner of the same data. There is also the cv::Mat::clone method that creates a full copy of the matrix data. See the example below: // create a big 8Mb matrix\nMat A(1000, 1000, CV_64F);\n \n// create another header for the same matrix;\n// this is an instant operation, regardless of the matrix size.\nMat B = A;\n// create another header for the 3-rd row of A; no data is copied either\nMat C = B.row(3);\n// now create a separate copy of the matrix\nMat D = B.clone();\n// copy the 5-th row of B to C, that is, copy the 5-th row of A\n// to the 3-rd row of A.\nB.row(5).copyTo(C);\n// now let A and D share the data; after that the modified version\n// of A is still referenced by B and C.\nA = D;\n// now make B an empty matrix (which references no memory buffers),\n// but the modified version of A will still be referenced by C,\n// despite that C is just a single row of the original A\nB.release();\n \n// finally, make a full copy of C. As a result, the big modified\n// matrix will be deallocated, since it is not referenced by anyone\nC = C.clone();\ncv::Mat::cloneCV_NODISCARD_STD Mat clone() constCreates a full copy of the array and the underlying data.\ncv::Mat::copyTovoid copyTo(OutputArray m) constCopies the matrix to another one.\ncv::Mat::rowMat row(int y) constCreates a matrix header for the specified matrix row.\ncv::Mat::releasevoid release()Decrements the reference counter and deallocates the matrix if needed.\nCV_64F#define CV_64FDefinition interface.h:79\n You see that the use of Mat and other basic structures is simple. But what about high-level classes or even user data types created without taking automatic memory management into account? For them, OpenCV offers the cv::Ptr template class that is similar to std::shared_ptr from C++11. So, instead of using plain pointers: T* ptr = new T(...);\n you can use: Ptr<T> ptr(new T(...));\ncv::Ptrstd::shared_ptr< _Tp > PtrDefinition cvstd_wrapper.hpp:23\n or: Ptr<T> ptr = makePtr<T>(...);\n Ptr<T> encapsulates a pointer to a T instance and a reference counter associated with the pointer. See the cv::Ptr description for details.\n\nAutomatic Allocation of the Output Data\nOpenCV deallocates the memory automatically, as well as automatically allocates the memory for output function parameters most of the time. So, if a function has one or more input arrays (cv::Mat instances) and some output arrays, the output arrays are automatically allocated or reallocated. The size and type of the output arrays are determined from the size and type of input arrays. If needed, the functions take extra parameters that help to figure out the output array properties.\nExample: #include \"opencv2/imgproc.hpp\"\n#include \"opencv2/highgui.hpp\"\n \nusing namespace cv;\n \nint main(int, char**)\n{\n VideoCapture cap(0);\n if(!cap.isOpened()) return -1;\n \n Mat frame, edges;\n    namedWindow(\"edges\", WINDOW_AUTOSIZE);\n for(;;)\n    {\n        cap >> frame;\n        cvtColor(frame, edges, COLOR_BGR2GRAY);\n        GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);\n        Canny(edges, edges, 0, 30, 3);\n        imshow(\"edges\", edges);\n if(waitKey(30) >= 0) break;\n    }\n return 0;\n}\ncv::Size_Template class for specifying the size of an image or rectangle.Definition types.hpp:335\ncv::VideoCaptureClass for video capturing from video files, image sequences or cameras.Definition videoio.hpp:735\nhighgui.hpp\nmainint main(int argc, char *argv[])Definition highgui_qt.cpp:3\nimgproc.hpp\n The array frame is automatically allocated by the >> operator since the video frame resolution and the bit-depth is known to the video capturing module. The array edges is automatically allocated by the cvtColor function. It has the same size and the bit-depth as the input array. The number of channels is 1 because the color conversion code cv::COLOR_BGR2GRAY is passed, which means a color to grayscale conversion. Note that frame and edges are allocated only once during the first execution of the loop body since all the next video frames have the same resolution. If you somehow change the video resolution, the arrays are automatically reallocated.\nThe key component of this technology is the cv::Mat::create method. It takes the desired array size and type. If the array already has the specified size and type, the method does nothing. Otherwise, it releases the previously allocated data, if any (this part involves decrementing the reference counter and comparing it with zero), and then allocates a new buffer of the required size. Most functions call the cv::Mat::create method for each output array, and so the automatic output data allocation is implemented.\nSome notable exceptions from this scheme are cv::mixChannels, cv::RNG::fill, and a few other functions and methods. They are not able to allocate the output array, so you have to do this in advance.\n\nSaturation Arithmetics\nAs a computer vision library, OpenCV deals a lot with image pixels that are often encoded in a compact, 8- or 16-bit per channel, form and thus have a limited value range. Furthermore, certain operations on images, like color space conversions, brightness/contrast adjustments, sharpening, complex interpolation (bi-cubic, Lanczos) can produce values out of the available range. If you just store the lowest 8 (16) bits of the result, this results in visual artifacts and may affect a further image analysis. To solve this problem, the so-called saturation arithmetics is used. For example, to store r, the result of an operation, to an 8-bit image, you find the nearest value within the 0..255 range:\n\n\\[I(x,y)= \\min ( \\max (\\textrm{round}(r), 0), 255)\\]\n\nSimilar rules are applied to 8-bit signed, 16-bit signed and unsigned types. This semantics is used everywhere in the library. In C++ code, it is done using the cv::saturate_cast<> functions that resemble standard C++ cast operations. See below the implementation of the formula provided above: I.at<uchar>(y, x) = saturate_cast<uchar>(r);\nucharunsigned char ucharDefinition interface.h:51\n where cv::uchar is an OpenCV 8-bit unsigned integer type. In the optimized SIMD code, such SSE2 instructions as paddusb, packuswb, and so on are used. They help achieve exactly the same behavior as in C++ code.\nNoteSaturation is not applied when the result is 32-bit integer.\n\nFixed Pixel Types. Limited Use of Templates\nTemplates is a great feature of C++ that enables implementation of very powerful, efficient and yet safe data structures and algorithms. However, the extensive use of templates may dramatically increase compilation time and code size. Besides, it is difficult to separate an interface and implementation when templates are used exclusively. This could be fine for basic algorithms but not good for computer vision libraries where a single algorithm may span thousands lines of code. Because of this and also to simplify development of bindings for other languages, like Python, Java, Matlab that do not have templates at all or have limited template capabilities, the current OpenCV implementation is based on polymorphism and runtime dispatching over templates. In those places where runtime dispatching would be too slow (like pixel access operators), impossible (generic cv::Ptr<> implementation), or just very inconvenient (cv::saturate_cast<>()) the current implementation introduces small template classes, methods, and functions. Anywhere else in the current OpenCV version the use of templates is limited.\nConsequently, there is a limited fixed set of primitive data types the library can operate on. That is, array elements should have one of the following types:\n\n8-bit unsigned integer (uchar)\n8-bit signed integer (schar)\n16-bit unsigned integer (ushort)\n16-bit signed integer (short)\n32-bit signed integer (int)\n32-bit floating-point number (float)\n64-bit floating-point number (double)\na tuple of several elements where all elements have the same type (one of the above). An array whose elements are such tuples, are called multi-channel arrays, as opposite to the single-channel arrays, whose elements are scalar values. The maximum possible number of channels is defined by the CV_CN_MAX constant, which is currently set to 512.\n\nFor these basic types, the following enumeration is applied: enum { CV_8U=0, CV_8S=1, CV_16U=2, CV_16S=3, CV_32S=4, CV_32F=5, CV_64F=6 };\nCV_8S#define CV_8SDefinition interface.h:74\nCV_8U#define CV_8UDefinition interface.h:73\nCV_32S#define CV_32SDefinition interface.h:77\nCV_16S#define CV_16SDefinition interface.h:76\nCV_16U#define CV_16UDefinition interface.h:75\n Multi-channel (n-channel) types can be specified using the following options:\n\nCV_8UC1 ... CV_64FC4 constants (for a number of channels from 1 to 4)\nCV_8UC(n) ... CV_64FC(n) or CV_MAKETYPE(CV_8U, n) ... CV_MAKETYPE(CV_64F, n) macros when the number of channels is more than 4 or unknown at the compilation time.\n\nNote#CV_32FC1 == #CV_32F, #CV_32FC2 == #CV_32FC(2) == #CV_MAKETYPE(CV_32F, 2), and #CV_MAKETYPE(depth, n) == ((depth&7) + ((n-1)<<3). This means that the constant type is formed from the depth, taking the lowest 3 bits, and the number of channels minus 1, taking the next log2(CV_CN_MAX) bits.\nExamples: Mat mtx(3, 3, CV_32F); // make a 3x3 floating-point matrix\nMat cmtx(10, 1, CV_64FC2); // make a 10x1 2-channel floating-point\n // matrix (10-element complex vector)\nMat img(Size(1920, 1080), CV_8UC3); // make a 3-channel (color) image\n // of 1920 columns and 1080 rows.\nMat grayscale(img.size(), CV_MAKETYPE(img.depth(), 1)); // make a 1-channel image of\n // the same size and same\n // channel type as img\nCV_8UC3#define CV_8UC3Definition interface.h:90\nCV_64FC2#define CV_64FC2Definition interface.h:125\nCV_MAKETYPE#define CV_MAKETYPE(depth, cn)Definition interface.h:85\n Arrays with more complex elements cannot be constructed or processed using OpenCV. Furthermore, each function or method can handle only a subset of all possible array types. Usually, the more complex the algorithm is, the smaller the supported subset of formats is. See below typical examples of such limitations:\n\nThe face detection algorithm only works with 8-bit grayscale or color images.\nLinear algebra functions and most of the machine learning algorithms work with floating-point arrays only.\nBasic functions, such as cv::add, support all types.\nColor space conversion functions support 8-bit unsigned, 16-bit unsigned, and 32-bit floating-point types.\n\nThe subset of supported types for each function has been defined from practical needs and could be extended in future based on user requests.\n\nInputArray and OutputArray\nMany OpenCV functions process dense 2-dimensional or multi-dimensional numerical arrays. Usually, such functions take cv::Mat as parameters, but in some cases it's more convenient to use std::vector<> (for a point set, for example) or cv::Matx<> (for 3x3 homography matrix and such). To avoid many duplicates in the API, special \"proxy\" classes have been introduced. The base \"proxy\" class is cv::InputArray. It is used for passing read-only arrays on a function input. The derived from InputArray class cv::OutputArray is used to specify an output array for a function. Normally, you should not care of those intermediate types (and you should not declare variables of those types explicitly) - it will all just work automatically. You can assume that instead of InputArray/OutputArray you can always use cv::Mat, std::vector<>, cv::Matx<>, cv::Vec<> or cv::Scalar. When a function has an optional input or output array, and you do not have or do not want one, pass cv::noArray().\n\nError Handling\nOpenCV uses exceptions to signal critical errors. When the input data has a correct format and belongs to the specified value range, but the algorithm cannot succeed for some reason (for example, the optimization algorithm did not converge), it returns a special error code (typically, just a boolean variable).\nThe exceptions can be instances of the cv::Exception class or its derivatives. In its turn, cv::Exception is a derivative of std::exception. So it can be gracefully handled in the code using other standard C++ library components.\nThe exception is typically thrown either using the #CV_Error(errcode, description) macro, or its printf-like #CV_Error_(errcode, (printf-spec, printf-args)) variant, or using the CV_Assert(condition) macro that checks the condition and throws an exception when it is not satisfied. For performance-critical code, there is CV_DbgAssert(condition) that is only retained in the Debug configuration. Due to the automatic memory management, all the intermediate buffers are automatically deallocated in case of a sudden error. You only need to add a try statement to catch exceptions, if needed: try\n{\n    ... // call OpenCV\n}\ncatch (const cv::Exception& e)\n{\n const char* err_msg = e.what();\n    std::cout << \"exception caught: \" << err_msg << std::endl;\n}\ncv::ExceptionClass passed to an error.Definition core.hpp:120\ncv::Exception::whatvirtual const char * what() const CV_NOEXCEPT CV_OVERRIDE\n\nMulti-threading and Re-enterability\nThe current OpenCV implementation is fully re-enterable. That is, the same function or the same methods of different class instances can be called from different threads. Also, the same Mat can be used in different threads because the reference-counting operations use the architecture-specific atomic instructions. \n\nGenerated on Mon Nov 11 2024 23:11:40 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d1/d19/group__viz.html","content_type":"text/html","title":"OpenCV: 3D Visualizer","language":null},"page_content":"OpenCV: 3D Visualizer\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nFunctions \n3D Visualizer\n\nModules\n Widget\n \n\nDetailed Description\nThis section describes 3D visualization window as well as classes and methods that are used to interact with it.\n3D visualization window (see Viz3d) is used to display widgets (see Widget), and it provides several methods to interact with scene and widgets. \n\nClasses\nclass  cv::viz::Camera\n This class wraps intrinsic parameters of a camera.  More...\n \nclass  cv::viz::Color\n This class represents color in BGR order.  More...\n \nclass  cv::viz::KeyboardEvent\n This class represents a keyboard event.  More...\n \nclass  cv::viz::Mesh\n This class wraps mesh attributes, and it can load a mesh from a ply file. :  More...\n \nclass  cv::viz::MouseEvent\n This class represents a mouse event.  More...\n \nclass  cv::viz::Viz3d\n The Viz3d class represents a 3D visualizer window. This class is implicitly shared.  More...\n \n\nFunctions\nvoid cv::viz::computeNormals (const Mesh &mesh, OutputArray normals)\n \nViz3d cv::viz::getWindowByName (const String &window_name)\n Retrieves a window by its name.  \n \nViz3d cv::viz::imshow (const String &window_name, InputArray image, const Size &window_size=Size(-1, -1))\n Displays image in specified window.  \n \ntemplate<typename _Tp > \nbool cv::viz::isNan (const Point3_< _Tp > &p)\n Checks float/double value for nan.  \n \ntemplate<typename _Tp , int cn> \nbool cv::viz::isNan (const Vec< _Tp, cn > &v)\n Checks float/double value for nan.  \n \nbool cv::viz::isNan (double x)\n Checks float/double value for nan.  \n \nbool cv::viz::isNan (float x)\n Checks float/double value for nan.  \n \nAffine3d cv::viz::makeCameraPose (const Vec3d &position, const Vec3d &focal_point, const Vec3d &y_dir)\n Constructs camera pose from position, focal_point and up_vector (see gluLookAt() for more information).  \n \nAffine3d cv::viz::makeTransformToGlobal (const Vec3d &axis_x, const Vec3d &axis_y, const Vec3d &axis_z, const Vec3d &origin=Vec3d::all(0))\n Takes coordinate frame data and builds transform to global coordinate frame.  \n \nMat cv::viz::readCloud (const String &file, OutputArray colors=noArray(), OutputArray normals=noArray())\n \nMesh cv::viz::readMesh (const String &file)\n Reads mesh. Only ply format is supported now and no texture load support.  \n \nbool cv::viz::readPose (const String &file, Affine3d &pose, const String &tag=\"pose\")\n Read/write poses and trajectories.  \n \nvoid cv::viz::readTrajectory (OutputArray traj, const String &files_format=\"pose%05d.xml\", int start=0, int end=INT_MAX, const String &tag=\"pose\")\n \nvoid cv::viz::unregisterAllWindows ()\n Unregisters all Viz windows from internal database. After it 'getWindowByName()' will create new windows instead of getting existing from the database.  \n \nvoid cv::viz::writeCloud (const String &file, InputArray cloud, InputArray colors=noArray(), InputArray normals=noArray(), bool binary=false)\n Read/write clouds. Supported formats: ply, xyz, obj and stl (readonly)  \n \nvoid cv::viz::writePose (const String &file, const Affine3d &pose, const String &tag=\"pose\")\n \nvoid cv::viz::writeTrajectory (InputArray traj, const String &files_format=\"pose%05d.xml\", int start=0, const String &tag=\"pose\")\n \n\nFunction Documentation\n\n◆ computeNormals()\n\nvoid cv::viz::computeNormals \n(\nconst Mesh & \nmesh, \n\nOutputArray \nnormals \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nComputing normals for mesh Parameters\n\nmeshInput mesh. \nnormalsNormals at very point in the mesh of type CV_64FC3. \n\n◆ getWindowByName()\n\nViz3d cv::viz::getWindowByName \n(\nconst String & \nwindow_name)\n\n#include <opencv2/viz/vizcore.hpp>\nRetrieves a window by its name. \nParameters\n\nwindow_nameName of the window that is to be retrieved.\n\nThis function returns a Viz3d object with the given name.\nNoteIf the window with that name already exists, that window is returned. Otherwise, new window is created with the given name, and it is returned. \n\n◆ imshow()\n\nViz3d cv::viz::imshow \n(\nconst String & \nwindow_name, \n\nInputArray \nimage, \n\nconst Size & \nwindow_size = Size(-1, -1) \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nDisplays image in specified window. \n\n◆ isNan() [1/4]\n\ntemplate<typename _Tp > \n\nbool cv::viz::isNan \n(\nconst Point3_< _Tp > & \np)\n\ninline \n\n#include <opencv2/viz/vizcore.hpp>\nChecks float/double value for nan. \nParameters\n\npreturn true if any of the elements of the point is nan. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ isNan() [2/4]\n\ntemplate<typename _Tp , int cn> \n\nbool cv::viz::isNan \n(\nconst Vec< _Tp, cn > & \nv)\n\ninline \n\n#include <opencv2/viz/vizcore.hpp>\nChecks float/double value for nan. \nParameters\n\nvreturn true if any of the elements of the vector is nan. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ isNan() [3/4]\n\nbool cv::viz::isNan \n(\ndouble \nx)\n\ninline \n\n#include <opencv2/viz/vizcore.hpp>\nChecks float/double value for nan. \nParameters\n\nxreturn true if nan. \n\n◆ isNan() [4/4]\n\nbool cv::viz::isNan \n(\nfloat \nx)\n\ninline \n\n#include <opencv2/viz/vizcore.hpp>\nChecks float/double value for nan. \nParameters\n\nxreturn true if nan. \n\n◆ makeCameraPose()\n\nAffine3d cv::viz::makeCameraPose \n(\nconst Vec3d & \nposition, \n\nconst Vec3d & \nfocal_point, \n\nconst Vec3d & \ny_dir \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nConstructs camera pose from position, focal_point and up_vector (see gluLookAt() for more information). \nParameters\n\npositionPosition of the camera in global coordinate frame. \nfocal_pointFocal point of the camera in global coordinate frame. \ny_dirUp vector of the camera in global coordinate frame.\n\nThis function returns pose of the camera in global coordinate frame. \n\n◆ makeTransformToGlobal()\n\nAffine3d cv::viz::makeTransformToGlobal \n(\nconst Vec3d & \naxis_x, \n\nconst Vec3d & \naxis_y, \n\nconst Vec3d & \naxis_z, \n\nconst Vec3d & \norigin = Vec3d::all(0) \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nTakes coordinate frame data and builds transform to global coordinate frame. \nParameters\n\naxis_xX axis vector in global coordinate frame. \naxis_yY axis vector in global coordinate frame. \naxis_zZ axis vector in global coordinate frame. \noriginOrigin of the coordinate frame in global coordinate frame.\n\nReturnsAn affine transform that describes transformation between global coordinate frame and a given coordinate frame. The returned transforms can transform a point in the given coordinate frame to the global coordinate frame. \n\n◆ readCloud()\n\nMat cv::viz::readCloud \n(\nconst String & \nfile, \n\nOutputArray \ncolors = noArray(), \n\nOutputArray \nnormals = noArray() \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nParameters\n\nfileFilename with extension. Supported formats: PLY, XYZ, OBJ and STL. \ncolorsUsed by PLY and STL formats only. \nnormalsUsed by PLY, OBJ and STL formats only. \n\nReturnsA mat containing the point coordinates with depth CV_32F or CV_64F and number of channels 3 or 4 with only 1 row. \n\n◆ readMesh()\n\nMesh cv::viz::readMesh \n(\nconst String & \nfile)\n\n#include <opencv2/viz/vizcore.hpp>\nReads mesh. Only ply format is supported now and no texture load support. \n\n◆ readPose()\n\nbool cv::viz::readPose \n(\nconst String & \nfile, \n\nAffine3d & \npose, \n\nconst String & \ntag = \"pose\" \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nRead/write poses and trajectories. \nParameters\n\nfileFilename of type supported by cv::FileStorage. \nposeOutput matrix. \ntagName of the pose in the file. \n\n◆ readTrajectory()\n\nvoid cv::viz::readTrajectory \n(\nOutputArray \ntraj, \n\nconst String & \nfiles_format = \"pose%05d.xml\", \n\nint \nstart = 0, \n\nint \nend = INT_MAX, \n\nconst String & \ntag = \"pose\" \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\ntakes vector<Affine3<T>> with T = float/double and loads poses from sequence of files\nParameters\n\ntrajOutput array containing a lists of poses. It can be\nstd::vector<cv::Affine3f>, std::vector<cv::Affine3d>\ncv::Mat \n\nfiles_formatFormat specifier string for constructing filenames. The only placeholder in the string should support int. \nstartThe initial counter for files_format. It must be greater than or equal to 0. \nendThe final counter for files_format. \ntagName of the matrix in the file. \n\n◆ unregisterAllWindows()\n\nvoid cv::viz::unregisterAllWindows \n(\n)\n\n#include <opencv2/viz/vizcore.hpp>\nUnregisters all Viz windows from internal database. After it 'getWindowByName()' will create new windows instead of getting existing from the database. \n\n◆ writeCloud()\n\nvoid cv::viz::writeCloud \n(\nconst String & \nfile, \n\nInputArray \ncloud, \n\nInputArray \ncolors = noArray(), \n\nInputArray \nnormals = noArray(), \n\nbool \nbinary = false \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nRead/write clouds. Supported formats: ply, xyz, obj and stl (readonly) \nParameters\n\nfileFilename with extension. Supported formats: PLY, XYZ and OBJ. \ncloudSupported depths: CV_32F and CV_64F. Supported channels: 3 and 4. \ncolorsUsed by PLY format only. Supported depth: CV_8U. Supported channels: 1, 3 and 4. \nnormalsUsed by PLY and OBJ format only. Supported depths: CV_32F and CV_64F. Supported channels: 3 and 4. \nbinaryUsed only for PLY format. \n\n◆ writePose()\n\nvoid cv::viz::writePose \n(\nconst String & \nfile, \n\nconst Affine3d & \npose, \n\nconst String & \ntag = \"pose\" \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\nParameters\n\nfileFilename. \nposeInput matrix. \ntagName of the pose to be saved into the given file. \n\n◆ writeTrajectory()\n\nvoid cv::viz::writeTrajectory \n(\nInputArray \ntraj, \n\nconst String & \nfiles_format = \"pose%05d.xml\", \n\nint \nstart = 0, \n\nconst String & \ntag = \"pose\" \n\n)\n\n#include <opencv2/viz/vizcore.hpp>\ntakes vector<Affine3<T>> with T = float/double and writes to a sequence of files with given filename format Parameters\n\ntrajTrajectory containing a list of poses. It can be\nstd::vector<cv::Mat>, each cv::Mat is of type CV_32F16 or CV_64FC16\nstd::vector<cv::Affine3f>, std::vector<cv::Affine3d>\ncv::Mat of type CV_32FC16 OR CV_64F16 \n\nfiles_formatFormat specifier string for constructing filenames. The only placeholder in the string should support int. \nstartThe initial counter for files_format. \ntagName of the matrix in the file. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d5/d54/group__objdetect.html","content_type":"text/html","title":"OpenCV: Object Detection","language":null},"page_content":"OpenCV: Object Detection\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nObject Detection\n\nModules\n Cascade Classifier for Object Detection\n \n HOG (Histogram of Oriented Gradients) descriptor and object detector\n \n Barcode detection and decoding\n \n QRCode detection and encoding\n \n DNN-based face detection and recognition\n \n Common functions and classes\n \n ArUco markers and boards detection for robust camera pose estimation\n \n\nDetailed Description\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/d12/group__dpm.html","content_type":"text/html","title":"OpenCV: Deformable Part-based Models","language":null},"page_content":"OpenCV: Deformable Part-based Models\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nDeformable Part-based Models\n\nDetailed Description\n\nDiscriminatively Trained Part Based Models for Object Detection\nThe object detector described below has been initially proposed by P.F. Felzenszwalb in [89] . It is based on a Dalal-Triggs detector that uses a single filter on histogram of oriented gradients (HOG) features to represent an object category. This detector uses a sliding window approach, where a filter is applied at all positions and scales of an image. The first innovation is enriching the Dalal-Triggs model using a star-structured part-based model defined by a \"root\" filter (analogous to the Dalal-Triggs filter) plus a set of parts filters and associated deformation models. The score of one of star models at a particular position and scale within an image is the score of the root filter at the given location plus the sum over parts of the maximum, over placements of that part, of the part filter score on its location minus a deformation cost easuring the deviation of the part from its ideal location relative to the root. Both root and part filter scores are defined by the dot product between a filter (a set of weights) and a subwindow of a feature pyramid computed from the input image. Another improvement is a representation of the class of models by a mixture of star models. The score of a mixture model at a particular position and scale is the maximum over components, of the score of that component model at the given location.\nThe detector was dramatically speeded-up with cascade algorithm proposed by P.F. Felzenszwalb in [88] . The algorithm prunes partial hypotheses using thresholds on their scores.The basic idea of the algorithm is to use a hierarchy of models defined by an ordering of the original model's parts. For a model with (n+1) parts, including the root, a sequence of (n+1) models is obtained. The i-th model in this sequence is defined by the first i parts from the original model. Using this hierarchy, low scoring hypotheses can be pruned after looking at the best configuration of a subset of the parts. Hypotheses that score high under a weak model are evaluated further using a richer model.\nIn OpenCV there is an C++ implementation of DPM cascade detector. \n\nClasses\nclass  cv::dpm::DPMDetector\n This is a C++ abstract class, it provides external user API to work with DPM.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/d3f/group__cudaobjdetect.html","content_type":"text/html","title":"OpenCV: Object Detection","language":null},"page_content":"OpenCV: Object Detection\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nObject DetectionCUDA-accelerated Computer Vision\n\nDetailed Description\n\nClasses\nclass  cv::cuda::CascadeClassifier\n Cascade classifier class used for object detection. Supports HAAR and LBP cascades. :  More...\n \nclass  cv::cuda::HOG\n The class implements Histogram of Oriented Gradients ([63]) object detector.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d8/d65/group__saliency.html","content_type":"text/html","title":"OpenCV: Saliency API","language":null},"page_content":"OpenCV: Saliency API\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nSaliency API\n\nDetailed Description\nMany computer vision applications may benefit from understanding where humans focus given a scene. Other than cognitively understanding the way human perceive images and scenes, finding salient regions and objects in the images helps various tasks such as speeding up object detection, object recognition, object tracking and content-aware image editing.\nAbout the saliency, there is a rich literature but the development is very fragmented. The principal purpose of this API is to give a unique interface, a unique framework for use and plug sever saliency algorithms, also with very different nature and methodology, but they share the same purpose, organizing algorithms into three main categories:\nStatic Saliency**: algorithms belonging to this category, exploit different image features that allow to detect salient objects in a non dynamic scenarios.\nMotion Saliency**: algorithms belonging to this category, are particularly focused to detect salient objects over time (hence also over frame), then there is a temporal component sealing cosider that allows to detect \"moving\" objects as salient, meaning therefore also the more general sense of detection the changes in the scene.\nObjectness**: Objectness is usually represented as a value which reflects how likely an image window covers an object of any category. Algorithms belonging to this category, avoid making decisions early on, by proposing a small number of category-independent proposals, that are expected to cover all objects in an image. Being able to perceive objects before identifying them is closely related to bottom up visual attention (saliency).\n\nSaliency diagram\nTo see how API works, try tracker demo: https://github.com/fpuja/opencv_contrib/blob/saliencyModuleDevelop/modules/saliency/samples/computeSaliency.cpp\nNoteThis API has been designed with PlantUML. If you modify this API please change UML. \n\nClasses\nclass  cv::saliency::MotionSaliency\n \nclass  cv::saliency::MotionSaliencyBinWangApr2014\n the Fast Self-tuning Background Subtraction Algorithm from [291] More...\n \nclass  cv::saliency::Objectness\n \nclass  cv::saliency::ObjectnessBING\n Objectness algorithms based on [3] [3] Cheng, Ming-Ming, et al. \"BING: Binarized normed gradients for objectness estimation at 300fps.\" IEEE CVPR. 2014.  More...\n \nclass  cv::saliency::Saliency\n \nclass  cv::saliency::StaticSaliency\n \nclass  cv::saliency::StaticSaliencyFineGrained\n the Fine Grained Saliency approach from [198] More...\n \nclass  cv::saliency::StaticSaliencySpectralResidual\n the Spectral Residual approach from [128] More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dc/ddd/group__line__descriptor.html","content_type":"text/html","title":"OpenCV: Binary descriptors for lines extracted from an image","language":null},"page_content":"OpenCV: Binary descriptors for lines extracted from an image\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nBinary descriptors for lines extracted from an image\n\nDetailed Description\n\nIntroduction\nOne of the most challenging activities in computer vision is the extraction of useful information from a given image. Such information, usually comes in the form of points that preserve some kind of property (for instance, they are scale-invariant) and are actually representative of input image.\nThe goal of this module is seeking a new kind of representative information inside an image and providing the functionalities for its extraction and representation. In particular, differently from previous methods for detection of relevant elements inside an image, lines are extracted in place of points; a new class is defined ad hoc to summarize a line's properties, for reuse and plotting purposes.\n\nComputation of binary descriptors\nTo obtatin a binary descriptor representing a certain line detected from a certain octave of an image, we first compute a non-binary descriptor as described in [316] . Such algorithm works on lines extracted using EDLine detector, as explained in [289] . Given a line, we consider a rectangular region centered at it and called line support region (LSR). Such region is divided into a set of bands \\(\\{B_1, B_2, ..., B_m\\}\\), whose length equals the one of line.\nIf we indicate with \\(\\bf{d}_L\\) the direction of line, the orthogonal and clockwise direction to line \\(\\bf{d}_{\\perp}\\) can be determined; these two directions, are used to construct a reference frame centered in the middle point of line. The gradients of pixels \\(\\bf{g'}\\) inside LSR can be projected to the newly determined frame, obtaining their local equivalent \\(\\bf{g'} = (\\bf{g}^T \\cdot \\bf{d}_{\\perp}, \\bf{g}^T \\cdot \\bf{d}_L)^T \\triangleq (\\bf{g'}_{d_{\\perp}}, \\bf{g'}_{d_L})^T\\).\nLater on, a Gaussian function is applied to all LSR's pixels along \\(\\bf{d}_\\perp\\) direction; first, we assign a global weighting coefficient \\(f_g(i) = (1/\\sqrt{2\\pi}\\sigma_g)e^{-d^2_i/2\\sigma^2_g}\\) to i*-th row in LSR, where \\(d_i\\) is the distance of i-th row from the center row in LSR, \\(\\sigma_g = 0.5(m \\cdot w - 1)\\) and \\(w\\) is the width of bands (the same for every band). Secondly, considering a band \\(B_j\\) and its neighbor bands \\(B_{j-1}, B_{j+1}\\), we assign a local weighting \\(F_l(k) = (1/\\sqrt{2\\pi}\\sigma_l)e^{-d'^2_k/2\\sigma_l^2}\\), where \\(d'_k\\) is the distance of k-th row from the center row in \\(B_j\\) and \\(\\sigma_l = w\\). Using the global and local weights, we obtain, at the same time, the reduction of role played by gradients far from line and of boundary effect, respectively.\nEach band \\(B_j\\) in LSR has an associated band descriptor(BD) which is computed considering previous and next band (top and bottom bands are ignored when computing descriptor for first and last band). Once each band has been assignen its BD, the LBD descriptor of line is simply given by\n\n\\[LBD = (BD_1^T, BD_2^T, ... , BD^T_m)^T.\\]\n\nTo compute a band descriptor \\(B_j\\), each k-th row in it is considered and the gradients in such row are accumulated:\n\n\\[\\begin{matrix} \\bf{V1}^k_j = \\lambda \\sum\\limits_{\\bf{g}'_{d_\\perp}>0}\\bf{g}'_{d_\\perp}, &  \\bf{V2}^k_j = \\lambda \\sum\\limits_{\\bf{g}'_{d_\\perp}<0} -\\bf{g}'_{d_\\perp}, \\\\ \\bf{V3}^k_j = \\lambda \\sum\\limits_{\\bf{g}'_{d_L}>0}\\bf{g}'_{d_L}, & \\bf{V4}^k_j = \\lambda \\sum\\limits_{\\bf{g}'_{d_L}<0} -\\bf{g}'_{d_L}\\end{matrix}.\\]\n\nwith \\(\\lambda = f_g(k)f_l(k)\\).\nBy stacking previous results, we obtain the band description matrix (BDM)\n\n\\[BDM_j = \\left(\\begin{matrix} \\bf{V1}_j^1 & \\bf{V1}_j^2 & \\ldots & \\bf{V1}_j^n \\\\ \\bf{V2}_j^1 & \\bf{V2}_j^2 & \\ldots & \\bf{V2}_j^n \\\\ \\bf{V3}_j^1 & \\bf{V3}_j^2 & \\ldots & \\bf{V3}_j^n \\\\ \\bf{V4}_j^1 & \\bf{V4}_j^2 & \\ldots & \\bf{V4}_j^n \\end{matrix} \\right) \\in \\mathbb{R}^{4\\times n},\\]\n\nwith \\(n\\) the number of rows in band \\(B_j\\):\n\n\\[n = \\begin{cases} 2w, & j = 1||m; \\\\ 3w, & \\mbox{else}. \\end{cases}\\]\n\nEach \\(BD_j\\) can be obtained using the standard deviation vector \\(S_j\\) and mean vector \\(M_j\\) of \\(BDM_J\\). Thus, finally:\n\n\\[LBD = (M_1^T, S_1^T, M_2^T, S_2^T, \\ldots, M_m^T, S_m^T)^T \\in \\mathbb{R}^{8m}\\]\n\nOnce the LBD has been obtained, it must be converted into a binary form. For such purpose, we consider 32 possible pairs of BD inside it; each couple of BD is compared bit by bit and comparison generates an 8 bit string. Concatenating 32 comparison strings, we get the 256-bit final binary representation of a single LBD. \n\nClasses\nclass  cv::line_descriptor::BinaryDescriptor\n Class implements both functionalities for detection of lines and computation of their binary descriptor.  More...\n \nclass  cv::line_descriptor::BinaryDescriptorMatcher\n furnishes all functionalities for querying a dataset provided by user or internal to class (that user must, anyway, populate) on the model of Descriptor Matchers More...\n \nstruct  cv::line_descriptor::DrawLinesMatchesFlags\n \nstruct  cv::line_descriptor::KeyLine\n A class to represent a line.  More...\n \nclass  cv::line_descriptor::LSDDetector\n \nstruct  cv::line_descriptor::LSDParam\n \n\nFunctions\nvoid cv::line_descriptor::drawKeylines (const Mat &image, const std::vector< KeyLine > &keylines, Mat &outImage, const Scalar &color=Scalar::all(-1), int flags=DrawLinesMatchesFlags::DEFAULT)\n Draws keylines.  \n \nvoid cv::line_descriptor::drawLineMatches (const Mat &img1, const std::vector< KeyLine > &keylines1, const Mat &img2, const std::vector< KeyLine > &keylines2, const std::vector< DMatch > &matches1to2, Mat &outImg, const Scalar &matchColor=Scalar::all(-1), const Scalar &singleLineColor=Scalar::all(-1), const std::vector< char > &matchesMask=std::vector< char >(), int flags=DrawLinesMatchesFlags::DEFAULT)\n Draws the found matches of keylines from two images.  \n \n\nFunction Documentation\n\n◆ drawKeylines()\n\nvoid cv::line_descriptor::drawKeylines \n(\nconst Mat & \nimage, \n\nconst std::vector< KeyLine > & \nkeylines, \n\nMat & \noutImage, \n\nconst Scalar & \ncolor = Scalar::all(-1), \n\nint \nflags = DrawLinesMatchesFlags::DEFAULT \n\n)\n\nPython:cv.line_descriptor.drawKeylines(image, keylines[, outImage[, color[, flags]]]) -> outImage\n\n#include <opencv2/line_descriptor/descriptor.hpp>\nDraws keylines. \nParameters\n\nimageinput image \nkeylineskeylines to be drawn \noutImageoutput image to draw on \ncolorcolor of lines to be drawn (if set to defaul value, color is chosen randomly) \nflagsdrawing flags \n\n◆ drawLineMatches()\n\nvoid cv::line_descriptor::drawLineMatches \n(\nconst Mat & \nimg1, \n\nconst std::vector< KeyLine > & \nkeylines1, \n\nconst Mat & \nimg2, \n\nconst std::vector< KeyLine > & \nkeylines2, \n\nconst std::vector< DMatch > & \nmatches1to2, \n\nMat & \noutImg, \n\nconst Scalar & \nmatchColor = Scalar::all(-1), \n\nconst Scalar & \nsingleLineColor = Scalar::all(-1), \n\nconst std::vector< char > & \nmatchesMask = std::vector< char >(), \n\nint \nflags = DrawLinesMatchesFlags::DEFAULT \n\n)\n\nPython:cv.line_descriptor.drawLineMatches(img1, keylines1, img2, keylines2, matches1to2[, outImg[, matchColor[, singleLineColor[, matchesMask[, flags]]]]]) -> outImg\n\n#include <opencv2/line_descriptor/descriptor.hpp>\nDraws the found matches of keylines from two images. \nParameters\n\nimg1first image \nkeylines1keylines extracted from first image \nimg2second image \nkeylines2keylines extracted from second image \nmatches1to2vector of matches \noutImgoutput matrix to draw on \nmatchColordrawing color for matches (chosen randomly in case of default value) \nsingleLineColordrawing color for keylines (chosen randomly in case of default value) \nmatchesMaskmask to indicate which matches must be drawn \nflagsdrawing flags, see DrawLinesMatchesFlags\n\nNoteIf both matchColor and singleLineColor are set to their default values, function draws matched lines and line connecting them with same color \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d7/dbd/group__imgproc.html","content_type":"text/html","title":"OpenCV: Image Processing","language":null},"page_content":"OpenCV: Image Processing\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nImage Processing\n\nModules\n Image Filtering\n \n Geometric Image Transformations\n \n Miscellaneous Image Transformations\n \n Drawing Functions\n \n Color Space Conversions\n \n ColorMaps in OpenCV\n \n Planar Subdivision\n \n Histograms\n \n Structural Analysis and Shape Descriptors\n \n Motion Analysis and Object Tracking\n \n Feature Detection\n \n Object Detection\n \n Image Segmentation\n \n Hardware Acceleration Layer\n \n\nDetailed Description\nThis module offers a comprehensive suite of image processing functions, enabling tasks such as those listed above. \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d7/de9/group__video.html","content_type":"text/html","title":"OpenCV: Video Analysis","language":null},"page_content":"OpenCV: Video Analysis\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules \nVideo Analysis\n\nModules\n Motion Analysis\n \n Object Tracking\n \n\nDetailed Description\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/d54/group__xobjdetect.html","content_type":"text/html","title":"OpenCV: Extended object detection","language":null},"page_content":"OpenCV: Extended object detection\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses \nExtended object detection\n\nDetailed Description\n\nClasses\nclass  cv::xobjdetect::WBDetector\n WaldBoost detector.  More...\n \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d7/d0a/group__superres.html","content_type":"text/html","title":"OpenCV: Super Resolution","language":null},"page_content":"OpenCV: Super Resolution\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nFunctions \nSuper Resolution\n\nDetailed Description\nThe Super Resolution module contains a set of functions and classes that can be used to solve the problem of resolution enhancement. There are a few methods implemented, most of them are described in the papers [83] and [197] . \n\nClasses\nclass  cv::superres::BroxOpticalFlow\n \nclass  cv::superres::DenseOpticalFlowExt\n \nclass  cv::superres::DualTVL1OpticalFlow\n \nclass  cv::superres::FarnebackOpticalFlow\n \nclass  cv::superres::FrameSource\n \nclass  cv::superres::PyrLKOpticalFlow\n \nclass  cv::superres::SuperResolution\n Base class for Super Resolution algorithms.  More...\n \n\nFunctions\nPtr< FrameSource > cv::superres::createFrameSource_Camera (int deviceId=0)\n \nPtr< FrameSource > cv::superres::createFrameSource_Empty ()\n \nPtr< FrameSource > cv::superres::createFrameSource_Video (const String &fileName)\n \nPtr< FrameSource > cv::superres::createFrameSource_Video_CUDA (const String &fileName)\n \nPtr< BroxOpticalFlow > cv::superres::createOptFlow_Brox_CUDA ()\n \nPtr< DualTVL1OpticalFlow > cv::superres::createOptFlow_DualTVL1 ()\n \nPtr< DualTVL1OpticalFlow > cv::superres::createOptFlow_DualTVL1_CUDA ()\n \nPtr< FarnebackOpticalFlow > cv::superres::createOptFlow_Farneback ()\n \nPtr< FarnebackOpticalFlow > cv::superres::createOptFlow_Farneback_CUDA ()\n \nPtr< PyrLKOpticalFlow > cv::superres::createOptFlow_PyrLK_CUDA ()\n \nPtr< SuperResolution > cv::superres::createSuperResolution_BTVL1 ()\n Create Bilateral TV-L1 Super Resolution.  \n \nPtr< SuperResolution > cv::superres::createSuperResolution_BTVL1_CUDA ()\n \n\nFunction Documentation\n\n◆ createFrameSource_Camera()\n\nPtr< FrameSource > cv::superres::createFrameSource_Camera \n(\nint \ndeviceId = 0)\n\n#include <opencv2/superres.hpp>\n\n◆ createFrameSource_Empty()\n\nPtr< FrameSource > cv::superres::createFrameSource_Empty \n(\n)\n\n#include <opencv2/superres.hpp>\n\n◆ createFrameSource_Video()\n\nPtr< FrameSource > cv::superres::createFrameSource_Video \n(\nconst String & \nfileName)\n\n#include <opencv2/superres.hpp>\n\n◆ createFrameSource_Video_CUDA()\n\nPtr< FrameSource > cv::superres::createFrameSource_Video_CUDA \n(\nconst String & \nfileName)\n\n#include <opencv2/superres.hpp>\n\n◆ createOptFlow_Brox_CUDA()\n\nPtr< BroxOpticalFlow > cv::superres::createOptFlow_Brox_CUDA \n(\n)\n\n#include <opencv2/superres/optical_flow.hpp>\n\n◆ createOptFlow_DualTVL1()\n\nPtr< DualTVL1OpticalFlow > cv::superres::createOptFlow_DualTVL1 \n(\n)\n\n#include <opencv2/superres/optical_flow.hpp>\n\n◆ createOptFlow_DualTVL1_CUDA()\n\nPtr< DualTVL1OpticalFlow > cv::superres::createOptFlow_DualTVL1_CUDA \n(\n)\n\n#include <opencv2/superres/optical_flow.hpp>\n\n◆ createOptFlow_Farneback()\n\nPtr< FarnebackOpticalFlow > cv::superres::createOptFlow_Farneback \n(\n)\n\n#include <opencv2/superres/optical_flow.hpp>\n\n◆ createOptFlow_Farneback_CUDA()\n\nPtr< FarnebackOpticalFlow > cv::superres::createOptFlow_Farneback_CUDA \n(\n)\n\n#include <opencv2/superres/optical_flow.hpp>\n\n◆ createOptFlow_PyrLK_CUDA()\n\nPtr< PyrLKOpticalFlow > cv::superres::createOptFlow_PyrLK_CUDA \n(\n)\n\n#include <opencv2/superres/optical_flow.hpp>\n\n◆ createSuperResolution_BTVL1()\n\nPtr< SuperResolution > cv::superres::createSuperResolution_BTVL1 \n(\n)\n\n#include <opencv2/superres.hpp>\nCreate Bilateral TV-L1 Super Resolution. \nThis class implements Super Resolution algorithm described in the papers [83] and [197] .\nHere are important members of the class that control the algorithm, which you can set after constructing the class instance:\n\nint scale Scale factor.\nint iterations Iteration count.\ndouble tau Asymptotic value of steepest descent method.\ndouble lambda Weight parameter to balance data term and smoothness term.\ndouble alpha Parameter of spacial distribution in Bilateral-TV.\nint btvKernelSize Kernel size of Bilateral-TV filter.\nint blurKernelSize Gaussian blur kernel size.\ndouble blurSigma Gaussian blur sigma.\nint temporalAreaRadius Radius of the temporal search area.\nPtr<DenseOpticalFlowExt> opticalFlow Dense optical flow algorithm. \n\n◆ createSuperResolution_BTVL1_CUDA()\n\nPtr< SuperResolution > cv::superres::createSuperResolution_BTVL1_CUDA \n(\n)\n\n#include <opencv2/superres.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html","content_type":"text/html","title":"OpenCV: Image file reading and writing","language":null},"page_content":"OpenCV: Image file reading and writing\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nFunctions \nImage file reading and writing\n\nModules\n Flags used for image file reading and writing\n \n iOS glue\n \n MacOS(OSX) glue\n \n\nDetailed Description\n\nClasses\nclass  cv::ImageCollection\n To read multi-page images on demand.  More...\n \n\nFunctions\nCV_EXPORTS_W bool cv::haveImageReader (const String &filename)\n Checks if the specified image file can be decoded by OpenCV.  \n \nCV_EXPORTS_W bool cv::haveImageWriter (const String &filename)\n Checks if the specified image file or specified file extension can be encoded by OpenCV.  \n \nCV_EXPORTS_W size_t cv::imcount (const String &filename, int flags=IMREAD_ANYCOLOR)\n Returns the number of images inside the given file.  \n \nCV_EXPORTS_W Mat cv::imdecode (InputArray buf, int flags)\n Reads an image from a buffer in memory.  \n \nCV_EXPORTS Mat cv::imdecode (InputArray buf, int flags, Mat *dst)\n \nCV_EXPORTS_W bool cv::imdecodemulti (InputArray buf, int flags, CV_OUT std::vector< Mat > &mats, const cv::Range &range=Range::all())\n Reads a multi-page image from a buffer in memory.  \n \nCV_EXPORTS_W bool cv::imencode (const String &ext, InputArray img, CV_OUT std::vector< uchar > &buf, const std::vector< int > &params=std::vector< int >())\n Encodes an image into a memory buffer.  \n \nCV_EXPORTS_W bool cv::imencodemulti (const String &ext, InputArrayOfArrays imgs, CV_OUT std::vector< uchar > &buf, const std::vector< int > &params=std::vector< int >())\n Encodes array of images into a memory buffer.  \n \nCV_EXPORTS_W Mat cv::imread (const String &filename, int flags=IMREAD_COLOR_BGR)\n Loads an image from a file.  \n \nCV_EXPORTS_W void cv::imread (const String &filename, OutputArray dst, int flags=IMREAD_COLOR_BGR)\n Loads an image from a file.  \n \nCV_EXPORTS_W bool cv::imreadmulti (const String &filename, CV_OUT std::vector< Mat > &mats, int flags=IMREAD_ANYCOLOR)\n Loads a multi-page image from a file.  \n \nCV_EXPORTS_W bool cv::imreadmulti (const String &filename, CV_OUT std::vector< Mat > &mats, int start, int count, int flags=IMREAD_ANYCOLOR)\n Loads images of a multi-page image from a file.  \n \nCV_EXPORTS_W bool cv::imwrite (const String &filename, InputArray img, const std::vector< int > &params=std::vector< int >())\n Saves an image to a specified file.  \n \nstatic CV_WRAP bool cv::imwritemulti (const String &filename, InputArrayOfArrays img, const std::vector< int > &params=std::vector< int >())\n multi-image overload for bindings  \n \n\nFunction Documentation\n\n◆ haveImageReader()\n\nCV_EXPORTS_W bool cv::haveImageReader \n(\nconst String & \nfilename)\n\nPython:cv.haveImageReader(filename) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nChecks if the specified image file can be decoded by OpenCV. \nThe function haveImageReader checks if OpenCV is capable of reading the specified file. This can be useful for verifying support for a given image format before attempting to load an image.\nParameters\n\nfilenameThe name of the file to be checked. \n\nReturnstrue if an image reader for the specified file is available and the file can be opened, false otherwise.\nNoteThe function checks the availability of image codecs that are either built into OpenCV or dynamically loaded. It does not check for the actual existence of the file but rather the ability to read the specified file type. If the file cannot be opened or the format is unsupported, the function will return false.\nSee alsocv::haveImageWriter, cv::imread, cv::imdecode \n\n◆ haveImageWriter()\n\nCV_EXPORTS_W bool cv::haveImageWriter \n(\nconst String & \nfilename)\n\nPython:cv.haveImageWriter(filename) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nChecks if the specified image file or specified file extension can be encoded by OpenCV. \nThe function haveImageWriter checks if OpenCV is capable of writing images with the specified file extension. This can be useful for verifying support for a given image format before attempting to save an image.\nParameters\n\nfilenameThe name of the file or the file extension (e.g., \".jpg\", \".png\"). It is recommended to provide the file extension rather than the full file name. \n\nReturnstrue if an image writer for the specified extension is available, false otherwise.\nNoteThe function checks the availability of image codecs that are either built into OpenCV or dynamically loaded. It does not check for the actual existence of the file but rather the ability to write files of the given type.\nSee alsocv::haveImageReader, cv::imwrite, cv::imencode \n\n◆ imcount()\n\nCV_EXPORTS_W size_t cv::imcount \n(\nconst String & \nfilename, \n\nint \nflags = IMREAD_ANYCOLOR \n\n)\n\nPython:cv.imcount(filename[, flags]) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nReturns the number of images inside the given file. \nThe function imcount returns the number of pages in a multi-page image (e.g. TIFF), the number of frames in an animation (e.g. AVIF), and 1 otherwise. If the image cannot be decoded, 0 is returned. Parameters\n\nfilenameName of file to be loaded. \nflagsFlag that can take values of cv::ImreadModes, default with cv::IMREAD_ANYCOLOR. \n\nTodo:when cv::IMREAD_LOAD_GDAL flag used the return value will be 0 or 1 because OpenCV's GDAL decoder doesn't support multi-page reading yet. \n\n◆ imdecode() [1/2]\n\nCV_EXPORTS_W Mat cv::imdecode \n(\nInputArray \nbuf, \n\nint \nflags \n\n)\n\nPython:cv.imdecode(buf, flags) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nReads an image from a buffer in memory. \nThe function imdecode reads an image from the specified buffer in the memory. If the buffer is too short or contains invalid data, the function returns an empty matrix ( Mat::data==NULL ).\nSee cv::imread for the list of supported formats and flags description.\nNoteIn the case of color images, the decoded images will have the channels stored in B G R order. \nParameters\n\nbufInput array or vector of bytes. \nflagsThe same flags as in cv::imread, see cv::ImreadModes. \n\n◆ imdecode() [2/2]\n\nCV_EXPORTS Mat cv::imdecode \n(\nInputArray \nbuf, \n\nint \nflags, \n\nMat * \ndst \n\n)\n\nPython:cv.imdecode(buf, flags) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nbufInput array or vector of bytes. \nflagsThe same flags as in cv::imread, see cv::ImreadModes. \ndstThe optional output placeholder for the decoded matrix. It can save the image reallocations when the function is called repeatedly for images of the same size. In case of decoder failure the function returns empty cv::Mat object, but does not release user-provided dst buffer. \n\n◆ imdecodemulti()\n\nCV_EXPORTS_W bool cv::imdecodemulti \n(\nInputArray \nbuf, \n\nint \nflags, \n\nCV_OUT std::vector< Mat > & \nmats, \n\nconst cv::Range & \nrange = Range::all() \n\n)\n\nPython:cv.imdecodemulti(buf, flags[, mats[, range]]) -> retval, mats\n\n#include <opencv2/imgcodecs.hpp>\nReads a multi-page image from a buffer in memory. \nThe function imdecodemulti reads a multi-page image from the specified buffer in the memory. If the buffer is too short or contains invalid data, the function returns false.\nSee cv::imreadmulti for the list of supported formats and flags description.\nNoteIn the case of color images, the decoded images will have the channels stored in B G R order. \nParameters\n\nbufInput array or vector of bytes. \nflagsThe same flags as in cv::imread, see cv::ImreadModes. \nmatsA vector of Mat objects holding each page, if more than one. \nrangeA continuous selection of pages. \n\n◆ imencode()\n\nCV_EXPORTS_W bool cv::imencode \n(\nconst String & \next, \n\nInputArray \nimg, \n\nCV_OUT std::vector< uchar > & \nbuf, \n\nconst std::vector< int > & \nparams = std::vector< int >() \n\n)\n\nPython:cv.imencode(ext, img[, params]) -> retval, buf\n\n#include <opencv2/imgcodecs.hpp>\nEncodes an image into a memory buffer. \nThe function imencode compresses the image and stores it in the memory buffer that is resized to fit the result. See cv::imwrite for the list of supported formats and flags description.\nParameters\n\nextFile extension that defines the output format. Must include a leading period. \nimgImage to be compressed. \nbufOutput buffer resized to fit the compressed image. \nparamsFormat-specific parameters. See cv::imwrite and cv::ImwriteFlags. \n\n◆ imencodemulti()\n\nCV_EXPORTS_W bool cv::imencodemulti \n(\nconst String & \next, \n\nInputArrayOfArrays \nimgs, \n\nCV_OUT std::vector< uchar > & \nbuf, \n\nconst std::vector< int > & \nparams = std::vector< int >() \n\n)\n\nPython:cv.imencodemulti(ext, imgs[, params]) -> retval, buf\n\n#include <opencv2/imgcodecs.hpp>\nEncodes array of images into a memory buffer. \nThe function is analog to cv::imencode for in-memory multi-page image compression. See cv::imwrite for the list of supported formats and flags description.\nParameters\n\nextFile extension that defines the output format. Must include a leading period. \nimgsVector of images to be written. \nbufOutput buffer resized to fit the compressed data. \nparamsFormat-specific parameters. See cv::imwrite and cv::ImwriteFlags. \n\n◆ imread() [1/2]\n\nCV_EXPORTS_W Mat cv::imread \n(\nconst String & \nfilename, \n\nint \nflags = IMREAD_COLOR_BGR \n\n)\n\nPython:cv.imread(filename[, flags]) -> retvalcv.imread(filename[, dst[, flags]]) -> dst\n\n#include <opencv2/imgcodecs.hpp>\nLoads an image from a file. \n The imread function loads an image from the specified file and returns OpenCV matrix. If the image cannot be read (because of a missing file, improper permissions, or unsupported/invalid format), the function returns an empty matrix.\nCurrently, the following file formats are supported:\n\nWindows bitmaps - *.bmp, *.dib (always supported)\nJPEG files - *.jpeg, *.jpg, *.jpe (see the Note section)\nJPEG 2000 files - *.jp2 (see the Note section)\nPortable Network Graphics - *.png (see the Note section)\nWebP - *.webp (see the Note section)\nAVIF - *.avif (see the Note section)\nPortable image format - *.pbm, *.pgm, *.ppm, *.pxm, *.pnm (always supported)\nPFM files - *.pfm (see the Note section)\nSun rasters - *.sr, *.ras (always supported)\nTIFF files - *.tiff, *.tif (see the Note section)\nOpenEXR Image files - *.exr (see the Note section)\nRadiance HDR - *.hdr, *.pic (always supported)\nRaster and Vector geospatial data supported by GDAL (see the Note section)\n\nNote\nThe function determines the type of an image by its content, not by the file extension.\nIn the case of color images, the decoded images will have the channels stored in B G R order.\nWhen using IMREAD_GRAYSCALE, the codec's internal grayscale conversion will be used, if available. Results may differ from the output of cvtColor().\nOn Microsoft Windows* and Mac OS*, the codecs shipped with OpenCV (libjpeg, libpng, libtiff, and libjasper) are used by default. So, OpenCV can always read JPEGs, PNGs, and TIFFs. On Mac OS, there is also an option to use native Mac OS image readers. However, beware that currently these native image loaders give images with different pixel values because of the color management embedded into Mac OS.\nOn Linux*, BSD flavors, and other Unix-like open-source operating systems, OpenCV looks for codecs supplied with the OS. Ensure the relevant packages are installed (including development files, such as \"libjpeg-dev\" in Debian* and Ubuntu*) to get codec support, or turn on the OPENCV_BUILD_3RDPARTY_LIBS flag in CMake.\nIf the WITH_GDAL flag is set to true in CMake and IMREAD_LOAD_GDAL is used to load the image, the GDAL driver will be used to decode the image, supporting Raster and Vector formats.\nIf EXIF information is embedded in the image file, the EXIF orientation will be taken into account, and thus the image will be rotated accordingly unless the flags IMREAD_IGNORE_ORIENTATION or IMREAD_UNCHANGED are passed.\nUse the IMREAD_UNCHANGED flag to preserve the floating-point values from PFM images.\nBy default, the number of pixels must be less than 2^30. This limit can be changed by setting the environment variable OPENCV_IO_MAX_IMAGE_PIXELS. See OpenCV environment variables reference.\n\nParameters\n\nfilenameName of the file to be loaded. \nflagsFlag that can take values of cv::ImreadModes. \n\n◆ imread() [2/2]\n\nCV_EXPORTS_W void cv::imread \n(\nconst String & \nfilename, \n\nOutputArray \ndst, \n\nint \nflags = IMREAD_COLOR_BGR \n\n)\n\nPython:cv.imread(filename[, flags]) -> retvalcv.imread(filename[, dst[, flags]]) -> dst\n\n#include <opencv2/imgcodecs.hpp>\nLoads an image from a file. \nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts and the return value. Parameters\n\nfilenameName of file to be loaded. \ndstobject in which the image will be loaded. \nflagsFlag that can take values of cv::ImreadModes \n\nNoteThe image passing through the img parameter can be pre-allocated. The memory is reused if the shape and the type match with the load image. \n\n◆ imreadmulti() [1/2]\n\nCV_EXPORTS_W bool cv::imreadmulti \n(\nconst String & \nfilename, \n\nCV_OUT std::vector< Mat > & \nmats, \n\nint \nflags = IMREAD_ANYCOLOR \n\n)\n\nPython:cv.imreadmulti(filename[, mats[, flags]]) -> retval, matscv.imreadmulti(filename, start, count[, mats[, flags]]) -> retval, mats\n\n#include <opencv2/imgcodecs.hpp>\nLoads a multi-page image from a file. \nThe function imreadmulti loads a multi-page image from the specified file into a vector of Mat objects. Parameters\n\nfilenameName of file to be loaded. \nmatsA vector of Mat objects holding each page. \nflagsFlag that can take values of cv::ImreadModes, default with cv::IMREAD_ANYCOLOR. \n\nSee alsocv::imread \n\n◆ imreadmulti() [2/2]\n\nCV_EXPORTS_W bool cv::imreadmulti \n(\nconst String & \nfilename, \n\nCV_OUT std::vector< Mat > & \nmats, \n\nint \nstart, \n\nint \ncount, \n\nint \nflags = IMREAD_ANYCOLOR \n\n)\n\nPython:cv.imreadmulti(filename[, mats[, flags]]) -> retval, matscv.imreadmulti(filename, start, count[, mats[, flags]]) -> retval, mats\n\n#include <opencv2/imgcodecs.hpp>\nLoads images of a multi-page image from a file. \nThe function imreadmulti loads a specified range from a multi-page image from the specified file into a vector of Mat objects. Parameters\n\nfilenameName of file to be loaded. \nmatsA vector of Mat objects holding each page. \nstartStart index of the image to load \ncountCount number of images to load \nflagsFlag that can take values of cv::ImreadModes, default with cv::IMREAD_ANYCOLOR. \n\nSee alsocv::imread \n\n◆ imwrite()\n\nCV_EXPORTS_W bool cv::imwrite \n(\nconst String & \nfilename, \n\nInputArray \nimg, \n\nconst std::vector< int > & \nparams = std::vector< int >() \n\n)\n\nPython:cv.imwrite(filename, img[, params]) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nSaves an image to a specified file. \nThe function imwrite saves the image to the specified file. The image format is chosen based on the filename extension (see cv::imread for the list of extensions). In general, only 8-bit unsigned (CV_8U) single-channel or 3-channel (with 'BGR' channel order) images can be saved using this function, with these exceptions:\n\nWith OpenEXR encoder, only 32-bit float (CV_32F) images can be saved.\n8-bit unsigned (CV_8U) images are not supported.\n\nWith Radiance HDR encoder, non 64-bit float (CV_64F) images can be saved.\nAll images will be converted to 32-bit float (CV_32F).\n\nWith JPEG 2000 encoder, 8-bit unsigned (CV_8U) and 16-bit unsigned (CV_16U) images can be saved.\nWith PAM encoder, 8-bit unsigned (CV_8U) and 16-bit unsigned (CV_16U) images can be saved.\nWith PNG encoder, 8-bit unsigned (CV_8U) and 16-bit unsigned (CV_16U) images can be saved.\nPNG images with an alpha channel can be saved using this function. To do this, create 8-bit (or 16-bit) 4-channel image BGRA, where the alpha channel goes last. Fully transparent pixels should have alpha set to 0, fully opaque pixels should have alpha set to 255/65535 (see the code sample below).\n\nWith PGM/PPM encoder, 8-bit unsigned (CV_8U) and 16-bit unsigned (CV_16U) images can be saved.\nWith TIFF encoder, 8-bit unsigned (CV_8U), 16-bit unsigned (CV_16U), 32-bit float (CV_32F) and 64-bit float (CV_64F) images can be saved.\nMultiple images (vector of Mat) can be saved in TIFF format (see the code sample below).\n32-bit float 3-channel (CV_32FC3) TIFF images will be saved using the LogLuv high dynamic range encoding (4 bytes per pixel)\n\nIf the image format is not supported, the image will be converted to 8-bit unsigned (CV_8U) and saved that way.\nIf the format, depth or channel order is different, use Mat::convertTo and cv::cvtColor to convert it before saving. Or, use the universal FileStorage I/O functions to save the image to XML or YAML format.\nThe sample below shows how to create a BGRA image, how to set custom compression parameters and save it to a PNG file. It also demonstrates how to save multiple images in a TIFF file: #include <opencv2/imgcodecs.hpp>\n \nusing namespace cv;\nusing namespace std;\n \nstatic void paintAlphaMat(Mat &mat)\n{\n CV_Assert(mat.channels() == 4);\n for (int i = 0; i < mat.rows; ++i)\n    {\n for (int j = 0; j < mat.cols; ++j)\n        {\n Vec4b& bgra = mat.at<Vec4b>(i, j);\n            bgra[0] = UCHAR_MAX; // Blue\n            bgra[1] = saturate_cast<uchar>((float (mat.cols - j)) / ((float)mat.cols) * UCHAR_MAX); // Green\n            bgra[2] = saturate_cast<uchar>((float (mat.rows - i)) / ((float)mat.rows) * UCHAR_MAX); // Red\n            bgra[3] = saturate_cast<uchar>(0.5 * (bgra[1] + bgra[2])); // Alpha\n        }\n    }\n}\n \nint main()\n{\n Mat mat(480, 640, CV_8UC4); // Create a matrix with alpha channel\n    paintAlphaMat(mat);\n \n    vector<int> compression_params;\n    compression_params.push_back(IMWRITE_PNG_COMPRESSION);\n    compression_params.push_back(9);\n \n bool result = false;\n try\n    {\n        result = imwrite(\"alpha.png\", mat, compression_params);\n    }\n catch (const cv::Exception& ex)\n    {\n        fprintf(stderr, \"Exception converting image to PNG format: %s\\n\", ex.what());\n    }\n \n if (result)\n        printf(\"Saved PNG file with alpha data.\\n\");\n else\n        printf(\"ERROR: Can't save PNG file.\\n\");\n \n    vector<Mat> imgs;\n    imgs.push_back(mat);\n    imgs.push_back(~mat);\n    imgs.push_back(mat(Rect(0, 0, mat.cols / 2, mat.rows / 2)));\n imwrite(\"test.tiff\", imgs);\n    printf(\"Multiple files saved in test.tiff\\n\");\n \n return result ? 0 : 1;\n}\ncv::ExceptionClass passed to an error.Definition core.hpp:120\ncv::Exception::whatvirtual const char * what() const CV_NOEXCEPT CV_OVERRIDE\ncv::Matn-dimensional dense array classDefinition mat.hpp:828\ncv::Mat::at_Tp & at(int i0=0)Returns a reference to the specified array element.\ncv::Mat::channelsint channels() constReturns the number of matrix channels.\ncv::Mat::colsint colsDefinition mat.hpp:2154\ncv::Mat::rowsint rowsthe number of rows and columns or (-1, -1) when the matrix has more than 2 dimensionsDefinition mat.hpp:2154\ncv::VecTemplate class for short numerical vectors, a partial case of Matx.Definition matx.hpp:369\ncv::RectRect2i RectDefinition types.hpp:496\nCV_8UC4#define CV_8UC4Definition interface.h:91\ncv::saturate_cast< uchar >uchar saturate_cast< uchar >(schar v)Definition saturate.hpp:101\nCV_Assert#define CV_Assert(expr)Checks a condition at runtime and throws exception if it fails.Definition base.hpp:359\ncv::IMWRITE_PNG_COMPRESSION@ IMWRITE_PNG_COMPRESSIONFor PNG, it can be the compression level from 0 to 9. A higher value means a smaller size and longer ...Definition imgcodecs.hpp:95\ncv::imwriteCV_EXPORTS_W bool imwrite(const String &filename, InputArray img, const std::vector< int > &params=std::vector< int >())Saves an image to a specified file.\nmainint main(int argc, char *argv[])Definition highgui_qt.cpp:3\nimgcodecs.hpp\ncvDefinition core.hpp:107\nstdSTL namespace.\n Parameters\n\nfilenameName of the file. \nimg(Mat or vector of Mat) Image or Images to be saved. \nparamsFormat-specific parameters encoded as pairs (paramId_1, paramValue_1, paramId_2, paramValue_2, ... .) see cv::ImwriteFlags \n\n◆ imwritemulti()\n\nstatic CV_WRAP bool cv::imwritemulti \n(\nconst String & \nfilename, \n\nInputArrayOfArrays \nimg, \n\nconst std::vector< int > & \nparams = std::vector<int>() \n\n)\n\ninlinestatic \n\nPython:cv.imwritemulti(filename, img[, params]) -> retval\n\n#include <opencv2/imgcodecs.hpp>\nmulti-image overload for bindings \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/dc/dfe/group__intensity__transform.html","content_type":"text/html","title":"OpenCV: The module brings implementations of intensity transformation algorithms to adjust image contrast.","language":null},"page_content":"OpenCV: The module brings implementations of intensity transformation algorithms to adjust image contrast.\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nFunctions \nThe module brings implementations of intensity transformation algorithms to adjust image contrast.\n\nDetailed Description\nNamespace for all functions is cv::intensity_transform.\n\nSupported Algorithms\n\nAutoscaling\nLog Transformations\nPower-Law (Gamma) Transformations\nContrast Stretching\nBIMEF, A Bio-Inspired Multi-Exposure Fusion Framework for Low-light Image Enhancement [310] [311]\n\nReferences from following book and websites:\nDigital Image Processing 4th Edition Chapter 3 [Rafael C. Gonzalez, Richard E. Woods] [222]\nhttp://www.cs.uregina.ca/Links/class-info/425/Lab3/ [154]\nhttps://theailearner.com/2019/01/30/contrast-stretching/ [269] \n\nFunctions\nvoid cv::intensity_transform::autoscaling (const Mat input, Mat &output)\n Given an input bgr or grayscale image, apply autoscaling on domain [0, 255] to increase the contrast of the input image and return the resulting image.  \n \nvoid cv::intensity_transform::BIMEF (InputArray input, OutputArray output, float k, float mu, float a, float b)\n Given an input color image, enhance low-light images using the BIMEF method ([310] [311]).  \n \nvoid cv::intensity_transform::BIMEF (InputArray input, OutputArray output, float mu=0.5f, float a=-0.3293f, float b=1.1258f)\n Given an input color image, enhance low-light images using the BIMEF method ([310] [311]).  \n \nvoid cv::intensity_transform::contrastStretching (const Mat input, Mat &output, const int r1, const int s1, const int r2, const int s2)\n Given an input bgr or grayscale image, apply linear contrast stretching on domain [0, 255] and return the resulting image.  \n \nvoid cv::intensity_transform::gammaCorrection (const Mat input, Mat &output, const float gamma)\n Given an input bgr or grayscale image and constant gamma, apply power-law transformation, a.k.a. gamma correction to the image on domain [0, 255] and return the resulting image.  \n \nvoid cv::intensity_transform::logTransform (const Mat input, Mat &output)\n Given an input bgr or grayscale image and constant c, apply log transformation to the image on domain [0, 255] and return the resulting image.  \n \n\nFunction Documentation\n\n◆ autoscaling()\n\nvoid cv::intensity_transform::autoscaling \n(\nconst Mat \ninput, \n\nMat & \noutput \n\n)\n\nPython:cv.intensity_transform.autoscaling(input, output) -> None\n\n#include <opencv2/intensity_transform.hpp>\nGiven an input bgr or grayscale image, apply autoscaling on domain [0, 255] to increase the contrast of the input image and return the resulting image. \nParameters\n\ninputinput bgr or grayscale image. \noutputresulting image of autoscaling. \n\n◆ BIMEF() [1/2]\n\nvoid cv::intensity_transform::BIMEF \n(\nInputArray \ninput, \n\nOutputArray \noutput, \n\nfloat \nk, \n\nfloat \nmu, \n\nfloat \na, \n\nfloat \nb \n\n)\n\nPython:cv.intensity_transform.BIMEF(input[, output[, mu[, a[, b]]]]) -> outputcv.intensity_transform.BIMEF2(input, k, mu, a, b[, output]) -> output\n\n#include <opencv2/intensity_transform.hpp>\nGiven an input color image, enhance low-light images using the BIMEF method ([310] [311]). \nThis is an overloaded function with the exposure ratio given as parameter.\nParameters\n\ninputinput color image. \noutputresulting image. \nkexposure ratio. \nmuenhancement ratio. \naa-parameter in the Camera Response Function (CRF). \nbb-parameter in the Camera Response Function (CRF).\n\nWarningThis is a C++ implementation of the original MATLAB algorithm. Compared to the original code, this implementation is a little bit slower and does not provide the same results. In particular, quality of the image enhancement is degraded for the bright areas in certain conditions. \n\n◆ BIMEF() [2/2]\n\nvoid cv::intensity_transform::BIMEF \n(\nInputArray \ninput, \n\nOutputArray \noutput, \n\nfloat \nmu = 0.5f, \n\nfloat \na = -0.3293f, \n\nfloat \nb = 1.1258f \n\n)\n\nPython:cv.intensity_transform.BIMEF(input[, output[, mu[, a[, b]]]]) -> outputcv.intensity_transform.BIMEF2(input, k, mu, a, b[, output]) -> output\n\n#include <opencv2/intensity_transform.hpp>\nGiven an input color image, enhance low-light images using the BIMEF method ([310] [311]). \nParameters\n\ninputinput color image. \noutputresulting image. \nmuenhancement ratio. \naa-parameter in the Camera Response Function (CRF). \nbb-parameter in the Camera Response Function (CRF).\n\nWarningThis is a C++ implementation of the original MATLAB algorithm. Compared to the original code, this implementation is a little bit slower and does not provide the same results. In particular, quality of the image enhancement is degraded for the bright areas in certain conditions. \n\n◆ contrastStretching()\n\nvoid cv::intensity_transform::contrastStretching \n(\nconst Mat \ninput, \n\nMat & \noutput, \n\nconst int \nr1, \n\nconst int \ns1, \n\nconst int \nr2, \n\nconst int \ns2 \n\n)\n\nPython:cv.intensity_transform.contrastStretching(input, output, r1, s1, r2, s2) -> None\n\n#include <opencv2/intensity_transform.hpp>\nGiven an input bgr or grayscale image, apply linear contrast stretching on domain [0, 255] and return the resulting image. \nParameters\n\ninputinput bgr or grayscale image. \noutputresulting image of contrast stretching. \nr1x coordinate of first point (r1, s1) in the transformation function. \ns1y coordinate of first point (r1, s1) in the transformation function. \nr2x coordinate of second point (r2, s2) in the transformation function. \ns2y coordinate of second point (r2, s2) in the transformation function. \n\n◆ gammaCorrection()\n\nvoid cv::intensity_transform::gammaCorrection \n(\nconst Mat \ninput, \n\nMat & \noutput, \n\nconst float \ngamma \n\n)\n\nPython:cv.intensity_transform.gammaCorrection(input, output, gamma) -> None\n\n#include <opencv2/intensity_transform.hpp>\nGiven an input bgr or grayscale image and constant gamma, apply power-law transformation, a.k.a. gamma correction to the image on domain [0, 255] and return the resulting image. \nParameters\n\ninputinput bgr or grayscale image. \noutputresulting image of gamma corrections. \ngammaconstant in c*r^gamma where r is pixel value. \n\n◆ logTransform()\n\nvoid cv::intensity_transform::logTransform \n(\nconst Mat \ninput, \n\nMat & \noutput \n\n)\n\nPython:cv.intensity_transform.logTransform(input, output) -> None\n\n#include <opencv2/intensity_transform.hpp>\nGiven an input bgr or grayscale image and constant c, apply log transformation to the image on domain [0, 255] and return the resulting image. \nParameters\n\ninputinput bgr or grayscale image. \noutputresulting image of log transformations. \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d2/d55/group__bgsegm.html","content_type":"text/html","title":"OpenCV: Improved Background-Foreground Segmentation Methods","language":null},"page_content":"OpenCV: Improved Background-Foreground Segmentation Methods\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nClasses |\nEnumerations |\nFunctions \nImproved Background-Foreground Segmentation Methods\n\nDetailed Description\n\nClasses\nclass  cv::bgsegm::BackgroundSubtractorCNT\n Background subtraction based on counting.  More...\n \nclass  cv::bgsegm::BackgroundSubtractorGMG\n Background Subtractor module based on the algorithm given in [106] .  More...\n \nclass  cv::bgsegm::BackgroundSubtractorGSOC\n Implementation of the different yet better algorithm which is called GSOC, as it was implemented during GSOC and was not originated from any paper.  More...\n \nclass  cv::bgsegm::BackgroundSubtractorLSBP\n Background Subtraction using Local SVD Binary Pattern. More details about the algorithm can be found at [115].  More...\n \nclass  cv::bgsegm::BackgroundSubtractorLSBPDesc\n This is for calculation of the LSBP descriptors.  More...\n \nclass  cv::bgsegm::BackgroundSubtractorMOG\n Gaussian Mixture-based Background/Foreground Segmentation Algorithm.  More...\n \nclass  cv::bgsegm::SyntheticSequenceGenerator\n Synthetic frame sequence generator for testing background subtraction algorithms.  More...\n \n\nEnumerations\nenum  cv::bgsegm::LSBPCameraMotionCompensation { \n  cv::bgsegm::LSBP_CAMERA_MOTION_COMPENSATION_NONE = 0\n, \n  cv::bgsegm::LSBP_CAMERA_MOTION_COMPENSATION_LK\n\n }\n \n\nFunctions\nPtr< BackgroundSubtractorCNT > cv::bgsegm::createBackgroundSubtractorCNT (int minPixelStability=15, bool useHistory=true, int maxPixelStability=15 *60, bool isParallel=true)\n Creates a CNT Background Subtractor.  \n \nPtr< BackgroundSubtractorGMG > cv::bgsegm::createBackgroundSubtractorGMG (int initializationFrames=120, double decisionThreshold=0.8)\n Creates a GMG Background Subtractor.  \n \nPtr< BackgroundSubtractorGSOC > cv::bgsegm::createBackgroundSubtractorGSOC (int mc=LSBP_CAMERA_MOTION_COMPENSATION_NONE, int nSamples=20, float replaceRate=0.003f, float propagationRate=0.01f, int hitsThreshold=32, float alpha=0.01f, float beta=0.0022f, float blinkingSupressionDecay=0.1f, float blinkingSupressionMultiplier=0.1f, float noiseRemovalThresholdFacBG=0.0004f, float noiseRemovalThresholdFacFG=0.0008f)\n Creates an instance of BackgroundSubtractorGSOC algorithm.  \n \nPtr< BackgroundSubtractorLSBP > cv::bgsegm::createBackgroundSubtractorLSBP (int mc=LSBP_CAMERA_MOTION_COMPENSATION_NONE, int nSamples=20, int LSBPRadius=16, float Tlower=2.0f, float Tupper=32.0f, float Tinc=1.0f, float Tdec=0.05f, float Rscale=10.0f, float Rincdec=0.005f, float noiseRemovalThresholdFacBG=0.0004f, float noiseRemovalThresholdFacFG=0.0008f, int LSBPthreshold=8, int minCount=2)\n Creates an instance of BackgroundSubtractorLSBP algorithm.  \n \nPtr< BackgroundSubtractorMOG > cv::bgsegm::createBackgroundSubtractorMOG (int history=200, int nmixtures=5, double backgroundRatio=0.7, double noiseSigma=0)\n Creates mixture-of-gaussian background subtractor.  \n \nPtr< SyntheticSequenceGenerator > cv::bgsegm::createSyntheticSequenceGenerator (InputArray background, InputArray object, double amplitude=2.0, double wavelength=20.0, double wavespeed=0.2, double objspeed=6.0)\n Creates an instance of SyntheticSequenceGenerator.  \n \n\nEnumeration Type Documentation\n\n◆ LSBPCameraMotionCompensation\n\nenum cv::bgsegm::LSBPCameraMotionCompensation\n\n#include <opencv2/bgsegm.hpp>\n\nEnumeratorLSBP_CAMERA_MOTION_COMPENSATION_NONE Python: cv.bgsegm.LSBP_CAMERA_MOTION_COMPENSATION_NONE\nLSBP_CAMERA_MOTION_COMPENSATION_LK Python: cv.bgsegm.LSBP_CAMERA_MOTION_COMPENSATION_LK\n\nFunction Documentation\n\n◆ createBackgroundSubtractorCNT()\n\nPtr< BackgroundSubtractorCNT > cv::bgsegm::createBackgroundSubtractorCNT \n(\nint \nminPixelStability = 15, \n\nbool \nuseHistory = true, \n\nint \nmaxPixelStability = 15 *60, \n\nbool \nisParallel = true \n\n)\n\nPython:cv.bgsegm.createBackgroundSubtractorCNT([, minPixelStability[, useHistory[, maxPixelStability[, isParallel]]]]) -> retval\n\n#include <opencv2/bgsegm.hpp>\nCreates a CNT Background Subtractor. \nParameters\n\nminPixelStabilitynumber of frames with same pixel color to consider stable \nuseHistorydetermines if we're giving a pixel credit for being stable for a long time \nmaxPixelStabilitymaximum allowed credit for a pixel in history \nisParalleldetermines if we're parallelizing the algorithm \n\n◆ createBackgroundSubtractorGMG()\n\nPtr< BackgroundSubtractorGMG > cv::bgsegm::createBackgroundSubtractorGMG \n(\nint \ninitializationFrames = 120, \n\ndouble \ndecisionThreshold = 0.8 \n\n)\n\nPython:cv.bgsegm.createBackgroundSubtractorGMG([, initializationFrames[, decisionThreshold]]) -> retval\n\n#include <opencv2/bgsegm.hpp>\nCreates a GMG Background Subtractor. \nParameters\n\ninitializationFramesnumber of frames used to initialize the background models. \ndecisionThresholdThreshold value, above which it is marked foreground, else background. \n\n◆ createBackgroundSubtractorGSOC()\n\nPtr< BackgroundSubtractorGSOC > cv::bgsegm::createBackgroundSubtractorGSOC \n(\nint \nmc = LSBP_CAMERA_MOTION_COMPENSATION_NONE, \n\nint \nnSamples = 20, \n\nfloat \nreplaceRate = 0.003f, \n\nfloat \npropagationRate = 0.01f, \n\nint \nhitsThreshold = 32, \n\nfloat \nalpha = 0.01f, \n\nfloat \nbeta = 0.0022f, \n\nfloat \nblinkingSupressionDecay = 0.1f, \n\nfloat \nblinkingSupressionMultiplier = 0.1f, \n\nfloat \nnoiseRemovalThresholdFacBG = 0.0004f, \n\nfloat \nnoiseRemovalThresholdFacFG = 0.0008f \n\n)\n\nPython:cv.bgsegm.createBackgroundSubtractorGSOC([, mc[, nSamples[, replaceRate[, propagationRate[, hitsThreshold[, alpha[, beta[, blinkingSupressionDecay[, blinkingSupressionMultiplier[, noiseRemovalThresholdFacBG[, noiseRemovalThresholdFacFG]]]]]]]]]]]) -> retval\n\n#include <opencv2/bgsegm.hpp>\nCreates an instance of BackgroundSubtractorGSOC algorithm. \nImplementation of the different yet better algorithm which is called GSOC, as it was implemented during GSOC and was not originated from any paper.\nParameters\n\nmcWhether to use camera motion compensation. \nnSamplesNumber of samples to maintain at each point of the frame. \nreplaceRateProbability of replacing the old sample - how fast the model will update itself. \npropagationRateProbability of propagating to neighbors. \nhitsThresholdHow many positives the sample must get before it will be considered as a possible replacement. \nalphaScale coefficient for threshold. \nbetaBias coefficient for threshold. \nblinkingSupressionDecayBlinking supression decay factor. \nblinkingSupressionMultiplierBlinking supression multiplier. \nnoiseRemovalThresholdFacBGStrength of the noise removal for background points. \nnoiseRemovalThresholdFacFGStrength of the noise removal for foreground points. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ createBackgroundSubtractorLSBP()\n\nPtr< BackgroundSubtractorLSBP > cv::bgsegm::createBackgroundSubtractorLSBP \n(\nint \nmc = LSBP_CAMERA_MOTION_COMPENSATION_NONE, \n\nint \nnSamples = 20, \n\nint \nLSBPRadius = 16, \n\nfloat \nTlower = 2.0f, \n\nfloat \nTupper = 32.0f, \n\nfloat \nTinc = 1.0f, \n\nfloat \nTdec = 0.05f, \n\nfloat \nRscale = 10.0f, \n\nfloat \nRincdec = 0.005f, \n\nfloat \nnoiseRemovalThresholdFacBG = 0.0004f, \n\nfloat \nnoiseRemovalThresholdFacFG = 0.0008f, \n\nint \nLSBPthreshold = 8, \n\nint \nminCount = 2 \n\n)\n\nPython:cv.bgsegm.createBackgroundSubtractorLSBP([, mc[, nSamples[, LSBPRadius[, Tlower[, Tupper[, Tinc[, Tdec[, Rscale[, Rincdec[, noiseRemovalThresholdFacBG[, noiseRemovalThresholdFacFG[, LSBPthreshold[, minCount]]]]]]]]]]]]]) -> retval\n\n#include <opencv2/bgsegm.hpp>\nCreates an instance of BackgroundSubtractorLSBP algorithm. \nBackground Subtraction using Local SVD Binary Pattern. More details about the algorithm can be found at [115]\nParameters\n\nmcWhether to use camera motion compensation. \nnSamplesNumber of samples to maintain at each point of the frame. \nLSBPRadiusLSBP descriptor radius. \nTlowerLower bound for T-values. See [115] for details. \nTupperUpper bound for T-values. See [115] for details. \nTincIncrease step for T-values. See [115] for details. \nTdecDecrease step for T-values. See [115] for details. \nRscaleScale coefficient for threshold values. \nRincdecIncrease/Decrease step for threshold values. \nnoiseRemovalThresholdFacBGStrength of the noise removal for background points. \nnoiseRemovalThresholdFacFGStrength of the noise removal for foreground points. \nLSBPthresholdThreshold for LSBP binary string. \nminCountMinimal number of matches for sample to be considered as foreground. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ createBackgroundSubtractorMOG()\n\nPtr< BackgroundSubtractorMOG > cv::bgsegm::createBackgroundSubtractorMOG \n(\nint \nhistory = 200, \n\nint \nnmixtures = 5, \n\ndouble \nbackgroundRatio = 0.7, \n\ndouble \nnoiseSigma = 0 \n\n)\n\nPython:cv.bgsegm.createBackgroundSubtractorMOG([, history[, nmixtures[, backgroundRatio[, noiseSigma]]]]) -> retval\n\n#include <opencv2/bgsegm.hpp>\nCreates mixture-of-gaussian background subtractor. \nParameters\n\nhistoryLength of the history. \nnmixturesNumber of Gaussian mixtures. \nbackgroundRatioBackground ratio. \nnoiseSigmaNoise strength (standard deviation of the brightness or each color channel). 0 means some automatic value. \n\n◆ createSyntheticSequenceGenerator()\n\nPtr< SyntheticSequenceGenerator > cv::bgsegm::createSyntheticSequenceGenerator \n(\nInputArray \nbackground, \n\nInputArray \nobject, \n\ndouble \namplitude = 2.0, \n\ndouble \nwavelength = 20.0, \n\ndouble \nwavespeed = 0.2, \n\ndouble \nobjspeed = 6.0 \n\n)\n\nPython:cv.bgsegm.createSyntheticSequenceGenerator(background, object[, amplitude[, wavelength[, wavespeed[, objspeed]]]]) -> retval\n\n#include <opencv2/bgsegm.hpp>\nCreates an instance of SyntheticSequenceGenerator. \nParameters\n\nbackgroundBackground image for object. \nobjectObject image which will move slowly over the background. \namplitudeAmplitude of wave distortion applied to background. \nwavelengthLength of waves in distortion applied to background. \nwavespeedHow fast waves will move. \nobjspeedHow fast object will fly over background. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d7/d44/group__julia.html","content_type":"text/html","title":"OpenCV: Julia bindings for OpenCV","language":null},"page_content":"OpenCV: Julia bindings for OpenCV\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nFunctions \nJulia bindings for OpenCV\n\nDetailed Description\nJulia (https://julialang.org) is a programming language for scientific community with growing popularity. These are bindings for a subset of OpenCV functionality, based on libcxxwrap-julia and CxxWrap packages.\nFor installation instructions, see README.md in this module or OpenCV wiki (https://github.com/opencv/opencv/wiki) \n\nFunctions\nvoid cv::julia::initJulia (int argc, char **argv)\n \n\nFunction Documentation\n\n◆ initJulia()\n\nvoid cv::julia::initJulia \n(\nint \nargc, \n\nchar ** \nargv \n\n)\n\n#include <opencv2/julia.hpp>\n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d2/d1f/group__signal.html","content_type":"text/html","title":"OpenCV: Signal Processing","language":null},"page_content":"OpenCV: Signal Processing\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nFunctions \nSignal Processing\n\nDetailed Description\nThis module includes signal processing algorithms. \n\nFunctions\nvoid cv::signal::resampleSignal (InputArray inputSignal, OutputArray outSignal, const int inFreq, const int outFreq)\n Signal resampling.  \n \n\nFunction Documentation\n\n◆ resampleSignal()\n\nvoid cv::signal::resampleSignal \n(\nInputArray \ninputSignal, \n\nOutputArray \noutSignal, \n\nconst int \ninFreq, \n\nconst int \noutFreq \n\n)\n\nPython:cv.signal.resampleSignal(inputSignal, inFreq, outFreq[, outSignal]) -> outSignal\n\n#include <opencv2/signal/signal_resample.hpp>\nSignal resampling. \nParameters\n\n[in]inputSignalArray with input signal. \n[out]outSignalArray with output signal \n[in]inFreqInput signal frequency. \n[in]outFreqOutput signal frequency. Signal resampling implemented a cubic interpolation function and a filtering function based on Kaiser window and Bessel function, used to construct a FIR filter. Result is similar to scipy.signal.resample.\n\nDetail: https://en.wikipedia.org/wiki/Sample-rate_conversion \n\nGenerated on Mon Nov 11 2024 23:11:43 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html","content_type":"text/html","title":"OpenCV: Camera Calibration and 3D Reconstruction","language":null},"page_content":"OpenCV: Camera Calibration and 3D Reconstruction\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nModules |\nClasses |\nTypedefs |\nEnumerations |\nFunctions \nCamera Calibration and 3D Reconstruction\n\nModules\n Fisheye camera model\n \n\nDetailed Description\nThe functions in this section use a so-called pinhole camera model. The view of a scene is obtained by projecting a scene's 3D point \\(P_w\\) into the image plane using a perspective transformation which forms the corresponding pixel \\(p\\). Both \\(P_w\\) and \\(p\\) are represented in homogeneous coordinates, i.e. as 3D and 2D homogeneous vector respectively. You will find a brief introduction to projective geometry, homogeneous vectors and homogeneous transformations at the end of this section's introduction. For more succinct notation, we often drop the 'homogeneous' and say vector instead of homogeneous vector.\nThe distortion-free projective transformation given by a pinhole camera model is shown below.\n\n\\[s \\; p = A \\begin{bmatrix} R|t \\end{bmatrix} P_w,\\]\n\nwhere \\(P_w\\) is a 3D point expressed with respect to the world coordinate system, \\(p\\) is a 2D pixel in the image plane, \\(A\\) is the camera intrinsic matrix, \\(R\\) and \\(t\\) are the rotation and translation that describe the change of coordinates from world to camera coordinate systems (or camera frame) and \\(s\\) is the projective transformation's arbitrary scaling and not part of the camera model.\nThe camera intrinsic matrix \\(A\\) (notation used as in [319] and also generally notated as \\(K\\)) projects 3D points given in the camera coordinate system to 2D pixel coordinates, i.e.\n\n\\[p = A P_c.\\]\n\nThe camera intrinsic matrix \\(A\\) is composed of the focal lengths \\(f_x\\) and \\(f_y\\), which are expressed in pixel units, and the principal point \\((c_x, c_y)\\), that is usually close to the image center:\n\n\\[A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1},\\]\n\nand thus\n\n\\[s \\vecthree{u}{v}{1} = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1} \\vecthree{X_c}{Y_c}{Z_c}.\\]\n\nThe matrix of intrinsic parameters does not depend on the scene viewed. So, once estimated, it can be re-used as long as the focal length is fixed (in case of a zoom lens). Thus, if an image from the camera is scaled by a factor, all of these parameters need to be scaled (multiplied/divided, respectively) by the same factor.\nThe joint rotation-translation matrix \\([R|t]\\) is the matrix product of a projective transformation and a homogeneous transformation. The 3-by-4 projective transformation maps 3D points represented in camera coordinates to 2D points in the image plane and represented in normalized camera coordinates \\(x' = X_c / Z_c\\) and \\(y' = Y_c / Z_c\\):\n\n\\[Z_c \\begin{bmatrix}\nx' \\\\\ny' \\\\\n1\n\\end{bmatrix} = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{bmatrix}.\\]\n\nThe homogeneous transformation is encoded by the extrinsic parameters \\(R\\) and \\(t\\) and represents the change of basis from world coordinate system \\(w\\) to the camera coordinate sytem \\(c\\). Thus, given the representation of the point \\(P\\) in world coordinates, \\(P_w\\), we obtain \\(P\\)'s representation in the camera coordinate system, \\(P_c\\), by\n\n\\[P_c = \\begin{bmatrix}\nR & t \\\\\n0 & 1\n\\end{bmatrix} P_w,\\]\n\nThis homogeneous transformation is composed out of \\(R\\), a 3-by-3 rotation matrix, and \\(t\\), a 3-by-1 translation vector:\n\n\\[\\begin{bmatrix}\nR & t \\\\\n0 & 1\n\\end{bmatrix} = \\begin{bmatrix}\nr_{11} & r_{12} & r_{13} & t_x \\\\\nr_{21} & r_{22} & r_{23} & t_y \\\\\nr_{31} & r_{32} & r_{33} & t_z \\\\\n0 & 0 & 0 & 1\n\\end{bmatrix},\n\\]\n\nand therefore\n\n\\[\\begin{bmatrix}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{bmatrix} = \\begin{bmatrix}\nr_{11} & r_{12} & r_{13} & t_x \\\\\nr_{21} & r_{22} & r_{23} & t_y \\\\\nr_{31} & r_{32} & r_{33} & t_z \\\\\n0 & 0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nX_w \\\\\nY_w \\\\\nZ_w \\\\\n1\n\\end{bmatrix}.\\]\n\nCombining the projective transformation and the homogeneous transformation, we obtain the projective transformation that maps 3D points in world coordinates into 2D points in the image plane and in normalized camera coordinates:\n\n\\[Z_c \\begin{bmatrix}\nx' \\\\\ny' \\\\\n1\n\\end{bmatrix} = \\begin{bmatrix} R|t \\end{bmatrix} \\begin{bmatrix}\nX_w \\\\\nY_w \\\\\nZ_w \\\\\n1\n\\end{bmatrix} = \\begin{bmatrix}\nr_{11} & r_{12} & r_{13} & t_x \\\\\nr_{21} & r_{22} & r_{23} & t_y \\\\\nr_{31} & r_{32} & r_{33} & t_z\n\\end{bmatrix}\n\\begin{bmatrix}\nX_w \\\\\nY_w \\\\\nZ_w \\\\\n1\n\\end{bmatrix},\\]\n\nwith \\(x' = X_c / Z_c\\) and \\(y' = Y_c / Z_c\\). Putting the equations for instrincs and extrinsics together, we can write out \\(s \\; p = A \\begin{bmatrix} R|t \\end{bmatrix} P_w\\) as\n\n\\[s \\vecthree{u}{v}{1} = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\n\\begin{bmatrix}\nr_{11} & r_{12} & r_{13} & t_x \\\\\nr_{21} & r_{22} & r_{23} & t_y \\\\\nr_{31} & r_{32} & r_{33} & t_z\n\\end{bmatrix}\n\\begin{bmatrix}\nX_w \\\\\nY_w \\\\\nZ_w \\\\\n1\n\\end{bmatrix}.\\]\n\nIf \\(Z_c \\ne 0\\), the transformation above is equivalent to the following,\n\n\\[\\begin{bmatrix}\nu \\\\\nv\n\\end{bmatrix} = \\begin{bmatrix}\nf_x X_c/Z_c + c_x \\\\\nf_y Y_c/Z_c + c_y\n\\end{bmatrix}\\]\n\nwith\n\n\\[\\vecthree{X_c}{Y_c}{Z_c} = \\begin{bmatrix}\nR|t\n\\end{bmatrix} \\begin{bmatrix}\nX_w \\\\\nY_w \\\\\nZ_w \\\\\n1\n\\end{bmatrix}.\\]\n\nThe following figure illustrates the pinhole camera model.\n\nPinhole camera model\nReal lenses usually have some distortion, mostly radial distortion, and slight tangential distortion. So, the above model is extended as:\n\n\\[\\begin{bmatrix}\nu \\\\\nv\n\\end{bmatrix} = \\begin{bmatrix}\nf_x x'' + c_x \\\\\nf_y y'' + c_y\n\\end{bmatrix}\\]\n\nwhere\n\n\\[\\begin{bmatrix}\nx'' \\\\\ny''\n\\end{bmatrix} = \\begin{bmatrix}\nx' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + 2 p_1 x' y' + p_2(r^2 + 2 x'^2) + s_1 r^2 + s_2 r^4 \\\\\ny' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + p_1 (r^2 + 2 y'^2) + 2 p_2 x' y' + s_3 r^2 + s_4 r^4 \\\\\n\\end{bmatrix}\\]\n\nwith\n\n\\[r^2 = x'^2 + y'^2\\]\n\nand\n\n\\[\\begin{bmatrix}\nx'\\\\\ny'\n\\end{bmatrix} = \\begin{bmatrix}\nX_c/Z_c \\\\\nY_c/Z_c\n\\end{bmatrix},\\]\n\nif \\(Z_c \\ne 0\\).\nThe distortion parameters are the radial coefficients \\(k_1\\), \\(k_2\\), \\(k_3\\), \\(k_4\\), \\(k_5\\), and \\(k_6\\) , \\(p_1\\) and \\(p_2\\) are the tangential distortion coefficients, and \\(s_1\\), \\(s_2\\), \\(s_3\\), and \\(s_4\\), are the thin prism distortion coefficients. Higher-order coefficients are not considered in OpenCV.\nThe next figures show two common types of radial distortion: barrel distortion ( \\( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6 \\) monotonically decreasing) and pincushion distortion ( \\( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6 \\) monotonically increasing). Radial distortion is always monotonic for real lenses, and if the estimator produces a non-monotonic result, this should be considered a calibration failure. More generally, radial distortion must be monotonic and the distortion function must be bijective. A failed estimation result may look deceptively good near the image center but will work poorly in e.g. AR/SFM applications. The optimization method used in OpenCV camera calibration does not include these constraints as the framework does not support the required integer programming and polynomial inequalities. See issue #15992 for additional information.\n \n \nIn some cases, the image sensor may be tilted in order to focus an oblique plane in front of the camera (Scheimpflug principle). This can be useful for particle image velocimetry (PIV) or triangulation with a laser fan. The tilt causes a perspective distortion of \\(x''\\) and \\(y''\\). This distortion can be modeled in the following way, see e.g. [172].\n\n\\[\\begin{bmatrix}\nu \\\\\nv\n\\end{bmatrix} = \\begin{bmatrix}\nf_x x''' + c_x \\\\\nf_y y''' + c_y\n\\end{bmatrix},\\]\n\nwhere\n\n\\[s\\vecthree{x'''}{y'''}{1} =\n\\vecthreethree{R_{33}(\\tau_x, \\tau_y)}{0}{-R_{13}(\\tau_x, \\tau_y)}\n{0}{R_{33}(\\tau_x, \\tau_y)}{-R_{23}(\\tau_x, \\tau_y)}\n{0}{0}{1} R(\\tau_x, \\tau_y) \\vecthree{x''}{y''}{1}\\]\n\nand the matrix \\(R(\\tau_x, \\tau_y)\\) is defined by two rotations with angular parameter \\(\\tau_x\\) and \\(\\tau_y\\), respectively,\n\n\\[\nR(\\tau_x, \\tau_y) =\n\\vecthreethree{\\cos(\\tau_y)}{0}{-\\sin(\\tau_y)}{0}{1}{0}{\\sin(\\tau_y)}{0}{\\cos(\\tau_y)}\n\\vecthreethree{1}{0}{0}{0}{\\cos(\\tau_x)}{\\sin(\\tau_x)}{0}{-\\sin(\\tau_x)}{\\cos(\\tau_x)} =\n\\vecthreethree{\\cos(\\tau_y)}{\\sin(\\tau_y)\\sin(\\tau_x)}{-\\sin(\\tau_y)\\cos(\\tau_x)}\n{0}{\\cos(\\tau_x)}{\\sin(\\tau_x)}\n{\\sin(\\tau_y)}{-\\cos(\\tau_y)\\sin(\\tau_x)}{\\cos(\\tau_y)\\cos(\\tau_x)}.\n\\]\n\nIn the functions below the coefficients are passed or returned as\n\n\\[(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\]\n\nvector. That is, if the vector contains four elements, it means that \\(k_3=0\\) . The distortion coefficients do not depend on the scene viewed. Thus, they also belong to the intrinsic camera parameters. And they remain the same regardless of the captured image resolution. If, for example, a camera has been calibrated on images of 320 x 240 resolution, absolutely the same distortion coefficients can be used for 640 x 480 images from the same camera while \\(f_x\\), \\(f_y\\), \\(c_x\\), and \\(c_y\\) need to be scaled appropriately.\nThe functions below use the above model to do the following:\n\nProject 3D points to the image plane given intrinsic and extrinsic parameters.\nCompute extrinsic parameters given intrinsic parameters, a few 3D points, and their projections.\nEstimate intrinsic and extrinsic camera parameters from several views of a known calibration pattern (every view is described by several 3D-2D point correspondences).\nEstimate the relative position and orientation of the stereo camera \"heads\" and compute the rectification* transformation that makes the camera optical axes parallel.\n\n Homogeneous Coordinates \n Homogeneous Coordinates are a system of coordinates that are used in projective geometry. Their use allows to represent points at infinity by finite coordinates and simplifies formulas when compared to the cartesian counterparts, e.g. they have the advantage that affine transformations can be expressed as linear homogeneous transformation.\nOne obtains the homogeneous vector \\(P_h\\) by appending a 1 along an n-dimensional cartesian vector \\(P\\) e.g. for a 3D cartesian vector the mapping \\(P \\rightarrow P_h\\) is:\n\n\\[\\begin{bmatrix}\nX \\\\\nY \\\\\nZ\n\\end{bmatrix} \\rightarrow \\begin{bmatrix}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{bmatrix}.\\]\n\nFor the inverse mapping \\(P_h \\rightarrow P\\), one divides all elements of the homogeneous vector by its last element, e.g. for a 3D homogeneous vector one gets its 2D cartesian counterpart by:\n\n\\[\\begin{bmatrix}\nX \\\\\nY \\\\\nW\n\\end{bmatrix} \\rightarrow \\begin{bmatrix}\nX / W \\\\\nY / W\n\\end{bmatrix},\\]\n\nif \\(W \\ne 0\\).\nDue to this mapping, all multiples \\(k P_h\\), for \\(k \\ne 0\\), of a homogeneous point represent the same point \\(P_h\\). An intuitive understanding of this property is that under a projective transformation, all multiples of \\(P_h\\) are mapped to the same point. This is the physical observation one does for pinhole cameras, as all points along a ray through the camera's pinhole are projected to the same image point, e.g. all points along the red ray in the image of the pinhole camera model above would be mapped to the same image coordinate. This property is also the source for the scale ambiguity s in the equation of the pinhole camera model.\nAs mentioned, by using homogeneous coordinates we can express any change of basis parameterized by \\(R\\) and \\(t\\) as a linear transformation, e.g. for the change of basis from coordinate system 0 to coordinate system 1 becomes:\n\n\\[P_1 = R P_0 + t \\rightarrow P_{h_1} = \\begin{bmatrix}\nR & t \\\\\n0 & 1\n\\end{bmatrix} P_{h_0}.\\]\n\nNote\nMany functions in this module take a camera intrinsic matrix as an input parameter. Although all functions assume the same structure of this parameter, they may name it differently. The parameter's description, however, will be clear in that a camera intrinsic matrix with the structure shown above is required.\nA calibration sample for 3 cameras in a horizontal position can be found at opencv_source_code/samples/cpp/3calibration.cpp\nA calibration sample based on a sequence of images can be found at opencv_source_code/samples/cpp/calibration.cpp\nA calibration sample in order to do 3D reconstruction can be found at opencv_source_code/samples/cpp/build3dmodel.cpp\nA calibration example on stereo calibration can be found at opencv_source_code/samples/cpp/stereo_calib.cpp\nA calibration example on stereo matching can be found at opencv_source_code/samples/cpp/stereo_match.cpp\n(Python) A camera calibration sample can be found at opencv_source_code/samples/python/calibrate.py \n\nClasses\nstruct  cv::CirclesGridFinderParameters\n \nclass  cv::LMSolver\n \nclass  cv::StereoBM\n Class for computing stereo correspondence using the block matching algorithm, introduced and contributed to OpenCV by K. Konolige.  More...\n \nclass  cv::StereoMatcher\n The base class for stereo correspondence algorithms.  More...\n \nclass  cv::StereoSGBM\n The class implements the modified H. Hirschmuller algorithm [126] that differs from the original one as follows:  More...\n \nstruct  cv::UsacParams\n \n\nTypedefs\ntypedef CirclesGridFinderParameters cv::CirclesGridFinderParameters2\n \n\nEnumerations\nenum  { \n  cv::LMEDS = 4\n, \n  cv::RANSAC = 8\n, \n  cv::RHO = 16\n, \n  cv::USAC_DEFAULT = 32\n, \n  cv::USAC_PARALLEL = 33\n, \n  cv::USAC_FM_8PTS = 34\n, \n  cv::USAC_FAST = 35\n, \n  cv::USAC_ACCURATE = 36\n, \n  cv::USAC_PROSAC = 37\n, \n  cv::USAC_MAGSAC = 38\n\n }\n type of the robust estimation algorithm  More...\n \nenum  { \n  cv::CALIB_CB_ADAPTIVE_THRESH = 1\n, \n  cv::CALIB_CB_NORMALIZE_IMAGE = 2\n, \n  cv::CALIB_CB_FILTER_QUADS = 4\n, \n  cv::CALIB_CB_FAST_CHECK = 8\n, \n  cv::CALIB_CB_EXHAUSTIVE = 16\n, \n  cv::CALIB_CB_ACCURACY = 32\n, \n  cv::CALIB_CB_LARGER = 64\n, \n  cv::CALIB_CB_MARKER = 128\n, \n  cv::CALIB_CB_PLAIN = 256\n\n }\n \nenum  { \n  cv::CALIB_CB_SYMMETRIC_GRID = 1\n, \n  cv::CALIB_CB_ASYMMETRIC_GRID = 2\n, \n  cv::CALIB_CB_CLUSTERING = 4\n\n }\n \nenum  { \n  cv::CALIB_NINTRINSIC = 18\n, \n  cv::CALIB_USE_INTRINSIC_GUESS = 0x00001\n, \n  cv::CALIB_FIX_ASPECT_RATIO = 0x00002\n, \n  cv::CALIB_FIX_PRINCIPAL_POINT = 0x00004\n, \n  cv::CALIB_ZERO_TANGENT_DIST = 0x00008\n, \n  cv::CALIB_FIX_FOCAL_LENGTH = 0x00010\n, \n  cv::CALIB_FIX_K1 = 0x00020\n, \n  cv::CALIB_FIX_K2 = 0x00040\n, \n  cv::CALIB_FIX_K3 = 0x00080\n, \n  cv::CALIB_FIX_K4 = 0x00800\n, \n  cv::CALIB_FIX_K5 = 0x01000\n, \n  cv::CALIB_FIX_K6 = 0x02000\n, \n  cv::CALIB_RATIONAL_MODEL = 0x04000\n, \n  cv::CALIB_THIN_PRISM_MODEL = 0x08000\n, \n  cv::CALIB_FIX_S1_S2_S3_S4 = 0x10000\n, \n  cv::CALIB_TILTED_MODEL = 0x40000\n, \n  cv::CALIB_FIX_TAUX_TAUY = 0x80000\n, \n  cv::CALIB_USE_QR = 0x100000\n, \n  cv::CALIB_FIX_TANGENT_DIST = 0x200000\n, \n  cv::CALIB_FIX_INTRINSIC = 0x00100\n, \n  cv::CALIB_SAME_FOCAL_LENGTH = 0x00200\n, \n  cv::CALIB_ZERO_DISPARITY = 0x00400\n, \n  cv::CALIB_USE_LU = (1 << 17)\n, \n  cv::CALIB_USE_EXTRINSIC_GUESS = (1 << 22)\n\n }\n \nenum  { \n  cv::FM_7POINT = 1\n, \n  cv::FM_8POINT = 2\n, \n  cv::FM_LMEDS = 4\n, \n  cv::FM_RANSAC = 8\n\n }\n the algorithm for finding fundamental matrix  More...\n \nenum  cv::HandEyeCalibrationMethod { \n  cv::CALIB_HAND_EYE_TSAI = 0\n, \n  cv::CALIB_HAND_EYE_PARK = 1\n, \n  cv::CALIB_HAND_EYE_HORAUD = 2\n, \n  cv::CALIB_HAND_EYE_ANDREFF = 3\n, \n  cv::CALIB_HAND_EYE_DANIILIDIS = 4\n\n }\n \nenum  cv::LocalOptimMethod { \n  cv::LOCAL_OPTIM_NULL =0\n, \n  cv::LOCAL_OPTIM_INNER_LO =1\n, \n  cv::LOCAL_OPTIM_INNER_AND_ITER_LO =2\n, \n  cv::LOCAL_OPTIM_GC =3\n, \n  cv::LOCAL_OPTIM_SIGMA =4\n\n }\n \nenum  cv::NeighborSearchMethod { \n  cv::NEIGH_FLANN_KNN =0\n, \n  cv::NEIGH_GRID =1\n, \n  cv::NEIGH_FLANN_RADIUS =2\n\n }\n \nenum  cv::PolishingMethod { \n  cv::NONE_POLISHER =0\n, \n  cv::LSQ_POLISHER =1\n, \n  cv::MAGSAC =2\n, \n  cv::COV_POLISHER =3\n\n }\n \nenum  cv::RobotWorldHandEyeCalibrationMethod { \n  cv::CALIB_ROBOT_WORLD_HAND_EYE_SHAH = 0\n, \n  cv::CALIB_ROBOT_WORLD_HAND_EYE_LI = 1\n\n }\n \nenum  cv::SamplingMethod { \n  cv::SAMPLING_UNIFORM =0\n, \n  cv::SAMPLING_PROGRESSIVE_NAPSAC =1\n, \n  cv::SAMPLING_NAPSAC =2\n, \n  cv::SAMPLING_PROSAC =3\n\n }\n \nenum  cv::ScoreMethod { \n  cv::SCORE_METHOD_RANSAC =0\n, \n  cv::SCORE_METHOD_MSAC =1\n, \n  cv::SCORE_METHOD_MAGSAC =2\n, \n  cv::SCORE_METHOD_LMEDS =3\n\n }\n \nenum  cv::SolvePnPMethod { \n  cv::SOLVEPNP_ITERATIVE = 0\n, \n  cv::SOLVEPNP_EPNP = 1\n, \n  cv::SOLVEPNP_P3P = 2\n, \n  cv::SOLVEPNP_DLS = 3\n, \n  cv::SOLVEPNP_UPNP = 4\n, \n  cv::SOLVEPNP_AP3P = 5\n, \n  cv::SOLVEPNP_IPPE = 6\n, \n  cv::SOLVEPNP_IPPE_SQUARE = 7\n, \n  cv::SOLVEPNP_SQPNP = 8\n\n }\n \nenum  cv::UndistortTypes { \n  cv::PROJ_SPHERICAL_ORTHO = 0\n, \n  cv::PROJ_SPHERICAL_EQRECT = 1\n\n }\n cv::undistort mode  More...\n \n\nFunctions\ndouble cv::calibrateCamera (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, int flags=0, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n \ndouble cv::calibrateCamera (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, OutputArray stdDeviationsIntrinsics, OutputArray stdDeviationsExtrinsics, OutputArray perViewErrors, int flags=0, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n Finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.  \n \ndouble cv::calibrateCameraRO (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, int iFixedPoint, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, OutputArray newObjPoints, int flags=0, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n \ndouble cv::calibrateCameraRO (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, int iFixedPoint, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, OutputArray newObjPoints, OutputArray stdDeviationsIntrinsics, OutputArray stdDeviationsExtrinsics, OutputArray stdDeviationsObjPoints, OutputArray perViewErrors, int flags=0, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON))\n Finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.  \n \nvoid cv::calibrateHandEye (InputArrayOfArrays R_gripper2base, InputArrayOfArrays t_gripper2base, InputArrayOfArrays R_target2cam, InputArrayOfArrays t_target2cam, OutputArray R_cam2gripper, OutputArray t_cam2gripper, HandEyeCalibrationMethod method=CALIB_HAND_EYE_TSAI)\n Computes Hand-Eye calibration: \\(_{}^{g}\\textrm{T}_c\\).  \n \nvoid cv::calibrateRobotWorldHandEye (InputArrayOfArrays R_world2cam, InputArrayOfArrays t_world2cam, InputArrayOfArrays R_base2gripper, InputArrayOfArrays t_base2gripper, OutputArray R_base2world, OutputArray t_base2world, OutputArray R_gripper2cam, OutputArray t_gripper2cam, RobotWorldHandEyeCalibrationMethod method=CALIB_ROBOT_WORLD_HAND_EYE_SHAH)\n Computes Robot-World/Hand-Eye calibration: \\(_{}^{w}\\textrm{T}_b\\) and \\(_{}^{c}\\textrm{T}_g\\).  \n \nvoid cv::calibrationMatrixValues (InputArray cameraMatrix, Size imageSize, double apertureWidth, double apertureHeight, double &fovx, double &fovy, double &focalLength, Point2d &principalPoint, double &aspectRatio)\n Computes useful camera characteristics from the camera intrinsic matrix.  \n \nbool cv::checkChessboard (InputArray img, Size size)\n \nvoid cv::composeRT (InputArray rvec1, InputArray tvec1, InputArray rvec2, InputArray tvec2, OutputArray rvec3, OutputArray tvec3, OutputArray dr3dr1=noArray(), OutputArray dr3dt1=noArray(), OutputArray dr3dr2=noArray(), OutputArray dr3dt2=noArray(), OutputArray dt3dr1=noArray(), OutputArray dt3dt1=noArray(), OutputArray dt3dr2=noArray(), OutputArray dt3dt2=noArray())\n Combines two rotation-and-shift transformations.  \n \nvoid cv::computeCorrespondEpilines (InputArray points, int whichImage, InputArray F, OutputArray lines)\n For points in an image of a stereo pair, computes the corresponding epilines in the other image.  \n \nvoid cv::convertPointsFromHomogeneous (InputArray src, OutputArray dst)\n Converts points from homogeneous to Euclidean space.  \n \nvoid cv::convertPointsHomogeneous (InputArray src, OutputArray dst)\n Converts points to/from homogeneous coordinates.  \n \nvoid cv::convertPointsToHomogeneous (InputArray src, OutputArray dst)\n Converts points from Euclidean to homogeneous space.  \n \nvoid cv::correctMatches (InputArray F, InputArray points1, InputArray points2, OutputArray newPoints1, OutputArray newPoints2)\n Refines coordinates of corresponding points.  \n \nvoid cv::decomposeEssentialMat (InputArray E, OutputArray R1, OutputArray R2, OutputArray t)\n Decompose an essential matrix to possible rotations and translation.  \n \nint cv::decomposeHomographyMat (InputArray H, InputArray K, OutputArrayOfArrays rotations, OutputArrayOfArrays translations, OutputArrayOfArrays normals)\n Decompose a homography matrix to rotation(s), translation(s) and plane normal(s).  \n \nvoid cv::decomposeProjectionMatrix (InputArray projMatrix, OutputArray cameraMatrix, OutputArray rotMatrix, OutputArray transVect, OutputArray rotMatrixX=noArray(), OutputArray rotMatrixY=noArray(), OutputArray rotMatrixZ=noArray(), OutputArray eulerAngles=noArray())\n Decomposes a projection matrix into a rotation matrix and a camera intrinsic matrix.  \n \nvoid cv::drawChessboardCorners (InputOutputArray image, Size patternSize, InputArray corners, bool patternWasFound)\n Renders the detected chessboard corners.  \n \nvoid cv::drawFrameAxes (InputOutputArray image, InputArray cameraMatrix, InputArray distCoeffs, InputArray rvec, InputArray tvec, float length, int thickness=3)\n Draw axes of the world/object coordinate system from pose estimation.  \n \ncv::Mat cv::estimateAffine2D (InputArray from, InputArray to, OutputArray inliers=noArray(), int method=RANSAC, double ransacReprojThreshold=3, size_t maxIters=2000, double confidence=0.99, size_t refineIters=10)\n Computes an optimal affine transformation between two 2D point sets.  \n \ncv::Mat cv::estimateAffine2D (InputArray pts1, InputArray pts2, OutputArray inliers, const UsacParams &params)\n \ncv::Mat cv::estimateAffine3D (InputArray src, InputArray dst, double *scale=nullptr, bool force_rotation=true)\n Computes an optimal affine transformation between two 3D point sets.  \n \nint cv::estimateAffine3D (InputArray src, InputArray dst, OutputArray out, OutputArray inliers, double ransacThreshold=3, double confidence=0.99)\n Computes an optimal affine transformation between two 3D point sets.  \n \ncv::Mat cv::estimateAffinePartial2D (InputArray from, InputArray to, OutputArray inliers=noArray(), int method=RANSAC, double ransacReprojThreshold=3, size_t maxIters=2000, double confidence=0.99, size_t refineIters=10)\n Computes an optimal limited affine transformation with 4 degrees of freedom between two 2D point sets.  \n \nScalar cv::estimateChessboardSharpness (InputArray image, Size patternSize, InputArray corners, float rise_distance=0.8F, bool vertical=false, OutputArray sharpness=noArray())\n Estimates the sharpness of a detected chessboard.  \n \nint cv::estimateTranslation3D (InputArray src, InputArray dst, OutputArray out, OutputArray inliers, double ransacThreshold=3, double confidence=0.99)\n Computes an optimal translation between two 3D point sets.  \n \nvoid cv::filterHomographyDecompByVisibleRefpoints (InputArrayOfArrays rotations, InputArrayOfArrays normals, InputArray beforePoints, InputArray afterPoints, OutputArray possibleSolutions, InputArray pointsMask=noArray())\n Filters homography decompositions based on additional information.  \n \nvoid cv::filterSpeckles (InputOutputArray img, double newVal, int maxSpeckleSize, double maxDiff, InputOutputArray buf=noArray())\n Filters off small noise blobs (speckles) in the disparity map.  \n \nbool cv::find4QuadCornerSubpix (InputArray img, InputOutputArray corners, Size region_size)\n finds subpixel-accurate positions of the chessboard corners  \n \nbool cv::findChessboardCorners (InputArray image, Size patternSize, OutputArray corners, int flags=CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE)\n Finds the positions of internal corners of the chessboard.  \n \nbool cv::findChessboardCornersSB (InputArray image, Size patternSize, OutputArray corners, int flags, OutputArray meta)\n Finds the positions of internal corners of the chessboard using a sector based approach.  \n \nbool cv::findChessboardCornersSB (InputArray image, Size patternSize, OutputArray corners, int flags=0)\n \nbool cv::findCirclesGrid (InputArray image, Size patternSize, OutputArray centers, int flags, const Ptr< FeatureDetector > &blobDetector, const CirclesGridFinderParameters &parameters)\n Finds centers in the grid of circles.  \n \nbool cv::findCirclesGrid (InputArray image, Size patternSize, OutputArray centers, int flags=CALIB_CB_SYMMETRIC_GRID, const Ptr< FeatureDetector > &blobDetector=SimpleBlobDetector::create())\n \nMat cv::findEssentialMat (InputArray points1, InputArray points2, double focal, Point2d pp, int method, double prob, double threshold, OutputArray mask)\n \nMat cv::findEssentialMat (InputArray points1, InputArray points2, double focal=1.0, Point2d pp=Point2d(0, 0), int method=RANSAC, double prob=0.999, double threshold=1.0, int maxIters=1000, OutputArray mask=noArray())\n \nMat cv::findEssentialMat (InputArray points1, InputArray points2, InputArray cameraMatrix, int method, double prob, double threshold, OutputArray mask)\n \nMat cv::findEssentialMat (InputArray points1, InputArray points2, InputArray cameraMatrix, int method=RANSAC, double prob=0.999, double threshold=1.0, int maxIters=1000, OutputArray mask=noArray())\n Calculates an essential matrix from the corresponding points in two images.  \n \nMat cv::findEssentialMat (InputArray points1, InputArray points2, InputArray cameraMatrix1, InputArray cameraMatrix2, InputArray dist_coeff1, InputArray dist_coeff2, OutputArray mask, const UsacParams &params)\n \nMat cv::findEssentialMat (InputArray points1, InputArray points2, InputArray cameraMatrix1, InputArray distCoeffs1, InputArray cameraMatrix2, InputArray distCoeffs2, int method=RANSAC, double prob=0.999, double threshold=1.0, OutputArray mask=noArray())\n Calculates an essential matrix from the corresponding points in two images from potentially two different cameras.  \n \nMat cv::findFundamentalMat (InputArray points1, InputArray points2, int method, double ransacReprojThreshold, double confidence, int maxIters, OutputArray mask=noArray())\n Calculates a fundamental matrix from the corresponding points in two images.  \n \nMat cv::findFundamentalMat (InputArray points1, InputArray points2, int method=FM_RANSAC, double ransacReprojThreshold=3., double confidence=0.99, OutputArray mask=noArray())\n \nMat cv::findFundamentalMat (InputArray points1, InputArray points2, OutputArray mask, const UsacParams &params)\n \nMat cv::findFundamentalMat (InputArray points1, InputArray points2, OutputArray mask, int method=FM_RANSAC, double ransacReprojThreshold=3., double confidence=0.99)\n \nMat cv::findHomography (InputArray srcPoints, InputArray dstPoints, int method=0, double ransacReprojThreshold=3, OutputArray mask=noArray(), const int maxIters=2000, const double confidence=0.995)\n Finds a perspective transformation between two planes.  \n \nMat cv::findHomography (InputArray srcPoints, InputArray dstPoints, OutputArray mask, const UsacParams &params)\n \nMat cv::findHomography (InputArray srcPoints, InputArray dstPoints, OutputArray mask, int method=0, double ransacReprojThreshold=3)\n \nMat cv::getDefaultNewCameraMatrix (InputArray cameraMatrix, Size imgsize=Size(), bool centerPrincipalPoint=false)\n Returns the default new camera matrix.  \n \nMat cv::getOptimalNewCameraMatrix (InputArray cameraMatrix, InputArray distCoeffs, Size imageSize, double alpha, Size newImgSize=Size(), Rect *validPixROI=0, bool centerPrincipalPoint=false)\n Returns the new camera intrinsic matrix based on the free scaling parameter.  \n \nRect cv::getValidDisparityROI (Rect roi1, Rect roi2, int minDisparity, int numberOfDisparities, int blockSize)\n computes valid disparity ROI from the valid ROIs of the rectified images (that are returned by stereoRectify)  \n \nMat cv::initCameraMatrix2D (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, double aspectRatio=1.0)\n Finds an initial camera intrinsic matrix from 3D-2D point correspondences.  \n \nvoid cv::initInverseRectificationMap (InputArray cameraMatrix, InputArray distCoeffs, InputArray R, InputArray newCameraMatrix, const Size &size, int m1type, OutputArray map1, OutputArray map2)\n Computes the projection and inverse-rectification transformation map. In essense, this is the inverse of initUndistortRectifyMap to accomodate stereo-rectification of projectors ('inverse-cameras') in projector-camera pairs.  \n \nvoid cv::initUndistortRectifyMap (InputArray cameraMatrix, InputArray distCoeffs, InputArray R, InputArray newCameraMatrix, Size size, int m1type, OutputArray map1, OutputArray map2)\n Computes the undistortion and rectification transformation map.  \n \nfloat cv::initWideAngleProjMap (InputArray cameraMatrix, InputArray distCoeffs, Size imageSize, int destImageWidth, int m1type, OutputArray map1, OutputArray map2, enum UndistortTypes projType=PROJ_SPHERICAL_EQRECT, double alpha=0)\n initializes maps for remap for wide-angle  \n \nstatic float cv::initWideAngleProjMap (InputArray cameraMatrix, InputArray distCoeffs, Size imageSize, int destImageWidth, int m1type, OutputArray map1, OutputArray map2, int projType, double alpha=0)\n \nvoid cv::matMulDeriv (InputArray A, InputArray B, OutputArray dABdA, OutputArray dABdB)\n Computes partial derivatives of the matrix product for each multiplied matrix.  \n \nvoid cv::projectPoints (InputArray objectPoints, InputArray rvec, InputArray tvec, InputArray cameraMatrix, InputArray distCoeffs, OutputArray imagePoints, OutputArray jacobian=noArray(), double aspectRatio=0)\n Projects 3D points to an image plane.  \n \nint cv::recoverPose (InputArray E, InputArray points1, InputArray points2, InputArray cameraMatrix, OutputArray R, OutputArray t, double distanceThresh, InputOutputArray mask=noArray(), OutputArray triangulatedPoints=noArray())\n \nint cv::recoverPose (InputArray E, InputArray points1, InputArray points2, InputArray cameraMatrix, OutputArray R, OutputArray t, InputOutputArray mask=noArray())\n Recovers the relative camera rotation and the translation from an estimated essential matrix and the corresponding points in two images, using chirality check. Returns the number of inliers that pass the check.  \n \nint cv::recoverPose (InputArray E, InputArray points1, InputArray points2, OutputArray R, OutputArray t, double focal=1.0, Point2d pp=Point2d(0, 0), InputOutputArray mask=noArray())\n \nint cv::recoverPose (InputArray points1, InputArray points2, InputArray cameraMatrix1, InputArray distCoeffs1, InputArray cameraMatrix2, InputArray distCoeffs2, OutputArray E, OutputArray R, OutputArray t, int method=cv::RANSAC, double prob=0.999, double threshold=1.0, InputOutputArray mask=noArray())\n Recovers the relative camera rotation and the translation from corresponding points in two images from two different cameras, using cheirality check. Returns the number of inliers that pass the check.  \n \nfloat cv::rectify3Collinear (InputArray cameraMatrix1, InputArray distCoeffs1, InputArray cameraMatrix2, InputArray distCoeffs2, InputArray cameraMatrix3, InputArray distCoeffs3, InputArrayOfArrays imgpt1, InputArrayOfArrays imgpt3, Size imageSize, InputArray R12, InputArray T12, InputArray R13, InputArray T13, OutputArray R1, OutputArray R2, OutputArray R3, OutputArray P1, OutputArray P2, OutputArray P3, OutputArray Q, double alpha, Size newImgSize, Rect *roi1, Rect *roi2, int flags)\n computes the rectification transformations for 3-head camera, where all the heads are on the same line.  \n \nvoid cv::reprojectImageTo3D (InputArray disparity, OutputArray _3dImage, InputArray Q, bool handleMissingValues=false, int ddepth=-1)\n Reprojects a disparity image to 3D space.  \n \nvoid cv::Rodrigues (InputArray src, OutputArray dst, OutputArray jacobian=noArray())\n Converts a rotation matrix to a rotation vector or vice versa.  \n \nVec3d cv::RQDecomp3x3 (InputArray src, OutputArray mtxR, OutputArray mtxQ, OutputArray Qx=noArray(), OutputArray Qy=noArray(), OutputArray Qz=noArray())\n Computes an RQ decomposition of 3x3 matrices.  \n \ndouble cv::sampsonDistance (InputArray pt1, InputArray pt2, InputArray F)\n Calculates the Sampson Distance between two points.  \n \nint cv::solveP3P (InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, int flags)\n Finds an object pose from 3 3D-2D point correspondences.  \n \nbool cv::solvePnP (InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec, bool useExtrinsicGuess=false, int flags=SOLVEPNP_ITERATIVE)\n Finds an object pose from 3D-2D point correspondences.  \n \nint cv::solvePnPGeneric (InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, bool useExtrinsicGuess=false, SolvePnPMethod flags=SOLVEPNP_ITERATIVE, InputArray rvec=noArray(), InputArray tvec=noArray(), OutputArray reprojectionError=noArray())\n Finds an object pose from 3D-2D point correspondences.  \n \nbool cv::solvePnPRansac (InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec, bool useExtrinsicGuess=false, int iterationsCount=100, float reprojectionError=8.0, double confidence=0.99, OutputArray inliers=noArray(), int flags=SOLVEPNP_ITERATIVE)\n Finds an object pose from 3D-2D point correspondences using the RANSAC scheme.  \n \nbool cv::solvePnPRansac (InputArray objectPoints, InputArray imagePoints, InputOutputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec, OutputArray inliers, const UsacParams &params=UsacParams())\n \nvoid cv::solvePnPRefineLM (InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, InputOutputArray rvec, InputOutputArray tvec, TermCriteria criteria=TermCriteria(TermCriteria::EPS+TermCriteria::COUNT, 20, FLT_EPSILON))\n Refine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution.  \n \nvoid cv::solvePnPRefineVVS (InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, InputOutputArray rvec, InputOutputArray tvec, TermCriteria criteria=TermCriteria(TermCriteria::EPS+TermCriteria::COUNT, 20, FLT_EPSILON), double VVSlambda=1)\n Refine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution.  \n \ndouble cv::stereoCalibrate (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints1, InputArrayOfArrays imagePoints2, InputOutputArray cameraMatrix1, InputOutputArray distCoeffs1, InputOutputArray cameraMatrix2, InputOutputArray distCoeffs2, Size imageSize, InputOutputArray R, InputOutputArray T, OutputArray E, OutputArray F, OutputArray perViewErrors, int flags=CALIB_FIX_INTRINSIC, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6))\n This is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts.  \n \ndouble cv::stereoCalibrate (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints1, InputArrayOfArrays imagePoints2, InputOutputArray cameraMatrix1, InputOutputArray distCoeffs1, InputOutputArray cameraMatrix2, InputOutputArray distCoeffs2, Size imageSize, InputOutputArray R, InputOutputArray T, OutputArray E, OutputArray F, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, OutputArray perViewErrors, int flags=CALIB_FIX_INTRINSIC, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6))\n Calibrates a stereo camera set up. This function finds the intrinsic parameters for each of the two cameras and the extrinsic parameters between the two cameras.  \n \ndouble cv::stereoCalibrate (InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints1, InputArrayOfArrays imagePoints2, InputOutputArray cameraMatrix1, InputOutputArray distCoeffs1, InputOutputArray cameraMatrix2, InputOutputArray distCoeffs2, Size imageSize, OutputArray R, OutputArray T, OutputArray E, OutputArray F, int flags=CALIB_FIX_INTRINSIC, TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6))\n This is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts.  \n \nvoid cv::stereoRectify (InputArray cameraMatrix1, InputArray distCoeffs1, InputArray cameraMatrix2, InputArray distCoeffs2, Size imageSize, InputArray R, InputArray T, OutputArray R1, OutputArray R2, OutputArray P1, OutputArray P2, OutputArray Q, int flags=CALIB_ZERO_DISPARITY, double alpha=-1, Size newImageSize=Size(), Rect *validPixROI1=0, Rect *validPixROI2=0)\n Computes rectification transforms for each head of a calibrated stereo camera.  \n \nbool cv::stereoRectifyUncalibrated (InputArray points1, InputArray points2, InputArray F, Size imgSize, OutputArray H1, OutputArray H2, double threshold=5)\n Computes a rectification transform for an uncalibrated stereo camera.  \n \nvoid cv::triangulatePoints (InputArray projMatr1, InputArray projMatr2, InputArray projPoints1, InputArray projPoints2, OutputArray points4D)\n This function reconstructs 3-dimensional points (in homogeneous coordinates) by using their observations with a stereo camera.  \n \nvoid cv::undistort (InputArray src, OutputArray dst, InputArray cameraMatrix, InputArray distCoeffs, InputArray newCameraMatrix=noArray())\n Transforms an image to compensate for lens distortion.  \n \nvoid cv::undistortImagePoints (InputArray src, OutputArray dst, InputArray cameraMatrix, InputArray distCoeffs, TermCriteria=TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 0.01))\n Compute undistorted image points position.  \n \nvoid cv::undistortPoints (InputArray src, OutputArray dst, InputArray cameraMatrix, InputArray distCoeffs, InputArray R, InputArray P, TermCriteria criteria)\n \nvoid cv::undistortPoints (InputArray src, OutputArray dst, InputArray cameraMatrix, InputArray distCoeffs, InputArray R=noArray(), InputArray P=noArray())\n Computes the ideal point coordinates from the observed point coordinates.  \n \nvoid cv::validateDisparity (InputOutputArray disparity, InputArray cost, int minDisparity, int numberOfDisparities, int disp12MaxDisp=1)\n validates disparity using the left-right check. The matrix \"cost\" should be computed by the stereo correspondence algorithm  \n \n\nTypedef Documentation\n\n◆ CirclesGridFinderParameters2\n\ntypedef CirclesGridFinderParameters cv::CirclesGridFinderParameters2\n\n#include <opencv2/calib3d.hpp>\n\nEnumeration Type Documentation\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/calib3d.hpp>\ntype of the robust estimation algorithm \n\nEnumeratorLMEDS Python: cv.LMEDSleast-median of squares algorithm \n\nRANSAC Python: cv.RANSACRANSAC algorithm. \n\nRHO Python: cv.RHORHO algorithm. \n\nUSAC_DEFAULT Python: cv.USAC_DEFAULTUSAC algorithm, default settings. \n\nUSAC_PARALLEL Python: cv.USAC_PARALLELUSAC, parallel version. \n\nUSAC_FM_8PTS Python: cv.USAC_FM_8PTSUSAC, fundamental matrix 8 points. \n\nUSAC_FAST Python: cv.USAC_FASTUSAC, fast settings. \n\nUSAC_ACCURATE Python: cv.USAC_ACCURATEUSAC, accurate settings. \n\nUSAC_PROSAC Python: cv.USAC_PROSACUSAC, sorted points, runs PROSAC. \n\nUSAC_MAGSAC Python: cv.USAC_MAGSACUSAC, runs MAGSAC++. \n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorCALIB_CB_ADAPTIVE_THRESH Python: cv.CALIB_CB_ADAPTIVE_THRESH\nCALIB_CB_NORMALIZE_IMAGE Python: cv.CALIB_CB_NORMALIZE_IMAGE\nCALIB_CB_FILTER_QUADS Python: cv.CALIB_CB_FILTER_QUADS\nCALIB_CB_FAST_CHECK Python: cv.CALIB_CB_FAST_CHECK\nCALIB_CB_EXHAUSTIVE Python: cv.CALIB_CB_EXHAUSTIVE\nCALIB_CB_ACCURACY Python: cv.CALIB_CB_ACCURACY\nCALIB_CB_LARGER Python: cv.CALIB_CB_LARGER\nCALIB_CB_MARKER Python: cv.CALIB_CB_MARKER\nCALIB_CB_PLAIN Python: cv.CALIB_CB_PLAIN\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorCALIB_CB_SYMMETRIC_GRID Python: cv.CALIB_CB_SYMMETRIC_GRID\nCALIB_CB_ASYMMETRIC_GRID Python: cv.CALIB_CB_ASYMMETRIC_GRID\nCALIB_CB_CLUSTERING Python: cv.CALIB_CB_CLUSTERING\n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorCALIB_NINTRINSIC Python: cv.CALIB_NINTRINSIC\nCALIB_USE_INTRINSIC_GUESS Python: cv.CALIB_USE_INTRINSIC_GUESS\nCALIB_FIX_ASPECT_RATIO Python: cv.CALIB_FIX_ASPECT_RATIO\nCALIB_FIX_PRINCIPAL_POINT Python: cv.CALIB_FIX_PRINCIPAL_POINT\nCALIB_ZERO_TANGENT_DIST Python: cv.CALIB_ZERO_TANGENT_DIST\nCALIB_FIX_FOCAL_LENGTH Python: cv.CALIB_FIX_FOCAL_LENGTH\nCALIB_FIX_K1 Python: cv.CALIB_FIX_K1\nCALIB_FIX_K2 Python: cv.CALIB_FIX_K2\nCALIB_FIX_K3 Python: cv.CALIB_FIX_K3\nCALIB_FIX_K4 Python: cv.CALIB_FIX_K4\nCALIB_FIX_K5 Python: cv.CALIB_FIX_K5\nCALIB_FIX_K6 Python: cv.CALIB_FIX_K6\nCALIB_RATIONAL_MODEL Python: cv.CALIB_RATIONAL_MODEL\nCALIB_THIN_PRISM_MODEL Python: cv.CALIB_THIN_PRISM_MODEL\nCALIB_FIX_S1_S2_S3_S4 Python: cv.CALIB_FIX_S1_S2_S3_S4\nCALIB_TILTED_MODEL Python: cv.CALIB_TILTED_MODEL\nCALIB_FIX_TAUX_TAUY Python: cv.CALIB_FIX_TAUX_TAUY\nCALIB_USE_QR Python: cv.CALIB_USE_QRuse QR instead of SVD decomposition for solving. Faster but potentially less precise \n\nCALIB_FIX_TANGENT_DIST Python: cv.CALIB_FIX_TANGENT_DIST\nCALIB_FIX_INTRINSIC Python: cv.CALIB_FIX_INTRINSIC\nCALIB_SAME_FOCAL_LENGTH Python: cv.CALIB_SAME_FOCAL_LENGTH\nCALIB_ZERO_DISPARITY Python: cv.CALIB_ZERO_DISPARITY\nCALIB_USE_LU Python: cv.CALIB_USE_LUuse LU instead of SVD decomposition for solving. much faster but potentially less precise \n\nCALIB_USE_EXTRINSIC_GUESS Python: cv.CALIB_USE_EXTRINSIC_GUESSfor stereoCalibrate \n\n◆ anonymous enum\n\nanonymous enum\n\n#include <opencv2/calib3d.hpp>\nthe algorithm for finding fundamental matrix \n\nEnumeratorFM_7POINT Python: cv.FM_7POINT7-point algorithm \n\nFM_8POINT Python: cv.FM_8POINT8-point algorithm \n\nFM_LMEDS Python: cv.FM_LMEDSleast-median algorithm. 7-point algorithm is used. \n\nFM_RANSAC Python: cv.FM_RANSACRANSAC algorithm. It needs at least 15 points. 7-point algorithm is used. \n\n◆ HandEyeCalibrationMethod\n\nenum cv::HandEyeCalibrationMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorCALIB_HAND_EYE_TSAI Python: cv.CALIB_HAND_EYE_TSAIA New Technique for Fully Autonomous and Efficient 3D Robotics Hand/Eye Calibration [274]. \n\nCALIB_HAND_EYE_PARK Python: cv.CALIB_HAND_EYE_PARKRobot Sensor Calibration: Solving AX = XB on the Euclidean Group [213]. \n\nCALIB_HAND_EYE_HORAUD Python: cv.CALIB_HAND_EYE_HORAUDHand-eye Calibration [127]. \n\nCALIB_HAND_EYE_ANDREFF Python: cv.CALIB_HAND_EYE_ANDREFFOn-line Hand-Eye Calibration [12]. \n\nCALIB_HAND_EYE_DANIILIDIS Python: cv.CALIB_HAND_EYE_DANIILIDISHand-Eye Calibration Using Dual Quaternions [65]. \n\n◆ LocalOptimMethod\n\nenum cv::LocalOptimMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorLOCAL_OPTIM_NULL Python: cv.LOCAL_OPTIM_NULL\nLOCAL_OPTIM_INNER_LO Python: cv.LOCAL_OPTIM_INNER_LO\nLOCAL_OPTIM_INNER_AND_ITER_LO Python: cv.LOCAL_OPTIM_INNER_AND_ITER_LO\nLOCAL_OPTIM_GC Python: cv.LOCAL_OPTIM_GC\nLOCAL_OPTIM_SIGMA Python: cv.LOCAL_OPTIM_SIGMA\n\n◆ NeighborSearchMethod\n\nenum cv::NeighborSearchMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorNEIGH_FLANN_KNN Python: cv.NEIGH_FLANN_KNN\nNEIGH_GRID Python: cv.NEIGH_GRID\nNEIGH_FLANN_RADIUS Python: cv.NEIGH_FLANN_RADIUS\n\n◆ PolishingMethod\n\nenum cv::PolishingMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorNONE_POLISHER Python: cv.NONE_POLISHER\nLSQ_POLISHER Python: cv.LSQ_POLISHER\nMAGSAC Python: cv.MAGSAC\nCOV_POLISHER Python: cv.COV_POLISHER\n\n◆ RobotWorldHandEyeCalibrationMethod\n\nenum cv::RobotWorldHandEyeCalibrationMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorCALIB_ROBOT_WORLD_HAND_EYE_SHAH Python: cv.CALIB_ROBOT_WORLD_HAND_EYE_SHAHSolving the robot-world/hand-eye calibration problem using the kronecker product [244]. \n\nCALIB_ROBOT_WORLD_HAND_EYE_LI Python: cv.CALIB_ROBOT_WORLD_HAND_EYE_LISimultaneous robot-world and hand-eye calibration using dual-quaternions and kronecker product [163]. \n\n◆ SamplingMethod\n\nenum cv::SamplingMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorSAMPLING_UNIFORM Python: cv.SAMPLING_UNIFORM\nSAMPLING_PROGRESSIVE_NAPSAC Python: cv.SAMPLING_PROGRESSIVE_NAPSAC\nSAMPLING_NAPSAC Python: cv.SAMPLING_NAPSAC\nSAMPLING_PROSAC Python: cv.SAMPLING_PROSAC\n\n◆ ScoreMethod\n\nenum cv::ScoreMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorSCORE_METHOD_RANSAC Python: cv.SCORE_METHOD_RANSAC\nSCORE_METHOD_MSAC Python: cv.SCORE_METHOD_MSAC\nSCORE_METHOD_MAGSAC Python: cv.SCORE_METHOD_MAGSAC\nSCORE_METHOD_LMEDS Python: cv.SCORE_METHOD_LMEDS\n\n◆ SolvePnPMethod\n\nenum cv::SolvePnPMethod\n\n#include <opencv2/calib3d.hpp>\n\nEnumeratorSOLVEPNP_ITERATIVE Python: cv.SOLVEPNP_ITERATIVEPose refinement using non-linear Levenberg-Marquardt minimization scheme [179] [77] \n Initial solution for non-planar \"objectPoints\" needs at least 6 points and uses the DLT algorithm. \n Initial solution for planar \"objectPoints\" needs at least 4 points and uses pose from homography decomposition. \n\nSOLVEPNP_EPNP Python: cv.SOLVEPNP_EPNPEPnP: Efficient Perspective-n-Point Camera Pose Estimation [158]. \n\nSOLVEPNP_P3P Python: cv.SOLVEPNP_P3PComplete Solution Classification for the Perspective-Three-Point Problem [98]. \n\nSOLVEPNP_DLS Python: cv.SOLVEPNP_DLSBroken implementation. Using this flag will fallback to EPnP. \n A Direct Least-Squares (DLS) Method for PnP [125] \n\nSOLVEPNP_UPNP Python: cv.SOLVEPNP_UPNPBroken implementation. Using this flag will fallback to EPnP. \n Exhaustive Linearization for Robust Camera Pose and Focal Length Estimation [214] \n\nSOLVEPNP_AP3P Python: cv.SOLVEPNP_AP3PAn Efficient Algebraic Solution to the Perspective-Three-Point Problem [145]. \n\nSOLVEPNP_IPPE Python: cv.SOLVEPNP_IPPEInfinitesimal Plane-Based Pose Estimation [61] \n Object points must be coplanar. \n\nSOLVEPNP_IPPE_SQUARE Python: cv.SOLVEPNP_IPPE_SQUAREInfinitesimal Plane-Based Pose Estimation [61] \n This is a special case suitable for marker pose estimation.\n 4 coplanar object points must be defined in the following order:\npoint 0: [-squareLength / 2, squareLength / 2, 0]\npoint 1: [ squareLength / 2, squareLength / 2, 0]\npoint 2: [ squareLength / 2, -squareLength / 2, 0]\npoint 3: [-squareLength / 2, -squareLength / 2, 0] \n\nSOLVEPNP_SQPNP Python: cv.SOLVEPNP_SQPNPSQPnP: A Consistently Fast and Globally OptimalSolution to the Perspective-n-Point Problem [268]. \n\n◆ UndistortTypes\n\nenum cv::UndistortTypes\n\n#include <opencv2/calib3d.hpp>\ncv::undistort mode \n\nEnumeratorPROJ_SPHERICAL_ORTHO Python: cv.PROJ_SPHERICAL_ORTHO\nPROJ_SPHERICAL_EQRECT Python: cv.PROJ_SPHERICAL_EQRECT\n\nFunction Documentation\n\n◆ calibrateCamera() [1/2]\n\ndouble cv::calibrateCamera \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints, \n\nSize \nimageSize, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nint \nflags = 0, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecscv.calibrateCameraExtended(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ calibrateCamera() [2/2]\n\ndouble cv::calibrateCamera \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints, \n\nSize \nimageSize, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nOutputArray \nstdDeviationsIntrinsics, \n\nOutputArray \nstdDeviationsExtrinsics, \n\nOutputArray \nperViewErrors, \n\nint \nflags = 0, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecscv.calibrateCameraExtended(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nFinds the camera intrinsic and extrinsic parameters from several views of a calibration pattern. \nParameters\n\nobjectPointsIn the new interface it is a vector of vectors of calibration pattern points in the calibration pattern coordinate space (e.g. std::vector<std::vector<cv::Vec3f>>). The outer vector contains as many elements as the number of pattern views. If the same calibration pattern is shown in each view and it is fully visible, all the vectors will be the same. Although, it is possible to use partially occluded patterns or even different patterns in different views. Then, the vectors will be different. Although the points are 3D, they all lie in the calibration pattern's XY coordinate plane (thus 0 in the Z-coordinate), if the used calibration pattern is a planar rig. In the old interface all the vectors of object points from different views are concatenated together. \nimagePointsIn the new interface it is a vector of vectors of the projections of calibration pattern points (e.g. std::vector<std::vector<cv::Vec2f>>). imagePoints.size() and objectPoints.size(), and imagePoints[i].size() and objectPoints[i].size() for each i, must be equal, respectively. In the old interface all the vectors of object points from different views are concatenated together. \nimageSizeSize of the image used only to initialize the camera intrinsic matrix. \ncameraMatrixInput/output 3x3 floating-point camera intrinsic matrix \\(\\cameramatrix{A}\\) . If CALIB_USE_INTRINSIC_GUESS and/or CALIB_FIX_ASPECT_RATIO, CALIB_FIX_PRINCIPAL_POINT or CALIB_FIX_FOCAL_LENGTH are specified, some or all of fx, fy, cx, cy must be initialized before calling the function. \ndistCoeffsInput/output vector of distortion coefficients \\(\\distcoeffs\\). \nrvecsOutput vector of rotation vectors (Rodrigues ) estimated for each pattern view (e.g. std::vector<cv::Mat>>). That is, each i-th rotation vector together with the corresponding i-th translation vector (see the next output parameter description) brings the calibration pattern from the object coordinate space (in which object points are specified) to the camera coordinate space. In more technical terms, the tuple of the i-th rotation and translation vector performs a change of basis from object coordinate space to camera coordinate space. Due to its duality, this tuple is equivalent to the position of the calibration pattern with respect to the camera coordinate space. \ntvecsOutput vector of translation vectors estimated for each pattern view, see parameter describtion above. \nstdDeviationsIntrinsicsOutput vector of standard deviations estimated for intrinsic parameters. Order of deviations values:  \\((f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\n s_4, \\tau_x, \\tau_y)\\) If one of parameters is not estimated, it's deviation is equals to zero. \nstdDeviationsExtrinsicsOutput vector of standard deviations estimated for extrinsic parameters. Order of deviations values: \\((R_0, T_0, \\dotsc , R_{M - 1}, T_{M - 1})\\) where M is the number of pattern views. \\(R_i, T_i\\) are concatenated 1x3 vectors. \nperViewErrorsOutput vector of the RMS re-projection error estimated for each pattern view. \nflagsDifferent flags that may be zero or a combination of the following values:\nCALIB_USE_INTRINSIC_GUESS cameraMatrix contains valid initial values of fx, fy, cx, cy that are optimized further. Otherwise, (cx, cy) is initially set to the image center ( imageSize is used), and focal distances are computed in a least-squares fashion. Note, that if intrinsic parameters are known, there is no need to use this function just to estimate extrinsic parameters. Use solvePnP instead.\nCALIB_FIX_PRINCIPAL_POINT The principal point is not changed during the global optimization. It stays at the center or at a different location specified when CALIB_USE_INTRINSIC_GUESS is set too.\nCALIB_FIX_ASPECT_RATIO The functions consider only fy as a free parameter. The ratio fx/fy stays the same as in the input cameraMatrix . When CALIB_USE_INTRINSIC_GUESS is not set, the actual input values of fx and fy are ignored, only their ratio is computed and used further.\nCALIB_ZERO_TANGENT_DIST Tangential distortion coefficients \\((p_1, p_2)\\) are set to zeros and stay zero.\nCALIB_FIX_FOCAL_LENGTH The focal length is not changed during the global optimization if CALIB_USE_INTRINSIC_GUESS is set.\nCALIB_FIX_K1,..., CALIB_FIX_K6 The corresponding radial distortion coefficient is not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\nCALIB_RATIONAL_MODEL Coefficients k4, k5, and k6 are enabled. To provide the backward compatibility, this extra flag should be explicitly specified to make the calibration function use the rational model and return 8 coefficients or more.\nCALIB_THIN_PRISM_MODEL Coefficients s1, s2, s3 and s4 are enabled. To provide the backward compatibility, this extra flag should be explicitly specified to make the calibration function use the thin prism model and return 12 coefficients or more.\nCALIB_FIX_S1_S2_S3_S4 The thin prism distortion coefficients are not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\nCALIB_TILTED_MODEL Coefficients tauX and tauY are enabled. To provide the backward compatibility, this extra flag should be explicitly specified to make the calibration function use the tilted sensor model and return 14 coefficients.\nCALIB_FIX_TAUX_TAUY The coefficients of the tilted sensor model are not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0. \n\ncriteriaTermination criteria for the iterative optimization algorithm.\n\nReturnsthe overall RMS re-projection error.\nThe function estimates the intrinsic camera parameters and extrinsic parameters for each of the views. The algorithm is based on [319] and [37] . The coordinates of 3D object points and their corresponding 2D projections in each view must be specified. That may be achieved by using an object with known geometry and easily detectable feature points. Such an object is called a calibration rig or calibration pattern, and OpenCV has built-in support for a chessboard as a calibration rig (see findChessboardCorners). Currently, initialization of intrinsic parameters (when CALIB_USE_INTRINSIC_GUESS is not set) is only implemented for planar calibration patterns (where Z-coordinates of the object points must be all zeros). 3D calibration rigs can also be used as long as initial cameraMatrix is provided.\nThe algorithm performs the following steps:\n\nCompute the initial intrinsic parameters (the option only available for planar calibration patterns) or read them from the input parameters. The distortion coefficients are all set to zeros initially unless some of CALIB_FIX_K? are specified.\nEstimate the initial camera pose as if the intrinsic parameters have been already known. This is done using solvePnP .\nRun the global Levenberg-Marquardt optimization algorithm to minimize the reprojection error, that is, the total sum of squared distances between the observed feature points imagePoints and the projected (using the current estimates for camera parameters and the poses) object points objectPoints. See projectPoints for details.\n\nNoteIf you use a non-square (i.e. non-N-by-N) grid and findChessboardCorners for calibration, and calibrateCamera returns bad values (zero distortion coefficients, \\(c_x\\) and \\(c_y\\) very far from the image center, and/or large differences between \\(f_x\\) and \\(f_y\\) (ratios of 10:1 or more)), then you are probably using patternSize=cvSize(rows,cols) instead of using patternSize=cvSize(cols,rows) in findChessboardCorners.\n\nThe function may throw exceptions, if unsupported combination of parameters is provided or the system is underconstrained.\nSee alsocalibrateCameraRO, findChessboardCorners, solvePnP, initCameraMatrix2D, stereoCalibrate, undistort \n\n◆ calibrateCameraRO() [1/2]\n\ndouble cv::calibrateCameraRO \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints, \n\nSize \nimageSize, \n\nint \niFixedPoint, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nOutputArray \nnewObjPoints, \n\nint \nflags = 0, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, flags[, criteria]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPointscv.calibrateCameraROExtended(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, stdDeviationsObjPoints[, perViewErrors[, flags[, criteria]]]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, stdDeviationsIntrinsics, stdDeviationsExtrinsics, stdDeviationsObjPoints, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ calibrateCameraRO() [2/2]\n\ndouble cv::calibrateCameraRO \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints, \n\nSize \nimageSize, \n\nint \niFixedPoint, \n\nInputOutputArray \ncameraMatrix, \n\nInputOutputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nOutputArray \nnewObjPoints, \n\nOutputArray \nstdDeviationsIntrinsics, \n\nOutputArray \nstdDeviationsExtrinsics, \n\nOutputArray \nstdDeviationsObjPoints, \n\nOutputArray \nperViewErrors, \n\nint \nflags = 0, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) \n\n)\n\nPython:cv.calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, flags[, criteria]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPointscv.calibrateCameraROExtended(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, stdDeviationsObjPoints[, perViewErrors[, flags[, criteria]]]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, stdDeviationsIntrinsics, stdDeviationsExtrinsics, stdDeviationsObjPoints, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nFinds the camera intrinsic and extrinsic parameters from several views of a calibration pattern. \nThis function is an extension of calibrateCamera with the method of releasing object which was proposed in [255]. In many common cases with inaccurate, unmeasured, roughly planar targets (calibration plates), this method can dramatically improve the precision of the estimated camera parameters. Both the object-releasing method and standard method are supported by this function. Use the parameter iFixedPoint for method selection. In the internal implementation, calibrateCamera is a wrapper for this function.\nParameters\n\nobjectPointsVector of vectors of calibration pattern points in the calibration pattern coordinate space. See calibrateCamera for details. If the method of releasing object to be used, the identical calibration board must be used in each view and it must be fully visible, and all objectPoints[i] must be the same and all points should be roughly close to a plane. The calibration target has to be rigid, or at least static if the camera (rather than the calibration target) is shifted for grabbing images. \nimagePointsVector of vectors of the projections of calibration pattern points. See calibrateCamera for details. \nimageSizeSize of the image used only to initialize the intrinsic camera matrix. \niFixedPointThe index of the 3D object point in objectPoints[0] to be fixed. It also acts as a switch for calibration method selection. If object-releasing method to be used, pass in the parameter in the range of [1, objectPoints[0].size()-2], otherwise a value out of this range will make standard calibration method selected. Usually the top-right corner point of the calibration board grid is recommended to be fixed when object-releasing method being utilized. According to [255], two other points are also fixed. In this implementation, objectPoints[0].front and objectPoints[0].back.z are used. With object-releasing method, accurate rvecs, tvecs and newObjPoints are only possible if coordinates of these three fixed points are accurate enough. \ncameraMatrixOutput 3x3 floating-point camera matrix. See calibrateCamera for details. \ndistCoeffsOutput vector of distortion coefficients. See calibrateCamera for details. \nrvecsOutput vector of rotation vectors estimated for each pattern view. See calibrateCamera for details. \ntvecsOutput vector of translation vectors estimated for each pattern view. \nnewObjPointsThe updated output vector of calibration pattern points. The coordinates might be scaled based on three fixed points. The returned coordinates are accurate only if the above mentioned three fixed points are accurate. If not needed, noArray() can be passed in. This parameter is ignored with standard calibration method. \nstdDeviationsIntrinsicsOutput vector of standard deviations estimated for intrinsic parameters. See calibrateCamera for details. \nstdDeviationsExtrinsicsOutput vector of standard deviations estimated for extrinsic parameters. See calibrateCamera for details. \nstdDeviationsObjPointsOutput vector of standard deviations estimated for refined coordinates of calibration pattern points. It has the same size and order as objectPoints[0] vector. This parameter is ignored with standard calibration method. \nperViewErrorsOutput vector of the RMS re-projection error estimated for each pattern view. \nflagsDifferent flags that may be zero or a combination of some predefined values. See calibrateCamera for details. If the method of releasing object is used, the calibration time may be much longer. CALIB_USE_QR or CALIB_USE_LU could be used for faster calibration with potentially less precise and less stable in some rare cases. \ncriteriaTermination criteria for the iterative optimization algorithm.\n\nReturnsthe overall RMS re-projection error.\nThe function estimates the intrinsic camera parameters and extrinsic parameters for each of the views. The algorithm is based on [319], [37] and [255]. See calibrateCamera for other detailed explanations. See alsocalibrateCamera, findChessboardCorners, solvePnP, initCameraMatrix2D, stereoCalibrate, undistort \n\n◆ calibrateHandEye()\n\nvoid cv::calibrateHandEye \n(\nInputArrayOfArrays \nR_gripper2base, \n\nInputArrayOfArrays \nt_gripper2base, \n\nInputArrayOfArrays \nR_target2cam, \n\nInputArrayOfArrays \nt_target2cam, \n\nOutputArray \nR_cam2gripper, \n\nOutputArray \nt_cam2gripper, \n\nHandEyeCalibrationMethod \nmethod = CALIB_HAND_EYE_TSAI \n\n)\n\nPython:cv.calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam[, R_cam2gripper[, t_cam2gripper[, method]]]) -> R_cam2gripper, t_cam2gripper\n\n#include <opencv2/calib3d.hpp>\nComputes Hand-Eye calibration: \\(_{}^{g}\\textrm{T}_c\\). \nParameters\n\n[in]R_gripper2baseRotation part extracted from the homogeneous matrix that transforms a point expressed in the gripper frame to the robot base frame ( \\(_{}^{b}\\textrm{T}_g\\)). This is a vector (vector<Mat>) that contains the rotation, (3x3) rotation matrices or (3x1) rotation vectors, for all the transformations from gripper frame to robot base frame. \n[in]t_gripper2baseTranslation part extracted from the homogeneous matrix that transforms a point expressed in the gripper frame to the robot base frame ( \\(_{}^{b}\\textrm{T}_g\\)). This is a vector (vector<Mat>) that contains the (3x1) translation vectors for all the transformations from gripper frame to robot base frame. \n[in]R_target2camRotation part extracted from the homogeneous matrix that transforms a point expressed in the target frame to the camera frame ( \\(_{}^{c}\\textrm{T}_t\\)). This is a vector (vector<Mat>) that contains the rotation, (3x3) rotation matrices or (3x1) rotation vectors, for all the transformations from calibration target frame to camera frame. \n[in]t_target2camRotation part extracted from the homogeneous matrix that transforms a point expressed in the target frame to the camera frame ( \\(_{}^{c}\\textrm{T}_t\\)). This is a vector (vector<Mat>) that contains the (3x1) translation vectors for all the transformations from calibration target frame to camera frame. \n[out]R_cam2gripperEstimated (3x3) rotation part extracted from the homogeneous matrix that transforms a point expressed in the camera frame to the gripper frame ( \\(_{}^{g}\\textrm{T}_c\\)). \n[out]t_cam2gripperEstimated (3x1) translation part extracted from the homogeneous matrix that transforms a point expressed in the camera frame to the gripper frame ( \\(_{}^{g}\\textrm{T}_c\\)). \n[in]methodOne of the implemented Hand-Eye calibration method, see cv::HandEyeCalibrationMethod\n\nThe function performs the Hand-Eye calibration using various methods. One approach consists in estimating the rotation then the translation (separable solutions) and the following methods are implemented:\nR. Tsai, R. Lenz A New Technique for Fully Autonomous and Efficient 3D Robotics Hand/EyeCalibration [274]\nF. Park, B. Martin Robot Sensor Calibration: Solving AX = XB on the Euclidean Group [213]\nR. Horaud, F. Dornaika Hand-Eye Calibration [127]\n\nAnother approach consists in estimating simultaneously the rotation and the translation (simultaneous solutions), with the following implemented methods:\nN. Andreff, R. Horaud, B. Espiau On-line Hand-Eye Calibration [12]\nK. Daniilidis Hand-Eye Calibration Using Dual Quaternions [65]\n\nThe following picture describes the Hand-Eye calibration problem where the transformation between a camera (\"eye\") mounted on a robot gripper (\"hand\") has to be estimated. This configuration is called eye-in-hand.\nThe eye-to-hand configuration consists in a static camera observing a calibration pattern mounted on the robot end-effector. The transformation from the camera to the robot base frame can then be estimated by inputting the suitable transformations to the function, see below.\n\nThe calibration procedure is the following:\na static calibration pattern is used to estimate the transformation between the target frame and the camera frame\nthe robot gripper is moved in order to acquire several poses\nfor each pose, the homogeneous transformation between the gripper frame and the robot base frame is recorded using for instance the robot kinematics  \n\\[\n    \\begin{bmatrix}\n    X_b\\\\\n    Y_b\\\\\n    Z_b\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{b}\\textrm{R}_g & _{}^{b}\\textrm{t}_g \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_g\\\\\n    Y_g\\\\\n    Z_g\\\\\n    1\n    \\end{bmatrix}\n\\]\n\nfor each pose, the homogeneous transformation between the calibration target frame and the camera frame is recorded using for instance a pose estimation method (PnP) from 2D-3D point correspondences  \n\\[\n    \\begin{bmatrix}\n    X_c\\\\\n    Y_c\\\\\n    Z_c\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{c}\\textrm{R}_t & _{}^{c}\\textrm{t}_t \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_t\\\\\n    Y_t\\\\\n    Z_t\\\\\n    1\n    \\end{bmatrix}\n\\]\n\nThe Hand-Eye calibration procedure returns the following homogeneous transformation  \n\\[\n    \\begin{bmatrix}\n    X_g\\\\\n    Y_g\\\\\n    Z_g\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{g}\\textrm{R}_c & _{}^{g}\\textrm{t}_c \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_c\\\\\n    Y_c\\\\\n    Z_c\\\\\n    1\n    \\end{bmatrix}\n\\]\n\nThis problem is also known as solving the \\(\\mathbf{A}\\mathbf{X}=\\mathbf{X}\\mathbf{B}\\) equation:\nfor an eye-in-hand configuration  \n\\[\n    \\begin{align*}\n    ^{b}{\\textrm{T}_g}^{(1)} \\hspace{0.2em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(1)} &=\n    \\hspace{0.1em} ^{b}{\\textrm{T}_g}^{(2)} \\hspace{0.2em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} \\\\\n\n    (^{b}{\\textrm{T}_g}^{(2)})^{-1} \\hspace{0.2em} ^{b}{\\textrm{T}_g}^{(1)} \\hspace{0.2em} ^{g}\\textrm{T}_c &=\n    \\hspace{0.1em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} (^{c}{\\textrm{T}_t}^{(1)})^{-1} \\\\\n\n    \\textrm{A}_i \\textrm{X} &= \\textrm{X} \\textrm{B}_i \\\\\n    \\end{align*}\n\\]\n\nfor an eye-to-hand configuration  \n\\[\n    \\begin{align*}\n    ^{g}{\\textrm{T}_b}^{(1)} \\hspace{0.2em} ^{b}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(1)} &=\n    \\hspace{0.1em} ^{g}{\\textrm{T}_b}^{(2)} \\hspace{0.2em} ^{b}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} \\\\\n\n    (^{g}{\\textrm{T}_b}^{(2)})^{-1} \\hspace{0.2em} ^{g}{\\textrm{T}_b}^{(1)} \\hspace{0.2em} ^{b}\\textrm{T}_c &=\n    \\hspace{0.1em} ^{b}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} (^{c}{\\textrm{T}_t}^{(1)})^{-1} \\\\\n\n    \\textrm{A}_i \\textrm{X} &= \\textrm{X} \\textrm{B}_i \\\\\n    \\end{align*}\n\\]\n\nNoteAdditional information can be found on this website. \n\nA minimum of 2 motions with non parallel rotation axes are necessary to determine the hand-eye transformation. So at least 3 different poses are required, but it is strongly recommended to use many more poses. \n\n◆ calibrateRobotWorldHandEye()\n\nvoid cv::calibrateRobotWorldHandEye \n(\nInputArrayOfArrays \nR_world2cam, \n\nInputArrayOfArrays \nt_world2cam, \n\nInputArrayOfArrays \nR_base2gripper, \n\nInputArrayOfArrays \nt_base2gripper, \n\nOutputArray \nR_base2world, \n\nOutputArray \nt_base2world, \n\nOutputArray \nR_gripper2cam, \n\nOutputArray \nt_gripper2cam, \n\nRobotWorldHandEyeCalibrationMethod \nmethod = CALIB_ROBOT_WORLD_HAND_EYE_SHAH \n\n)\n\nPython:cv.calibrateRobotWorldHandEye(R_world2cam, t_world2cam, R_base2gripper, t_base2gripper[, R_base2world[, t_base2world[, R_gripper2cam[, t_gripper2cam[, method]]]]]) -> R_base2world, t_base2world, R_gripper2cam, t_gripper2cam\n\n#include <opencv2/calib3d.hpp>\nComputes Robot-World/Hand-Eye calibration: \\(_{}^{w}\\textrm{T}_b\\) and \\(_{}^{c}\\textrm{T}_g\\). \nParameters\n\n[in]R_world2camRotation part extracted from the homogeneous matrix that transforms a point expressed in the world frame to the camera frame ( \\(_{}^{c}\\textrm{T}_w\\)). This is a vector (vector<Mat>) that contains the rotation, (3x3) rotation matrices or (3x1) rotation vectors, for all the transformations from world frame to the camera frame. \n[in]t_world2camTranslation part extracted from the homogeneous matrix that transforms a point expressed in the world frame to the camera frame ( \\(_{}^{c}\\textrm{T}_w\\)). This is a vector (vector<Mat>) that contains the (3x1) translation vectors for all the transformations from world frame to the camera frame. \n[in]R_base2gripperRotation part extracted from the homogeneous matrix that transforms a point expressed in the robot base frame to the gripper frame ( \\(_{}^{g}\\textrm{T}_b\\)). This is a vector (vector<Mat>) that contains the rotation, (3x3) rotation matrices or (3x1) rotation vectors, for all the transformations from robot base frame to the gripper frame. \n[in]t_base2gripperRotation part extracted from the homogeneous matrix that transforms a point expressed in the robot base frame to the gripper frame ( \\(_{}^{g}\\textrm{T}_b\\)). This is a vector (vector<Mat>) that contains the (3x1) translation vectors for all the transformations from robot base frame to the gripper frame. \n[out]R_base2worldEstimated (3x3) rotation part extracted from the homogeneous matrix that transforms a point expressed in the robot base frame to the world frame ( \\(_{}^{w}\\textrm{T}_b\\)). \n[out]t_base2worldEstimated (3x1) translation part extracted from the homogeneous matrix that transforms a point expressed in the robot base frame to the world frame ( \\(_{}^{w}\\textrm{T}_b\\)). \n[out]R_gripper2camEstimated (3x3) rotation part extracted from the homogeneous matrix that transforms a point expressed in the gripper frame to the camera frame ( \\(_{}^{c}\\textrm{T}_g\\)). \n[out]t_gripper2camEstimated (3x1) translation part extracted from the homogeneous matrix that transforms a point expressed in the gripper frame to the camera frame ( \\(_{}^{c}\\textrm{T}_g\\)). \n[in]methodOne of the implemented Robot-World/Hand-Eye calibration method, see cv::RobotWorldHandEyeCalibrationMethod\n\nThe function performs the Robot-World/Hand-Eye calibration using various methods. One approach consists in estimating the rotation then the translation (separable solutions):\nM. Shah, Solving the robot-world/hand-eye calibration problem using the kronecker product [244]\n\nAnother approach consists in estimating simultaneously the rotation and the translation (simultaneous solutions), with the following implemented method:\nA. Li, L. Wang, and D. Wu, Simultaneous robot-world and hand-eye calibration using dual-quaternions and kronecker product [163]\n\nThe following picture describes the Robot-World/Hand-Eye calibration problem where the transformations between a robot and a world frame and between a robot gripper (\"hand\") and a camera (\"eye\") mounted at the robot end-effector have to be estimated.\n\nThe calibration procedure is the following:\na static calibration pattern is used to estimate the transformation between the target frame and the camera frame\nthe robot gripper is moved in order to acquire several poses\nfor each pose, the homogeneous transformation between the gripper frame and the robot base frame is recorded using for instance the robot kinematics  \n\\[\n    \\begin{bmatrix}\n    X_g\\\\\n    Y_g\\\\\n    Z_g\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{g}\\textrm{R}_b & _{}^{g}\\textrm{t}_b \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_b\\\\\n    Y_b\\\\\n    Z_b\\\\\n    1\n    \\end{bmatrix}\n\\]\n\nfor each pose, the homogeneous transformation between the calibration target frame (the world frame) and the camera frame is recorded using for instance a pose estimation method (PnP) from 2D-3D point correspondences  \n\\[\n    \\begin{bmatrix}\n    X_c\\\\\n    Y_c\\\\\n    Z_c\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{c}\\textrm{R}_w & _{}^{c}\\textrm{t}_w \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_w\\\\\n    Y_w\\\\\n    Z_w\\\\\n    1\n    \\end{bmatrix}\n\\]\n\nThe Robot-World/Hand-Eye calibration procedure returns the following homogeneous transformations  \n\\[\n    \\begin{bmatrix}\n    X_w\\\\\n    Y_w\\\\\n    Z_w\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{w}\\textrm{R}_b & _{}^{w}\\textrm{t}_b \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_b\\\\\n    Y_b\\\\\n    Z_b\\\\\n    1\n    \\end{bmatrix}\n\\]\n\n\\[\n    \\begin{bmatrix}\n    X_c\\\\\n    Y_c\\\\\n    Z_c\\\\\n    1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    _{}^{c}\\textrm{R}_g & _{}^{c}\\textrm{t}_g \\\\\n    0_{1 \\times 3} & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    X_g\\\\\n    Y_g\\\\\n    Z_g\\\\\n    1\n    \\end{bmatrix}\n\\]\n\nThis problem is also known as solving the \\(\\mathbf{A}\\mathbf{X}=\\mathbf{Z}\\mathbf{B}\\) equation, with:\n\\(\\mathbf{A} \\Leftrightarrow \\hspace{0.1em} _{}^{c}\\textrm{T}_w\\)\n\\(\\mathbf{X} \\Leftrightarrow \\hspace{0.1em} _{}^{w}\\textrm{T}_b\\)\n\\(\\mathbf{Z} \\Leftrightarrow \\hspace{0.1em} _{}^{c}\\textrm{T}_g\\)\n\\(\\mathbf{B} \\Leftrightarrow \\hspace{0.1em} _{}^{g}\\textrm{T}_b\\)\n\nNoteAt least 3 measurements are required (input vectors size must be greater or equal to 3). \n\n◆ calibrationMatrixValues()\n\nvoid cv::calibrationMatrixValues \n(\nInputArray \ncameraMatrix, \n\nSize \nimageSize, \n\ndouble \napertureWidth, \n\ndouble \napertureHeight, \n\ndouble & \nfovx, \n\ndouble & \nfovy, \n\ndouble & \nfocalLength, \n\nPoint2d & \nprincipalPoint, \n\ndouble & \naspectRatio \n\n)\n\nPython:cv.calibrationMatrixValues(cameraMatrix, imageSize, apertureWidth, apertureHeight) -> fovx, fovy, focalLength, principalPoint, aspectRatio\n\n#include <opencv2/calib3d.hpp>\nComputes useful camera characteristics from the camera intrinsic matrix. \nParameters\n\ncameraMatrixInput camera intrinsic matrix that can be estimated by calibrateCamera or stereoCalibrate . \nimageSizeInput image size in pixels. \napertureWidthPhysical width in mm of the sensor. \napertureHeightPhysical height in mm of the sensor. \nfovxOutput field of view in degrees along the horizontal sensor axis. \nfovyOutput field of view in degrees along the vertical sensor axis. \nfocalLengthFocal length of the lens in mm. \nprincipalPointPrincipal point in mm. \naspectRatio\\(f_y/f_x\\)\n\nThe function computes various useful camera characteristics from the previously estimated camera matrix.\nNoteDo keep in mind that the unity measure 'mm' stands for whatever unit of measure one chooses for the chessboard pitch (it can thus be any value). \n\n◆ checkChessboard()\n\nbool cv::checkChessboard \n(\nInputArray \nimg, \n\nSize \nsize \n\n)\n\nPython:cv.checkChessboard(img, size) -> retval\n\n#include <opencv2/calib3d.hpp>\n\n◆ composeRT()\n\nvoid cv::composeRT \n(\nInputArray \nrvec1, \n\nInputArray \ntvec1, \n\nInputArray \nrvec2, \n\nInputArray \ntvec2, \n\nOutputArray \nrvec3, \n\nOutputArray \ntvec3, \n\nOutputArray \ndr3dr1 = noArray(), \n\nOutputArray \ndr3dt1 = noArray(), \n\nOutputArray \ndr3dr2 = noArray(), \n\nOutputArray \ndr3dt2 = noArray(), \n\nOutputArray \ndt3dr1 = noArray(), \n\nOutputArray \ndt3dt1 = noArray(), \n\nOutputArray \ndt3dr2 = noArray(), \n\nOutputArray \ndt3dt2 = noArray() \n\n)\n\nPython:cv.composeRT(rvec1, tvec1, rvec2, tvec2[, rvec3[, tvec3[, dr3dr1[, dr3dt1[, dr3dr2[, dr3dt2[, dt3dr1[, dt3dt1[, dt3dr2[, dt3dt2]]]]]]]]]]) -> rvec3, tvec3, dr3dr1, dr3dt1, dr3dr2, dr3dt2, dt3dr1, dt3dt1, dt3dr2, dt3dt2\n\n#include <opencv2/calib3d.hpp>\nCombines two rotation-and-shift transformations. \nParameters\n\nrvec1First rotation vector. \ntvec1First translation vector. \nrvec2Second rotation vector. \ntvec2Second translation vector. \nrvec3Output rotation vector of the superposition. \ntvec3Output translation vector of the superposition. \ndr3dr1Optional output derivative of rvec3 with regard to rvec1 \ndr3dt1Optional output derivative of rvec3 with regard to tvec1 \ndr3dr2Optional output derivative of rvec3 with regard to rvec2 \ndr3dt2Optional output derivative of rvec3 with regard to tvec2 \ndt3dr1Optional output derivative of tvec3 with regard to rvec1 \ndt3dt1Optional output derivative of tvec3 with regard to tvec1 \ndt3dr2Optional output derivative of tvec3 with regard to rvec2 \ndt3dt2Optional output derivative of tvec3 with regard to tvec2\n\nThe functions compute:\n\n\\[\\begin{array}{l} \\texttt{rvec3} =  \\mathrm{rodrigues} ^{-1} \\left ( \\mathrm{rodrigues} ( \\texttt{rvec2} )  \\cdot \\mathrm{rodrigues} ( \\texttt{rvec1} ) \\right )  \\\\ \\texttt{tvec3} =  \\mathrm{rodrigues} ( \\texttt{rvec2} )  \\cdot \\texttt{tvec1} +  \\texttt{tvec2} \\end{array} ,\\]\n\nwhere \\(\\mathrm{rodrigues}\\) denotes a rotation vector to a rotation matrix transformation, and \\(\\mathrm{rodrigues}^{-1}\\) denotes the inverse transformation. See Rodrigues for details.\nAlso, the functions can compute the derivatives of the output vectors with regards to the input vectors (see matMulDeriv ). The functions are used inside stereoCalibrate but can also be used in your own code where Levenberg-Marquardt or another gradient-based solver is used to optimize a function that contains a matrix multiplication. \n\n◆ computeCorrespondEpilines()\n\nvoid cv::computeCorrespondEpilines \n(\nInputArray \npoints, \n\nint \nwhichImage, \n\nInputArray \nF, \n\nOutputArray \nlines \n\n)\n\nPython:cv.computeCorrespondEpilines(points, whichImage, F[, lines]) -> lines\n\n#include <opencv2/calib3d.hpp>\nFor points in an image of a stereo pair, computes the corresponding epilines in the other image. \nParameters\n\npointsInput points. \\(N \\times 1\\) or \\(1 \\times N\\) matrix of type CV_32FC2 or vector<Point2f> . \nwhichImageIndex of the image (1 or 2) that contains the points . \nFFundamental matrix that can be estimated using findFundamentalMat or stereoRectify . \nlinesOutput vector of the epipolar lines corresponding to the points in the other image. Each line \\(ax + by + c=0\\) is encoded by 3 numbers \\((a, b, c)\\) .\n\nFor every point in one of the two images of a stereo pair, the function finds the equation of the corresponding epipolar line in the other image.\nFrom the fundamental matrix definition (see findFundamentalMat ), line \\(l^{(2)}_i\\) in the second image for the point \\(p^{(1)}_i\\) in the first image (when whichImage=1 ) is computed as:\n\n\\[l^{(2)}_i = F p^{(1)}_i\\]\n\nAnd vice versa, when whichImage=2, \\(l^{(1)}_i\\) is computed from \\(p^{(2)}_i\\) as:\n\n\\[l^{(1)}_i = F^T p^{(2)}_i\\]\n\nLine coefficients are defined up to a scale. They are normalized so that \\(a_i^2+b_i^2=1\\) . \n\n◆ convertPointsFromHomogeneous()\n\nvoid cv::convertPointsFromHomogeneous \n(\nInputArray \nsrc, \n\nOutputArray \ndst \n\n)\n\nPython:cv.convertPointsFromHomogeneous(src[, dst]) -> dst\n\n#include <opencv2/calib3d.hpp>\nConverts points from homogeneous to Euclidean space. \nParameters\n\nsrcInput vector of N-dimensional points. \ndstOutput vector of N-1-dimensional points.\n\nThe function converts points homogeneous to Euclidean space using perspective projection. That is, each point (x1, x2, ... x(n-1), xn) is converted to (x1/xn, x2/xn, ..., x(n-1)/xn). When xn=0, the output point coordinates will be (0,0,0,...). \n\n◆ convertPointsHomogeneous()\n\nvoid cv::convertPointsHomogeneous \n(\nInputArray \nsrc, \n\nOutputArray \ndst \n\n)\n\n#include <opencv2/calib3d.hpp>\nConverts points to/from homogeneous coordinates. \nParameters\n\nsrcInput array or vector of 2D, 3D, or 4D points. \ndstOutput vector of 2D, 3D, or 4D points.\n\nThe function converts 2D or 3D points from/to homogeneous coordinates by calling either convertPointsToHomogeneous or convertPointsFromHomogeneous.\nNoteThe function is obsolete. Use one of the previous two functions instead. \n\n◆ convertPointsToHomogeneous()\n\nvoid cv::convertPointsToHomogeneous \n(\nInputArray \nsrc, \n\nOutputArray \ndst \n\n)\n\nPython:cv.convertPointsToHomogeneous(src[, dst]) -> dst\n\n#include <opencv2/calib3d.hpp>\nConverts points from Euclidean to homogeneous space. \nParameters\n\nsrcInput vector of N-dimensional points. \ndstOutput vector of N+1-dimensional points.\n\nThe function converts points from Euclidean to homogeneous space by appending 1's to the tuple of point coordinates. That is, each point (x1, x2, ..., xn) is converted to (x1, x2, ..., xn, 1). \n\n◆ correctMatches()\n\nvoid cv::correctMatches \n(\nInputArray \nF, \n\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nOutputArray \nnewPoints1, \n\nOutputArray \nnewPoints2 \n\n)\n\nPython:cv.correctMatches(F, points1, points2[, newPoints1[, newPoints2]]) -> newPoints1, newPoints2\n\n#include <opencv2/calib3d.hpp>\nRefines coordinates of corresponding points. \nParameters\n\nF3x3 fundamental matrix. \npoints11xN array containing the first set of points. \npoints21xN array containing the second set of points. \nnewPoints1The optimized points1. \nnewPoints2The optimized points2.\n\nThe function implements the Optimal Triangulation Method (see Multiple View Geometry [117] for details). For each given point correspondence points1[i] <-> points2[i], and a fundamental matrix F, it computes the corrected correspondences newPoints1[i] <-> newPoints2[i] that minimize the geometric error \\(d(points1[i], newPoints1[i])^2 + d(points2[i],newPoints2[i])^2\\) (where \\(d(a,b)\\) is the geometric distance between points \\(a\\) and \\(b\\) ) subject to the epipolar constraint \\(newPoints2^T \\cdot F \\cdot newPoints1 = 0\\) . \n\n◆ decomposeEssentialMat()\n\nvoid cv::decomposeEssentialMat \n(\nInputArray \nE, \n\nOutputArray \nR1, \n\nOutputArray \nR2, \n\nOutputArray \nt \n\n)\n\nPython:cv.decomposeEssentialMat(E[, R1[, R2[, t]]]) -> R1, R2, t\n\n#include <opencv2/calib3d.hpp>\nDecompose an essential matrix to possible rotations and translation. \nParameters\n\nEThe input essential matrix. \nR1One possible rotation matrix. \nR2Another possible rotation matrix. \ntOne possible translation.\n\nThis function decomposes the essential matrix E using svd decomposition [117]. In general, four possible poses exist for the decomposition of E. They are \\([R_1, t]\\), \\([R_1, -t]\\), \\([R_2, t]\\), \\([R_2, -t]\\).\nIf E gives the epipolar constraint \\([p_2; 1]^T A^{-T} E A^{-1} [p_1; 1] = 0\\) between the image points \\(p_1\\) in the first image and \\(p_2\\) in second image, then any of the tuples \\([R_1, t]\\), \\([R_1, -t]\\), \\([R_2, t]\\), \\([R_2, -t]\\) is a change of basis from the first camera's coordinate system to the second camera's coordinate system. However, by decomposing E, one can only get the direction of the translation. For this reason, the translation t is returned with unit length. \n\n◆ decomposeHomographyMat()\n\nint cv::decomposeHomographyMat \n(\nInputArray \nH, \n\nInputArray \nK, \n\nOutputArrayOfArrays \nrotations, \n\nOutputArrayOfArrays \ntranslations, \n\nOutputArrayOfArrays \nnormals \n\n)\n\nPython:cv.decomposeHomographyMat(H, K[, rotations[, translations[, normals]]]) -> retval, rotations, translations, normals\n\n#include <opencv2/calib3d.hpp>\nDecompose a homography matrix to rotation(s), translation(s) and plane normal(s). \nParameters\n\nHThe input homography matrix between two images. \nKThe input camera intrinsic matrix. \nrotationsArray of rotation matrices. \ntranslationsArray of translation matrices. \nnormalsArray of plane normal matrices.\n\nThis function extracts relative camera motion between two views of a planar object and returns up to four mathematical solution tuples of rotation, translation, and plane normal. The decomposition of the homography matrix H is described in detail in [181].\nIf the homography H, induced by the plane, gives the constraint \n\\[s_i \\vecthree{x'_i}{y'_i}{1} \\sim H \\vecthree{x_i}{y_i}{1}\\]\n\n on the source image points \\(p_i\\) and the destination image points \\(p'_i\\), then the tuple of rotations[k] and translations[k] is a change of basis from the source camera's coordinate system to the destination camera's coordinate system. However, by decomposing H, one can only get the translation normalized by the (typically unknown) depth of the scene, i.e. its direction but with normalized length.\nIf point correspondences are available, at least two solutions may further be invalidated, by applying positive depth constraint, i.e. all points must be in front of the camera. \n\n◆ decomposeProjectionMatrix()\n\nvoid cv::decomposeProjectionMatrix \n(\nInputArray \nprojMatrix, \n\nOutputArray \ncameraMatrix, \n\nOutputArray \nrotMatrix, \n\nOutputArray \ntransVect, \n\nOutputArray \nrotMatrixX = noArray(), \n\nOutputArray \nrotMatrixY = noArray(), \n\nOutputArray \nrotMatrixZ = noArray(), \n\nOutputArray \neulerAngles = noArray() \n\n)\n\nPython:cv.decomposeProjectionMatrix(projMatrix[, cameraMatrix[, rotMatrix[, transVect[, rotMatrixX[, rotMatrixY[, rotMatrixZ[, eulerAngles]]]]]]]) -> cameraMatrix, rotMatrix, transVect, rotMatrixX, rotMatrixY, rotMatrixZ, eulerAngles\n\n#include <opencv2/calib3d.hpp>\nDecomposes a projection matrix into a rotation matrix and a camera intrinsic matrix. \nParameters\n\nprojMatrix3x4 input projection matrix P. \ncameraMatrixOutput 3x3 camera intrinsic matrix \\(\\cameramatrix{A}\\). \nrotMatrixOutput 3x3 external rotation matrix R. \ntransVectOutput 4x1 translation vector T. \nrotMatrixXOptional 3x3 rotation matrix around x-axis. \nrotMatrixYOptional 3x3 rotation matrix around y-axis. \nrotMatrixZOptional 3x3 rotation matrix around z-axis. \neulerAnglesOptional three-element vector containing three Euler angles of rotation in degrees.\n\nThe function computes a decomposition of a projection matrix into a calibration and a rotation matrix and the position of a camera.\nIt optionally returns three rotation matrices, one for each axis, and three Euler angles that could be used in OpenGL. Note, there is always more than one sequence of rotations about the three principal axes that results in the same orientation of an object, e.g. see [248] . Returned three rotation matrices and corresponding three Euler angles are only one of the possible solutions.\nThe function is based on RQDecomp3x3 . \n\n◆ drawChessboardCorners()\n\nvoid cv::drawChessboardCorners \n(\nInputOutputArray \nimage, \n\nSize \npatternSize, \n\nInputArray \ncorners, \n\nbool \npatternWasFound \n\n)\n\nPython:cv.drawChessboardCorners(image, patternSize, corners, patternWasFound) -> image\n\n#include <opencv2/calib3d.hpp>\nRenders the detected chessboard corners. \nParameters\n\nimageDestination image. It must be an 8-bit color image. \npatternSizeNumber of inner corners per a chessboard row and column (patternSize = cv::Size(points_per_row,points_per_column)). \ncornersArray of detected corners, the output of findChessboardCorners. \npatternWasFoundParameter indicating whether the complete board was found or not. The return value of findChessboardCorners should be passed here.\n\nThe function draws individual chessboard corners detected either as red circles if the board was not found, or as colored corners connected with lines if the board was found. \n\n◆ drawFrameAxes()\n\nvoid cv::drawFrameAxes \n(\nInputOutputArray \nimage, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputArray \nrvec, \n\nInputArray \ntvec, \n\nfloat \nlength, \n\nint \nthickness = 3 \n\n)\n\nPython:cv.drawFrameAxes(image, cameraMatrix, distCoeffs, rvec, tvec, length[, thickness]) -> image\n\n#include <opencv2/calib3d.hpp>\nDraw axes of the world/object coordinate system from pose estimation. \nSee alsosolvePnP\nParameters\n\nimageInput/output image. It must have 1 or 3 channels. The number of channels is not altered. \ncameraMatrixInput 3x3 floating-point matrix of camera intrinsic parameters. \\(\\cameramatrix{A}\\) \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is empty, the zero distortion coefficients are assumed. \nrvecRotation vector (see Rodrigues ) that, together with tvec, brings points from the model coordinate system to the camera coordinate system. \ntvecTranslation vector. \nlengthLength of the painted axes in the same unit than tvec (usually in meters). \nthicknessLine thickness of the painted axes.\n\nThis function draws the axes of the world/object coordinate system w.r.t. to the camera frame. OX is drawn in red, OY in green and OZ in blue. \n\n◆ estimateAffine2D() [1/2]\n\ncv::Mat cv::estimateAffine2D \n(\nInputArray \nfrom, \n\nInputArray \nto, \n\nOutputArray \ninliers = noArray(), \n\nint \nmethod = RANSAC, \n\ndouble \nransacReprojThreshold = 3, \n\nsize_t \nmaxIters = 2000, \n\ndouble \nconfidence = 0.99, \n\nsize_t \nrefineIters = 10 \n\n)\n\nPython:cv.estimateAffine2D(from_, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inlierscv.estimateAffine2D(pts1, pts2, params[, inliers]) -> retval, inliers\n\n#include <opencv2/calib3d.hpp>\nComputes an optimal affine transformation between two 2D point sets. \nIt computes  \n\\[\n\\begin{bmatrix}\nx\\\\\ny\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11} & a_{12}\\\\\na_{21} & a_{22}\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nX\\\\\nY\\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_1\\\\\nb_2\\\\\n\\end{bmatrix}\n\\]\n\nParameters\n\nfromFirst input 2D point set containing \\((X,Y)\\). \ntoSecond input 2D point set containing \\((x,y)\\). \ninliersOutput vector indicating which points are inliers (1-inlier, 0-outlier). \nmethodRobust method used to compute transformation. The following methods are possible:\nRANSAC - RANSAC-based robust method\nLMEDS - Least-Median robust method RANSAC is the default method. \n\nransacReprojThresholdMaximum reprojection error in the RANSAC algorithm to consider a point as an inlier. Applies only to RANSAC. \nmaxItersThe maximum number of robust method iterations. \nconfidenceConfidence level, between 0 and 1, for the estimated transformation. Anything between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation. \nrefineItersMaximum number of iterations of refining algorithm (Levenberg-Marquardt). Passing 0 will disable refining, so the output matrix will be output of robust method.\n\nReturnsOutput 2D affine transformation matrix \\(2 \\times 3\\) or empty matrix if transformation could not be estimated. The returned matrix has the following form:  \n\\[\n\\begin{bmatrix}\na_{11} & a_{12} & b_1\\\\\na_{21} & a_{22} & b_2\\\\\n\\end{bmatrix}\n\\]\n\nThe function estimates an optimal 2D affine transformation between two 2D point sets using the selected robust algorithm.\nThe computed transformation is then refined further (using only inliers) with the Levenberg-Marquardt method to reduce the re-projection error even more.\nNoteThe RANSAC method can handle practically any ratio of outliers but needs a threshold to distinguish inliers from outliers. The method LMeDS does not need any threshold but it works correctly only when there are more than 50% of inliers.\nSee alsoestimateAffinePartial2D, getAffineTransform \n\n◆ estimateAffine2D() [2/2]\n\ncv::Mat cv::estimateAffine2D \n(\nInputArray \npts1, \n\nInputArray \npts2, \n\nOutputArray \ninliers, \n\nconst UsacParams & \nparams \n\n)\n\nPython:cv.estimateAffine2D(from_, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inlierscv.estimateAffine2D(pts1, pts2, params[, inliers]) -> retval, inliers\n\n#include <opencv2/calib3d.hpp>\n\n◆ estimateAffine3D() [1/2]\n\ncv::Mat cv::estimateAffine3D \n(\nInputArray \nsrc, \n\nInputArray \ndst, \n\ndouble * \nscale = nullptr, \n\nbool \nforce_rotation = true \n\n)\n\nPython:cv.estimateAffine3D(src, dst[, out[, inliers[, ransacThreshold[, confidence]]]]) -> retval, out, inlierscv.estimateAffine3D(src, dst[, force_rotation]) -> retval, scale\n\n#include <opencv2/calib3d.hpp>\nComputes an optimal affine transformation between two 3D point sets. \nIt computes \\(R,s,t\\) minimizing \\(\\sum{i} dst_i - c \\cdot R \\cdot src_i \\) where \\(R\\) is a 3x3 rotation matrix, \\(t\\) is a 3x1 translation vector and \\(s\\) is a scalar size value. This is an implementation of the algorithm by Umeyama [278] . The estimated affine transform has a homogeneous scale which is a subclass of affine transformations with 7 degrees of freedom. The paired point sets need to comprise at least 3 points each.\nParameters\n\nsrcFirst input 3D point set. \ndstSecond input 3D point set. \nscaleIf null is passed, the scale parameter c will be assumed to be 1.0. Else the pointed-to variable will be set to the optimal scale. \nforce_rotationIf true, the returned rotation will never be a reflection. This might be unwanted, e.g. when optimizing a transform between a right- and a left-handed coordinate system. \n\nReturns3D affine transformation matrix \\(3 \\times 4\\) of the form  \n\\[T =\n\\begin{bmatrix}\nR & t\\\\\n\\end{bmatrix}\n\\]\n\n◆ estimateAffine3D() [2/2]\n\nint cv::estimateAffine3D \n(\nInputArray \nsrc, \n\nInputArray \ndst, \n\nOutputArray \nout, \n\nOutputArray \ninliers, \n\ndouble \nransacThreshold = 3, \n\ndouble \nconfidence = 0.99 \n\n)\n\nPython:cv.estimateAffine3D(src, dst[, out[, inliers[, ransacThreshold[, confidence]]]]) -> retval, out, inlierscv.estimateAffine3D(src, dst[, force_rotation]) -> retval, scale\n\n#include <opencv2/calib3d.hpp>\nComputes an optimal affine transformation between two 3D point sets. \nIt computes  \n\\[\n\\begin{bmatrix}\nx\\\\\ny\\\\\nz\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nX\\\\\nY\\\\\nZ\\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_1\\\\\nb_2\\\\\nb_3\\\\\n\\end{bmatrix}\n\\]\n\nParameters\n\nsrcFirst input 3D point set containing \\((X,Y,Z)\\). \ndstSecond input 3D point set containing \\((x,y,z)\\). \noutOutput 3D affine transformation matrix \\(3 \\times 4\\) of the form  \n\\[\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} & b_1\\\\\na_{21} & a_{22} & a_{23} & b_2\\\\\na_{31} & a_{32} & a_{33} & b_3\\\\\n\\end{bmatrix}\n\\]\n\ninliersOutput vector indicating which points are inliers (1-inlier, 0-outlier). \nransacThresholdMaximum reprojection error in the RANSAC algorithm to consider a point as an inlier. \nconfidenceConfidence level, between 0 and 1, for the estimated transformation. Anything between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n\nThe function estimates an optimal 3D affine transformation between two 3D point sets using the RANSAC algorithm. \n\n◆ estimateAffinePartial2D()\n\ncv::Mat cv::estimateAffinePartial2D \n(\nInputArray \nfrom, \n\nInputArray \nto, \n\nOutputArray \ninliers = noArray(), \n\nint \nmethod = RANSAC, \n\ndouble \nransacReprojThreshold = 3, \n\nsize_t \nmaxIters = 2000, \n\ndouble \nconfidence = 0.99, \n\nsize_t \nrefineIters = 10 \n\n)\n\nPython:cv.estimateAffinePartial2D(from_, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inliers\n\n#include <opencv2/calib3d.hpp>\nComputes an optimal limited affine transformation with 4 degrees of freedom between two 2D point sets. \nParameters\n\nfromFirst input 2D point set. \ntoSecond input 2D point set. \ninliersOutput vector indicating which points are inliers. \nmethodRobust method used to compute transformation. The following methods are possible:\nRANSAC - RANSAC-based robust method\nLMEDS - Least-Median robust method RANSAC is the default method. \n\nransacReprojThresholdMaximum reprojection error in the RANSAC algorithm to consider a point as an inlier. Applies only to RANSAC. \nmaxItersThe maximum number of robust method iterations. \nconfidenceConfidence level, between 0 and 1, for the estimated transformation. Anything between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation. \nrefineItersMaximum number of iterations of refining algorithm (Levenberg-Marquardt). Passing 0 will disable refining, so the output matrix will be output of robust method.\n\nReturnsOutput 2D affine transformation (4 degrees of freedom) matrix \\(2 \\times 3\\) or empty matrix if transformation could not be estimated.\nThe function estimates an optimal 2D affine transformation with 4 degrees of freedom limited to combinations of translation, rotation, and uniform scaling. Uses the selected algorithm for robust estimation.\nThe computed transformation is then refined further (using only inliers) with the Levenberg-Marquardt method to reduce the re-projection error even more.\nEstimated transformation matrix is:  \n\\[ \\begin{bmatrix} \\cos(\\theta) \\cdot s & -\\sin(\\theta) \\cdot s & t_x \\\\\n                \\sin(\\theta) \\cdot s & \\cos(\\theta) \\cdot s & t_y\n\\end{bmatrix} \\]\n\n Where \\( \\theta \\) is the rotation angle, \\( s \\) the scaling factor and \\( t_x, t_y \\) are translations in \\( x, y \\) axes respectively.\nNoteThe RANSAC method can handle practically any ratio of outliers but need a threshold to distinguish inliers from outliers. The method LMeDS does not need any threshold but it works correctly only when there are more than 50% of inliers.\nSee alsoestimateAffine2D, getAffineTransform \n\n◆ estimateChessboardSharpness()\n\nScalar cv::estimateChessboardSharpness \n(\nInputArray \nimage, \n\nSize \npatternSize, \n\nInputArray \ncorners, \n\nfloat \nrise_distance = 0.8F, \n\nbool \nvertical = false, \n\nOutputArray \nsharpness = noArray() \n\n)\n\nPython:cv.estimateChessboardSharpness(image, patternSize, corners[, rise_distance[, vertical[, sharpness]]]) -> retval, sharpness\n\n#include <opencv2/calib3d.hpp>\nEstimates the sharpness of a detected chessboard. \nImage sharpness, as well as brightness, are a critical parameter for accuracte camera calibration. For accessing these parameters for filtering out problematic calibraiton images, this method calculates edge profiles by traveling from black to white chessboard cell centers. Based on this, the number of pixels is calculated required to transit from black to white. This width of the transition area is a good indication of how sharp the chessboard is imaged and should be below ~3.0 pixels.\nParameters\n\nimageGray image used to find chessboard corners \npatternSizeSize of a found chessboard pattern \ncornersCorners found by findChessboardCornersSB \nrise_distanceRise distance 0.8 means 10% ... 90% of the final signal strength \nverticalBy default edge responses for horizontal lines are calculated \nsharpnessOptional output array with a sharpness value for calculated edge responses (see description)\n\nThe optional sharpness array is of type CV_32FC1 and has for each calculated profile one row with the following five entries: 0 = x coordinate of the underlying edge in the image 1 = y coordinate of the underlying edge in the image 2 = width of the transition area (sharpness) 3 = signal strength in the black cell (min brightness) 4 = signal strength in the white cell (max brightness)\nReturnsScalar(average sharpness, average min brightness, average max brightness,0) \n\n◆ estimateTranslation3D()\n\nint cv::estimateTranslation3D \n(\nInputArray \nsrc, \n\nInputArray \ndst, \n\nOutputArray \nout, \n\nOutputArray \ninliers, \n\ndouble \nransacThreshold = 3, \n\ndouble \nconfidence = 0.99 \n\n)\n\nPython:cv.estimateTranslation3D(src, dst[, out[, inliers[, ransacThreshold[, confidence]]]]) -> retval, out, inliers\n\n#include <opencv2/calib3d.hpp>\nComputes an optimal translation between two 3D point sets. \nIt computes  \n\\[\n\\begin{bmatrix}\nx\\\\\ny\\\\\nz\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nX\\\\\nY\\\\\nZ\\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_1\\\\\nb_2\\\\\nb_3\\\\\n\\end{bmatrix}\n\\]\n\nParameters\n\nsrcFirst input 3D point set containing \\((X,Y,Z)\\). \ndstSecond input 3D point set containing \\((x,y,z)\\). \noutOutput 3D translation vector \\(3 \\times 1\\) of the form  \n\\[\n\\begin{bmatrix}\nb_1 \\\\\nb_2 \\\\\nb_3 \\\\\n\\end{bmatrix}\n\\]\n\ninliersOutput vector indicating which points are inliers (1-inlier, 0-outlier). \nransacThresholdMaximum reprojection error in the RANSAC algorithm to consider a point as an inlier. \nconfidenceConfidence level, between 0 and 1, for the estimated transformation. Anything between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n\nThe function estimates an optimal 3D translation between two 3D point sets using the RANSAC algorithm. \n\n◆ filterHomographyDecompByVisibleRefpoints()\n\nvoid cv::filterHomographyDecompByVisibleRefpoints \n(\nInputArrayOfArrays \nrotations, \n\nInputArrayOfArrays \nnormals, \n\nInputArray \nbeforePoints, \n\nInputArray \nafterPoints, \n\nOutputArray \npossibleSolutions, \n\nInputArray \npointsMask = noArray() \n\n)\n\nPython:cv.filterHomographyDecompByVisibleRefpoints(rotations, normals, beforePoints, afterPoints[, possibleSolutions[, pointsMask]]) -> possibleSolutions\n\n#include <opencv2/calib3d.hpp>\nFilters homography decompositions based on additional information. \nParameters\n\nrotationsVector of rotation matrices. \nnormalsVector of plane normal matrices. \nbeforePointsVector of (rectified) visible reference points before the homography is applied \nafterPointsVector of (rectified) visible reference points after the homography is applied \npossibleSolutionsVector of int indices representing the viable solution set after filtering \npointsMaskoptional Mat/Vector of 8u type representing the mask for the inliers as given by the findHomography function\n\nThis function is intended to filter the output of the decomposeHomographyMat based on additional information as described in [181] . The summary of the method: the decomposeHomographyMat function returns 2 unique solutions and their \"opposites\" for a total of 4 solutions. If we have access to the sets of points visible in the camera frame before and after the homography transformation is applied, we can determine which are the true potential solutions and which are the opposites by verifying which homographies are consistent with all visible reference points being in front of the camera. The inputs are left unchanged; the filtered solution set is returned as indices into the existing one. \n\n◆ filterSpeckles()\n\nvoid cv::filterSpeckles \n(\nInputOutputArray \nimg, \n\ndouble \nnewVal, \n\nint \nmaxSpeckleSize, \n\ndouble \nmaxDiff, \n\nInputOutputArray \nbuf = noArray() \n\n)\n\nPython:cv.filterSpeckles(img, newVal, maxSpeckleSize, maxDiff[, buf]) -> img, buf\n\n#include <opencv2/calib3d.hpp>\nFilters off small noise blobs (speckles) in the disparity map. \nParameters\n\nimgThe input 16-bit signed disparity image \nnewValThe disparity value used to paint-off the speckles \nmaxSpeckleSizeThe maximum speckle size to consider it a speckle. Larger blobs are not affected by the algorithm \nmaxDiffMaximum difference between neighbor disparity pixels to put them into the same blob. Note that since StereoBM, StereoSGBM and may be other algorithms return a fixed-point disparity map, where disparity values are multiplied by 16, this scale factor should be taken into account when specifying this parameter value. \nbufThe optional temporary buffer to avoid memory allocation within the function. \n\n◆ find4QuadCornerSubpix()\n\nbool cv::find4QuadCornerSubpix \n(\nInputArray \nimg, \n\nInputOutputArray \ncorners, \n\nSize \nregion_size \n\n)\n\nPython:cv.find4QuadCornerSubpix(img, corners, region_size) -> retval, corners\n\n#include <opencv2/calib3d.hpp>\nfinds subpixel-accurate positions of the chessboard corners \n\n◆ findChessboardCorners()\n\nbool cv::findChessboardCorners \n(\nInputArray \nimage, \n\nSize \npatternSize, \n\nOutputArray \ncorners, \n\nint \nflags = CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE \n\n)\n\nPython:cv.findChessboardCorners(image, patternSize[, corners[, flags]]) -> retval, corners\n\n#include <opencv2/calib3d.hpp>\nFinds the positions of internal corners of the chessboard. \nParameters\n\nimageSource chessboard view. It must be an 8-bit grayscale or color image. \npatternSizeNumber of inner corners per a chessboard row and column ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ). \ncornersOutput array of detected corners. \nflagsVarious operation flags that can be zero or a combination of the following values:\nCALIB_CB_ADAPTIVE_THRESH Use adaptive thresholding to convert the image to black and white, rather than a fixed threshold level (computed from the average image brightness).\nCALIB_CB_NORMALIZE_IMAGE Normalize the image gamma with equalizeHist before applying fixed or adaptive thresholding.\nCALIB_CB_FILTER_QUADS Use additional criteria (like contour area, perimeter, square-like shape) to filter out false quads extracted at the contour retrieval stage.\nCALIB_CB_FAST_CHECK Run a fast check on the image that looks for chessboard corners, and shortcut the call if none is found. This can drastically speed up the call in the degenerate condition when no chessboard is observed.\nCALIB_CB_PLAIN All other flags are ignored. The input image is taken as is. No image processing is done to improve to find the checkerboard. This has the effect of speeding up the execution of the function but could lead to not recognizing the checkerboard if the image is not previously binarized in the appropriate manner.\n\nThe function attempts to determine whether the input image is a view of the chessboard pattern and locate the internal chessboard corners. The function returns a non-zero value if all of the corners are found and they are placed in a certain order (row by row, left to right in every row). Otherwise, if the function fails to find all the corners or reorder them, it returns 0. For example, a regular chessboard has 8 x 8 squares and 7 x 7 internal corners, that is, points where the black squares touch each other. The detected coordinates are approximate, and to determine their positions more accurately, the function calls cornerSubPix. You also may use the function cornerSubPix with different parameters if returned coordinates are not accurate enough.\nSample usage of detecting and drawing chessboard corners: : Size patternsize(8,6); //interior number of corners\nMat gray = ....; //source image\nvector<Point2f> corners; //this will be filled by the detected corners\n \n//CALIB_CB_FAST_CHECK saves a lot of time on images\n//that do not contain any chessboard corners\nbool patternfound = findChessboardCorners(gray, patternsize, corners,\n CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE\n        + CALIB_CB_FAST_CHECK);\n \nif(patternfound)\n cornerSubPix(gray, corners, Size(11, 11), Size(-1, -1),\n TermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 30, 0.1));\n \ndrawChessboardCorners(img, patternsize, Mat(corners), patternfound);\ncv::Matn-dimensional dense array classDefinition mat.hpp:828\ncv::Size_Template class for specifying the size of an image or rectangle.Definition types.hpp:335\ncv::TermCriteriaThe class defining termination criteria for iterative algorithms.Definition types.hpp:893\ncv::drawChessboardCornersvoid drawChessboardCorners(InputOutputArray image, Size patternSize, InputArray corners, bool patternWasFound)Renders the detected chessboard corners.\ncv::findChessboardCornersbool findChessboardCorners(InputArray image, Size patternSize, OutputArray corners, int flags=CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE)Finds the positions of internal corners of the chessboard.\ncv::CALIB_CB_FAST_CHECK@ CALIB_CB_FAST_CHECKDefinition calib3d.hpp:488\ncv::CALIB_CB_ADAPTIVE_THRESH@ CALIB_CB_ADAPTIVE_THRESHDefinition calib3d.hpp:485\ncv::CALIB_CB_NORMALIZE_IMAGE@ CALIB_CB_NORMALIZE_IMAGEDefinition calib3d.hpp:486\ncv::SizeSize2i SizeDefinition types.hpp:370\ncv::cornerSubPixvoid cornerSubPix(InputArray image, InputOutputArray corners, Size winSize, Size zeroZone, TermCriteria criteria)Refines the corner locations.\n NoteThe function requires white space (like a square-thick border, the wider the better) around the board to make the detection more robust in various environments. Otherwise, if there is no border and the background is dark, the outer black squares cannot be segmented properly and so the square grouping and ordering algorithm fails.\nUse gen_pattern.py (Create calibration pattern) to create checkerboard. \n\n◆ findChessboardCornersSB() [1/2]\n\nbool cv::findChessboardCornersSB \n(\nInputArray \nimage, \n\nSize \npatternSize, \n\nOutputArray \ncorners, \n\nint \nflags, \n\nOutputArray \nmeta \n\n)\n\nPython:cv.findChessboardCornersSB(image, patternSize[, corners[, flags]]) -> retval, cornerscv.findChessboardCornersSBWithMeta(image, patternSize, flags[, corners[, meta]]) -> retval, corners, meta\n\n#include <opencv2/calib3d.hpp>\nFinds the positions of internal corners of the chessboard using a sector based approach. \nParameters\n\nimageSource chessboard view. It must be an 8-bit grayscale or color image. \npatternSizeNumber of inner corners per a chessboard row and column ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ). \ncornersOutput array of detected corners. \nflagsVarious operation flags that can be zero or a combination of the following values:\nCALIB_CB_NORMALIZE_IMAGE Normalize the image gamma with equalizeHist before detection.\nCALIB_CB_EXHAUSTIVE Run an exhaustive search to improve detection rate.\nCALIB_CB_ACCURACY Up sample input image to improve sub-pixel accuracy due to aliasing effects.\nCALIB_CB_LARGER The detected pattern is allowed to be larger than patternSize (see description).\nCALIB_CB_MARKER The detected pattern must have a marker (see description). This should be used if an accurate camera calibration is required. \n\nmetaOptional output arrray of detected corners (CV_8UC1 and size = cv::Size(columns,rows)). Each entry stands for one corner of the pattern and can have one of the following values:\n0 = no meta data attached\n1 = left-top corner of a black cell\n2 = left-top corner of a white cell\n3 = left-top corner of a black cell with a white marker dot\n4 = left-top corner of a white cell with a black marker dot (pattern origin in case of markers otherwise first corner)\n\nThe function is analog to findChessboardCorners but uses a localized radon transformation approximated by box filters being more robust to all sort of noise, faster on larger images and is able to directly return the sub-pixel position of the internal chessboard corners. The Method is based on the paper [74] \"Accurate Detection and Localization of Checkerboard Corners for\nCalibration\" demonstrating that the returned sub-pixel positions are more accurate than the one returned by cornerSubPix allowing a precise camera calibration for demanding applications.\nIn the case, the flags CALIB_CB_LARGER or CALIB_CB_MARKER are given, the result can be recovered from the optional meta array. Both flags are helpful to use calibration patterns exceeding the field of view of the camera. These oversized patterns allow more accurate calibrations as corners can be utilized, which are as close as possible to the image borders. For a consistent coordinate system across all images, the optional marker (see image below) can be used to move the origin of the board to the location where the black circle is located.\nNoteThe function requires a white boarder with roughly the same width as one of the checkerboard fields around the whole board to improve the detection in various environments. In addition, because of the localized radon transformation it is beneficial to use round corners for the field corners which are located on the outside of the board. The following figure illustrates a sample checkerboard optimized for the detection. However, any other checkerboard can be used as well.\nUse gen_pattern.py (Create calibration pattern) to create checkerboard.  \n\n◆ findChessboardCornersSB() [2/2]\n\nbool cv::findChessboardCornersSB \n(\nInputArray \nimage, \n\nSize \npatternSize, \n\nOutputArray \ncorners, \n\nint \nflags = 0 \n\n)\n\ninline \n\nPython:cv.findChessboardCornersSB(image, patternSize[, corners[, flags]]) -> retval, cornerscv.findChessboardCornersSBWithMeta(image, patternSize, flags[, corners[, meta]]) -> retval, corners, meta\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ findCirclesGrid() [1/2]\n\nbool cv::findCirclesGrid \n(\nInputArray \nimage, \n\nSize \npatternSize, \n\nOutputArray \ncenters, \n\nint \nflags, \n\nconst Ptr< FeatureDetector > & \nblobDetector, \n\nconst CirclesGridFinderParameters & \nparameters \n\n)\n\nPython:cv.findCirclesGrid(image, patternSize, flags, blobDetector, parameters[, centers]) -> retval, centerscv.findCirclesGrid(image, patternSize[, centers[, flags[, blobDetector]]]) -> retval, centers\n\n#include <opencv2/calib3d.hpp>\nFinds centers in the grid of circles. \nParameters\n\nimagegrid view of input circles; it must be an 8-bit grayscale or color image. \npatternSizenumber of circles per row and column ( patternSize = Size(points_per_row, points_per_colum) ). \ncentersoutput array of detected centers. \nflagsvarious operation flags that can be one of the following values:\nCALIB_CB_SYMMETRIC_GRID uses symmetric pattern of circles.\nCALIB_CB_ASYMMETRIC_GRID uses asymmetric pattern of circles.\nCALIB_CB_CLUSTERING uses a special algorithm for grid detection. It is more robust to perspective distortions but much more sensitive to background clutter. \n\nblobDetectorfeature detector that finds blobs like dark circles on light background. If blobDetector is NULL then image represents Point2f array of candidates. \nparametersstruct for finding circles in a grid pattern.\n\nThe function attempts to determine whether the input image contains a grid of circles. If it is, the function locates centers of the circles. The function returns a non-zero value if all of the centers have been found and they have been placed in a certain order (row by row, left to right in every row). Otherwise, if the function fails to find all the corners or reorder them, it returns 0.\nSample usage of detecting and drawing the centers of circles: : Size patternsize(7,7); //number of centers\nMat gray = ...; //source image\nvector<Point2f> centers; //this will be filled by the detected centers\n \nbool patternfound = findCirclesGrid(gray, patternsize, centers);\n \ndrawChessboardCorners(img, patternsize, Mat(centers), patternfound);\ncv::findCirclesGridbool findCirclesGrid(InputArray image, Size patternSize, OutputArray centers, int flags, const Ptr< FeatureDetector > &blobDetector, const CirclesGridFinderParameters &parameters)Finds centers in the grid of circles.\n NoteThe function requires white space (like a square-thick border, the wider the better) around the board to make the detection more robust in various environments. \n\n◆ findCirclesGrid() [2/2]\n\nbool cv::findCirclesGrid \n(\nInputArray \nimage, \n\nSize \npatternSize, \n\nOutputArray \ncenters, \n\nint \nflags = CALIB_CB_SYMMETRIC_GRID, \n\nconst Ptr< FeatureDetector > & \nblobDetector = SimpleBlobDetector::create() \n\n)\n\nPython:cv.findCirclesGrid(image, patternSize, flags, blobDetector, parameters[, centers]) -> retval, centerscv.findCirclesGrid(image, patternSize[, centers[, flags[, blobDetector]]]) -> retval, centers\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ findEssentialMat() [1/6]\n\nMat cv::findEssentialMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\ndouble \nfocal, \n\nPoint2d \npp, \n\nint \nmethod, \n\ndouble \nprob, \n\ndouble \nthreshold, \n\nOutputArray \nmask \n\n)\n\nPython:cv.findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, maxIters[, mask]]]]]) -> retval, maskcv.findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, maxIters[, mask]]]]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, method[, prob[, threshold[, mask]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ findEssentialMat() [2/6]\n\nMat cv::findEssentialMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\ndouble \nfocal = 1.0, \n\nPoint2d \npp = Point2d(0, 0), \n\nint \nmethod = RANSAC, \n\ndouble \nprob = 0.999, \n\ndouble \nthreshold = 1.0, \n\nint \nmaxIters = 1000, \n\nOutputArray \nmask = noArray() \n\n)\n\nPython:cv.findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, maxIters[, mask]]]]]) -> retval, maskcv.findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, maxIters[, mask]]]]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, method[, prob[, threshold[, mask]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\npoints1Array of N (N >= 5) 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1 . \nfocalfocal length of the camera. Note that this function assumes that points1 and points2 are feature points from cameras with same focal length and principal point. \nppprincipal point of the camera. \nmethodMethod for computing a fundamental matrix.\nRANSAC for the RANSAC algorithm.\nLMEDS for the LMedS algorithm. \n\nthresholdParameter used for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise. \nprobParameter used for the RANSAC or LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct. \nmaskOutput array of N elements, every element of which is set to 0 for outliers and to 1 for the other points. The array is computed only in the RANSAC and LMedS methods. \nmaxItersThe maximum number of robust method iterations.\n\nThis function differs from the one above that it computes camera intrinsic matrix from focal length and principal point:\n\n\\[A =\n\\begin{bmatrix}\nf & 0 & x_{pp}  \\\\\n0 & f & y_{pp}  \\\\\n0 & 0 & 1\n\\end{bmatrix}\\]\n\n◆ findEssentialMat() [3/6]\n\nMat cv::findEssentialMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix, \n\nint \nmethod, \n\ndouble \nprob, \n\ndouble \nthreshold, \n\nOutputArray \nmask \n\n)\n\nPython:cv.findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, maxIters[, mask]]]]]) -> retval, maskcv.findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, maxIters[, mask]]]]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, method[, prob[, threshold[, mask]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ findEssentialMat() [4/6]\n\nMat cv::findEssentialMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix, \n\nint \nmethod = RANSAC, \n\ndouble \nprob = 0.999, \n\ndouble \nthreshold = 1.0, \n\nint \nmaxIters = 1000, \n\nOutputArray \nmask = noArray() \n\n)\n\nPython:cv.findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, maxIters[, mask]]]]]) -> retval, maskcv.findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, maxIters[, mask]]]]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, method[, prob[, threshold[, mask]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nCalculates an essential matrix from the corresponding points in two images. \nParameters\n\npoints1Array of N (N >= 5) 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1. \ncameraMatrixCamera intrinsic matrix \\(\\cameramatrix{A}\\) . Note that this function assumes that points1 and points2 are feature points from cameras with the same camera intrinsic matrix. If this assumption does not hold for your use case, use another function overload or undistortPoints with P = cv::NoArray() for both cameras to transform image points to normalized image coordinates, which are valid for the identity camera intrinsic matrix. When passing these coordinates, pass the identity matrix for this parameter. \nmethodMethod for computing an essential matrix.\nRANSAC for the RANSAC algorithm.\nLMEDS for the LMedS algorithm. \n\nprobParameter used for the RANSAC or LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct. \nthresholdParameter used for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise. \nmaskOutput array of N elements, every element of which is set to 0 for outliers and to 1 for the other points. The array is computed only in the RANSAC and LMedS methods. \nmaxItersThe maximum number of robust method iterations.\n\nThis function estimates essential matrix based on the five-point algorithm solver in [209] . [252] is also a related. The epipolar geometry is described by the following equation:\n\n\\[[p_2; 1]^T K^{-T} E K^{-1} [p_1; 1] = 0\\]\n\nwhere \\(E\\) is an essential matrix, \\(p_1\\) and \\(p_2\\) are corresponding points in the first and the second images, respectively. The result of this function may be passed further to decomposeEssentialMat or recoverPose to recover the relative pose between cameras. \n\n◆ findEssentialMat() [5/6]\n\nMat cv::findEssentialMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix1, \n\nInputArray \ncameraMatrix2, \n\nInputArray \ndist_coeff1, \n\nInputArray \ndist_coeff2, \n\nOutputArray \nmask, \n\nconst UsacParams & \nparams \n\n)\n\nPython:cv.findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, maxIters[, mask]]]]]) -> retval, maskcv.findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, maxIters[, mask]]]]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, method[, prob[, threshold[, mask]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\n\n◆ findEssentialMat() [6/6]\n\nMat cv::findEssentialMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix1, \n\nInputArray \ndistCoeffs1, \n\nInputArray \ncameraMatrix2, \n\nInputArray \ndistCoeffs2, \n\nint \nmethod = RANSAC, \n\ndouble \nprob = 0.999, \n\ndouble \nthreshold = 1.0, \n\nOutputArray \nmask = noArray() \n\n)\n\nPython:cv.findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, maxIters[, mask]]]]]) -> retval, maskcv.findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, maxIters[, mask]]]]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, method[, prob[, threshold[, mask]]]]) -> retval, maskcv.findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nCalculates an essential matrix from the corresponding points in two images from potentially two different cameras. \nParameters\n\npoints1Array of N (N >= 5) 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1. \ncameraMatrix1Camera matrix for the first camera \\(K = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ncameraMatrix2Camera matrix for the second camera \\(K = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ndistCoeffs1Input vector of distortion coefficients for the first camera \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed. \ndistCoeffs2Input vector of distortion coefficients for the second camera \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed. \nmethodMethod for computing an essential matrix.\nRANSAC for the RANSAC algorithm.\nLMEDS for the LMedS algorithm. \n\nprobParameter used for the RANSAC or LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct. \nthresholdParameter used for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise. \nmaskOutput array of N elements, every element of which is set to 0 for outliers and to 1 for the other points. The array is computed only in the RANSAC and LMedS methods.\n\nThis function estimates essential matrix based on the five-point algorithm solver in [209] . [252] is also a related. The epipolar geometry is described by the following equation:\n\n\\[[p_2; 1]^T K^{-T} E K^{-1} [p_1; 1] = 0\\]\n\nwhere \\(E\\) is an essential matrix, \\(p_1\\) and \\(p_2\\) are corresponding points in the first and the second images, respectively. The result of this function may be passed further to decomposeEssentialMat or recoverPose to recover the relative pose between cameras. \n\n◆ findFundamentalMat() [1/4]\n\nMat cv::findFundamentalMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nint \nmethod, \n\ndouble \nransacReprojThreshold, \n\ndouble \nconfidence, \n\nint \nmaxIters, \n\nOutputArray \nmask = noArray() \n\n)\n\nPython:cv.findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters[, mask]) -> retval, maskcv.findFundamentalMat(points1, points2[, method[, ransacReprojThreshold[, confidence[, mask]]]]) -> retval, maskcv.findFundamentalMat(points1, points2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nCalculates a fundamental matrix from the corresponding points in two images. \nParameters\n\npoints1Array of N points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1 . \nmethodMethod for computing a fundamental matrix.\nFM_7POINT for a 7-point algorithm. \\(N = 7\\)\nFM_8POINT for an 8-point algorithm. \\(N \\ge 8\\)\nFM_RANSAC for the RANSAC algorithm. \\(N \\ge 8\\)\nFM_LMEDS for the LMedS algorithm. \\(N \\ge 8\\) \n\nransacReprojThresholdParameter used only for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise. \nconfidenceParameter used for the RANSAC and LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct. \n[out]maskoptional output mask \nmaxItersThe maximum number of robust method iterations.\n\nThe epipolar geometry is described by the following equation:\n\n\\[[p_2; 1]^T F [p_1; 1] = 0\\]\n\nwhere \\(F\\) is a fundamental matrix, \\(p_1\\) and \\(p_2\\) are corresponding points in the first and the second images, respectively.\nThe function calculates the fundamental matrix using one of four methods listed above and returns the found fundamental matrix. Normally just one matrix is found. But in case of the 7-point algorithm, the function may return up to 3 solutions ( \\(9 \\times 3\\) matrix that stores all 3 matrices sequentially).\nThe calculated fundamental matrix may be passed further to computeCorrespondEpilines that finds the epipolar lines corresponding to the specified points. It can also be passed to stereoRectifyUncalibrated to compute the rectification transformation. : // Example. Estimation of fundamental matrix using the RANSAC algorithm\nint point_count = 100;\nvector<Point2f> points1(point_count);\nvector<Point2f> points2(point_count);\n \n// initialize the points here ...\nfor( int i = 0; i < point_count; i++ )\n{\n    points1[i] = ...;\n    points2[i] = ...;\n}\n \nMat fundamental_matrix =\n findFundamentalMat(points1, points2, FM_RANSAC, 3, 0.99);\ncv::findFundamentalMatMat findFundamentalMat(InputArray points1, InputArray points2, int method, double ransacReprojThreshold, double confidence, int maxIters, OutputArray mask=noArray())Calculates a fundamental matrix from the corresponding points in two images.\ncv::FM_RANSAC@ FM_RANSACRANSAC algorithm. It needs at least 15 points. 7-point algorithm is used.Definition calib3d.hpp:533\n\n◆ findFundamentalMat() [2/4]\n\nMat cv::findFundamentalMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nint \nmethod = FM_RANSAC, \n\ndouble \nransacReprojThreshold = 3., \n\ndouble \nconfidence = 0.99, \n\nOutputArray \nmask = noArray() \n\n)\n\nPython:cv.findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters[, mask]) -> retval, maskcv.findFundamentalMat(points1, points2[, method[, ransacReprojThreshold[, confidence[, mask]]]]) -> retval, maskcv.findFundamentalMat(points1, points2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ findFundamentalMat() [3/4]\n\nMat cv::findFundamentalMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nOutputArray \nmask, \n\nconst UsacParams & \nparams \n\n)\n\nPython:cv.findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters[, mask]) -> retval, maskcv.findFundamentalMat(points1, points2[, method[, ransacReprojThreshold[, confidence[, mask]]]]) -> retval, maskcv.findFundamentalMat(points1, points2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\n\n◆ findFundamentalMat() [4/4]\n\nMat cv::findFundamentalMat \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nOutputArray \nmask, \n\nint \nmethod = FM_RANSAC, \n\ndouble \nransacReprojThreshold = 3., \n\ndouble \nconfidence = 0.99 \n\n)\n\nPython:cv.findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters[, mask]) -> retval, maskcv.findFundamentalMat(points1, points2[, method[, ransacReprojThreshold[, confidence[, mask]]]]) -> retval, maskcv.findFundamentalMat(points1, points2, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ findHomography() [1/3]\n\nMat cv::findHomography \n(\nInputArray \nsrcPoints, \n\nInputArray \ndstPoints, \n\nint \nmethod = 0, \n\ndouble \nransacReprojThreshold = 3, \n\nOutputArray \nmask = noArray(), \n\nconst int \nmaxIters = 2000, \n\nconst double \nconfidence = 0.995 \n\n)\n\nPython:cv.findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, maskcv.findHomography(srcPoints, dstPoints, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nFinds a perspective transformation between two planes. \nParameters\n\nsrcPointsCoordinates of the points in the original plane, a matrix of the type CV_32FC2 or vector<Point2f> . \ndstPointsCoordinates of the points in the target plane, a matrix of the type CV_32FC2 or a vector<Point2f> . \nmethodMethod used to compute a homography matrix. The following methods are possible:\n0 - a regular method using all the points, i.e., the least squares method\nRANSAC - RANSAC-based robust method\nLMEDS - Least-Median robust method\nRHO - PROSAC-based robust method \n\nransacReprojThresholdMaximum allowed reprojection error to treat a point pair as an inlier (used in the RANSAC and RHO methods only). That is, if \n\\[\\| \\texttt{dstPoints} _i -  \\texttt{convertPointsHomogeneous} ( \\texttt{H} \\cdot \\texttt{srcPoints} _i) \\|_2  >  \\texttt{ransacReprojThreshold}\\]\n\n then the point \\(i\\) is considered as an outlier. If srcPoints and dstPoints are measured in pixels, it usually makes sense to set this parameter somewhere in the range of 1 to 10. \nmaskOptional output mask set by a robust method ( RANSAC or LMeDS ). Note that the input mask values are ignored. \nmaxItersThe maximum number of RANSAC iterations. \nconfidenceConfidence level, between 0 and 1.\n\nThe function finds and returns the perspective transformation \\(H\\) between the source and the destination planes:\n\n\\[s_i  \\vecthree{x'_i}{y'_i}{1} \\sim H  \\vecthree{x_i}{y_i}{1}\\]\n\nso that the back-projection error\n\n\\[\\sum _i \\left ( x'_i- \\frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \\right )^2+ \\left ( y'_i- \\frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \\right )^2\\]\n\nis minimized. If the parameter method is set to the default value 0, the function uses all the point pairs to compute an initial homography estimate with a simple least-squares scheme.\nHowever, if not all of the point pairs ( \\(srcPoints_i\\), \\(dstPoints_i\\) ) fit the rigid perspective transformation (that is, there are some outliers), this initial estimate will be poor. In this case, you can use one of the three robust methods. The methods RANSAC, LMeDS and RHO try many different random subsets of the corresponding point pairs (of four pairs each, collinear pairs are discarded), estimate the homography matrix using this subset and a simple least-squares algorithm, and then compute the quality/goodness of the computed homography (which is the number of inliers for RANSAC or the least median re-projection error for LMeDS). The best subset is then used to produce the initial estimate of the homography matrix and the mask of inliers/outliers.\nRegardless of the method, robust or not, the computed homography matrix is refined further (using inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the re-projection error even more.\nThe methods RANSAC and RHO can handle practically any ratio of outliers but need a threshold to distinguish inliers from outliers. The method LMeDS does not need any threshold but it works correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the noise is rather small, use the default method (method=0).\nThe function is used to find initial intrinsic and extrinsic matrices. Homography matrix is determined up to a scale. If \\(h_{33}\\) is non-zero, the matrix is normalized so that \\(h_{33}=1\\). NoteWhenever an \\(H\\) matrix cannot be estimated, an empty one will be returned.\nSee alsogetAffineTransform, estimateAffine2D, estimateAffinePartial2D, getPerspectiveTransform, warpPerspective, perspectiveTransform \n\n◆ findHomography() [2/3]\n\nMat cv::findHomography \n(\nInputArray \nsrcPoints, \n\nInputArray \ndstPoints, \n\nOutputArray \nmask, \n\nconst UsacParams & \nparams \n\n)\n\nPython:cv.findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, maskcv.findHomography(srcPoints, dstPoints, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\n\n◆ findHomography() [3/3]\n\nMat cv::findHomography \n(\nInputArray \nsrcPoints, \n\nInputArray \ndstPoints, \n\nOutputArray \nmask, \n\nint \nmethod = 0, \n\ndouble \nransacReprojThreshold = 3 \n\n)\n\nPython:cv.findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, maskcv.findHomography(srcPoints, dstPoints, params[, mask]) -> retval, mask\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ getDefaultNewCameraMatrix()\n\nMat cv::getDefaultNewCameraMatrix \n(\nInputArray \ncameraMatrix, \n\nSize \nimgsize = Size(), \n\nbool \ncenterPrincipalPoint = false \n\n)\n\nPython:cv.getDefaultNewCameraMatrix(cameraMatrix[, imgsize[, centerPrincipalPoint]]) -> retval\n\n#include <opencv2/calib3d.hpp>\nReturns the default new camera matrix. \nThe function returns the camera matrix that is either an exact copy of the input cameraMatrix (when centerPrinicipalPoint=false ), or the modified one (when centerPrincipalPoint=true).\nIn the latter case, the new camera matrix will be:\n\n\\[\\begin{bmatrix} f_x && 0 && ( \\texttt{imgSize.width} -1)*0.5  \\\\ 0 && f_y && ( \\texttt{imgSize.height} -1)*0.5  \\\\ 0 && 0 && 1 \\end{bmatrix} ,\\]\n\nwhere \\(f_x\\) and \\(f_y\\) are \\((0,0)\\) and \\((1,1)\\) elements of cameraMatrix, respectively.\nBy default, the undistortion functions in OpenCV (see initUndistortRectifyMap, undistort) do not move the principal point. However, when you work with stereo, it is important to move the principal points in both views to the same y-coordinate (which is required by most of stereo correspondence algorithms), and may be to the same x-coordinate too. So, you can form the new camera matrix for each view where the principal points are located at the center.\nParameters\n\ncameraMatrixInput camera matrix. \nimgsizeCamera view image size in pixels. \ncenterPrincipalPointLocation of the principal point in the new camera matrix. The parameter indicates whether this location should be at the image center or not. \n\n◆ getOptimalNewCameraMatrix()\n\nMat cv::getOptimalNewCameraMatrix \n(\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nSize \nimageSize, \n\ndouble \nalpha, \n\nSize \nnewImgSize = Size(), \n\nRect * \nvalidPixROI = 0, \n\nbool \ncenterPrincipalPoint = false \n\n)\n\nPython:cv.getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, alpha[, newImgSize[, centerPrincipalPoint]]) -> retval, validPixROI\n\n#include <opencv2/calib3d.hpp>\nReturns the new camera intrinsic matrix based on the free scaling parameter. \nParameters\n\ncameraMatrixInput camera intrinsic matrix. \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nimageSizeOriginal image size. \nalphaFree scaling parameter between 0 (when all the pixels in the undistorted image are valid) and 1 (when all the source image pixels are retained in the undistorted image). See stereoRectify for details. \nnewImgSizeImage size after rectification. By default, it is set to imageSize . \nvalidPixROIOptional output rectangle that outlines all-good-pixels region in the undistorted image. See roi1, roi2 description in stereoRectify . \ncenterPrincipalPointOptional flag that indicates whether in the new camera intrinsic matrix the principal point should be at the image center or not. By default, the principal point is chosen to best fit a subset of the source image (determined by alpha) to the corrected image. \n\nReturnsnew_camera_matrix Output new camera intrinsic matrix.\nThe function computes and returns the optimal new camera intrinsic matrix based on the free scaling parameter. By varying this parameter, you may retrieve only sensible pixels alpha=0 , keep all the original image pixels if there is valuable information in the corners alpha=1 , or get something in between. When alpha>0 , the undistorted result is likely to have some black pixels corresponding to \"virtual\" pixels outside of the captured distorted image. The original camera intrinsic matrix, distortion coefficients, the computed new camera intrinsic matrix, and newImageSize should be passed to initUndistortRectifyMap to produce the maps for remap . \n\n◆ getValidDisparityROI()\n\nRect cv::getValidDisparityROI \n(\nRect \nroi1, \n\nRect \nroi2, \n\nint \nminDisparity, \n\nint \nnumberOfDisparities, \n\nint \nblockSize \n\n)\n\nPython:cv.getValidDisparityROI(roi1, roi2, minDisparity, numberOfDisparities, blockSize) -> retval\n\n#include <opencv2/calib3d.hpp>\ncomputes valid disparity ROI from the valid ROIs of the rectified images (that are returned by stereoRectify) \n\n◆ initCameraMatrix2D()\n\nMat cv::initCameraMatrix2D \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints, \n\nSize \nimageSize, \n\ndouble \naspectRatio = 1.0 \n\n)\n\nPython:cv.initCameraMatrix2D(objectPoints, imagePoints, imageSize[, aspectRatio]) -> retval\n\n#include <opencv2/calib3d.hpp>\nFinds an initial camera intrinsic matrix from 3D-2D point correspondences. \nParameters\n\nobjectPointsVector of vectors of the calibration pattern points in the calibration pattern coordinate space. In the old interface all the per-view vectors are concatenated. See calibrateCamera for details. \nimagePointsVector of vectors of the projections of the calibration pattern points. In the old interface all the per-view vectors are concatenated. \nimageSizeImage size in pixels used to initialize the principal point. \naspectRatioIf it is zero or negative, both \\(f_x\\) and \\(f_y\\) are estimated independently. Otherwise, \\(f_x = f_y \\cdot \\texttt{aspectRatio}\\) .\n\nThe function estimates and returns an initial camera intrinsic matrix for the camera calibration process. Currently, the function only supports planar calibration patterns, which are patterns where each object point has z-coordinate =0. \n\n◆ initInverseRectificationMap()\n\nvoid cv::initInverseRectificationMap \n(\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputArray \nR, \n\nInputArray \nnewCameraMatrix, \n\nconst Size & \nsize, \n\nint \nm1type, \n\nOutputArray \nmap1, \n\nOutputArray \nmap2 \n\n)\n\nPython:cv.initInverseRectificationMap(cameraMatrix, distCoeffs, R, newCameraMatrix, size, m1type[, map1[, map2]]) -> map1, map2\n\n#include <opencv2/calib3d.hpp>\nComputes the projection and inverse-rectification transformation map. In essense, this is the inverse of initUndistortRectifyMap to accomodate stereo-rectification of projectors ('inverse-cameras') in projector-camera pairs. \nThe function computes the joint projection and inverse rectification transformation and represents the result in the form of maps for remap. The projected image looks like a distorted version of the original which, once projected by a projector, should visually match the original. In case of a monocular camera, newCameraMatrix is usually equal to cameraMatrix, or it can be computed by getOptimalNewCameraMatrix for a better control over scaling. In case of a projector-camera pair, newCameraMatrix is normally set to P1 or P2 computed by stereoRectify .\nThe projector is oriented differently in the coordinate space, according to R. In case of projector-camera pairs, this helps align the projector (in the same manner as initUndistortRectifyMap for the camera) to create a stereo-rectified pair. This allows epipolar lines on both images to become horizontal and have the same y-coordinate (in case of a horizontally aligned projector-camera pair).\nThe function builds the maps for the inverse mapping algorithm that is used by remap. That is, for each pixel \\((u, v)\\) in the destination (projected and inverse-rectified) image, the function computes the corresponding coordinates in the source image (that is, in the original digital image). The following process is applied:\n\n\\[\n\\begin{array}{l}\n\\text{newCameraMatrix}\\\\\nx  \\leftarrow (u - {c'}_x)/{f'}_x  \\\\\ny  \\leftarrow (v - {c'}_y)/{f'}_y  \\\\\n\n\\\\\\text{Undistortion}\n\\\\\\scriptsize{\\textit{though equation shown is for radial undistortion, function implements cv::undistortPoints()}}\\\\\nr^2  \\leftarrow x^2 + y^2 \\\\\n\\theta \\leftarrow \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\\\\\nx' \\leftarrow \\frac{x}{\\theta} \\\\\ny'  \\leftarrow \\frac{y}{\\theta} \\\\\n\n\\\\\\text{Rectification}\\\\\n{[X\\,Y\\,W]} ^T  \\leftarrow R*[x' \\, y' \\, 1]^T  \\\\\nx''  \\leftarrow X/W  \\\\\ny''  \\leftarrow Y/W  \\\\\n\n\\\\\\text{cameraMatrix}\\\\\nmap_x(u,v)  \\leftarrow x'' f_x + c_x  \\\\\nmap_y(u,v)  \\leftarrow y'' f_y + c_y\n\\end{array}\n\\]\n\n where \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) are the distortion coefficients vector distCoeffs.\nIn case of a stereo-rectified projector-camera pair, this function is called for the projector while initUndistortRectifyMap is called for the camera head. This is done after stereoRectify, which in turn is called after stereoCalibrate. If the projector-camera pair is not calibrated, it is still possible to compute the rectification transformations directly from the fundamental matrix using stereoRectifyUncalibrated. For the projector and camera, the function computes homography H as the rectification transformation in a pixel domain, not a rotation matrix R in 3D space. R can be computed from H as \n\\[\\texttt{R} = \\texttt{cameraMatrix} ^{-1} \\cdot \\texttt{H} \\cdot \\texttt{cameraMatrix}\\]\n\n where cameraMatrix can be chosen arbitrarily.\nParameters\n\ncameraMatrixInput camera matrix \\(A=\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ndistCoeffsInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed. \nROptional rectification transformation in the object space (3x3 matrix). R1 or R2, computed by stereoRectify can be passed here. If the matrix is empty, the identity transformation is assumed. \nnewCameraMatrixNew camera matrix \\(A'=\\vecthreethree{f_x'}{0}{c_x'}{0}{f_y'}{c_y'}{0}{0}{1}\\). \nsizeDistorted image size. \nm1typeType of the first output map. Can be CV_32FC1, CV_32FC2 or CV_16SC2, see convertMaps \nmap1The first output map for remap. \nmap2The second output map for remap. \n\n◆ initUndistortRectifyMap()\n\nvoid cv::initUndistortRectifyMap \n(\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputArray \nR, \n\nInputArray \nnewCameraMatrix, \n\nSize \nsize, \n\nint \nm1type, \n\nOutputArray \nmap1, \n\nOutputArray \nmap2 \n\n)\n\nPython:cv.initUndistortRectifyMap(cameraMatrix, distCoeffs, R, newCameraMatrix, size, m1type[, map1[, map2]]) -> map1, map2\n\n#include <opencv2/calib3d.hpp>\nComputes the undistortion and rectification transformation map. \nThe function computes the joint undistortion and rectification transformation and represents the result in the form of maps for remap. The undistorted image looks like original, as if it is captured with a camera using the camera matrix =newCameraMatrix and zero distortion. In case of a monocular camera, newCameraMatrix is usually equal to cameraMatrix, or it can be computed by getOptimalNewCameraMatrix for a better control over scaling. In case of a stereo camera, newCameraMatrix is normally set to P1 or P2 computed by stereoRectify .\nAlso, this new camera is oriented differently in the coordinate space, according to R. That, for example, helps to align two heads of a stereo camera so that the epipolar lines on both images become horizontal and have the same y- coordinate (in case of a horizontally aligned stereo camera).\nThe function actually builds the maps for the inverse mapping algorithm that is used by remap. That is, for each pixel \\((u, v)\\) in the destination (corrected and rectified) image, the function computes the corresponding coordinates in the source image (that is, in the original image from camera). The following process is applied:  \n\\[\n\\begin{array}{l}\nx  \\leftarrow (u - {c'}_x)/{f'}_x  \\\\\ny  \\leftarrow (v - {c'}_y)/{f'}_y  \\\\\n{[X\\,Y\\,W]} ^T  \\leftarrow R^{-1}*[x \\, y \\, 1]^T  \\\\\nx'  \\leftarrow X/W  \\\\\ny'  \\leftarrow Y/W  \\\\\nr^2  \\leftarrow x'^2 + y'^2 \\\\\nx''  \\leftarrow x' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\n+ 2p_1 x' y' + p_2(r^2 + 2 x'^2)  + s_1 r^2 + s_2 r^4\\\\\ny''  \\leftarrow y' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\n+ p_1 (r^2 + 2 y'^2) + 2 p_2 x' y' + s_3 r^2 + s_4 r^4 \\\\\ns\\vecthree{x'''}{y'''}{1} =\n\\vecthreethree{R_{33}(\\tau_x, \\tau_y)}{0}{-R_{13}((\\tau_x, \\tau_y)}\n{0}{R_{33}(\\tau_x, \\tau_y)}{-R_{23}(\\tau_x, \\tau_y)}\n{0}{0}{1} R(\\tau_x, \\tau_y) \\vecthree{x''}{y''}{1}\\\\\nmap_x(u,v)  \\leftarrow x''' f_x + c_x  \\\\\nmap_y(u,v)  \\leftarrow y''' f_y + c_y\n\\end{array}\n\\]\n\n where \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) are the distortion coefficients.\nIn case of a stereo camera, this function is called twice: once for each camera head, after stereoRectify, which in its turn is called after stereoCalibrate. But if the stereo camera was not calibrated, it is still possible to compute the rectification transformations directly from the fundamental matrix using stereoRectifyUncalibrated. For each camera, the function computes homography H as the rectification transformation in a pixel domain, not a rotation matrix R in 3D space. R can be computed from H as \n\\[\\texttt{R} = \\texttt{cameraMatrix} ^{-1} \\cdot \\texttt{H} \\cdot \\texttt{cameraMatrix}\\]\n\n where cameraMatrix can be chosen arbitrarily.\nParameters\n\ncameraMatrixInput camera matrix \\(A=\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ndistCoeffsInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed. \nROptional rectification transformation in the object space (3x3 matrix). R1 or R2 , computed by stereoRectify can be passed here. If the matrix is empty, the identity transformation is assumed. In initUndistortRectifyMap R assumed to be an identity matrix. \nnewCameraMatrixNew camera matrix \\(A'=\\vecthreethree{f_x'}{0}{c_x'}{0}{f_y'}{c_y'}{0}{0}{1}\\). \nsizeUndistorted image size. \nm1typeType of the first output map that can be CV_32FC1, CV_32FC2 or CV_16SC2, see convertMaps \nmap1The first output map. \nmap2The second output map. \n\n◆ initWideAngleProjMap() [1/2]\n\nfloat cv::initWideAngleProjMap \n(\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nSize \nimageSize, \n\nint \ndestImageWidth, \n\nint \nm1type, \n\nOutputArray \nmap1, \n\nOutputArray \nmap2, \n\nenum UndistortTypes \nprojType = PROJ_SPHERICAL_EQRECT, \n\ndouble \nalpha = 0 \n\n)\n\n#include <opencv2/calib3d.hpp>\ninitializes maps for remap for wide-angle \n\n◆ initWideAngleProjMap() [2/2]\n\nstatic float cv::initWideAngleProjMap \n(\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nSize \nimageSize, \n\nint \ndestImageWidth, \n\nint \nm1type, \n\nOutputArray \nmap1, \n\nOutputArray \nmap2, \n\nint \nprojType, \n\ndouble \nalpha = 0 \n\n)\n\ninlinestatic \n\n#include <opencv2/calib3d.hpp>\n\nHere is the call graph for this function:\n\nThis browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.\n\n◆ matMulDeriv()\n\nvoid cv::matMulDeriv \n(\nInputArray \nA, \n\nInputArray \nB, \n\nOutputArray \ndABdA, \n\nOutputArray \ndABdB \n\n)\n\nPython:cv.matMulDeriv(A, B[, dABdA[, dABdB]]) -> dABdA, dABdB\n\n#include <opencv2/calib3d.hpp>\nComputes partial derivatives of the matrix product for each multiplied matrix. \nParameters\n\nAFirst multiplied matrix. \nBSecond multiplied matrix. \ndABdAFirst output derivative matrix d(A*B)/dA of size \\(\\texttt{A.rows*B.cols} \\times {A.rows*A.cols}\\) . \ndABdBSecond output derivative matrix d(A*B)/dB of size \\(\\texttt{A.rows*B.cols} \\times {B.rows*B.cols}\\) .\n\nThe function computes partial derivatives of the elements of the matrix product \\(A*B\\) with regard to the elements of each of the two input matrices. The function is used to compute the Jacobian matrices in stereoCalibrate but can also be used in any other similar optimization function. \n\n◆ projectPoints()\n\nvoid cv::projectPoints \n(\nInputArray \nobjectPoints, \n\nInputArray \nrvec, \n\nInputArray \ntvec, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArray \nimagePoints, \n\nOutputArray \njacobian = noArray(), \n\ndouble \naspectRatio = 0 \n\n)\n\nPython:cv.projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs[, imagePoints[, jacobian[, aspectRatio]]]) -> imagePoints, jacobian\n\n#include <opencv2/calib3d.hpp>\nProjects 3D points to an image plane. \nParameters\n\nobjectPointsArray of object points expressed wrt. the world coordinate frame. A 3xN/Nx3 1-channel or 1xN/Nx1 3-channel (or vector<Point3f> ), where N is the number of points in the view. \nrvecThe rotation vector (Rodrigues) that, together with tvec, performs a change of basis from world to camera coordinate system, see calibrateCamera for details. \ntvecThe translation vector, see parameter description above. \ncameraMatrixCamera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\) . If the vector is empty, the zero distortion coefficients are assumed. \nimagePointsOutput array of image points, 1xN/Nx1 2-channel, or vector<Point2f> . \njacobianOptional output 2Nx(10+<numDistCoeffs>) jacobian matrix of derivatives of image points with respect to components of the rotation vector, translation vector, focal lengths, coordinates of the principal point and the distortion coefficients. In the old interface different components of the jacobian are returned via different output parameters. \naspectRatioOptional \"fixed aspect ratio\" parameter. If the parameter is not 0, the function assumes that the aspect ratio ( \\(f_x / f_y\\)) is fixed and correspondingly adjusts the jacobian matrix.\n\nThe function computes the 2D projections of 3D points to the image plane, given intrinsic and extrinsic camera parameters. Optionally, the function computes Jacobians -matrices of partial derivatives of image points coordinates (as functions of all the input parameters) with respect to the particular parameters, intrinsic and/or extrinsic. The Jacobians are used during the global optimization in calibrateCamera, solvePnP, and stereoCalibrate. The function itself can also be used to compute a re-projection error, given the current intrinsic and extrinsic parameters.\nNoteBy setting rvec = tvec = \\([0, 0, 0]\\), or by setting cameraMatrix to a 3x3 identity matrix, or by passing zero distortion coefficients, one can get various useful partial cases of the function. This means, one can compute the distorted coordinates for a sparse set of points or apply a perspective transformation (and also compute the derivatives) in the ideal zero-distortion setup. \n\n◆ recoverPose() [1/4]\n\nint cv::recoverPose \n(\nInputArray \nE, \n\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix, \n\nOutputArray \nR, \n\nOutputArray \nt, \n\ndouble \ndistanceThresh, \n\nInputOutputArray \nmask = noArray(), \n\nOutputArray \ntriangulatedPoints = noArray() \n\n)\n\nPython:cv.recoverPose(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, E[, R[, t[, method[, prob[, threshold[, mask]]]]]]]) -> retval, E, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix[, R[, t[, mask]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2[, R[, t[, focal[, pp[, mask]]]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix, distanceThresh[, R[, t[, mask[, triangulatedPoints]]]]) -> retval, R, t, mask, triangulatedPoints\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nEThe input essential matrix. \npoints1Array of N 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1. \ncameraMatrixCamera intrinsic matrix \\(\\cameramatrix{A}\\) . Note that this function assumes that points1 and points2 are feature points from cameras with the same camera intrinsic matrix. \nROutput rotation matrix. Together with the translation vector, this matrix makes up a tuple that performs a change of basis from the first camera's coordinate system to the second camera's coordinate system. Note that, in general, t can not be used for this tuple, see the parameter description below. \ntOutput translation vector. This vector is obtained by decomposeEssentialMat and therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit length. \ndistanceThreshthreshold distance which is used to filter out far away points (i.e. infinite points). \nmaskInput/output mask for inliers in points1 and points2. If it is not empty, then it marks inliers in points1 and points2 for the given essential matrix E. Only these inliers will be used to recover pose. In the output mask only inliers which pass the chirality check. \ntriangulatedPoints3D points which were reconstructed by triangulation.\n\nThis function differs from the one above that it outputs the triangulated 3D point that are used for the chirality check. \n\n◆ recoverPose() [2/4]\n\nint cv::recoverPose \n(\nInputArray \nE, \n\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix, \n\nOutputArray \nR, \n\nOutputArray \nt, \n\nInputOutputArray \nmask = noArray() \n\n)\n\nPython:cv.recoverPose(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, E[, R[, t[, method[, prob[, threshold[, mask]]]]]]]) -> retval, E, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix[, R[, t[, mask]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2[, R[, t[, focal[, pp[, mask]]]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix, distanceThresh[, R[, t[, mask[, triangulatedPoints]]]]) -> retval, R, t, mask, triangulatedPoints\n\n#include <opencv2/calib3d.hpp>\nRecovers the relative camera rotation and the translation from an estimated essential matrix and the corresponding points in two images, using chirality check. Returns the number of inliers that pass the check. \nParameters\n\nEThe input essential matrix. \npoints1Array of N 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1 . \ncameraMatrixCamera intrinsic matrix \\(\\cameramatrix{A}\\) . Note that this function assumes that points1 and points2 are feature points from cameras with the same camera intrinsic matrix. \nROutput rotation matrix. Together with the translation vector, this matrix makes up a tuple that performs a change of basis from the first camera's coordinate system to the second camera's coordinate system. Note that, in general, t can not be used for this tuple, see the parameter described below. \ntOutput translation vector. This vector is obtained by decomposeEssentialMat and therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit length. \nmaskInput/output mask for inliers in points1 and points2. If it is not empty, then it marks inliers in points1 and points2 for the given essential matrix E. Only these inliers will be used to recover pose. In the output mask only inliers which pass the chirality check.\n\nThis function decomposes an essential matrix using decomposeEssentialMat and then verifies possible pose hypotheses by doing chirality check. The chirality check means that the triangulated 3D points should have positive depth. Some details can be found in [209].\nThis function can be used to process the output E and mask from findEssentialMat. In this scenario, points1 and points2 are the same input for findEssentialMat : // Example. Estimation of fundamental matrix using the RANSAC algorithm\nint point_count = 100;\nvector<Point2f> points1(point_count);\nvector<Point2f> points2(point_count);\n \n// initialize the points here ...\nfor( int i = 0; i < point_count; i++ )\n{\n    points1[i] = ...;\n    points2[i] = ...;\n}\n \n// cametra matrix with both focal lengths = 1, and principal point = (0, 0)\nMat cameraMatrix = Mat::eye(3, 3, CV_64F);\n \nMat E, R, t, mask;\n \nE = findEssentialMat(points1, points2, cameraMatrix, RANSAC, 0.999, 1.0, mask);\nrecoverPose(E, points1, points2, cameraMatrix, R, t, mask);\ncv::Mat::eyestatic CV_NODISCARD_STD MatExpr eye(int rows, int cols, int type)Returns an identity matrix of the specified size and type.\ncv::recoverPoseint recoverPose(InputArray points1, InputArray points2, InputArray cameraMatrix1, InputArray distCoeffs1, InputArray cameraMatrix2, InputArray distCoeffs2, OutputArray E, OutputArray R, OutputArray t, int method=cv::RANSAC, double prob=0.999, double threshold=1.0, InputOutputArray mask=noArray())Recovers the relative camera rotation and the translation from corresponding points in two images fro...\ncv::findEssentialMatMat findEssentialMat(InputArray points1, InputArray points2, InputArray cameraMatrix, int method=RANSAC, double prob=0.999, double threshold=1.0, int maxIters=1000, OutputArray mask=noArray())Calculates an essential matrix from the corresponding points in two images.\ncv::RANSAC@ RANSACRANSAC algorithm.Definition calib3d.hpp:448\nCV_64F#define CV_64FDefinition interface.h:79\n\n◆ recoverPose() [3/4]\n\nint cv::recoverPose \n(\nInputArray \nE, \n\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nOutputArray \nR, \n\nOutputArray \nt, \n\ndouble \nfocal = 1.0, \n\nPoint2d \npp = Point2d(0, 0), \n\nInputOutputArray \nmask = noArray() \n\n)\n\nPython:cv.recoverPose(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, E[, R[, t[, method[, prob[, threshold[, mask]]]]]]]) -> retval, E, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix[, R[, t[, mask]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2[, R[, t[, focal[, pp[, mask]]]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix, distanceThresh[, R[, t[, mask[, triangulatedPoints]]]]) -> retval, R, t, mask, triangulatedPoints\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. Parameters\n\nEThe input essential matrix. \npoints1Array of N 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1 . \nROutput rotation matrix. Together with the translation vector, this matrix makes up a tuple that performs a change of basis from the first camera's coordinate system to the second camera's coordinate system. Note that, in general, t can not be used for this tuple, see the parameter description below. \ntOutput translation vector. This vector is obtained by decomposeEssentialMat and therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit length. \nfocalFocal length of the camera. Note that this function assumes that points1 and points2 are feature points from cameras with same focal length and principal point. \nppprincipal point of the camera. \nmaskInput/output mask for inliers in points1 and points2. If it is not empty, then it marks inliers in points1 and points2 for the given essential matrix E. Only these inliers will be used to recover pose. In the output mask only inliers which pass the chirality check.\n\nThis function differs from the one above that it computes camera intrinsic matrix from focal length and principal point:\n\n\\[A =\n\\begin{bmatrix}\nf & 0 & x_{pp}  \\\\\n0 & f & y_{pp}  \\\\\n0 & 0 & 1\n\\end{bmatrix}\\]\n\n◆ recoverPose() [4/4]\n\nint cv::recoverPose \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \ncameraMatrix1, \n\nInputArray \ndistCoeffs1, \n\nInputArray \ncameraMatrix2, \n\nInputArray \ndistCoeffs2, \n\nOutputArray \nE, \n\nOutputArray \nR, \n\nOutputArray \nt, \n\nint \nmethod = cv::RANSAC, \n\ndouble \nprob = 0.999, \n\ndouble \nthreshold = 1.0, \n\nInputOutputArray \nmask = noArray() \n\n)\n\nPython:cv.recoverPose(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2[, E[, R[, t[, method[, prob[, threshold[, mask]]]]]]]) -> retval, E, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix[, R[, t[, mask]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2[, R[, t[, focal[, pp[, mask]]]]]) -> retval, R, t, maskcv.recoverPose(E, points1, points2, cameraMatrix, distanceThresh[, R[, t[, mask[, triangulatedPoints]]]]) -> retval, R, t, mask, triangulatedPoints\n\n#include <opencv2/calib3d.hpp>\nRecovers the relative camera rotation and the translation from corresponding points in two images from two different cameras, using cheirality check. Returns the number of inliers that pass the check. \nParameters\n\npoints1Array of N 2D points from the first image. The point coordinates should be floating-point (single or double precision). \npoints2Array of the second image points of the same size and format as points1 . \ncameraMatrix1Input/output camera matrix for the first camera, the same as in calibrateCamera. Furthermore, for the stereo case, additional flags may be used, see below. \ndistCoeffs1Input/output vector of distortion coefficients, the same as in calibrateCamera. \ncameraMatrix2Input/output camera matrix for the first camera, the same as in calibrateCamera. Furthermore, for the stereo case, additional flags may be used, see below. \ndistCoeffs2Input/output vector of distortion coefficients, the same as in calibrateCamera. \nEThe output essential matrix. \nROutput rotation matrix. Together with the translation vector, this matrix makes up a tuple that performs a change of basis from the first camera's coordinate system to the second camera's coordinate system. Note that, in general, t can not be used for this tuple, see the parameter described below. \ntOutput translation vector. This vector is obtained by decomposeEssentialMat and therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit length. \nmethodMethod for computing an essential matrix.\nRANSAC for the RANSAC algorithm.\nLMEDS for the LMedS algorithm. \n\nprobParameter used for the RANSAC or LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct. \nthresholdParameter used for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise. \nmaskInput/output mask for inliers in points1 and points2. If it is not empty, then it marks inliers in points1 and points2 for then given essential matrix E. Only these inliers will be used to recover pose. In the output mask only inliers which pass the cheirality check.\n\nThis function decomposes an essential matrix using decomposeEssentialMat and then verifies possible pose hypotheses by doing cheirality check. The cheirality check means that the triangulated 3D points should have positive depth. Some details can be found in [209].\nThis function can be used to process the output E and mask from findEssentialMat. In this scenario, points1 and points2 are the same input for findEssentialMat.: // Example. Estimation of fundamental matrix using the RANSAC algorithm\nint point_count = 100;\nvector<Point2f> points1(point_count);\nvector<Point2f> points2(point_count);\n \n// initialize the points here ...\nfor( int i = 0; i < point_count; i++ )\n{\n    points1[i] = ...;\n    points2[i] = ...;\n}\n \n// Input: camera calibration of both cameras, for example using intrinsic chessboard calibration.\nMat cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2;\n \n// Output: Essential matrix, relative rotation and relative translation.\nMat E, R, t, mask;\n \nrecoverPose(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, E, R, t, mask);\n\n◆ rectify3Collinear()\n\nfloat cv::rectify3Collinear \n(\nInputArray \ncameraMatrix1, \n\nInputArray \ndistCoeffs1, \n\nInputArray \ncameraMatrix2, \n\nInputArray \ndistCoeffs2, \n\nInputArray \ncameraMatrix3, \n\nInputArray \ndistCoeffs3, \n\nInputArrayOfArrays \nimgpt1, \n\nInputArrayOfArrays \nimgpt3, \n\nSize \nimageSize, \n\nInputArray \nR12, \n\nInputArray \nT12, \n\nInputArray \nR13, \n\nInputArray \nT13, \n\nOutputArray \nR1, \n\nOutputArray \nR2, \n\nOutputArray \nR3, \n\nOutputArray \nP1, \n\nOutputArray \nP2, \n\nOutputArray \nP3, \n\nOutputArray \nQ, \n\ndouble \nalpha, \n\nSize \nnewImgSize, \n\nRect * \nroi1, \n\nRect * \nroi2, \n\nint \nflags \n\n)\n\nPython:cv.rectify3Collinear(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, cameraMatrix3, distCoeffs3, imgpt1, imgpt3, imageSize, R12, T12, R13, T13, alpha, newImgSize, flags[, R1[, R2[, R3[, P1[, P2[, P3[, Q]]]]]]]) -> retval, R1, R2, R3, P1, P2, P3, Q, roi1, roi2\n\n#include <opencv2/calib3d.hpp>\ncomputes the rectification transformations for 3-head camera, where all the heads are on the same line. \n\n◆ reprojectImageTo3D()\n\nvoid cv::reprojectImageTo3D \n(\nInputArray \ndisparity, \n\nOutputArray \n_3dImage, \n\nInputArray \nQ, \n\nbool \nhandleMissingValues = false, \n\nint \nddepth = -1 \n\n)\n\nPython:cv.reprojectImageTo3D(disparity, Q[, _3dImage[, handleMissingValues[, ddepth]]]) -> _3dImage\n\n#include <opencv2/calib3d.hpp>\nReprojects a disparity image to 3D space. \nParameters\n\ndisparityInput single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit floating-point disparity image. The values of 8-bit / 16-bit signed formats are assumed to have no fractional bits. If the disparity is 16-bit signed format, as computed by StereoBM or StereoSGBM and maybe other algorithms, it should be divided by 16 (and scaled to float) before being used here. \n_3dImageOutput 3-channel floating-point image of the same size as disparity. Each element of _3dImage(x,y) contains 3D coordinates of the point (x,y) computed from the disparity map. If one uses Q obtained by stereoRectify, then the returned points are represented in the first camera's rectified coordinate system. \nQ\\(4 \\times 4\\) perspective transformation matrix that can be obtained with stereoRectify. \nhandleMissingValuesIndicates, whether the function should handle missing values (i.e. points where the disparity was not computed). If handleMissingValues=true, then pixels with the minimal disparity that corresponds to the outliers (see StereoMatcher::compute ) are transformed to 3D points with a very large Z value (currently set to 10000). \nddepthThe optional output array depth. If it is -1, the output image will have CV_32F depth. ddepth can also be set to CV_16S, CV_32S or CV_32F.\n\nThe function transforms a single-channel disparity map to a 3-channel image representing a 3D surface. That is, for each pixel (x,y) and the corresponding disparity d=disparity(x,y) , it computes:\n\n\\[\\begin{bmatrix}\nX \\\\\nY \\\\\nZ \\\\\nW\n\\end{bmatrix} = Q \\begin{bmatrix}\nx \\\\\ny \\\\\n\\texttt{disparity} (x,y) \\\\\n1\n\\end{bmatrix}.\\]\n\nSee alsoTo reproject a sparse set of points {(x,y,d),...} to 3D space, use perspectiveTransform. \n\n◆ Rodrigues()\n\nvoid cv::Rodrigues \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nOutputArray \njacobian = noArray() \n\n)\n\nPython:cv.Rodrigues(src[, dst[, jacobian]]) -> dst, jacobian\n\n#include <opencv2/calib3d.hpp>\nConverts a rotation matrix to a rotation vector or vice versa. \nParameters\n\nsrcInput rotation vector (3x1 or 1x3) or rotation matrix (3x3). \ndstOutput rotation matrix (3x3) or rotation vector (3x1 or 1x3), respectively. \njacobianOptional output Jacobian matrix, 3x9 or 9x3, which is a matrix of partial derivatives of the output array components with respect to the input array components.\n\n\\[\\begin{array}{l} \\theta \\leftarrow norm(r) \\\\ r  \\leftarrow r/ \\theta \\\\ R =  \\cos(\\theta) I + (1- \\cos{\\theta} ) r r^T +  \\sin(\\theta) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} \\end{array}\\]\n\nInverse transformation can be also done easily, since\n\n\\[\\sin ( \\theta ) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} = \\frac{R - R^T}{2}\\]\n\nA rotation vector is a convenient and most compact representation of a rotation matrix (since any rotation matrix has just 3 degrees of freedom). The representation is used in the global 3D geometry optimization procedures like calibrateCamera, stereoCalibrate, or solvePnP .\nNoteMore information about the computation of the derivative of a 3D rotation matrix with respect to its exponential coordinate can be found in:\nA Compact Formula for the Derivative of a 3-D Rotation in Exponential Coordinates, Guillermo Gallego, Anthony J. Yezzi [97]\n\nUseful information on SE(3) and Lie Groups can be found in:\nA tutorial on SE(3) transformation parameterizations and on-manifold optimization, Jose-Luis Blanco [29]\nLie Groups for 2D and 3D Transformation, Ethan Eade [78]\nA micro Lie theory for state estimation in robotics, Joan Solà, Jérémie Deray, Dinesh Atchuthan [249] \n\n◆ RQDecomp3x3()\n\nVec3d cv::RQDecomp3x3 \n(\nInputArray \nsrc, \n\nOutputArray \nmtxR, \n\nOutputArray \nmtxQ, \n\nOutputArray \nQx = noArray(), \n\nOutputArray \nQy = noArray(), \n\nOutputArray \nQz = noArray() \n\n)\n\nPython:cv.RQDecomp3x3(src[, mtxR[, mtxQ[, Qx[, Qy[, Qz]]]]]) -> retval, mtxR, mtxQ, Qx, Qy, Qz\n\n#include <opencv2/calib3d.hpp>\nComputes an RQ decomposition of 3x3 matrices. \nParameters\n\nsrc3x3 input matrix. \nmtxROutput 3x3 upper-triangular matrix. \nmtxQOutput 3x3 orthogonal matrix. \nQxOptional output 3x3 rotation matrix around x-axis. \nQyOptional output 3x3 rotation matrix around y-axis. \nQzOptional output 3x3 rotation matrix around z-axis.\n\nThe function computes a RQ decomposition using the given rotations. This function is used in decomposeProjectionMatrix to decompose the left 3x3 submatrix of a projection matrix into a camera and a rotation matrix.\nIt optionally returns three rotation matrices, one for each axis, and the three Euler angles in degrees (as the return value) that could be used in OpenGL. Note, there is always more than one sequence of rotations about the three principal axes that results in the same orientation of an object, e.g. see [248] . Returned three rotation matrices and corresponding three Euler angles are only one of the possible solutions. \n\n◆ sampsonDistance()\n\ndouble cv::sampsonDistance \n(\nInputArray \npt1, \n\nInputArray \npt2, \n\nInputArray \nF \n\n)\n\nPython:cv.sampsonDistance(pt1, pt2, F) -> retval\n\n#include <opencv2/calib3d.hpp>\nCalculates the Sampson Distance between two points. \nThe function cv::sampsonDistance calculates and returns the first order approximation of the geometric error as:  \n\\[\nsd( \\texttt{pt1} , \\texttt{pt2} )=\n\\frac{(\\texttt{pt2}^t \\cdot \\texttt{F} \\cdot \\texttt{pt1})^2}\n{((\\texttt{F} \\cdot \\texttt{pt1})(0))^2 +\n((\\texttt{F} \\cdot \\texttt{pt1})(1))^2 +\n((\\texttt{F}^t \\cdot \\texttt{pt2})(0))^2 +\n((\\texttt{F}^t \\cdot \\texttt{pt2})(1))^2}\n\\]\n\n The fundamental matrix may be calculated using the findFundamentalMat function. See [117] 11.4.3 for details. Parameters\n\npt1first homogeneous 2d point \npt2second homogeneous 2d point \nFfundamental matrix \n\nReturnsThe computed Sampson distance. \n\n◆ solveP3P()\n\nint cv::solveP3P \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nint \nflags \n\n)\n\nPython:cv.solveP3P(objectPoints, imagePoints, cameraMatrix, distCoeffs, flags[, rvecs[, tvecs]]) -> retval, rvecs, tvecs\n\n#include <opencv2/calib3d.hpp>\nFinds an object pose from 3 3D-2D point correspondences. \nSee alsoPerspective-n-Point (PnP) pose computation\nParameters\n\nobjectPointsArray of object points in the object coordinate space, 3x3 1-channel or 1x3/3x1 3-channel. vector<Point3f> can be also passed here. \nimagePointsArray of corresponding image points, 3x2 1-channel or 1x3/3x1 2-channel. vector<Point2f> can be also passed here. \ncameraMatrixInput camera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nrvecsOutput rotation vectors (see Rodrigues ) that, together with tvecs, brings points from the model coordinate system to the camera coordinate system. A P3P problem has up to 4 solutions. \ntvecsOutput translation vectors. \nflagsMethod for solving a P3P problem:\nSOLVEPNP_P3P Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang \"Complete Solution Classification for the Perspective-Three-Point Problem\" ([98]).\nSOLVEPNP_AP3P Method is based on the paper of T. Ke and S. Roumeliotis. \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" ([145]).\n\nThe function estimates the object pose given 3 object points, their corresponding image projections, as well as the camera intrinsic matrix and the distortion coefficients.\nNoteThe solutions are sorted by reprojection errors (lowest to highest). \n\n◆ solvePnP()\n\nbool cv::solvePnP \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArray \nrvec, \n\nOutputArray \ntvec, \n\nbool \nuseExtrinsicGuess = false, \n\nint \nflags = SOLVEPNP_ITERATIVE \n\n)\n\nPython:cv.solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, flags]]]]) -> retval, rvec, tvec\n\n#include <opencv2/calib3d.hpp>\nFinds an object pose from 3D-2D point correspondences. \nSee alsoPerspective-n-Point (PnP) pose computation\nThis function returns the rotation and the translation vectors that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame, using different methods:\nP3P methods (SOLVEPNP_P3P, SOLVEPNP_AP3P): need 4 input points to return a unique solution.\nSOLVEPNP_IPPE Input points must be >= 4 and object points must be coplanar.\nSOLVEPNP_IPPE_SQUARE Special case suitable for marker pose estimation. Number of input points must be 4. Object points must be defined in the following order:\npoint 0: [-squareLength / 2, squareLength / 2, 0]\npoint 1: [ squareLength / 2, squareLength / 2, 0]\npoint 2: [ squareLength / 2, -squareLength / 2, 0]\npoint 3: [-squareLength / 2, -squareLength / 2, 0]\n\nfor all the other flags, number of input points must be >= 4 and object points can be in any configuration.\n\nParameters\n\nobjectPointsArray of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. vector<Point3d> can be also passed here. \nimagePointsArray of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. vector<Point2d> can be also passed here. \ncameraMatrixInput camera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nrvecOutput rotation vector (see Rodrigues ) that, together with tvec, brings points from the model coordinate system to the camera coordinate system. \ntvecOutput translation vector. \nuseExtrinsicGuessParameter used for SOLVEPNP_ITERATIVE. If true (1), the function uses the provided rvec and tvec values as initial approximations of the rotation and translation vectors, respectively, and further optimizes them. \nflagsMethod for solving a PnP problem: see calib3d_solvePnP_flags\n\nMore information about Perspective-n-Points is described in Perspective-n-Point (PnP) pose computation\nNote\nAn example of how to use solvePnP for planar augmented reality can be found at opencv_source_code/samples/python/plane_ar.py\nIf you are using Python:\nNumpy array slices won't work as input because solvePnP requires contiguous arrays (enforced by the assertion using cv::Mat::checkVector() around line 55 of modules/calib3d/src/solvepnp.cpp version 2.4.9)\nThe P3P algorithm requires image points to be in an array of shape (N,1,2) due to its calling of undistortPoints (around line 75 of modules/calib3d/src/solvepnp.cpp version 2.4.9) which requires 2-channel information.\nThus, given some data D = np.array(...) where D.shape = (N,M), in order to use a subset of it as, e.g., imagePoints, one must effectively copy it into a new array: imagePoints = np.ascontiguousarray(D[:,:2]).reshape((N,1,2))\n\nThe methods SOLVEPNP_DLS and SOLVEPNP_UPNP cannot be used as the current implementations are unstable and sometimes give completely wrong results. If you pass one of these two flags, SOLVEPNP_EPNP method will be used instead.\nThe minimum number of points is 4 in the general case. In the case of SOLVEPNP_P3P and SOLVEPNP_AP3P methods, it is required to use exactly 4 points (the first 3 points are used to estimate all the solutions of the P3P problem, the last one is used to retain the best solution that minimizes the reprojection error).\nWith SOLVEPNP_ITERATIVE method and useExtrinsicGuess=true, the minimum number of points is 3 (3 points are sufficient to compute a pose but there are up to 4 solutions). The initial solution should be close to the global solution to converge.\nWith SOLVEPNP_IPPE input points must be >= 4 and object points must be coplanar.\nWith SOLVEPNP_IPPE_SQUARE this is a special case suitable for marker pose estimation. Number of input points must be 4. Object points must be defined in the following order:\npoint 0: [-squareLength / 2, squareLength / 2, 0]\npoint 1: [ squareLength / 2, squareLength / 2, 0]\npoint 2: [ squareLength / 2, -squareLength / 2, 0]\npoint 3: [-squareLength / 2, -squareLength / 2, 0]\n\nWith SOLVEPNP_SQPNP input points must be >= 3 \n\n◆ solvePnPGeneric()\n\nint cv::solvePnPGeneric \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nbool \nuseExtrinsicGuess = false, \n\nSolvePnPMethod \nflags = SOLVEPNP_ITERATIVE, \n\nInputArray \nrvec = noArray(), \n\nInputArray \ntvec = noArray(), \n\nOutputArray \nreprojectionError = noArray() \n\n)\n\nPython:cv.solvePnPGeneric(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvecs[, tvecs[, useExtrinsicGuess[, flags[, rvec[, tvec[, reprojectionError]]]]]]]) -> retval, rvecs, tvecs, reprojectionError\n\n#include <opencv2/calib3d.hpp>\nFinds an object pose from 3D-2D point correspondences. \nSee alsoPerspective-n-Point (PnP) pose computation\nThis function returns a list of all the possible solutions (a solution is a <rotation vector, translation vector> couple), depending on the number of input points and the chosen method:\nP3P methods (SOLVEPNP_P3P, SOLVEPNP_AP3P): 3 or 4 input points. Number of returned solutions can be between 0 and 4 with 3 input points.\nSOLVEPNP_IPPE Input points must be >= 4 and object points must be coplanar. Returns 2 solutions.\nSOLVEPNP_IPPE_SQUARE Special case suitable for marker pose estimation. Number of input points must be 4 and 2 solutions are returned. Object points must be defined in the following order:\npoint 0: [-squareLength / 2, squareLength / 2, 0]\npoint 1: [ squareLength / 2, squareLength / 2, 0]\npoint 2: [ squareLength / 2, -squareLength / 2, 0]\npoint 3: [-squareLength / 2, -squareLength / 2, 0]\n\nfor all the other flags, number of input points must be >= 4 and object points can be in any configuration. Only 1 solution is returned.\n\nParameters\n\nobjectPointsArray of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. vector<Point3d> can be also passed here. \nimagePointsArray of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. vector<Point2d> can be also passed here. \ncameraMatrixInput camera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nrvecsVector of output rotation vectors (see Rodrigues ) that, together with tvecs, brings points from the model coordinate system to the camera coordinate system. \ntvecsVector of output translation vectors. \nuseExtrinsicGuessParameter used for SOLVEPNP_ITERATIVE. If true (1), the function uses the provided rvec and tvec values as initial approximations of the rotation and translation vectors, respectively, and further optimizes them. \nflagsMethod for solving a PnP problem: see calib3d_solvePnP_flags \nrvecRotation vector used to initialize an iterative PnP refinement algorithm, when flag is SOLVEPNP_ITERATIVE and useExtrinsicGuess is set to true. \ntvecTranslation vector used to initialize an iterative PnP refinement algorithm, when flag is SOLVEPNP_ITERATIVE and useExtrinsicGuess is set to true. \nreprojectionErrorOptional vector of reprojection error, that is the RMS error ( \\( \\text{RMSE} = \\sqrt{\\frac{\\sum_{i}^{N} \\left ( \\hat{y_i} - y_i \\right )^2}{N}} \\)) between the input image points and the 3D object points projected with the estimated pose.\n\nMore information is described in Perspective-n-Point (PnP) pose computation\nNote\nAn example of how to use solvePnP for planar augmented reality can be found at opencv_source_code/samples/python/plane_ar.py\nIf you are using Python:\nNumpy array slices won't work as input because solvePnP requires contiguous arrays (enforced by the assertion using cv::Mat::checkVector() around line 55 of modules/calib3d/src/solvepnp.cpp version 2.4.9)\nThe P3P algorithm requires image points to be in an array of shape (N,1,2) due to its calling of undistortPoints (around line 75 of modules/calib3d/src/solvepnp.cpp version 2.4.9) which requires 2-channel information.\nThus, given some data D = np.array(...) where D.shape = (N,M), in order to use a subset of it as, e.g., imagePoints, one must effectively copy it into a new array: imagePoints = np.ascontiguousarray(D[:,:2]).reshape((N,1,2))\n\nThe methods SOLVEPNP_DLS and SOLVEPNP_UPNP cannot be used as the current implementations are unstable and sometimes give completely wrong results. If you pass one of these two flags, SOLVEPNP_EPNP method will be used instead.\nThe minimum number of points is 4 in the general case. In the case of SOLVEPNP_P3P and SOLVEPNP_AP3P methods, it is required to use exactly 4 points (the first 3 points are used to estimate all the solutions of the P3P problem, the last one is used to retain the best solution that minimizes the reprojection error).\nWith SOLVEPNP_ITERATIVE method and useExtrinsicGuess=true, the minimum number of points is 3 (3 points are sufficient to compute a pose but there are up to 4 solutions). The initial solution should be close to the global solution to converge.\nWith SOLVEPNP_IPPE input points must be >= 4 and object points must be coplanar.\nWith SOLVEPNP_IPPE_SQUARE this is a special case suitable for marker pose estimation. Number of input points must be 4. Object points must be defined in the following order:\npoint 0: [-squareLength / 2, squareLength / 2, 0]\npoint 1: [ squareLength / 2, squareLength / 2, 0]\npoint 2: [ squareLength / 2, -squareLength / 2, 0]\npoint 3: [-squareLength / 2, -squareLength / 2, 0] \n\n◆ solvePnPRansac() [1/2]\n\nbool cv::solvePnPRansac \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArray \nrvec, \n\nOutputArray \ntvec, \n\nbool \nuseExtrinsicGuess = false, \n\nint \niterationsCount = 100, \n\nfloat \nreprojectionError = 8.0, \n\ndouble \nconfidence = 0.99, \n\nOutputArray \ninliers = noArray(), \n\nint \nflags = SOLVEPNP_ITERATIVE \n\n)\n\nPython:cv.solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, iterationsCount[, reprojectionError[, confidence[, inliers[, flags]]]]]]]]) -> retval, rvec, tvec, inlierscv.solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, inliers[, params]]]]) -> retval, cameraMatrix, rvec, tvec, inliers\n\n#include <opencv2/calib3d.hpp>\nFinds an object pose from 3D-2D point correspondences using the RANSAC scheme. \nSee alsoPerspective-n-Point (PnP) pose computation\nParameters\n\nobjectPointsArray of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. vector<Point3d> can be also passed here. \nimagePointsArray of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. vector<Point2d> can be also passed here. \ncameraMatrixInput camera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nrvecOutput rotation vector (see Rodrigues ) that, together with tvec, brings points from the model coordinate system to the camera coordinate system. \ntvecOutput translation vector. \nuseExtrinsicGuessParameter used for SOLVEPNP_ITERATIVE. If true (1), the function uses the provided rvec and tvec values as initial approximations of the rotation and translation vectors, respectively, and further optimizes them. \niterationsCountNumber of iterations. \nreprojectionErrorInlier threshold value used by the RANSAC procedure. The parameter value is the maximum allowed distance between the observed and computed point projections to consider it an inlier. \nconfidenceThe probability that the algorithm produces a useful result. \ninliersOutput vector that contains indices of inliers in objectPoints and imagePoints . \nflagsMethod for solving a PnP problem (see solvePnP ).\n\nThe function estimates an object pose given a set of object points, their corresponding image projections, as well as the camera intrinsic matrix and the distortion coefficients. This function finds such a pose that minimizes reprojection error, that is, the sum of squared distances between the observed projections imagePoints and the projected (using projectPoints ) objectPoints. The use of RANSAC makes the function resistant to outliers.\nNote\nAn example of how to use solvePNPRansac for object detection can be found at opencv_source_code/samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/\nThe default method used to estimate the camera pose for the Minimal Sample Sets step is SOLVEPNP_EPNP. Exceptions are:\nif you choose SOLVEPNP_P3P or SOLVEPNP_AP3P, these methods will be used.\nif the number of input points is equal to 4, SOLVEPNP_P3P is used.\n\nThe method used to estimate the camera pose using all the inliers is defined by the flags parameters unless it is equal to SOLVEPNP_P3P or SOLVEPNP_AP3P. In this case, the method SOLVEPNP_EPNP will be used instead. \n\n◆ solvePnPRansac() [2/2]\n\nbool cv::solvePnPRansac \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputOutputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nOutputArray \nrvec, \n\nOutputArray \ntvec, \n\nOutputArray \ninliers, \n\nconst UsacParams & \nparams = UsacParams() \n\n)\n\nPython:cv.solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, iterationsCount[, reprojectionError[, confidence[, inliers[, flags]]]]]]]]) -> retval, rvec, tvec, inlierscv.solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, inliers[, params]]]]) -> retval, cameraMatrix, rvec, tvec, inliers\n\n#include <opencv2/calib3d.hpp>\n\n◆ solvePnPRefineLM()\n\nvoid cv::solvePnPRefineLM \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputOutputArray \nrvec, \n\nInputOutputArray \ntvec, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::EPS+TermCriteria::COUNT, 20, FLT_EPSILON) \n\n)\n\nPython:cv.solvePnPRefineLM(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec[, criteria]) -> rvec, tvec\n\n#include <opencv2/calib3d.hpp>\nRefine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution. \nSee alsoPerspective-n-Point (PnP) pose computation\nParameters\n\nobjectPointsArray of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. vector<Point3d> can also be passed here. \nimagePointsArray of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. vector<Point2d> can also be passed here. \ncameraMatrixInput camera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nrvecInput/Output rotation vector (see Rodrigues ) that, together with tvec, brings points from the model coordinate system to the camera coordinate system. Input values are used as an initial solution. \ntvecInput/Output translation vector. Input values are used as an initial solution. \ncriteriaCriteria when to stop the Levenberg-Marquard iterative algorithm.\n\nThe function refines the object pose given at least 3 object points, their corresponding image projections, an initial solution for the rotation and translation vector, as well as the camera intrinsic matrix and the distortion coefficients. The function minimizes the projection error with respect to the rotation and the translation vectors, according to a Levenberg-Marquardt iterative minimization [179] [77] process. \n\n◆ solvePnPRefineVVS()\n\nvoid cv::solvePnPRefineVVS \n(\nInputArray \nobjectPoints, \n\nInputArray \nimagePoints, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputOutputArray \nrvec, \n\nInputOutputArray \ntvec, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::EPS+TermCriteria::COUNT, 20, FLT_EPSILON), \n\ndouble \nVVSlambda = 1 \n\n)\n\nPython:cv.solvePnPRefineVVS(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec[, criteria[, VVSlambda]]) -> rvec, tvec\n\n#include <opencv2/calib3d.hpp>\nRefine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution. \nSee alsoPerspective-n-Point (PnP) pose computation\nParameters\n\nobjectPointsArray of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel, where N is the number of points. vector<Point3d> can also be passed here. \nimagePointsArray of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel, where N is the number of points. vector<Point2d> can also be passed here. \ncameraMatrixInput camera intrinsic matrix \\(\\cameramatrix{A}\\) . \ndistCoeffsInput vector of distortion coefficients \\(\\distcoeffs\\). If the vector is NULL/empty, the zero distortion coefficients are assumed. \nrvecInput/Output rotation vector (see Rodrigues ) that, together with tvec, brings points from the model coordinate system to the camera coordinate system. Input values are used as an initial solution. \ntvecInput/Output translation vector. Input values are used as an initial solution. \ncriteriaCriteria when to stop the Levenberg-Marquard iterative algorithm. \nVVSlambdaGain for the virtual visual servoing control law, equivalent to the \\(\\alpha\\) gain in the Damped Gauss-Newton formulation.\n\nThe function refines the object pose given at least 3 object points, their corresponding image projections, an initial solution for the rotation and translation vector, as well as the camera intrinsic matrix and the distortion coefficients. The function minimizes the projection error with respect to the rotation and the translation vectors, using a virtual visual servoing (VVS) [51] [183] scheme. \n\n◆ stereoCalibrate() [1/3]\n\ndouble cv::stereoCalibrate \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints1, \n\nInputArrayOfArrays \nimagePoints2, \n\nInputOutputArray \ncameraMatrix1, \n\nInputOutputArray \ndistCoeffs1, \n\nInputOutputArray \ncameraMatrix2, \n\nInputOutputArray \ndistCoeffs2, \n\nSize \nimageSize, \n\nInputOutputArray \nR, \n\nInputOutputArray \nT, \n\nOutputArray \nE, \n\nOutputArray \nF, \n\nOutputArray \nperViewErrors, \n\nint \nflags = CALIB_FIX_INTRINSIC, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6) \n\n)\n\nPython:cv.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize[, R[, T[, E[, F[, flags[, criteria]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, Fcv.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, perViewErrors[, flags[, criteria]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, perViewErrorscv.stereoCalibrateExtended(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, rvecs[, tvecs[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, rvecs, tvecs, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ stereoCalibrate() [2/3]\n\ndouble cv::stereoCalibrate \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints1, \n\nInputArrayOfArrays \nimagePoints2, \n\nInputOutputArray \ncameraMatrix1, \n\nInputOutputArray \ndistCoeffs1, \n\nInputOutputArray \ncameraMatrix2, \n\nInputOutputArray \ndistCoeffs2, \n\nSize \nimageSize, \n\nInputOutputArray \nR, \n\nInputOutputArray \nT, \n\nOutputArray \nE, \n\nOutputArray \nF, \n\nOutputArrayOfArrays \nrvecs, \n\nOutputArrayOfArrays \ntvecs, \n\nOutputArray \nperViewErrors, \n\nint \nflags = CALIB_FIX_INTRINSIC, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6) \n\n)\n\nPython:cv.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize[, R[, T[, E[, F[, flags[, criteria]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, Fcv.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, perViewErrors[, flags[, criteria]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, perViewErrorscv.stereoCalibrateExtended(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, rvecs[, tvecs[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, rvecs, tvecs, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nCalibrates a stereo camera set up. This function finds the intrinsic parameters for each of the two cameras and the extrinsic parameters between the two cameras. \nParameters\n\nobjectPointsVector of vectors of the calibration pattern points. The same structure as in calibrateCamera. For each pattern view, both cameras need to see the same object points. Therefore, objectPoints.size(), imagePoints1.size(), and imagePoints2.size() need to be equal as well as objectPoints[i].size(), imagePoints1[i].size(), and imagePoints2[i].size() need to be equal for each i. \nimagePoints1Vector of vectors of the projections of the calibration pattern points, observed by the first camera. The same structure as in calibrateCamera. \nimagePoints2Vector of vectors of the projections of the calibration pattern points, observed by the second camera. The same structure as in calibrateCamera. \ncameraMatrix1Input/output camera intrinsic matrix for the first camera, the same as in calibrateCamera. Furthermore, for the stereo case, additional flags may be used, see below. \ndistCoeffs1Input/output vector of distortion coefficients, the same as in calibrateCamera. \ncameraMatrix2Input/output second camera intrinsic matrix for the second camera. See description for cameraMatrix1. \ndistCoeffs2Input/output lens distortion coefficients for the second camera. See description for distCoeffs1. \nimageSizeSize of the image used only to initialize the camera intrinsic matrices. \nROutput rotation matrix. Together with the translation vector T, this matrix brings points given in the first camera's coordinate system to points in the second camera's coordinate system. In more technical terms, the tuple of R and T performs a change of basis from the first camera's coordinate system to the second camera's coordinate system. Due to its duality, this tuple is equivalent to the position of the first camera with respect to the second camera coordinate system. \nTOutput translation vector, see description above. \nEOutput essential matrix. \nFOutput fundamental matrix. \nrvecsOutput vector of rotation vectors ( Rodrigues ) estimated for each pattern view in the coordinate system of the first camera of the stereo pair (e.g. std::vector<cv::Mat>). More in detail, each i-th rotation vector together with the corresponding i-th translation vector (see the next output parameter description) brings the calibration pattern from the object coordinate space (in which object points are specified) to the camera coordinate space of the first camera of the stereo pair. In more technical terms, the tuple of the i-th rotation and translation vector performs a change of basis from object coordinate space to camera coordinate space of the first camera of the stereo pair. \ntvecsOutput vector of translation vectors estimated for each pattern view, see parameter description of previous output parameter ( rvecs ). \nperViewErrorsOutput vector of the RMS re-projection error estimated for each pattern view. \nflagsDifferent flags that may be zero or a combination of the following values:\nCALIB_FIX_INTRINSIC Fix cameraMatrix? and distCoeffs? so that only R, T, E, and F matrices are estimated.\nCALIB_USE_INTRINSIC_GUESS Optimize some or all of the intrinsic parameters according to the specified flags. Initial values are provided by the user.\nCALIB_USE_EXTRINSIC_GUESS R and T contain valid initial values that are optimized further. Otherwise R and T are initialized to the median value of the pattern views (each dimension separately).\nCALIB_FIX_PRINCIPAL_POINT Fix the principal points during the optimization.\nCALIB_FIX_FOCAL_LENGTH Fix \\(f^{(j)}_x\\) and \\(f^{(j)}_y\\) .\nCALIB_FIX_ASPECT_RATIO Optimize \\(f^{(j)}_y\\) . Fix the ratio \\(f^{(j)}_x/f^{(j)}_y\\)\n\nCALIB_SAME_FOCAL_LENGTH Enforce \\(f^{(0)}_x=f^{(1)}_x\\) and \\(f^{(0)}_y=f^{(1)}_y\\) .\nCALIB_ZERO_TANGENT_DIST Set tangential distortion coefficients for each camera to zeros and fix there.\nCALIB_FIX_K1,..., CALIB_FIX_K6 Do not change the corresponding radial distortion coefficient during the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\nCALIB_RATIONAL_MODEL Enable coefficients k4, k5, and k6. To provide the backward compatibility, this extra flag should be explicitly specified to make the calibration function use the rational model and return 8 coefficients. If the flag is not set, the function computes and returns only 5 distortion coefficients.\nCALIB_THIN_PRISM_MODEL Coefficients s1, s2, s3 and s4 are enabled. To provide the backward compatibility, this extra flag should be explicitly specified to make the calibration function use the thin prism model and return 12 coefficients. If the flag is not set, the function computes and returns only 5 distortion coefficients.\nCALIB_FIX_S1_S2_S3_S4 The thin prism distortion coefficients are not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\nCALIB_TILTED_MODEL Coefficients tauX and tauY are enabled. To provide the backward compatibility, this extra flag should be explicitly specified to make the calibration function use the tilted sensor model and return 14 coefficients. If the flag is not set, the function computes and returns only 5 distortion coefficients.\nCALIB_FIX_TAUX_TAUY The coefficients of the tilted sensor model are not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0. \n\ncriteriaTermination criteria for the iterative optimization algorithm.\n\nThe function estimates the transformation between two cameras making a stereo pair. If one computes the poses of an object relative to the first camera and to the second camera, ( \\(R_1\\), \\(T_1\\) ) and ( \\(R_2\\), \\(T_2\\)), respectively, for a stereo camera where the relative position and orientation between the two cameras are fixed, then those poses definitely relate to each other. This means, if the relative position and orientation ( \\(R\\), \\(T\\)) of the two cameras is known, it is possible to compute ( \\(R_2\\), \\(T_2\\)) when ( \\(R_1\\), \\(T_1\\)) is given. This is what the described function does. It computes ( \\(R\\), \\(T\\)) such that:\n\n\\[R_2=R R_1\\]\n\n\\[T_2=R T_1 + T.\\]\n\nTherefore, one can compute the coordinate representation of a 3D point for the second camera's coordinate system when given the point's coordinate representation in the first camera's coordinate system:\n\n\\[\\begin{bmatrix}\nX_2 \\\\\nY_2 \\\\\nZ_2 \\\\\n1\n\\end{bmatrix} = \\begin{bmatrix}\nR & T \\\\\n0 & 1\n\\end{bmatrix} \\begin{bmatrix}\nX_1 \\\\\nY_1 \\\\\nZ_1 \\\\\n1\n\\end{bmatrix}.\\]\n\nOptionally, it computes the essential matrix E:\n\n\\[E= \\vecthreethree{0}{-T_2}{T_1}{T_2}{0}{-T_0}{-T_1}{T_0}{0} R\\]\n\nwhere \\(T_i\\) are components of the translation vector \\(T\\) : \\(T=[T_0, T_1, T_2]^T\\) . And the function can also compute the fundamental matrix F:\n\n\\[F = cameraMatrix2^{-T}\\cdot E \\cdot cameraMatrix1^{-1}\\]\n\nBesides the stereo-related information, the function can also perform a full calibration of each of the two cameras. However, due to the high dimensionality of the parameter space and noise in the input data, the function can diverge from the correct solution. If the intrinsic parameters can be estimated with high accuracy for each of the cameras individually (for example, using calibrateCamera ), you are recommended to do so and then pass CALIB_FIX_INTRINSIC flag to the function along with the computed intrinsic parameters. Otherwise, if all the parameters are estimated at once, it makes sense to restrict some parameters, for example, pass CALIB_SAME_FOCAL_LENGTH and CALIB_ZERO_TANGENT_DIST flags, which is usually a reasonable assumption.\nSimilarly to calibrateCamera, the function minimizes the total re-projection error for all the points in all the available views from both cameras. The function returns the final value of the re-projection error. \n\n◆ stereoCalibrate() [3/3]\n\ndouble cv::stereoCalibrate \n(\nInputArrayOfArrays \nobjectPoints, \n\nInputArrayOfArrays \nimagePoints1, \n\nInputArrayOfArrays \nimagePoints2, \n\nInputOutputArray \ncameraMatrix1, \n\nInputOutputArray \ndistCoeffs1, \n\nInputOutputArray \ncameraMatrix2, \n\nInputOutputArray \ndistCoeffs2, \n\nSize \nimageSize, \n\nOutputArray \nR, \n\nOutputArray \nT, \n\nOutputArray \nE, \n\nOutputArray \nF, \n\nint \nflags = CALIB_FIX_INTRINSIC, \n\nTermCriteria \ncriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6) \n\n)\n\nPython:cv.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize[, R[, T[, E[, F[, flags[, criteria]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, Fcv.stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, perViewErrors[, flags[, criteria]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, perViewErrorscv.stereoCalibrateExtended(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, rvecs[, tvecs[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, rvecs, tvecs, perViewErrors\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. \n\n◆ stereoRectify()\n\nvoid cv::stereoRectify \n(\nInputArray \ncameraMatrix1, \n\nInputArray \ndistCoeffs1, \n\nInputArray \ncameraMatrix2, \n\nInputArray \ndistCoeffs2, \n\nSize \nimageSize, \n\nInputArray \nR, \n\nInputArray \nT, \n\nOutputArray \nR1, \n\nOutputArray \nR2, \n\nOutputArray \nP1, \n\nOutputArray \nP2, \n\nOutputArray \nQ, \n\nint \nflags = CALIB_ZERO_DISPARITY, \n\ndouble \nalpha = -1, \n\nSize \nnewImageSize = Size(), \n\nRect * \nvalidPixROI1 = 0, \n\nRect * \nvalidPixROI2 = 0 \n\n)\n\nPython:cv.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, R1[, R2[, P1[, P2[, Q[, flags[, alpha[, newImageSize]]]]]]]]) -> R1, R2, P1, P2, Q, validPixROI1, validPixROI2\n\n#include <opencv2/calib3d.hpp>\nComputes rectification transforms for each head of a calibrated stereo camera. \nParameters\n\ncameraMatrix1First camera intrinsic matrix. \ndistCoeffs1First camera distortion parameters. \ncameraMatrix2Second camera intrinsic matrix. \ndistCoeffs2Second camera distortion parameters. \nimageSizeSize of the image used for stereo calibration. \nRRotation matrix from the coordinate system of the first camera to the second camera, see stereoCalibrate. \nTTranslation vector from the coordinate system of the first camera to the second camera, see stereoCalibrate. \nR1Output 3x3 rectification transform (rotation matrix) for the first camera. This matrix brings points given in the unrectified first camera's coordinate system to points in the rectified first camera's coordinate system. In more technical terms, it performs a change of basis from the unrectified first camera's coordinate system to the rectified first camera's coordinate system. \nR2Output 3x3 rectification transform (rotation matrix) for the second camera. This matrix brings points given in the unrectified second camera's coordinate system to points in the rectified second camera's coordinate system. In more technical terms, it performs a change of basis from the unrectified second camera's coordinate system to the rectified second camera's coordinate system. \nP1Output 3x4 projection matrix in the new (rectified) coordinate systems for the first camera, i.e. it projects points given in the rectified first camera coordinate system into the rectified first camera's image. \nP2Output 3x4 projection matrix in the new (rectified) coordinate systems for the second camera, i.e. it projects points given in the rectified first camera coordinate system into the rectified second camera's image. \nQOutput \\(4 \\times 4\\) disparity-to-depth mapping matrix (see reprojectImageTo3D). \nflagsOperation flags that may be zero or CALIB_ZERO_DISPARITY . If the flag is set, the function makes the principal points of each camera have the same pixel coordinates in the rectified views. And if the flag is not set, the function may still shift the images in the horizontal or vertical direction (depending on the orientation of epipolar lines) to maximize the useful image area. \nalphaFree scaling parameter. If it is -1 or absent, the function performs the default scaling. Otherwise, the parameter should be between 0 and 1. alpha=0 means that the rectified images are zoomed and shifted so that only valid pixels are visible (no black areas after rectification). alpha=1 means that the rectified image is decimated and shifted so that all the pixels from the original images from the cameras are retained in the rectified images (no source image pixels are lost). Any intermediate value yields an intermediate result between those two extreme cases. \nnewImageSizeNew image resolution after rectification. The same size should be passed to initUndistortRectifyMap (see the stereo_calib.cpp sample in OpenCV samples directory). When (0,0) is passed (default), it is set to the original imageSize . Setting it to a larger value can help you preserve details in the original image, especially when there is a big radial distortion. \nvalidPixROI1Optional output rectangles inside the rectified images where all the pixels are valid. If alpha=0 , the ROIs cover the whole images. Otherwise, they are likely to be smaller (see the picture below). \nvalidPixROI2Optional output rectangles inside the rectified images where all the pixels are valid. If alpha=0 , the ROIs cover the whole images. Otherwise, they are likely to be smaller (see the picture below).\n\nThe function computes the rotation matrices for each camera that (virtually) make both camera image planes the same plane. Consequently, this makes all the epipolar lines parallel and thus simplifies the dense stereo correspondence problem. The function takes the matrices computed by stereoCalibrate as input. As output, it provides two rotation matrices and also two projection matrices in the new coordinates. The function distinguishes the following two cases:\n\nHorizontal stereo: the first and the second camera views are shifted relative to each other mainly along the x-axis (with possible small vertical shift). In the rectified images, the corresponding epipolar lines in the left and right cameras are horizontal and have the same y-coordinate. P1 and P2 look like:\n\n\\[\\texttt{P1} = \\begin{bmatrix}\n                        f & 0 & cx_1 & 0 \\\\\n                        0 & f & cy & 0 \\\\\n                        0 & 0 & 1 & 0\n                     \\end{bmatrix}\\]\n\n\\[\\texttt{P2} = \\begin{bmatrix}\n                        f & 0 & cx_2 & T_x \\cdot f \\\\\n                        0 & f & cy & 0 \\\\\n                        0 & 0 & 1 & 0\n                     \\end{bmatrix} ,\\]\n\n\\[\\texttt{Q} = \\begin{bmatrix}\n                        1 & 0 & 0 & -cx_1 \\\\\n                        0 & 1 & 0 & -cy \\\\\n                        0 & 0 & 0 & f \\\\\n                        0 & 0 & -\\frac{1}{T_x} & \\frac{cx_1 - cx_2}{T_x}\n                    \\end{bmatrix} \\]\n\nwhere \\(T_x\\) is a horizontal shift between the cameras and \\(cx_1=cx_2\\) if CALIB_ZERO_DISPARITY is set.\n\nVertical stereo: the first and the second camera views are shifted relative to each other mainly in the vertical direction (and probably a bit in the horizontal direction too). The epipolar lines in the rectified images are vertical and have the same x-coordinate. P1 and P2 look like:\n\n\\[\\texttt{P1} = \\begin{bmatrix}\n                        f & 0 & cx & 0 \\\\\n                        0 & f & cy_1 & 0 \\\\\n                        0 & 0 & 1 & 0\n                     \\end{bmatrix}\\]\n\n\\[\\texttt{P2} = \\begin{bmatrix}\n                        f & 0 & cx & 0 \\\\\n                        0 & f & cy_2 & T_y \\cdot f \\\\\n                        0 & 0 & 1 & 0\n                     \\end{bmatrix},\\]\n\n\\[\\texttt{Q} = \\begin{bmatrix}\n                        1 & 0 & 0 & -cx \\\\\n                        0 & 1 & 0 & -cy_1 \\\\\n                        0 & 0 & 0 & f \\\\\n                        0 & 0 & -\\frac{1}{T_y} & \\frac{cy_1 - cy_2}{T_y}\n                    \\end{bmatrix} \\]\n\nwhere \\(T_y\\) is a vertical shift between the cameras and \\(cy_1=cy_2\\) if CALIB_ZERO_DISPARITY is set.\nAs you can see, the first three columns of P1 and P2 will effectively be the new \"rectified\" camera matrices. The matrices, together with R1 and R2 , can then be passed to initUndistortRectifyMap to initialize the rectification map for each camera.\nSee below the screenshot from the stereo_calib.cpp sample. Some red horizontal lines pass through the corresponding image regions. This means that the images are well rectified, which is what most stereo correspondence algorithms rely on. The green rectangles are roi1 and roi2 . You see that their interiors are all valid pixels.\n\nimage\n\n◆ stereoRectifyUncalibrated()\n\nbool cv::stereoRectifyUncalibrated \n(\nInputArray \npoints1, \n\nInputArray \npoints2, \n\nInputArray \nF, \n\nSize \nimgSize, \n\nOutputArray \nH1, \n\nOutputArray \nH2, \n\ndouble \nthreshold = 5 \n\n)\n\nPython:cv.stereoRectifyUncalibrated(points1, points2, F, imgSize[, H1[, H2[, threshold]]]) -> retval, H1, H2\n\n#include <opencv2/calib3d.hpp>\nComputes a rectification transform for an uncalibrated stereo camera. \nParameters\n\npoints1Array of feature points in the first image. \npoints2The corresponding points in the second image. The same formats as in findFundamentalMat are supported. \nFInput fundamental matrix. It can be computed from the same set of point pairs using findFundamentalMat . \nimgSizeSize of the image. \nH1Output rectification homography matrix for the first image. \nH2Output rectification homography matrix for the second image. \nthresholdOptional threshold used to filter out the outliers. If the parameter is greater than zero, all the point pairs that do not comply with the epipolar geometry (that is, the points for which \\(|\\texttt{points2[i]}^T \\cdot \\texttt{F} \\cdot \\texttt{points1[i]}|>\\texttt{threshold}\\) ) are rejected prior to computing the homographies. Otherwise, all the points are considered inliers.\n\nThe function computes the rectification transformations without knowing intrinsic parameters of the cameras and their relative position in the space, which explains the suffix \"uncalibrated\". Another related difference from stereoRectify is that the function outputs not the rectification transformations in the object (3D) space, but the planar perspective transformations encoded by the homography matrices H1 and H2 . The function implements the algorithm [118] .\nNoteWhile the algorithm does not need to know the intrinsic parameters of the cameras, it heavily depends on the epipolar geometry. Therefore, if the camera lenses have a significant distortion, it would be better to correct it before computing the fundamental matrix and calling this function. For example, distortion coefficients can be estimated for each head of stereo camera separately by using calibrateCamera . Then, the images can be corrected using undistort , or just the point coordinates can be corrected with undistortPoints . \n\n◆ triangulatePoints()\n\nvoid cv::triangulatePoints \n(\nInputArray \nprojMatr1, \n\nInputArray \nprojMatr2, \n\nInputArray \nprojPoints1, \n\nInputArray \nprojPoints2, \n\nOutputArray \npoints4D \n\n)\n\nPython:cv.triangulatePoints(projMatr1, projMatr2, projPoints1, projPoints2[, points4D]) -> points4D\n\n#include <opencv2/calib3d.hpp>\nThis function reconstructs 3-dimensional points (in homogeneous coordinates) by using their observations with a stereo camera. \nParameters\n\nprojMatr13x4 projection matrix of the first camera, i.e. this matrix projects 3D points given in the world's coordinate system into the first image. \nprojMatr23x4 projection matrix of the second camera, i.e. this matrix projects 3D points given in the world's coordinate system into the second image. \nprojPoints12xN array of feature points in the first image. In the case of the c++ version, it can be also a vector of feature points or two-channel matrix of size 1xN or Nx1. \nprojPoints22xN array of corresponding points in the second image. In the case of the c++ version, it can be also a vector of feature points or two-channel matrix of size 1xN or Nx1. \npoints4D4xN array of reconstructed points in homogeneous coordinates. These points are returned in the world's coordinate system.\n\nNoteKeep in mind that all input data should be of float type in order for this function to work.\n\nIf the projection matrices from stereoRectify are used, then the returned points are represented in the first camera's rectified coordinate system.\nSee alsoreprojectImageTo3D \n\n◆ undistort()\n\nvoid cv::undistort \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputArray \nnewCameraMatrix = noArray() \n\n)\n\nPython:cv.undistort(src, cameraMatrix, distCoeffs[, dst[, newCameraMatrix]]) -> dst\n\n#include <opencv2/calib3d.hpp>\nTransforms an image to compensate for lens distortion. \nThe function transforms an image to compensate radial and tangential lens distortion.\nThe function is simply a combination of initUndistortRectifyMap (with unity R ) and remap (with bilinear interpolation). See the former function for details of the transformation being performed.\nThose pixels in the destination image, for which there is no correspondent pixels in the source image, are filled with zeros (black color).\nA particular subset of the source image that will be visible in the corrected image can be regulated by newCameraMatrix. You can use getOptimalNewCameraMatrix to compute the appropriate newCameraMatrix depending on your requirements.\nThe camera matrix and the distortion parameters can be determined using calibrateCamera. If the resolution of images is different from the resolution used at the calibration stage, \\(f_x,\nf_y, c_x\\) and \\(c_y\\) need to be scaled accordingly, while the distortion coefficients remain the same.\nParameters\n\nsrcInput (distorted) image. \ndstOutput (corrected) image that has the same size and type as src . \ncameraMatrixInput camera matrix \\(A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ndistCoeffsInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed. \nnewCameraMatrixCamera matrix of the distorted image. By default, it is the same as cameraMatrix but you may additionally scale and shift the result by using a different matrix. \n\n◆ undistortImagePoints()\n\nvoid cv::undistortImagePoints \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nTermCriteria \n = TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 0.01) \n\n)\n\nPython:cv.undistortImagePoints(src, cameraMatrix, distCoeffs[, dst[, arg1]]) -> dst\n\n#include <opencv2/calib3d.hpp>\nCompute undistorted image points position. \nParameters\n\nsrcObserved points position, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel (CV_32FC2 or CV_64FC2) (or vector<Point2f> ). \ndstOutput undistorted points position (1xN/Nx1 2-channel or vector<Point2f> ). \ncameraMatrixCamera matrix \\(\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ndistCoeffsDistortion coefficients \n\n◆ undistortPoints() [1/2]\n\nvoid cv::undistortPoints \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputArray \nR, \n\nInputArray \nP, \n\nTermCriteria \ncriteria \n\n)\n\nPython:cv.undistortPoints(src, cameraMatrix, distCoeffs[, dst[, R[, P]]]) -> dstcv.undistortPointsIter(src, cameraMatrix, distCoeffs, R, P, criteria[, dst]) -> dst\n\n#include <opencv2/calib3d.hpp>\nThis is an overloaded member function, provided for convenience. It differs from the above function only in what argument(s) it accepts. NoteDefault version of undistortPoints does 5 iterations to compute undistorted points. \n\n◆ undistortPoints() [2/2]\n\nvoid cv::undistortPoints \n(\nInputArray \nsrc, \n\nOutputArray \ndst, \n\nInputArray \ncameraMatrix, \n\nInputArray \ndistCoeffs, \n\nInputArray \nR = noArray(), \n\nInputArray \nP = noArray() \n\n)\n\nPython:cv.undistortPoints(src, cameraMatrix, distCoeffs[, dst[, R[, P]]]) -> dstcv.undistortPointsIter(src, cameraMatrix, distCoeffs, R, P, criteria[, dst]) -> dst\n\n#include <opencv2/calib3d.hpp>\nComputes the ideal point coordinates from the observed point coordinates. \nThe function is similar to undistort and initUndistortRectifyMap but it operates on a sparse set of points instead of a raster image. Also the function performs a reverse transformation to projectPoints. In case of a 3D object, it does not reconstruct its 3D coordinates, but for a planar object, it does, up to a translation vector, if the proper R is specified.\nFor each observed point coordinate \\((u, v)\\) the function computes:  \n\\[\n\\begin{array}{l}\nx^{\"}  \\leftarrow (u - c_x)/f_x  \\\\\ny^{\"}  \\leftarrow (v - c_y)/f_y  \\\\\n(x',y') = undistort(x^{\"},y^{\"}, \\texttt{distCoeffs}) \\\\\n{[X\\,Y\\,W]} ^T  \\leftarrow R*[x' \\, y' \\, 1]^T  \\\\\nx  \\leftarrow X/W  \\\\\ny  \\leftarrow Y/W  \\\\\n\\text{only performed if P is specified:} \\\\\nu'  \\leftarrow x {f'}_x + {c'}_x  \\\\\nv'  \\leftarrow y {f'}_y + {c'}_y\n\\end{array}\n\\]\n\nwhere undistort is an approximate iterative algorithm that estimates the normalized original point coordinates out of the normalized distorted point coordinates (\"normalized\" means that the coordinates do not depend on the camera matrix).\nThe function can be used for both a stereo camera head or a monocular camera (when R is empty). Parameters\n\nsrcObserved point coordinates, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel (CV_32FC2 or CV_64FC2) (or vector<Point2f> ). \ndstOutput ideal point coordinates (1xN/Nx1 2-channel or vector<Point2f> ) after undistortion and reverse perspective transformation. If matrix P is identity or omitted, dst will contain normalized point coordinates. \ncameraMatrixCamera matrix \\(\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\) . \ndistCoeffsInput vector of distortion coefficients \\((k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\) of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed. \nRRectification transformation in the object space (3x3 matrix). R1 or R2 computed by stereoRectify can be passed here. If the matrix is empty, the identity transformation is used. \nPNew camera matrix (3x3) or new projection matrix (3x4) \\(\\begin{bmatrix} {f'}_x & 0 & {c'}_x & t_x \\\\ 0 & {f'}_y & {c'}_y & t_y \\\\ 0 & 0 & 1 & t_z \\end{bmatrix}\\). P1 or P2 computed by stereoRectify can be passed here. If the matrix is empty, the identity new camera matrix is used. \n\n◆ validateDisparity()\n\nvoid cv::validateDisparity \n(\nInputOutputArray \ndisparity, \n\nInputArray \ncost, \n\nint \nminDisparity, \n\nint \nnumberOfDisparities, \n\nint \ndisp12MaxDisp = 1 \n\n)\n\nPython:cv.validateDisparity(disparity, cost, minDisparity, numberOfDisparities[, disp12MaxDisp]) -> disparity\n\n#include <opencv2/calib3d.hpp>\nvalidates disparity using the left-right check. The matrix \"cost\" should be computed by the stereo correspondence algorithm \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
{"id":null,"metadata":{"source":"https://docs.opencv.org/4.x/d5/d10/tutorial_js_root.html","content_type":"text/html","title":"OpenCV: OpenCV.js Tutorials","language":null},"page_content":"OpenCV: OpenCV.js Tutorials\n\nOpenCV\n    4.10.0-dev\n\nOpen Source Computer Vision\n\nLoading...\nSearching...\nNo Matches\n\nOpenCV.js Tutorials\n\nIntroduction to OpenCV.js\nLearn how to use OpenCV.js inside your web pages!\n\nGUI Features\nHere you will learn how to read and display images and videos, and create trackbar.\n\nCore Operations\nIn this section you will learn some basic operations on image, some mathematical tools and some data structures etc.\n\nImage Processing\nIn this section you will learn different image processing functions inside OpenCV.\n\nVideo Analysis\nIn this section you will learn different techniques to work with videos like object tracking etc.\n\nObject Detection\nIn this section you will object detection techniques like face detection etc.\n\nDeep Neural Networks (dnn module)\nThese tutorials show how to use dnn module in JavaScript \n\nGenerated on Mon Nov 11 2024 23:11:42 for OpenCV by  \n\n 1.9.8","type":"Document"}
